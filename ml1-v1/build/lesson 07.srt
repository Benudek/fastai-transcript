1
00:00:00,089 --> 00:00:05,460
welcome back we're going to be talking

2
00:00:01,700 --> 00:00:07,169
today about random forests we're going

3
00:00:05,459 --> 00:00:12,359
to finish building our own random forest

4
00:00:07,169 --> 00:00:14,939
from scratch but before we do I wanted

5
00:00:12,359 --> 00:00:16,589
to tackle a few things that have come up

6
00:00:14,939 --> 00:00:19,829
during the week a few questions that

7
00:00:16,589 --> 00:00:21,809
I've had and I want to start with kind

8
00:00:19,829 --> 00:00:25,409
of the position of random forests in

9
00:00:21,809 --> 00:00:27,659
general so we spent about half of his

10
00:00:25,410 --> 00:00:29,189
course doing random forests and then

11
00:00:27,660 --> 00:00:32,909
after today the second half of this

12
00:00:29,189 --> 00:00:35,270
course will be neural networks broadly

13
00:00:32,909 --> 00:00:35,269
defined

14
00:00:38,009 --> 00:00:44,579
this is because these these to represent

15
00:00:42,119 --> 00:00:47,908
like the tea the two key classes of

16
00:00:44,579 --> 00:00:50,789
techniques which cover nearly everything

17
00:00:47,908 --> 00:00:51,929
that you're likely to need to do random

18
00:00:50,789 --> 00:00:54,798
forests belong to the class of

19
00:00:51,929 --> 00:00:57,359
techniques of decision tree ensembles

20
00:00:54,798 --> 00:00:58,859
along with gradient boosting machines

21
00:00:57,359 --> 00:01:01,460
being the other key type and some

22
00:00:58,859 --> 00:01:05,489
variants like extremely randomized trees

23
00:01:01,460 --> 00:01:08,219
they have the benefit that they're

24
00:01:05,489 --> 00:01:11,189
highly interpretive all scalable

25
00:01:08,219 --> 00:01:13,739
flexible work well for most kinds of

26
00:01:11,189 --> 00:01:18,118
data they have the downside that they

27
00:01:13,739 --> 00:01:19,799
don't extrapolate at all to like data

28
00:01:18,118 --> 00:01:21,299
that's outside the range that you've

29
00:01:19,799 --> 00:01:27,090
seen as we looked at at the end of last

30
00:01:21,299 --> 00:01:28,709
week's session but you know they're

31
00:01:27,090 --> 00:01:31,100
there they're a great starting point and

32
00:01:28,709 --> 00:01:33,438
so

33
00:01:31,099 --> 00:01:36,890
I think you know there's a huge

34
00:01:33,438 --> 00:01:39,939
catalogue of machine learning tools out

35
00:01:36,890 --> 00:01:42,739
there and I got lot of courses and books

36
00:01:39,939 --> 00:01:44,780
don't attempt to kind of curate that

37
00:01:42,739 --> 00:01:46,129
down and say like for these kinds of

38
00:01:44,780 --> 00:01:48,978
problems use this for these kinds of

39
00:01:46,129 --> 00:01:51,259
problems is that finished you know but

40
00:01:48,978 --> 00:01:54,679
they're rather like here's a description

41
00:01:51,259 --> 00:01:57,109
of 100 different algorithms and you just

42
00:01:54,680 --> 00:01:59,600
don't need them you know like I don't

43
00:01:57,109 --> 00:02:02,030
see why you would ever use in support

44
00:01:59,599 --> 00:02:04,519
vector machine today for instance like

45
00:02:02,030 --> 00:02:05,629
not know no reason at all I could think

46
00:02:04,519 --> 00:02:08,090
of doing that

47
00:02:05,629 --> 00:02:09,978
people love studying them in the 90s

48
00:02:08,090 --> 00:02:12,379
because they are like very theoretically

49
00:02:09,979 --> 00:02:14,239
elegant and like you can really write a

50
00:02:12,379 --> 00:02:15,949
lot of math about support vector

51
00:02:14,239 --> 00:02:18,500
machines and people did but you know in

52
00:02:15,949 --> 00:02:20,799
practice I don't see them as having any

53
00:02:18,500 --> 00:02:20,800
place

54
00:02:23,199 --> 00:02:26,738
there's like a lot of techniques that

55
00:02:24,789 --> 00:02:28,209
you could include in an exhaustive list

56
00:02:26,739 --> 00:02:31,239
of every way that people adopt machine

57
00:02:28,209 --> 00:02:32,860
learning problems but I would rather

58
00:02:31,239 --> 00:02:34,689
tell you like how to actually solve

59
00:02:32,860 --> 00:02:36,910
machine learning problems in practice I

60
00:02:34,689 --> 00:02:38,650
think they you know we've we've about to

61
00:02:36,909 --> 00:02:40,239
finish today the first class which is

62
00:02:38,650 --> 00:02:43,209
you know one type of decision tree

63
00:02:40,239 --> 00:02:45,159
ensembles in in part to you net will

64
00:02:43,209 --> 00:02:47,050
tell you about the other key type there

65
00:02:45,159 --> 00:02:50,079
being gradient boosting and we're about

66
00:02:47,050 --> 00:02:54,700
to launch next lesson into neural nets

67
00:02:50,080 --> 00:02:58,689
which includes all kinds of GLM Ridge

68
00:02:54,699 --> 00:03:01,419
regression elastic net lasso logistic

69
00:02:58,689 --> 00:03:07,409
regression etc or all variants of neural

70
00:03:01,419 --> 00:03:07,409
nets you know interestingly

71
00:03:07,789 --> 00:03:14,349
leo breiman who created random forests

72
00:03:11,150 --> 00:03:17,300
did so very late in his life and

73
00:03:14,349 --> 00:03:21,979
unfortunately passed away not many years

74
00:03:17,300 --> 00:03:23,780
later so partly because of that very

75
00:03:21,979 --> 00:03:26,149
little has been written about them in

76
00:03:23,780 --> 00:03:28,819
the academic literature partly because

77
00:03:26,150 --> 00:03:30,379
SVM's were just taken over at that point

78
00:03:28,819 --> 00:03:35,539
you know other people didn't look at

79
00:03:30,379 --> 00:03:38,120
them and also like just because they're

80
00:03:35,539 --> 00:03:40,009
like quite hard to grasp at a

81
00:03:38,120 --> 00:03:41,659
theoretical level like analyze them

82
00:03:40,009 --> 00:03:43,939
theoretically it's quite hard to write

83
00:03:41,659 --> 00:03:45,620
conference papers about them or academic

84
00:03:43,939 --> 00:03:47,479
papers about them so there hasn't been

85
00:03:45,620 --> 00:03:49,250
that much written about them

86
00:03:47,479 --> 00:03:52,280
but there's been a real resurgence or

87
00:03:49,250 --> 00:03:54,469
not resurgence a new wave in recent

88
00:03:52,280 --> 00:03:56,840
years of empirical machine learning like

89
00:03:54,469 --> 00:03:59,569
what actually works

90
00:03:56,840 --> 00:04:01,120
kegels been part of that but also just

91
00:03:59,569 --> 00:04:03,319
in part of it has just been like

92
00:04:01,120 --> 00:04:05,150
companies using machine learning to make

93
00:04:03,319 --> 00:04:08,299
loads of money like Amazon and

94
00:04:05,150 --> 00:04:11,210
Google and so nowadays a lot of people

95
00:04:08,300 --> 00:04:12,980
are writing about decision tree

96
00:04:11,210 --> 00:04:14,840
ensembles in creating better software

97
00:04:12,979 --> 00:04:19,599
for decision tree ensembles like like

98
00:04:14,840 --> 00:04:23,810
GBM and x3 boost and Ranger 4r and

99
00:04:19,600 --> 00:04:25,550
scikit-learn and so forth but a lot of

100
00:04:23,810 --> 00:04:29,810
this is being done in industry rather

101
00:04:25,550 --> 00:04:33,579
than academia but you know it's it's

102
00:04:29,810 --> 00:04:36,470
encouraging to see there's certainly

103
00:04:33,579 --> 00:04:38,889
more work being done in deep learning

104
00:04:36,470 --> 00:04:42,020
than in decision tree ensembles

105
00:04:38,889 --> 00:04:44,269
particularly in in academia but but

106
00:04:42,019 --> 00:04:48,529
there's a lot of progress being made in

107
00:04:44,269 --> 00:04:50,659
both you know if you look at like of the

108
00:04:48,529 --> 00:04:53,539
packages being used today for decision

109
00:04:50,660 --> 00:04:55,640
tree ensembles like all the best ones

110
00:04:53,540 --> 00:04:57,250
the top five or six I don't know that

111
00:04:55,639 --> 00:05:00,259
any of them really existed

112
00:04:57,250 --> 00:05:02,509
five years ago you know maybe other than

113
00:05:00,259 --> 00:05:06,199
like SK learn or even three years ago so

114
00:05:02,509 --> 00:05:08,689
yet so that's that's been good but I

115
00:05:06,199 --> 00:05:11,800
think there's a lot of work still to be

116
00:05:08,689 --> 00:05:14,000
done we talked about for example

117
00:05:11,800 --> 00:05:17,210
figuring out what interactions are the

118
00:05:14,000 --> 00:05:18,620
most important last week and some of you

119
00:05:17,209 --> 00:05:20,359
pointed out in the forum's that actually

120
00:05:18,620 --> 00:05:22,040
there is such a project already for a

121
00:05:20,360 --> 00:05:23,689
gradient boosting machine

122
00:05:22,040 --> 00:05:24,800
which is great but it doesn't seem that

123
00:05:23,689 --> 00:05:27,079
there's anything like that yet for

124
00:05:24,800 --> 00:05:29,990
random forests and you know random

125
00:05:27,079 --> 00:05:32,689
forests do have a nice benefit over gbms

126
00:05:29,990 --> 00:05:37,460
that they're kind of harder to screw up

127
00:05:32,689 --> 00:05:39,259
you know and easier to scale so

128
00:05:37,459 --> 00:05:43,279
hopefully that's something that you know

129
00:05:39,259 --> 00:05:45,259
this community might help fix another

130
00:05:43,279 --> 00:05:50,359
question I had during the week was about

131
00:05:45,259 --> 00:05:54,980
the size of your validations that how

132
00:05:50,360 --> 00:05:56,180
big should it be so like to answer this

133
00:05:54,980 --> 00:05:59,060
question about how big does your

134
00:05:56,180 --> 00:06:05,030
validation set need to be you first need

135
00:05:59,060 --> 00:06:08,569
to answer the question how how accurate

136
00:06:05,029 --> 00:06:13,269
do I need help recite to know the

137
00:06:08,569 --> 00:06:16,310
accuracy of this algorithm right so like

138
00:06:13,269 --> 00:06:20,120
if the validation set that you have is

139
00:06:16,310 --> 00:06:23,509
saying like this is 70% accurate and if

140
00:06:20,120 --> 00:06:25,250
somebody said well is it 75% or 65% or

141
00:06:23,509 --> 00:06:27,310
70% and the answer was I don't know

142
00:06:25,250 --> 00:06:30,230
anything in that range is close enough

143
00:06:27,310 --> 00:06:33,079
like that would be one answer where else

144
00:06:30,230 --> 00:06:34,910
if it's like is that 70 percent or 70

145
00:06:33,079 --> 00:06:37,310
point oh one percent or sixty nine point

146
00:06:34,910 --> 00:06:38,060
nine nine percent like then that's

147
00:06:37,310 --> 00:06:40,339
something else again

148
00:06:38,060 --> 00:06:42,949
right so you need to kind of start out

149
00:06:40,339 --> 00:06:46,729
by saying like how how accurate do I

150
00:06:42,949 --> 00:06:48,079
need this so like for example in the

151
00:06:46,730 --> 00:06:52,310
deep learning course we've been looking

152
00:06:48,079 --> 00:06:54,229
at dogs versus cats images and the

153
00:06:52,310 --> 00:06:58,009
models that we're looking at had about a

154
00:06:54,230 --> 00:07:00,319
ninety nine point four ninety nine point

155
00:06:58,009 --> 00:07:08,558
five percent accuracy on the validation

156
00:07:00,319 --> 00:07:10,688
set and a validation set size was 2000

157
00:07:08,559 --> 00:07:15,399
okay in fact let's do this in Excel

158
00:07:10,689 --> 00:07:24,809
that'll be a bit easier so our

159
00:07:15,399 --> 00:07:29,939
validation set size was 2000 and was

160
00:07:24,809 --> 00:07:37,539
99.4% right so the number of incorrect

161
00:07:29,939 --> 00:07:41,549
is something around one - accuracy times

162
00:07:37,538 --> 00:07:49,358
and so we were getting about 12 wrong

163
00:07:41,548 --> 00:07:54,338
right and the number of cats we had is

164
00:07:49,358 --> 00:08:02,258
1/2 and so the number of wrong cats is

165
00:07:54,338 --> 00:08:05,889
about 6 ok so then like we we run a new

166
00:08:02,259 --> 00:08:12,549
model and we find instead that the

167
00:08:05,889 --> 00:08:14,889
accuracy has gone to 99.2% right and

168
00:08:12,548 --> 00:08:17,828
then it's like okay is this less good at

169
00:08:14,889 --> 00:08:19,800
finding cats that's like well it got 2

170
00:08:17,829 --> 00:08:24,900
more cats wrong

171
00:08:19,800 --> 00:08:26,430
so it's like probably not right so but

172
00:08:24,899 --> 00:08:28,739
then it's like well does this matter

173
00:08:26,430 --> 00:08:31,769
there's ninety nine point four versus

174
00:08:28,740 --> 00:08:33,750
ninety nine point two matter and if this

175
00:08:31,769 --> 00:08:36,689
was like it wasn't about cats and dogs

176
00:08:33,750 --> 00:08:39,179
but it was about finding fraud right

177
00:08:36,690 --> 00:08:40,500
then the difference between a point six

178
00:08:39,179 --> 00:08:41,879
percent error rate and a point eight

179
00:08:40,500 --> 00:08:43,860
percent error rate is like twenty five

180
00:08:41,879 --> 00:08:48,059
percent of your cost of fraud

181
00:08:43,860 --> 00:08:49,589
so like that can be huge like it's

182
00:08:48,059 --> 00:08:51,239
really interesting like when imagenet

183
00:08:49,589 --> 00:08:53,970
came out earlier this year the new

184
00:08:51,240 --> 00:08:55,950
competition results came out and the

185
00:08:53,970 --> 00:08:58,769
accuracy had gone down from three

186
00:08:55,950 --> 00:09:00,810
percent so the error went down from

187
00:08:58,769 --> 00:09:02,189
three percent to two percent and I saw a

188
00:09:00,809 --> 00:09:03,869
lot of people on the internet like

189
00:09:02,190 --> 00:09:07,380
famous machine learning researchers

190
00:09:03,870 --> 00:09:09,778
being like yeah some Chinese guys got it

191
00:09:07,379 --> 00:09:11,519
better from like 97% to one ninety eight

192
00:09:09,778 --> 00:09:13,588
percent it's like statistically not even

193
00:09:11,519 --> 00:09:17,429
significant who cares kind of a thing

194
00:09:13,589 --> 00:09:20,250
but actually I thought like holy crap

195
00:09:17,429 --> 00:09:21,479
this Chinese team just blew away the

196
00:09:20,250 --> 00:09:23,879
state-of-the-art an image recognition

197
00:09:21,480 --> 00:09:25,980
like the old one was fifty percent less

198
00:09:23,879 --> 00:09:27,600
accurate than the new one like that's

199
00:09:25,980 --> 00:09:29,670
that's actually the right way to think

200
00:09:27,600 --> 00:09:31,620
about it isn't it because it's like you

201
00:09:29,669 --> 00:09:34,979
know we were trying to recognize you

202
00:09:31,620 --> 00:09:38,100
know like which tomatoes were ripe and

203
00:09:34,980 --> 00:09:40,139
which ones weren't and like our new

204
00:09:38,100 --> 00:09:43,769
approach you know the old approach like

205
00:09:40,139 --> 00:09:47,519
fifty percent of the time more was like

206
00:09:43,769 --> 00:09:49,289
letting in the unripe Tomatoes or you

207
00:09:47,519 --> 00:09:51,809
know 50 percent more of the time we were

208
00:09:49,289 --> 00:09:55,528
like accepting fraudulent customers like

209
00:09:51,809 --> 00:09:57,179
that's a really big difference so just

210
00:09:55,528 --> 00:09:59,309
because like this particular validation

211
00:09:57,179 --> 00:10:01,439
set we can't really see six versus eight

212
00:09:59,309 --> 00:10:05,099
doesn't mean the 0.2% different isn't

213
00:10:01,440 --> 00:10:07,260
important it could be so my kind of rule

214
00:10:05,100 --> 00:10:10,709
of thumb is that this like this number

215
00:10:07,259 --> 00:10:12,659
of like how many observations you

216
00:10:10,708 --> 00:10:14,489
actually looking at I want that

217
00:10:12,659 --> 00:10:17,969
generally to be somewhere higher than

218
00:10:14,490 --> 00:10:19,909
twenty-two why 22 because 22 is the

219
00:10:17,970 --> 00:10:22,019
magic number where the t-distribution

220
00:10:19,909 --> 00:10:24,328
roughly turns into the normal

221
00:10:22,019 --> 00:10:27,240
distribution right so as you may have

222
00:10:24,328 --> 00:10:30,299
learned the T distribution is is the

223
00:10:27,240 --> 00:10:32,579
normal distribution for small data sets

224
00:10:30,299 --> 00:10:33,689
right and so in other words once we have

225
00:10:32,578 --> 00:10:36,059
twenty-two of

226
00:10:33,690 --> 00:10:40,680
thing or more it kind of starts to

227
00:10:36,059 --> 00:10:41,939
behave kind of normally in both sense of

228
00:10:40,679 --> 00:10:43,649
the words like it's kind of more stable

229
00:10:41,940 --> 00:10:47,280
and you can kind of understand it better

230
00:10:43,649 --> 00:10:49,289
so that's my magic number when somebody

231
00:10:47,279 --> 00:10:50,789
says do I have enough of something I

232
00:10:49,289 --> 00:10:53,219
kind of start out by saying like do you

233
00:10:50,789 --> 00:10:56,360
have 22 observations of the thing of

234
00:10:53,220 --> 00:10:59,730
interest so if you were looking at like

235
00:10:56,360 --> 00:11:02,310
Lyme cancer you know and you had a data

236
00:10:59,730 --> 00:11:04,560
set that had like a thousand people

237
00:11:02,309 --> 00:11:06,929
without lung cancer and 20 people with

238
00:11:04,559 --> 00:11:08,189
lung cancer I'd be like I very much

239
00:11:06,929 --> 00:11:10,649
doubt we're going to make much progress

240
00:11:08,190 --> 00:11:12,990
you know because we haven't even got 20

241
00:11:10,649 --> 00:11:14,730
of the thing you want so ditto with a

242
00:11:12,990 --> 00:11:16,139
validation set if you don't have twenty

243
00:11:14,730 --> 00:11:18,629
of the thing you want that is very

244
00:11:16,139 --> 00:11:20,730
unlikely to be useful or if like the at

245
00:11:18,629 --> 00:11:22,740
the level of accuracy we need it's not

246
00:11:20,730 --> 00:11:24,440
plus or minus 20 it's just it's that

247
00:11:22,740 --> 00:11:28,259
that's the point where I'm thinking like

248
00:11:24,440 --> 00:11:33,330
be a bit careful so just to be clear you

249
00:11:28,259 --> 00:11:35,669
want 22 to be the number of samples in

250
00:11:33,330 --> 00:11:37,470
each set like in the validation the test

251
00:11:35,669 --> 00:11:40,019
and the Train

252
00:11:37,470 --> 00:11:44,730
so what I'm saying is like if there's if

253
00:11:40,019 --> 00:11:48,240
there's less than 22 of a class in any

254
00:11:44,730 --> 00:11:50,070
of the sets then it's it's going to get

255
00:11:48,240 --> 00:11:53,460
it's getting pretty unstable at that

256
00:11:50,070 --> 00:11:56,310
point right and so like that's just like

257
00:11:53,460 --> 00:11:58,460
the first rule of thumb but then what I

258
00:11:56,309 --> 00:12:00,949
would actually do is like start

259
00:11:58,460 --> 00:12:04,740
practicing what we learned about the

260
00:12:00,950 --> 00:12:11,040
binomial distribution or actually very

261
00:12:04,740 --> 00:12:14,820
weak distribution so what's the what is

262
00:12:11,039 --> 00:12:20,519
the mean of the binomial distribution of

263
00:12:14,820 --> 00:12:23,730
n samples and probability P n times P

264
00:12:20,519 --> 00:12:26,309
okay thank you and times P is that mean

265
00:12:23,730 --> 00:12:29,190
all right so if you've got a 50% chance

266
00:12:26,309 --> 00:12:31,500
of getting ahead and you toss it a

267
00:12:29,190 --> 00:12:34,290
hundred times on average you get 50

268
00:12:31,500 --> 00:12:44,820
heads okay and then what's the standard

269
00:12:34,289 --> 00:12:47,389
deviation and P 1 minus B okay so these

270
00:12:44,820 --> 00:12:48,560
are like two numbers

271
00:12:47,389 --> 00:12:50,088
the first number you don't have to

272
00:12:48,559 --> 00:12:52,509
remember it's intuitively obvious the

273
00:12:50,089 --> 00:12:55,250
second one is one that try to remember

274
00:12:52,509 --> 00:12:57,200
forevermore because not only does it

275
00:12:55,250 --> 00:12:59,419
come up all the time the people that you

276
00:12:57,200 --> 00:13:00,829
work with we'll all have forgotten it so

277
00:12:59,419 --> 00:13:02,750
you'll be like the one person in the

278
00:13:00,828 --> 00:13:04,219
conversation who could immediately go we

279
00:13:02,750 --> 00:13:05,149
don't have to run this 100 times I can

280
00:13:04,220 --> 00:13:08,720
tell you straight away

281
00:13:05,149 --> 00:13:12,759
it's binomial it's going to be NP q NP 1

282
00:13:08,720 --> 00:13:16,759
minus B then there's the standard error

283
00:13:12,759 --> 00:13:21,620
the standard error is if you run a bunch

284
00:13:16,759 --> 00:13:25,149
of trials each time getting a mean what

285
00:13:21,620 --> 00:13:27,169
is the standard deviation of the mean I

286
00:13:25,149 --> 00:13:29,720
don't think you guys are covered this

287
00:13:27,169 --> 00:13:32,120
yet is that right No

288
00:13:29,720 --> 00:13:35,740
so this is really important because this

289
00:13:32,120 --> 00:13:38,810
means like if you train a hundred models

290
00:13:35,740 --> 00:13:40,909
right each time the validation set

291
00:13:38,809 --> 00:13:43,399
accuracy is like the meaning of a

292
00:13:40,909 --> 00:13:45,409
distribution and so therefore the

293
00:13:43,399 --> 00:13:48,259
standard deviation of that validation

294
00:13:45,409 --> 00:13:50,509
set accuracy it can be calculated with

295
00:13:48,259 --> 00:13:54,708
the standard error and this is equal to

296
00:13:50,509 --> 00:14:01,278
the standard deviation divided by square

297
00:13:54,708 --> 00:14:02,989
root n all right so this tells you so

298
00:14:01,278 --> 00:14:05,389
like one approach to figuring out like

299
00:14:02,990 --> 00:14:08,120
is my validation set big enough is train

300
00:14:05,389 --> 00:14:10,429
your model five times with exactly the

301
00:14:08,120 --> 00:14:13,070
same hyper parameters each time and look

302
00:14:10,429 --> 00:14:15,649
at the validation set accuracy each time

303
00:14:13,070 --> 00:14:17,329
and give you know there's like a mean

304
00:14:15,649 --> 00:14:18,649
and a standard deviation of five numbers

305
00:14:17,328 --> 00:14:21,679
you could use or a maximum and a minimum

306
00:14:18,649 --> 00:14:23,839
you can choose but to save yourself some

307
00:14:21,679 --> 00:14:29,689
time you can figure out straight away

308
00:14:23,839 --> 00:14:33,709
that like okay well I I have a point

309
00:14:29,690 --> 00:14:35,690
nine nine accuracy as to you know

310
00:14:33,708 --> 00:14:36,349
whether I get the cat correct or not

311
00:14:35,690 --> 00:14:39,050
correct

312
00:14:36,350 --> 00:14:44,810
so therefore the standard deviation is

313
00:14:39,049 --> 00:14:50,778
equal to 0.99 times 0.01 okay and then I

314
00:14:44,809 --> 00:14:52,909
can get the standard error of that right

315
00:14:50,778 --> 00:14:54,458
so so basically the size of the

316
00:14:52,909 --> 00:14:58,818
validation set you need

317
00:14:54,458 --> 00:15:01,109
it's like however big it has to be such

318
00:14:58,818 --> 00:15:03,708
that your insights about

319
00:15:01,110 --> 00:15:06,659
accuracy good enough for your particular

320
00:15:03,708 --> 00:15:09,028
business problem and so like I say like

321
00:15:06,659 --> 00:15:10,679
the simple way to do it is to pick a

322
00:15:09,028 --> 00:15:14,189
validation set of like a size of

323
00:15:10,679 --> 00:15:16,078
thousand trained five models and see how

324
00:15:14,190 --> 00:15:17,579
much the validation set accuracy varies

325
00:15:16,078 --> 00:15:20,009
and if it's like if they're if it's

326
00:15:17,578 --> 00:15:23,069
they're all close enough for what you

327
00:15:20,009 --> 00:15:25,950
need then you're fine if it's not maybe

328
00:15:23,070 --> 00:15:29,329
you should make it bigger or maybe you

329
00:15:25,950 --> 00:15:34,470
should consider using cross-validation

330
00:15:29,328 --> 00:15:36,929
instead okay so like as you can see it

331
00:15:34,470 --> 00:15:40,740
really depends on what it is you're

332
00:15:36,929 --> 00:15:42,689
trying to do how common you're less

333
00:15:40,740 --> 00:15:44,129
common class is and how accurate your

334
00:15:42,690 --> 00:15:48,660
model is could you pass that back to

335
00:15:44,129 --> 00:15:50,370
Melissa please thank you I have a

336
00:15:48,659 --> 00:15:53,610
question about the less common classes

337
00:15:50,370 --> 00:15:57,328
if you have less than 22 let's say you

338
00:15:53,610 --> 00:15:58,700
have one sample of something let's say

339
00:15:57,328 --> 00:16:01,049
it's a face and I only have one

340
00:15:58,700 --> 00:16:04,290
representation from that particular

341
00:16:01,049 --> 00:16:06,809
country do I toss that into the training

342
00:16:04,289 --> 00:16:11,240
set and it adds variety to I pull it out

343
00:16:06,809 --> 00:16:15,208
completely out of the data set or do I

344
00:16:11,240 --> 00:16:17,669
put it in a test set instead of the

345
00:16:15,208 --> 00:16:19,198
validation set so he certainly couldn't

346
00:16:17,669 --> 00:16:21,360
put it in the test of the validation set

347
00:16:19,198 --> 00:16:22,889
because you're asking kind of I mean in

348
00:16:21,360 --> 00:16:24,120
general because you're asking can I

349
00:16:22,889 --> 00:16:27,720
recognize something I've never seen

350
00:16:24,120 --> 00:16:29,159
before but actually this this question

351
00:16:27,720 --> 00:16:30,570
of like can I recognize something I've

352
00:16:29,159 --> 00:16:32,909
not seen before there's actually a whole

353
00:16:30,570 --> 00:16:34,709
class of models specifically for that

354
00:16:32,909 --> 00:16:36,328
purpose it's called either one-shot

355
00:16:34,708 --> 00:16:37,500
learning which is you get to see

356
00:16:36,328 --> 00:16:40,139
something once and you have to recognize

357
00:16:37,500 --> 00:16:41,220
it again or zero shot learning which is

358
00:16:40,139 --> 00:16:42,750
where you have to recognize something

359
00:16:41,220 --> 00:16:47,699
you've never seen before we're not going

360
00:16:42,750 --> 00:16:50,129
to cover them in this course but they

361
00:16:47,698 --> 00:16:52,919
can be useful for things like face

362
00:16:50,129 --> 00:16:55,289
recognition you know like is this the

363
00:16:52,919 --> 00:16:57,120
same person I've seen before and so

364
00:16:55,289 --> 00:16:58,889
generally speaking obviously for

365
00:16:57,120 --> 00:17:00,570
something like that to work it's not

366
00:16:58,889 --> 00:17:03,088
that you've never seen a face before

367
00:17:00,570 --> 00:17:04,709
it's that you've never seen Melissa's

368
00:17:03,089 --> 00:17:06,390
face before you know and so you see

369
00:17:04,709 --> 00:17:09,380
Melissa's face once and you have to

370
00:17:06,390 --> 00:17:09,380
recognize it again

371
00:17:10,190 --> 00:17:14,480
yeah so in general you know your

372
00:17:11,359 --> 00:17:19,729
validation set and test set need to have

373
00:17:14,480 --> 00:17:21,920
the same mix or frequency observations

374
00:17:19,730 --> 00:17:24,740
that you're going to see in production

375
00:17:21,920 --> 00:17:29,990
in the real world and then your training

376
00:17:24,740 --> 00:17:33,950
set should have an equal number in each

377
00:17:29,990 --> 00:17:38,269
class and if you don't just replicate

378
00:17:33,950 --> 00:17:39,289
the less common one until it is equal so

379
00:17:38,269 --> 00:17:40,819
this is I think we've mentioned this

380
00:17:39,289 --> 00:17:42,440
paper before a very recent paper that

381
00:17:40,819 --> 00:17:44,149
came out they tried lots of different

382
00:17:42,440 --> 00:17:46,570
approaches to training with unbalanced

383
00:17:44,150 --> 00:17:49,040
datasets and found consistently that

384
00:17:46,569 --> 00:17:51,649
over sampling the less common class

385
00:17:49,039 --> 00:17:54,139
until that is the same size as the more

386
00:17:51,650 --> 00:17:58,970
common class is always the right thing

387
00:17:54,140 --> 00:18:00,590
to do so you could literally copy you

388
00:17:58,970 --> 00:18:02,180
know so like I've only got a thousand

389
00:18:00,589 --> 00:18:04,220
you know ten examples of people with

390
00:18:02,180 --> 00:18:07,460
cancer and 100 without so I could just

391
00:18:04,220 --> 00:18:11,480
copy those 10 and other you know 90

392
00:18:07,460 --> 00:18:14,269
times that's kind of a little memory and

393
00:18:11,480 --> 00:18:16,400
efficient so a lot of things including I

394
00:18:14,269 --> 00:18:18,529
think SK learns random forests have a

395
00:18:16,400 --> 00:18:20,810
class weights parameter that says each

396
00:18:18,529 --> 00:18:23,180
time your boot strapping or resampling I

397
00:18:20,809 --> 00:18:26,389
want you to sample the less common class

398
00:18:23,180 --> 00:18:28,100
with a higher probability or did or if

399
00:18:26,390 --> 00:18:29,870
you do and doing deep learning you know

400
00:18:28,099 --> 00:18:32,240
make sure in your mini batch it's not

401
00:18:29,869 --> 00:18:34,549
randomly sampled but it's a stratified

402
00:18:32,240 --> 00:18:40,640
sample so the less common class is

403
00:18:34,549 --> 00:18:43,879
picked more often okay okay so let's get

404
00:18:40,640 --> 00:18:45,980
back to finishing off our random forests

405
00:18:43,880 --> 00:18:47,570
and so what we're going to do today is

406
00:18:45,980 --> 00:18:49,250
we're going to finish off writing our

407
00:18:47,569 --> 00:18:51,679
random forests and then after day you're

408
00:18:49,250 --> 00:18:56,660
after today your homework will be to

409
00:18:51,680 --> 00:18:58,130
take this class and to add to it all of

410
00:18:56,660 --> 00:19:00,680
the random forest interpretation

411
00:18:58,130 --> 00:19:02,750
algorithms that we've learned ok so

412
00:19:00,680 --> 00:19:04,549
obviously to be able to do that you're

413
00:19:02,750 --> 00:19:07,700
going to need to totally understand how

414
00:19:04,549 --> 00:19:08,629
this class works so please you know ask

415
00:19:07,700 --> 00:19:12,380
lots of questions

416
00:19:08,630 --> 00:19:14,950
as necessary as we go along so just to

417
00:19:12,380 --> 00:19:14,950
remind you

418
00:19:16,420 --> 00:19:22,130
we're doing the the bulldozers tackle

419
00:19:19,549 --> 00:19:24,409
competition data set again we split it

420
00:19:22,130 --> 00:19:28,520
as before into 12,000 validation the

421
00:19:24,410 --> 00:19:30,890
last 12,000 records and then just to

422
00:19:28,519 --> 00:19:31,879
make it easier for us to keep track of

423
00:19:30,890 --> 00:19:34,280
what we're doing we're going to just

424
00:19:31,880 --> 00:19:36,980
pick two columns out to start with year

425
00:19:34,279 --> 00:19:39,889
made and Machine hours on the meter okay

426
00:19:36,980 --> 00:19:42,200
and so what we did last time was we

427
00:19:39,890 --> 00:19:45,320
started out by creating a tree ensemble

428
00:19:42,200 --> 00:19:48,140
and the tree ensemble had a bunch of

429
00:19:45,319 --> 00:19:52,399
trees which was literally a list of

430
00:19:48,140 --> 00:19:57,050
entries trees where each time we just

431
00:19:52,400 --> 00:20:02,390
called create tree and create tree

432
00:19:57,049 --> 00:20:06,230
contained a sample size number of random

433
00:20:02,390 --> 00:20:07,509
indexes okay this one is drawn without

434
00:20:06,230 --> 00:20:11,660
replacement

435
00:20:07,509 --> 00:20:13,910
so remember bootstrapping means sampling

436
00:20:11,660 --> 00:20:17,420
with replacement so normally with

437
00:20:13,910 --> 00:20:21,200
scikit-learn if you've got n rows we

438
00:20:17,420 --> 00:20:23,240
grab n rows with replacement which means

439
00:20:21,200 --> 00:20:26,090
many of them will appear more than once

440
00:20:23,240 --> 00:20:28,940
so each time we get a different sample

441
00:20:26,089 --> 00:20:31,189
but it's always the same size as the

442
00:20:28,940 --> 00:20:34,549
original data set and then we have our

443
00:20:31,190 --> 00:20:38,390
set our F samples a function that we can

444
00:20:34,549 --> 00:20:41,779
use which does with replacement sampling

445
00:20:38,390 --> 00:20:44,150
of less than n rows this is doing

446
00:20:41,779 --> 00:20:47,480
something again which is its sampling

447
00:20:44,150 --> 00:20:50,330
without replacement sample size rows

448
00:20:47,480 --> 00:20:53,509
okay because we're permuting the numbers

449
00:20:50,329 --> 00:20:55,429
from naught to self dot y -1 and then

450
00:20:53,509 --> 00:20:57,440
grabbing the first self dot sample size

451
00:20:55,430 --> 00:21:00,289
of them actually there's a faster way to

452
00:20:57,440 --> 00:21:02,930
do this you can just use NPR and embrace

453
00:21:00,289 --> 00:21:05,599
which is a slightly more direct way but

454
00:21:02,930 --> 00:21:08,570
this way it works as well alright so

455
00:21:05,599 --> 00:21:13,669
this is our random sample for this one

456
00:21:08,569 --> 00:21:15,919
of our entries trees add so then we're

457
00:21:13,670 --> 00:21:18,680
going to create a decision tree and our

458
00:21:15,920 --> 00:21:21,529
decision tree we don't pass it all of X

459
00:21:18,680 --> 00:21:25,250
we pass it these specific indexes and

460
00:21:21,529 --> 00:21:27,470
remember X is a panda's data frame so if

461
00:21:25,250 --> 00:21:28,549
we want to index into it with a bunch of

462
00:21:27,470 --> 00:21:32,750
integers we

463
00:21:28,549 --> 00:21:35,210
to use iLok integer locations and that

464
00:21:32,750 --> 00:21:40,880
makes it behave indexing wise just like

465
00:21:35,210 --> 00:21:43,250
numpy now why vector is numpy so we can

466
00:21:40,880 --> 00:21:44,750
just index into it directly and then

467
00:21:43,250 --> 00:21:49,369
we're going to keep track about minimum

468
00:21:44,750 --> 00:21:50,869
of each size and so then the only other

469
00:21:49,369 --> 00:21:52,849
thing we really need an ensemble is

470
00:21:50,869 --> 00:21:55,219
somewhere to make a prediction and so we

471
00:21:52,849 --> 00:21:59,959
were just going to do the mean of the

472
00:21:55,220 --> 00:22:02,750
tree prediction for each tree all right

473
00:21:59,960 --> 00:22:05,630
so that was that and so then in order to

474
00:22:02,750 --> 00:22:08,000
be able to run that we need a decision

475
00:22:05,630 --> 00:22:13,610
tree class because it's being called

476
00:22:08,000 --> 00:22:18,680
here and so there we go okay so that's

477
00:22:13,609 --> 00:22:21,979
the starting point so the next thing we

478
00:22:18,680 --> 00:22:23,509
need to do is to flesh out our decision

479
00:22:21,980 --> 00:22:27,380
tree so the important thing to remember

480
00:22:23,509 --> 00:22:30,559
is all of our randomness happened back

481
00:22:27,380 --> 00:22:33,200
here in the tree ensemble the decision

482
00:22:30,559 --> 00:22:37,819
tree class we're going to create doesn't

483
00:22:33,200 --> 00:22:40,610
have randomness in it okay so all right

484
00:22:37,819 --> 00:22:42,319
now we are building a random B regressor

485
00:22:40,609 --> 00:22:46,669
right so that's why we're taking the

486
00:22:42,319 --> 00:22:48,980
mean of the tree the outputs if we were

487
00:22:46,670 --> 00:22:51,590
to work with classification do we take

488
00:22:48,980 --> 00:22:54,289
the max like the classifier will give

489
00:22:51,589 --> 00:22:57,199
you either zeros or ones no I would

490
00:22:54,289 --> 00:23:00,619
still take the mean so the so each tree

491
00:22:57,200 --> 00:23:03,920
is going to tell you what percentage of

492
00:23:00,619 --> 00:23:06,529
that leaf node contains cats and what

493
00:23:03,920 --> 00:23:07,940
percentage to take contains dogs so then

494
00:23:06,529 --> 00:23:10,190
I would average all those percentages

495
00:23:07,940 --> 00:23:16,090
and say across the trees on average

496
00:23:10,190 --> 00:23:21,500
there is 19% cats and 81 percent dogs

497
00:23:16,089 --> 00:23:25,039
good question so you know random tree

498
00:23:21,500 --> 00:23:26,720
classifiers are almost identical or can

499
00:23:25,039 --> 00:23:30,319
be almost identical the random tree

500
00:23:26,720 --> 00:23:32,210
regresses the technique we're going to

501
00:23:30,319 --> 00:23:34,879
use to build this today will basically

502
00:23:32,210 --> 00:23:36,620
exactly work for a classification it's

503
00:23:34,880 --> 00:23:38,720
certainly for binary classification you

504
00:23:36,619 --> 00:23:40,609
can do with exactly the same code for

505
00:23:38,720 --> 00:23:43,400
multi-class classification you just need

506
00:23:40,609 --> 00:23:45,019
to change your data structure but so

507
00:23:43,400 --> 00:23:49,610
that like you have like a one hot

508
00:23:45,019 --> 00:23:51,289
encoded matrix or a list of integers

509
00:23:49,609 --> 00:23:59,539
that you treat as a one hot encoded

510
00:23:51,289 --> 00:24:01,369
matrix okay so our decision tree so

511
00:23:59,539 --> 00:24:03,799
remember our idea here is that we're

512
00:24:01,369 --> 00:24:06,709
going to like try to avoid thinking so

513
00:24:03,799 --> 00:24:08,869
we're going to basically write it as if

514
00:24:06,710 --> 00:24:11,990
everything we need already exists okay

515
00:24:08,869 --> 00:24:13,759
so we know from when we created the

516
00:24:11,990 --> 00:24:17,299
decision tree we're kind of pass in the

517
00:24:13,759 --> 00:24:18,920
X the Y and the minimum leaf size so

518
00:24:17,299 --> 00:24:21,680
here we need to make sure we've got the

519
00:24:18,920 --> 00:24:24,019
X and the y and the minimum left sides

520
00:24:21,680 --> 00:24:28,400
okay so then there's one other thing

521
00:24:24,019 --> 00:24:30,440
which is as we split our tree into sub

522
00:24:28,400 --> 00:24:34,430
trees we're going to need to keep track

523
00:24:30,440 --> 00:24:36,170
of which of the row indexes went into

524
00:24:34,430 --> 00:24:37,549
the left-hand side of the tree which

525
00:24:36,170 --> 00:24:37,970
went into the right-hand side of the

526
00:24:37,549 --> 00:24:39,619
tree

527
00:24:37,970 --> 00:24:44,690
okay so we're going to have this thing

528
00:24:39,619 --> 00:24:46,099
called indexes as well right so at first

529
00:24:44,690 --> 00:24:47,930
we just didn't bother passing and

530
00:24:46,099 --> 00:24:50,209
indexes at all so if indexes is not

531
00:24:47,930 --> 00:24:53,539
passed in if it's none then we're just

532
00:24:50,210 --> 00:24:56,779
going to set it to everything the entire

533
00:24:53,539 --> 00:24:59,629
length of Y right so NP dot a range is

534
00:24:56,779 --> 00:25:02,690
the same as just range in Python but it

535
00:24:59,630 --> 00:25:06,260
returns an umpire rate right so that the

536
00:25:02,690 --> 00:25:08,210
root of a decision tree contains all the

537
00:25:06,259 --> 00:25:10,970
roads that's the definition really of

538
00:25:08,210 --> 00:25:13,910
the root of a decision tree so all the

539
00:25:10,970 --> 00:25:18,250
rows is Rho naught Rho 1 Rho 2 etc up to

540
00:25:13,910 --> 00:25:20,290
row y -1 okay

541
00:25:18,250 --> 00:25:22,539
is going to store away all that

542
00:25:20,289 --> 00:25:25,059
information that we were given we're

543
00:25:22,539 --> 00:25:27,039
going to keep track of how many rows are

544
00:25:25,059 --> 00:25:28,139
there and how many columns are there

545
00:25:27,039 --> 00:25:33,909
okay

546
00:25:28,140 --> 00:25:37,420
so then the every leaf and every node in

547
00:25:33,910 --> 00:25:39,400
a tree has a value it has a prediction

548
00:25:37,420 --> 00:25:43,810
that prediction is just equal to the

549
00:25:39,400 --> 00:25:49,720
average of the dependent variable okay

550
00:25:43,809 --> 00:25:53,049
so every node in the tree Y indexed with

551
00:25:49,720 --> 00:25:54,370
the indexes is the values of the

552
00:25:53,049 --> 00:25:57,250
dependent variable that are in this

553
00:25:54,369 --> 00:26:04,089
branch of the tree and so here is the

554
00:25:57,250 --> 00:26:07,329
main some nodes in a tree also have a

555
00:26:04,089 --> 00:26:11,259
score which is like how effective was

556
00:26:07,329 --> 00:26:13,059
the split here right but that's only

557
00:26:11,259 --> 00:26:15,549
going to be true if it's not a leaf node

558
00:26:13,059 --> 00:26:18,159
right a leaf node has no further splits

559
00:26:15,549 --> 00:26:20,889
and at this point when we create a tree

560
00:26:18,160 --> 00:26:23,710
we haven't done any splits yet so it's

561
00:26:20,890 --> 00:26:27,430
score starts out as being infinity okay

562
00:26:23,710 --> 00:26:30,400
so having built that the root of the

563
00:26:27,430 --> 00:26:33,120
tree our next job is to find out which

564
00:26:30,400 --> 00:26:35,560
variable should we split on and what

565
00:26:33,119 --> 00:26:37,539
level of that variable should we split

566
00:26:35,559 --> 00:26:41,429
on so let's pretend that there's

567
00:26:37,539 --> 00:26:44,349
something that does them find bass bit

568
00:26:41,430 --> 00:26:52,080
so then we're done okay

569
00:26:44,349 --> 00:26:55,339
so how do we find a variable to split on

570
00:26:52,079 --> 00:26:58,349
so well we could just go through each

571
00:26:55,339 --> 00:27:00,720
potential variable so C contains the

572
00:26:58,349 --> 00:27:03,449
number of columns we have so go through

573
00:27:00,720 --> 00:27:07,220
each one and see if we can find a better

574
00:27:03,450 --> 00:27:14,220
split than we have so far on that column

575
00:27:07,220 --> 00:27:16,350
okay now notice this is like not the

576
00:27:14,220 --> 00:27:19,230
full random forest definition this is

577
00:27:16,349 --> 00:27:21,149
assuming that max features they're set

578
00:27:19,230 --> 00:27:23,849
to all right remember we could set max

579
00:27:21,150 --> 00:27:25,200
features too like 0.5 in which case we

580
00:27:23,849 --> 00:27:27,990
wouldn't check all the numbers should

581
00:27:25,200 --> 00:27:29,789
not to see we would check half the

582
00:27:27,990 --> 00:27:32,670
numbers at random from not to see so if

583
00:27:29,789 --> 00:27:35,700
you want to turn this into like a random

584
00:27:32,670 --> 00:27:38,130
forest that has the max features support

585
00:27:35,700 --> 00:27:40,950
we could easily like add one line of

586
00:27:38,130 --> 00:27:45,780
code to do that but we're not going to

587
00:27:40,950 --> 00:27:47,220
do it in our implementation today so

588
00:27:45,779 --> 00:27:49,019
then we just need to find better split

589
00:27:47,220 --> 00:27:50,370
and since we're not interested in

590
00:27:49,019 --> 00:27:52,970
thinking at the moment for now we're

591
00:27:50,369 --> 00:27:58,309
just going to leave that empty alright

592
00:27:52,970 --> 00:28:00,660
so there one other thing I like to do

593
00:27:58,309 --> 00:28:02,309
with my kind of word start writing a

594
00:28:00,660 --> 00:28:04,950
class is I'd like to have some way to

595
00:28:02,309 --> 00:28:07,769
print out what's in that class all right

596
00:28:04,950 --> 00:28:09,660
and so if you type print followed by an

597
00:28:07,769 --> 00:28:13,200
object or if it Jupiter notebook you

598
00:28:09,660 --> 00:28:15,990
just type the name of the object at the

599
00:28:13,200 --> 00:28:17,519
moment it's just printing out underscore

600
00:28:15,990 --> 00:28:19,470
underscore main underscore underscore

601
00:28:17,519 --> 00:28:22,049
got decision tree at blah blah blah

602
00:28:19,470 --> 00:28:23,490
which is not very helpful right so if we

603
00:28:22,049 --> 00:28:26,779
want to replace this with something

604
00:28:23,490 --> 00:28:31,529
helpful we have to define the special

605
00:28:26,779 --> 00:28:34,079
Python method named dan direct crack to

606
00:28:31,529 --> 00:28:36,980
get a representation of this object so

607
00:28:34,079 --> 00:28:39,419
when we type when we see please just

608
00:28:36,980 --> 00:28:41,579
write the name like this behind the

609
00:28:39,420 --> 00:28:44,279
scenes that calls that function and the

610
00:28:41,579 --> 00:28:47,699
default implementation of that method is

611
00:28:44,279 --> 00:28:50,309
just to print out this unhelpful stuff

612
00:28:47,700 --> 00:28:53,670
so we can replace it by instead saying

613
00:28:50,309 --> 00:28:56,250
let's create a format string where we're

614
00:28:53,670 --> 00:28:58,650
going to print out N and then show N and

615
00:28:56,250 --> 00:29:01,589
then print vowel and then show Val okay

616
00:28:58,650 --> 00:29:04,769
so how many how many rows are in this

617
00:29:01,589 --> 00:29:05,579
node and what's the average of the

618
00:29:04,769 --> 00:29:10,769
dependent variable

619
00:29:05,579 --> 00:29:12,899
okay then if it's not a leaf node so if

620
00:29:10,769 --> 00:29:16,139
it has a split then we should also be

621
00:29:12,900 --> 00:29:18,690
able to print out the score the value we

622
00:29:16,140 --> 00:29:23,400
split out and the variable that we split

623
00:29:18,690 --> 00:29:26,700
on now you'll notice here self dot is

624
00:29:23,400 --> 00:29:28,259
leaf is leaf is defined as a method but

625
00:29:26,700 --> 00:29:31,500
I don't have any parentheses after it

626
00:29:28,259 --> 00:29:34,019
this is a special kind of method code of

627
00:29:31,500 --> 00:29:36,690
property and so a property is something

628
00:29:34,019 --> 00:29:40,230
that kind of looks like a regular

629
00:29:36,690 --> 00:29:43,500
variable but it's actually calculated on

630
00:29:40,230 --> 00:29:46,740
the fly so when I call is leaf it

631
00:29:43,500 --> 00:29:49,619
actually calls this function right but

632
00:29:46,740 --> 00:29:50,460
I've got this special decorator property

633
00:29:49,619 --> 00:29:52,709
okay

634
00:29:50,460 --> 00:29:53,970
and what this says is basically you

635
00:29:52,710 --> 00:29:58,170
don't have to include the parentheses

636
00:29:53,970 --> 00:30:00,180
when you call it okay and so it's going

637
00:29:58,170 --> 00:30:02,940
to say all right is this a leaf or not

638
00:30:00,180 --> 00:30:05,880
so a leaf is something that we don't

639
00:30:02,940 --> 00:30:08,340
spit on if we haven't split on it then

640
00:30:05,880 --> 00:30:12,600
it's score is still set to infinity so

641
00:30:08,339 --> 00:30:17,819
that's my logic that makes sense

642
00:30:12,599 --> 00:30:19,769
so this uh this at notation is called a

643
00:30:17,819 --> 00:30:22,500
decorator it's basically a way of

644
00:30:19,769 --> 00:30:25,048
telling Python more information about

645
00:30:22,500 --> 00:30:30,138
your method does anybody here remember

646
00:30:25,048 --> 00:30:30,138
where you have seen decorators before

647
00:30:30,720 --> 00:30:34,660
we pass it over you

648
00:30:32,920 --> 00:30:36,279
yeah where have you seen that where have

649
00:30:34,660 --> 00:30:39,120
you seen decorators tell us more about

650
00:30:36,279 --> 00:30:39,119
flask and Wow

651
00:30:39,460 --> 00:30:50,170
yeah what is that - that no words

652
00:30:47,259 --> 00:30:52,299
so flasks so anybody who's done any web

653
00:30:50,170 --> 00:30:55,180
programming before with something like

654
00:30:52,299 --> 00:30:57,129
flask or a similar framework would have

655
00:30:55,180 --> 00:31:00,160
had to have said like this method is

656
00:30:57,130 --> 00:31:02,830
going to respond to this bit of the URL

657
00:31:00,160 --> 00:31:07,650
and either to post or to get and you put

658
00:31:02,829 --> 00:31:10,869
it in a special decorator so

659
00:31:07,650 --> 00:31:13,360
behind-the-scenes that's telling Python

660
00:31:10,869 --> 00:31:16,779
to treat this method in a special way so

661
00:31:13,359 --> 00:31:18,339
here's another decorator okay and so you

662
00:31:16,779 --> 00:31:19,629
know if you get more advanced with

663
00:31:18,339 --> 00:31:21,609
Python you can actually learn how to

664
00:31:19,630 --> 00:31:23,680
write your own decorators which as was

665
00:31:21,609 --> 00:31:25,869
mentioned you know basically insert some

666
00:31:23,680 --> 00:31:28,480
additional code but for now just know

667
00:31:25,869 --> 00:31:31,719
there's a bunch of predefined decorators

668
00:31:28,480 --> 00:31:33,610
we can use to change how our methods

669
00:31:31,720 --> 00:31:35,710
behave and one of them is a property

670
00:31:33,609 --> 00:31:37,449
which basically means you don't have to

671
00:31:35,710 --> 00:31:39,579
put parentheses anymore which of course

672
00:31:37,450 --> 00:31:46,120
means you can't add any more parameters

673
00:31:39,579 --> 00:31:49,899
beyond self.y if it's not belief why is

674
00:31:46,119 --> 00:31:53,619
this for infinity because infinity mean

675
00:31:49,900 --> 00:31:55,180
you're at the root why no infinity means

676
00:31:53,619 --> 00:31:57,609
that you're not at the root it means

677
00:31:55,180 --> 00:32:00,130
you're at a leaf so the root will have a

678
00:31:57,609 --> 00:32:01,809
split assuming we find one but

679
00:32:00,130 --> 00:32:04,030
everything will have a split till we get

680
00:32:01,809 --> 00:32:06,220
all the way to the bottom and leaf and

681
00:32:04,029 --> 00:32:10,180
so the leaves will have a score of

682
00:32:06,220 --> 00:32:16,120
infinity because they won't split great

683
00:32:10,180 --> 00:32:18,160
all right so that's our decision tree it

684
00:32:16,119 --> 00:32:20,949
doesn't do very much but at least we can

685
00:32:18,160 --> 00:32:23,560
like create an ensemble right ten trees

686
00:32:20,950 --> 00:32:25,630
sample size a thousand right and we can

687
00:32:23,559 --> 00:32:26,349
make print out so now when I go M trees

688
00:32:25,630 --> 00:32:28,120
zero

689
00:32:26,349 --> 00:32:31,959
it doesn't say blah blah blah blah blah

690
00:32:28,119 --> 00:32:36,849
it says what we asked it to say n called

691
00:32:31,960 --> 00:32:39,910
the thousand now : 10.8 oh wait okay and

692
00:32:36,849 --> 00:32:41,769
this is the leaf because we haven't spit

693
00:32:39,910 --> 00:32:43,860
on it yet so we've got nothing more to

694
00:32:41,769 --> 00:32:43,859
say

695
00:32:43,869 --> 00:32:50,229
okay so then the indexes are all the

696
00:32:47,769 --> 00:32:51,908
numbers from nought to a thousand okay

697
00:32:50,230 --> 00:32:54,599
because the base of the tree has

698
00:32:51,909 --> 00:32:57,220
everything this is like everything in

699
00:32:54,599 --> 00:32:58,418
the random sample that was passed to it

700
00:32:57,220 --> 00:32:59,788
because remember by the time we get to

701
00:32:58,419 --> 00:33:02,288
the point where it's a decision tree

702
00:32:59,788 --> 00:33:03,759
where we don't have to worry about any

703
00:33:02,288 --> 00:33:11,129
of the randomness in the random forest

704
00:33:03,759 --> 00:33:15,460
anymore okay all right so let's try to

705
00:33:11,130 --> 00:33:19,360
write the thing which finds a split okay

706
00:33:15,460 --> 00:33:22,509
so we need to implement find better

707
00:33:19,359 --> 00:33:25,329
split okay and so it's going to take the

708
00:33:22,509 --> 00:33:27,460
index of a variable variable number one

709
00:33:25,329 --> 00:33:30,579
variable number three whatever and it's

710
00:33:27,460 --> 00:33:33,278
going to figure out what's the best blit

711
00:33:30,579 --> 00:33:35,949
point is that better than any split we

712
00:33:33,278 --> 00:33:37,630
have so far and for the first variable

713
00:33:35,950 --> 00:33:39,580
the answer will always be yes because

714
00:33:37,630 --> 00:33:44,620
the best one so far is none at all which

715
00:33:39,579 --> 00:33:45,519
is infinity bad okay so let's start by

716
00:33:44,619 --> 00:33:46,869
making sure we've got something to

717
00:33:45,519 --> 00:33:49,690
compare to so the thing we're going to

718
00:33:46,869 --> 00:33:52,629
compare two will be scikit-learn x'

719
00:33:49,690 --> 00:33:54,399
random forest and so we need to make

720
00:33:52,630 --> 00:33:56,200
sure that psychic learns random forest

721
00:33:54,398 --> 00:33:58,558
gets exactly the same data that we have

722
00:33:56,200 --> 00:34:01,960
so we start out by creating ensemble

723
00:33:58,558 --> 00:34:04,839
grab a tree out of it and then find out

724
00:34:01,960 --> 00:34:07,840
which particular random sample of x and

725
00:34:04,839 --> 00:34:09,429
y did this tree use okay and we're going

726
00:34:07,839 --> 00:34:11,949
to store them away so that we can pass

727
00:34:09,429 --> 00:34:15,460
them to scikit-learn so we have exactly

728
00:34:11,949 --> 00:34:17,199
the same information so let's go ahead

729
00:34:15,460 --> 00:34:17,889
and now create a random forest using

730
00:34:17,199 --> 00:34:21,098
scikit-learn

731
00:34:17,889 --> 00:34:24,639
so one tree one decision

732
00:34:21,099 --> 00:34:27,609
no bootstrapping so the whole the whole

733
00:34:24,639 --> 00:34:29,108
data set that's oh this should be

734
00:34:27,608 --> 00:34:33,338
exactly the same as the thing that we're

735
00:34:29,108 --> 00:34:38,529
going to create this tree okay so let's

736
00:34:33,338 --> 00:34:42,309
try so we need to define find better

737
00:34:38,530 --> 00:34:47,519
split okay so fine better split takes a

738
00:34:42,309 --> 00:34:49,898
variable okay so let's define our x

739
00:34:47,519 --> 00:34:53,050
independent variables and say okay well

740
00:34:49,898 --> 00:34:55,799
it's everything inside our tree but only

741
00:34:53,050 --> 00:34:58,830
those indexes that are

742
00:34:55,800 --> 00:35:00,750
in this node right which at the top of

743
00:34:58,829 --> 00:35:05,400
the tree is everything all right and

744
00:35:00,750 --> 00:35:08,190
just this one variable okay and then for

745
00:35:05,400 --> 00:35:10,200
our Y's it's just whatever a dependent

746
00:35:08,190 --> 00:35:15,210
variable is at the indexes in this node

747
00:35:10,199 --> 00:35:19,009
okay so there's our X&amp;Y so let's now go

748
00:35:15,210 --> 00:35:23,010
through every single value in our

749
00:35:19,010 --> 00:35:25,080
independent variable and so I'll show

750
00:35:23,010 --> 00:35:28,460
you what's going to happen so let's say

751
00:35:25,079 --> 00:35:28,460
our independent variable is um ade

752
00:35:31,750 --> 00:35:44,829
and not going to be an order right and

753
00:35:42,278 --> 00:35:46,900
so we're going to go to the very first

754
00:35:44,829 --> 00:35:49,990
row and we're going to say okay yeah

755
00:35:46,900 --> 00:35:51,548
mate here is three right and so what I'm

756
00:35:49,989 --> 00:35:55,629
going to do is I'm going to try and

757
00:35:51,548 --> 00:35:58,778
calculate the score if we decided to

758
00:35:55,630 --> 00:36:01,809
branch on the number three alright so I

759
00:35:58,778 --> 00:36:04,509
need to know which rows are greater than

760
00:36:01,809 --> 00:36:06,009
three which rows are less than equal to

761
00:36:04,509 --> 00:36:07,960
three and they're going to become my

762
00:36:06,009 --> 00:36:10,889
left-hand side my right hand side but

763
00:36:07,960 --> 00:36:13,630
and then we need a score right so

764
00:36:10,889 --> 00:36:15,848
there's lots of schools we could use so

765
00:36:13,630 --> 00:36:17,980
in random forests we call this the

766
00:36:15,849 --> 00:36:19,568
information gain right the information

767
00:36:17,980 --> 00:36:21,338
gain is like how much better does our

768
00:36:19,568 --> 00:36:23,679
score get because we split it into these

769
00:36:21,338 --> 00:36:24,909
two groups of data there's lots of ways

770
00:36:23,679 --> 00:36:27,429
we could calculate it Jinni

771
00:36:24,909 --> 00:36:31,778
cross-entropy root mean squared error

772
00:36:27,429 --> 00:36:33,730
whatever if you think about it there is

773
00:36:31,778 --> 00:36:35,739
an alternative formulation of root mean

774
00:36:33,730 --> 00:36:38,858
squared error which is mathematically

775
00:36:35,739 --> 00:36:40,118
the same to within a constant scale but

776
00:36:38,858 --> 00:36:42,848
it's a little bit easier to deal with

777
00:36:40,119 --> 00:36:46,900
which is we're gonna try and find a

778
00:36:42,849 --> 00:36:49,390
split which the causes the two groups to

779
00:36:46,900 --> 00:36:51,940
each have as lower standard deviation as

780
00:36:49,389 --> 00:36:53,558
possible right so like I want to find a

781
00:36:51,940 --> 00:36:55,900
spirit that puts all the cats over here

782
00:36:53,559 --> 00:36:57,789
and all the dogs over here right so if

783
00:36:55,900 --> 00:36:59,858
these are all cats and these are all

784
00:36:57,789 --> 00:37:01,509
dogs then this has a standard deviation

785
00:36:59,858 --> 00:37:03,759
of zero and this has a standard

786
00:37:01,509 --> 00:37:05,920
deviation of zero or else this is like a

787
00:37:03,759 --> 00:37:07,539
total around a mix of cats and dogs this

788
00:37:05,920 --> 00:37:09,039
is a totally random mix of cats and dogs

789
00:37:07,539 --> 00:37:11,180
they're going to have a much higher

790
00:37:09,039 --> 00:37:13,339
standard deviation

791
00:37:11,179 --> 00:37:15,889
make sense and so it turns out if you

792
00:37:13,338 --> 00:37:18,078
find a split that minimizes those group

793
00:37:15,889 --> 00:37:20,118
standard deviations or specifically the

794
00:37:18,079 --> 00:37:22,280
weighted average of the true standard

795
00:37:20,119 --> 00:37:24,289
deviations it's mathematically the same

796
00:37:22,280 --> 00:37:26,210
as minimizing the root mean square error

797
00:37:24,289 --> 00:37:29,420
that's something you can prove to

798
00:37:26,210 --> 00:37:32,568
yourself after class if you want to okay

799
00:37:29,420 --> 00:37:33,769
so we're going to need to find first of

800
00:37:32,568 --> 00:37:36,108
all split this into two groups so

801
00:37:33,769 --> 00:37:38,568
where's all the stuff that is greater

802
00:37:36,108 --> 00:37:40,699
than three so greater than three is this

803
00:37:38,568 --> 00:37:43,818
one this one and this one so we need the

804
00:37:40,699 --> 00:37:46,929
standard deviation of that so let's go

805
00:37:43,818 --> 00:37:51,199
ahead and say standard deviation of

806
00:37:46,929 --> 00:37:56,029
greater than three that one that one and

807
00:37:51,199 --> 00:38:00,828
that one okay and then the next will be

808
00:37:56,030 --> 00:38:03,700
the standard deviation of less than or

809
00:38:00,829 --> 00:38:08,599
equal to three so that would be that one

810
00:38:03,699 --> 00:38:09,949
that one that one and then we just take

811
00:38:08,599 --> 00:38:12,980
the weighted average of those two and

812
00:38:09,949 --> 00:38:17,269
that's our score that would be our score

813
00:38:12,980 --> 00:38:19,159
if we split on three that make sense and

814
00:38:17,269 --> 00:38:22,039
so then the next step would be try to

815
00:38:19,159 --> 00:38:25,789
spit on four try spitting on one try

816
00:38:22,039 --> 00:38:28,670
spitting on six redundantly try

817
00:38:25,789 --> 00:38:30,019
splitting on four again redundantly try

818
00:38:28,670 --> 00:38:33,048
spitting on one again and find out which

819
00:38:30,019 --> 00:38:34,789
one works best so that's our code here

820
00:38:33,048 --> 00:38:38,980
is we're going to go through every row

821
00:38:34,789 --> 00:38:42,558
and so let's say okay left hand side is

822
00:38:38,980 --> 00:38:46,608
any values in X that are less than or

823
00:38:42,559 --> 00:38:49,369
equal to this particular value our right

824
00:38:46,608 --> 00:38:52,630
hand side is every value in X that are

825
00:38:49,369 --> 00:38:52,630
greater than this particular value

826
00:38:57,420 --> 00:39:04,269
okay so what's the data type that's

827
00:39:01,269 --> 00:39:07,230
going to be in LHS and RHS what are they

828
00:39:04,269 --> 00:39:07,230
actually going to contain

829
00:39:09,059 --> 00:39:13,349
they're going to be arrays arrays of

830
00:39:11,139 --> 00:39:16,199
what

831
00:39:13,349 --> 00:39:18,900
rays of erosive audience yeah which we

832
00:39:16,199 --> 00:39:21,989
can treat a zero and one okay so LHS

833
00:39:18,900 --> 00:39:24,000
will be an array of false every time

834
00:39:21,989 --> 00:39:26,159
it's not less than or equal to and true

835
00:39:24,000 --> 00:39:29,789
otherwise and RHS will be a boolean

836
00:39:26,159 --> 00:39:31,679
array of the opposite okay and now we

837
00:39:29,789 --> 00:39:34,349
can't take a standard deviation of an

838
00:39:31,679 --> 00:39:37,559
empty set right so if there's nothing

839
00:39:34,349 --> 00:39:40,679
that's greater than this number then

840
00:39:37,559 --> 00:39:43,799
these will all be false which means the

841
00:39:40,679 --> 00:39:45,989
sum will be zero okay and in that case

842
00:39:43,800 --> 00:39:47,190
let's not go any further with this step

843
00:39:45,989 --> 00:39:49,109
because there's nothing to take the

844
00:39:47,190 --> 00:39:51,900
standard deviation of and it's obviously

845
00:39:49,110 --> 00:39:53,880
not a useful split okay so assuming

846
00:39:51,900 --> 00:39:55,530
we've got this far we can now calculate

847
00:39:53,880 --> 00:39:59,280
the standard deviation of the left-hand

848
00:39:55,530 --> 00:40:02,310
side and of the right-hand side and take

849
00:39:59,280 --> 00:40:05,220
the weighted average or the sums the

850
00:40:02,309 --> 00:40:07,679
same thing to us to a scaler right and

851
00:40:05,219 --> 00:40:09,839
so there's a score and so we can then

852
00:40:07,679 --> 00:40:12,000
check is this better than our best score

853
00:40:09,840 --> 00:40:14,460
so far and our best score so far we

854
00:40:12,000 --> 00:40:16,619
initially initialized it to infinity

855
00:40:14,460 --> 00:40:20,220
right so initially this is this is

856
00:40:16,619 --> 00:40:22,579
better so if it's better let's store

857
00:40:20,219 --> 00:40:22,579
away

858
00:40:23,710 --> 00:40:26,970
well as the information we need which

859
00:40:25,030 --> 00:40:30,790
variable has found this better split

860
00:40:26,969 --> 00:40:35,529
what was the score we found and what was

861
00:40:30,789 --> 00:40:41,409
the value that we spit on okay so there

862
00:40:35,530 --> 00:40:43,540
it is so if we run that and I'm using

863
00:40:41,409 --> 00:40:46,058
time it so what time it does is that

864
00:40:43,539 --> 00:40:48,190
sees how long this command takes to run

865
00:40:46,059 --> 00:40:50,440
and it tries to give you a kind of

866
00:40:48,190 --> 00:40:52,630
statistically valid measure of that so

867
00:40:50,440 --> 00:40:55,838
you can see here it's run run at ten

868
00:40:52,630 --> 00:40:58,329
times to get an average and then it's

869
00:40:55,838 --> 00:41:00,369
done that seven times to get a mean and

870
00:40:58,329 --> 00:41:02,500
standard deviation across runs and so

871
00:41:00,369 --> 00:41:06,579
it's taking me 75 milliseconds plus or

872
00:41:02,500 --> 00:41:11,139
minus ten okay so let's check that this

873
00:41:06,579 --> 00:41:13,990
works find bladder split tree zero so

874
00:41:11,139 --> 00:41:20,348
zero is year made one is machine hours

875
00:41:13,989 --> 00:41:22,509
current meter so I with one we got back

876
00:41:20,349 --> 00:41:24,789
machine hours current meter thirty seven

877
00:41:22,510 --> 00:41:27,520
four four with this score and then we

878
00:41:24,789 --> 00:41:30,219
ran it again with zero that's year made

879
00:41:27,519 --> 00:41:35,519
and we've got a better score 658 and

880
00:41:30,219 --> 00:41:37,989
split 1974 and so 1974 let's compare

881
00:41:35,519 --> 00:41:40,480
yeah that was what this treated as well

882
00:41:37,989 --> 00:41:43,959
okay so we've got we've confirmed that

883
00:41:40,480 --> 00:41:46,389
this method is doing is giving the same

884
00:41:43,960 --> 00:41:48,970
result that as K loans random forests

885
00:41:46,389 --> 00:41:52,808
did okay and you can also see here the

886
00:41:48,969 --> 00:41:54,969
value 10 point oh eight and again

887
00:41:52,809 --> 00:41:56,619
matching here the value ten point oh

888
00:41:54,969 --> 00:41:58,779
eight okay

889
00:41:56,619 --> 00:42:01,000
so we've got something that can find

890
00:41:58,780 --> 00:42:02,570
once bit could you pass that to your net

891
00:42:01,000 --> 00:42:05,300
please

892
00:42:02,570 --> 00:42:11,000
so Jeremy why don't we put a unique on

893
00:42:05,300 --> 00:42:13,190
the eggs there because I'm not trying to

894
00:42:11,000 --> 00:42:16,250
optimize the performance yet but do you

895
00:42:13,190 --> 00:42:17,360
see that no like he is doing more yeah

896
00:42:16,250 --> 00:42:19,579
so it's like and you can see in the

897
00:42:17,360 --> 00:42:24,519
excel I like checked this one twice I

898
00:42:19,579 --> 00:42:29,539
check this four twice unnecessarily yeah

899
00:42:24,519 --> 00:42:32,980
okay so and so you're not already

900
00:42:29,539 --> 00:42:35,659
thinking about performance which is good

901
00:42:32,980 --> 00:42:40,820
so tell me what is the computational

902
00:42:35,659 --> 00:42:43,549
complexity of this section of the code

903
00:42:40,820 --> 00:42:45,230
and and like ever think about it but

904
00:42:43,550 --> 00:42:48,260
also like feel free to talk us through

905
00:42:45,230 --> 00:42:50,510
it if you want to kind of think and talk

906
00:42:48,260 --> 00:42:52,820
at the same time what's the

907
00:42:50,510 --> 00:42:55,120
computational complexity of this piece

908
00:42:52,820 --> 00:42:55,120
of code

909
00:42:57,750 --> 00:43:04,110
can I pass it over there yes all right

910
00:43:02,340 --> 00:43:08,370
Jay take us through your thought process

911
00:43:04,110 --> 00:43:10,800
I think you have to take each different

912
00:43:08,369 --> 00:43:14,849
values through the column to calculate

913
00:43:10,800 --> 00:43:15,960
it once to see those splits so and then

914
00:43:14,849 --> 00:43:18,509
compare

915
00:43:15,960 --> 00:43:20,519
oh the cup like all the possible

916
00:43:18,510 --> 00:43:22,860
combinations between these different

917
00:43:20,519 --> 00:43:23,489
values so that can be expensive like

918
00:43:22,860 --> 00:43:25,920
this yours

919
00:43:23,489 --> 00:43:27,119
huh can you do somebody else would have

920
00:43:25,920 --> 00:43:29,280
tell us the actual computational

921
00:43:27,119 --> 00:43:33,469
complexity so like yeah quite high

922
00:43:29,280 --> 00:43:33,470
Jayde's thinking how high

923
00:43:33,880 --> 00:43:40,269
I think it's great okay so tell me why

924
00:43:37,960 --> 00:43:43,240
is it N squared Oh because for the full

925
00:43:40,269 --> 00:43:45,340
loop it is in yes and I think I guess

926
00:43:43,239 --> 00:43:46,779
the standard deviation well ticket in so

927
00:43:45,340 --> 00:43:49,329
it's in square okay

928
00:43:46,780 --> 00:43:51,820
or um this one maybe is even is yet to

929
00:43:49,329 --> 00:43:53,710
know like this is like which ones are

930
00:43:51,820 --> 00:43:55,269
less than X I I'm gonna have to check

931
00:43:53,710 --> 00:43:59,070
every value to see if it's less than X I

932
00:43:55,269 --> 00:44:01,750
okay and so so it's useful to know like

933
00:43:59,070 --> 00:44:03,730
how do I quickly calculate computational

934
00:44:01,750 --> 00:44:05,349
complexity I can guarantee most of the

935
00:44:03,730 --> 00:44:07,150
interviews you do are going to ask you

936
00:44:05,349 --> 00:44:08,889
to calculate computational complexity on

937
00:44:07,150 --> 00:44:10,900
the fly and it's also like when you're

938
00:44:08,889 --> 00:44:13,929
coding you want it to be second nature

939
00:44:10,900 --> 00:44:16,660
so the technique is basically is there a

940
00:44:13,929 --> 00:44:17,980
loop okay with then we're obviously

941
00:44:16,659 --> 00:44:20,259
doing this end times

942
00:44:17,980 --> 00:44:22,599
okay so there's an N involved it's there

943
00:44:20,260 --> 00:44:23,770
a loop inside the loop if there is then

944
00:44:22,599 --> 00:44:26,380
you need to multiply those two together

945
00:44:23,769 --> 00:44:28,690
in this case there's not is there

946
00:44:26,380 --> 00:44:31,240
anything inside the loop that's not a

947
00:44:28,690 --> 00:44:33,010
constant time thing so you might see a

948
00:44:31,239 --> 00:44:35,469
sort in there and you just need to know

949
00:44:33,010 --> 00:44:37,330
that sort is n log n like that should be

950
00:44:35,469 --> 00:44:39,069
second nature if you see a matrix

951
00:44:37,329 --> 00:44:42,069
multiply you need to know what that is

952
00:44:39,070 --> 00:44:44,470
in this case there are some things that

953
00:44:42,070 --> 00:44:46,420
are doing element wise array operations

954
00:44:44,469 --> 00:44:48,969
right so keep an eye out for anything

955
00:44:46,420 --> 00:44:50,349
where lump I is doing something to every

956
00:44:48,969 --> 00:44:52,959
value of an array in this case is

957
00:44:50,349 --> 00:44:54,639
checking every value of x against a

958
00:44:52,960 --> 00:44:57,730
constant so it's going to have to do

959
00:44:54,639 --> 00:44:59,949
that n times so to flesh this out into a

960
00:44:57,730 --> 00:45:02,289
computational complexity you just take

961
00:44:59,949 --> 00:45:04,779
the number of things in the loop and you

962
00:45:02,289 --> 00:45:07,059
multiply it by the highest computational

963
00:45:04,780 --> 00:45:11,260
complexity inside the loop n times n is

964
00:45:07,059 --> 00:45:13,719
N squared and you pass them in this case

965
00:45:11,260 --> 00:45:15,760
couldn't we just pre sort the list and

966
00:45:13,719 --> 00:45:17,139
then do like 1 + log n computation

967
00:45:15,760 --> 00:45:18,460
there's lots of things we can do to

968
00:45:17,139 --> 00:45:19,690
speed this up so at this stage is just

969
00:45:18,460 --> 00:45:22,449
like what is the computational

970
00:45:19,690 --> 00:45:23,980
complexity we have and but absolutely

971
00:45:22,449 --> 00:45:24,969
it's certainly not as good as it can be

972
00:45:23,980 --> 00:45:26,679
okay

973
00:45:24,969 --> 00:45:29,169
so and that's where we're going to go

974
00:45:26,679 --> 00:45:31,449
next just like alright N squared is not

975
00:45:29,170 --> 00:45:33,599
is not great so let's try and make it

976
00:45:31,449 --> 00:45:33,599
better

977
00:45:34,949 --> 00:45:43,480
so here's my attempt at making it better

978
00:45:38,460 --> 00:45:45,338
and the idea is this ok who wants to

979
00:45:43,480 --> 00:45:48,670
first of all tell me

980
00:45:45,338 --> 00:45:56,588
what's the equation for standard

981
00:45:48,670 --> 00:45:59,289
deviation Masha can you grab the pose so

982
00:45:56,588 --> 00:46:00,909
for the standard deviation it's the

983
00:45:59,289 --> 00:46:04,989
difference between the value and its

984
00:46:00,909 --> 00:46:09,778
mean it's we take a square root of that

985
00:46:04,989 --> 00:46:12,849
so that we take the the power of two

986
00:46:09,778 --> 00:46:15,039
then we sum up all of these situations

987
00:46:12,849 --> 00:46:17,318
and we take the square root out of all

988
00:46:15,039 --> 00:46:19,239
this sum yeah you have to fight divided

989
00:46:17,318 --> 00:46:23,679
by M yep yep great

990
00:46:19,239 --> 00:46:25,929
good okay now in practice we don't

991
00:46:23,679 --> 00:46:28,899
normally use that formulation because it

992
00:46:25,929 --> 00:46:31,778
kind of requires us calculating you know

993
00:46:28,900 --> 00:46:33,548
X minus the mean lots of times does

994
00:46:31,778 --> 00:46:37,690
anybody know the formulation that just

995
00:46:33,548 --> 00:46:38,889
requires X and x squared anybody happen

996
00:46:37,690 --> 00:46:41,010
to know that one yes at the back can I

997
00:46:38,889 --> 00:46:45,920
pass that back there

998
00:46:41,010 --> 00:46:48,570
square root of a mean of squares -

999
00:46:45,920 --> 00:46:50,608
squared off mean yeah great mean of

1000
00:46:48,570 --> 00:46:54,660
squares minus the square of the means

1001
00:46:50,608 --> 00:46:56,309
right so that's a really good 1/8 that's

1002
00:46:54,659 --> 00:47:00,690
a really good one to know because like

1003
00:46:56,309 --> 00:47:02,670
you can now calculate variances or

1004
00:47:00,690 --> 00:47:04,559
standard deviations of anything you just

1005
00:47:02,670 --> 00:47:07,858
have to first of all grab the column as

1006
00:47:04,559 --> 00:47:09,119
it is the column squared right and as

1007
00:47:07,858 --> 00:47:11,699
long as you've got those stored away

1008
00:47:09,119 --> 00:47:14,460
somewhere you can immediately calculate

1009
00:47:11,699 --> 00:47:17,639
the standard deviation so the reason

1010
00:47:14,460 --> 00:47:23,579
this is handy for us is that if we first

1011
00:47:17,639 --> 00:47:26,639
of all sort our data right let's go

1012
00:47:23,579 --> 00:47:28,739
ahead and sort our data then if you

1013
00:47:26,639 --> 00:47:31,710
think about it as we kind of start going

1014
00:47:28,739 --> 00:47:33,809
down one step at a time right then each

1015
00:47:31,710 --> 00:47:36,210
group it's exactly the same as the

1016
00:47:33,809 --> 00:47:38,549
previous group on the left hand side

1017
00:47:36,210 --> 00:47:40,139
with one more thing in it and on the

1018
00:47:38,550 --> 00:47:42,180
right hand side with one less thing in

1019
00:47:40,139 --> 00:47:44,519
it so given that we just have to keep

1020
00:47:42,179 --> 00:47:47,429
track of some of X and some of x squared

1021
00:47:44,519 --> 00:47:49,139
we can just add one more thing to X one

1022
00:47:47,429 --> 00:47:52,319
more thing - x squared on the left and

1023
00:47:49,139 --> 00:47:54,269
remove one thing on the right okay so we

1024
00:47:52,320 --> 00:47:57,390
don't have to go through the whole lot

1025
00:47:54,269 --> 00:48:01,079
each time and so we can turn this into a

1026
00:47:57,389 --> 00:48:03,389
order n algorithm so that's all I do

1027
00:48:01,079 --> 00:48:04,949
here is I sort the data right and

1028
00:48:03,389 --> 00:48:07,769
they're going to keep track of the count

1029
00:48:04,949 --> 00:48:09,750
of things on the right the sum of things

1030
00:48:07,769 --> 00:48:12,960
on the right and the sum of squares on

1031
00:48:09,750 --> 00:48:13,760
the right and initially everything's on

1032
00:48:12,960 --> 00:48:18,269
the right hand side

1033
00:48:13,760 --> 00:48:21,690
okay so initially n is the count Y sum

1034
00:48:18,269 --> 00:48:23,460
is the sum on the right and Y squared

1035
00:48:21,690 --> 00:48:25,858
sum is the sum of squares on the right

1036
00:48:23,460 --> 00:48:29,159
and then nothing is initially on the

1037
00:48:25,858 --> 00:48:32,599
left so it's zeros okay and then we just

1038
00:48:29,159 --> 00:48:35,868
have to loop through each observation

1039
00:48:32,599 --> 00:48:35,868
right and

1040
00:48:35,980 --> 00:48:40,449
add one to the left hand count subtract

1041
00:48:38,289 --> 00:48:42,009
one from the left right hand count add

1042
00:48:40,449 --> 00:48:43,449
the value to the left hand count

1043
00:48:42,010 --> 00:48:46,060
subtract it from the right hand count

1044
00:48:43,449 --> 00:48:50,519
add the value squared to the left hand

1045
00:48:46,059 --> 00:48:52,809
subtract it from the right hand okay now

1046
00:48:50,519 --> 00:48:55,480
we do need to be careful though because

1047
00:48:52,809 --> 00:48:58,299
if we're saying less than or equal to

1048
00:48:55,480 --> 00:48:59,740
one say we're not stopping here we're

1049
00:48:58,300 --> 00:49:01,960
stopping here like we have to have

1050
00:48:59,739 --> 00:49:02,889
everything in that group so the other

1051
00:49:01,960 --> 00:49:06,039
thing I'm going to do is I'm just going

1052
00:49:02,889 --> 00:49:08,289
to make sure that the next value is not

1053
00:49:06,039 --> 00:49:09,400
the same as this value if it is I'm

1054
00:49:08,289 --> 00:49:10,690
going to skip over it

1055
00:49:09,400 --> 00:49:13,840
right so I'm just going to double check

1056
00:49:10,690 --> 00:49:17,800
that this value and the next one aren't

1057
00:49:13,840 --> 00:49:20,108
the same okay so as long as they're not

1058
00:49:17,800 --> 00:49:21,730
the same I can keep going ahead and

1059
00:49:20,108 --> 00:49:24,940
calculate my standard deviation now

1060
00:49:21,730 --> 00:49:28,619
passing in the count the sum and the sum

1061
00:49:24,940 --> 00:49:33,970
squared right and there's that formula

1062
00:49:28,619 --> 00:49:36,160
okay the sum is squared divided by the

1063
00:49:33,969 --> 00:49:39,730
square of the sum so i minus the square

1064
00:49:36,159 --> 00:49:41,799
of the sum i do that's the right hand

1065
00:49:39,730 --> 00:49:43,990
side and so now we can calculate the

1066
00:49:41,800 --> 00:49:46,030
weighted average score just like before

1067
00:49:43,989 --> 00:49:46,899
and all of these lames are now the same

1068
00:49:46,030 --> 00:49:49,810
okay

1069
00:49:46,900 --> 00:49:52,000
so we've turned our order and square an

1070
00:49:49,809 --> 00:49:56,049
algorithm into an order n algorithm and

1071
00:49:52,000 --> 00:49:58,059
in general stuff like this is going to

1072
00:49:56,050 --> 00:50:00,039
get you a lot more value than like

1073
00:49:58,059 --> 00:50:03,820
pushing something onto a spark cluster

1074
00:50:00,039 --> 00:50:06,719
or ordering faster ram or using more

1075
00:50:03,820 --> 00:50:09,519
cores and your cpu or whatever right

1076
00:50:06,719 --> 00:50:12,868
this is the way you want to be you know

1077
00:50:09,519 --> 00:50:16,179
improving your code and specifically

1078
00:50:12,869 --> 00:50:19,090
write your code right without thinking

1079
00:50:16,179 --> 00:50:21,309
too much about performance run it is it

1080
00:50:19,090 --> 00:50:25,510
fast enough for what you need then

1081
00:50:21,309 --> 00:50:30,519
you're done if not profile it right so

1082
00:50:25,510 --> 00:50:34,780
in Jupiter instead of seeing percent

1083
00:50:30,519 --> 00:50:38,530
time at you say % p run and it will tell

1084
00:50:34,780 --> 00:50:40,540
you exactly where the time was spent in

1085
00:50:38,530 --> 00:50:42,100
your algorithm and then you can go to

1086
00:50:40,539 --> 00:50:45,880
the bit that's actually taking the time

1087
00:50:42,099 --> 00:50:48,929
and think about like okay is this this

1088
00:50:45,880 --> 00:50:52,559
is algorithmically as efficient as a

1089
00:50:48,929 --> 00:50:57,169
can be okay so in this case we run it

1090
00:50:52,559 --> 00:51:01,410
and we've gone down from 76 milliseconds

1091
00:50:57,170 --> 00:51:03,720
to less than 2 milliseconds and now some

1092
00:51:01,409 --> 00:51:06,838
people that are new to programming think

1093
00:51:03,719 --> 00:51:09,118
like oh great I've saved 60 something

1094
00:51:06,838 --> 00:51:12,539
milliseconds but the point is this is

1095
00:51:09,119 --> 00:51:16,380
going to get run like tens of millions

1096
00:51:12,539 --> 00:51:18,869
of clients okay so the 76 millisecond

1097
00:51:16,380 --> 00:51:21,568
version is so slow that it's got to be

1098
00:51:18,869 --> 00:51:24,119
impractical for any random forest you

1099
00:51:21,568 --> 00:51:25,980
using in practice right where else the

1100
00:51:24,119 --> 00:51:30,390
one millisecond version I found is

1101
00:51:25,980 --> 00:51:32,219
actually quite quite acceptable and then

1102
00:51:30,389 --> 00:51:34,879
check the numbers should be exactly the

1103
00:51:32,219 --> 00:51:39,299
same as before and oh yeah okay

1104
00:51:34,880 --> 00:51:41,300
so now that we have a function find

1105
00:51:39,300 --> 00:51:44,339
better split that does what we want I

1106
00:51:41,300 --> 00:51:46,950
want to insert it into my decision tree

1107
00:51:44,338 --> 00:51:49,529
class and this is a really cool Python

1108
00:51:46,949 --> 00:51:54,480
trick Python does everything dynamically

1109
00:51:49,530 --> 00:51:57,780
right so we can actually say the method

1110
00:51:54,480 --> 00:52:01,889
called find better split in decision

1111
00:51:57,780 --> 00:52:05,359
tree is that function I just created and

1112
00:52:01,889 --> 00:52:08,759
that might sticks it inside that class

1113
00:52:05,358 --> 00:52:11,159
now I'll tell you what's slightly

1114
00:52:08,760 --> 00:52:14,339
confusing about this is that this thing

1115
00:52:11,159 --> 00:52:15,779
this word here and this word here they

1116
00:52:14,338 --> 00:52:16,078
actually have no relationship to each

1117
00:52:15,780 --> 00:52:17,160
other

1118
00:52:16,079 --> 00:52:19,318
they just happen to have the same

1119
00:52:17,159 --> 00:52:22,009
letters in the same order right so like

1120
00:52:19,318 --> 00:52:26,429
I could call this find better split

1121
00:52:22,010 --> 00:52:35,640
underscore foo right and then I could

1122
00:52:26,429 --> 00:52:37,289
like call that right and call that right

1123
00:52:35,639 --> 00:52:39,838
so now my function is actually called

1124
00:52:37,289 --> 00:52:44,670
fine better split underscore foo but my

1125
00:52:39,838 --> 00:52:47,460
method I'm expecting to call something

1126
00:52:44,670 --> 00:52:49,650
called decision tree dot fine better

1127
00:52:47,460 --> 00:52:51,720
split all right so here I could say

1128
00:52:49,650 --> 00:52:54,588
decision tree dot fine better split

1129
00:52:51,719 --> 00:52:55,739
equals find better split underscore foo

1130
00:52:54,588 --> 00:52:57,779
okay

1131
00:52:55,739 --> 00:53:01,588
you see that's the same thing okay so

1132
00:52:57,780 --> 00:53:02,630
like it's important to understand how

1133
00:53:01,588 --> 00:53:05,838
namespaces

1134
00:53:02,630 --> 00:53:07,430
work like in in every language that you

1135
00:53:05,838 --> 00:53:09,828
use one of the most important things is

1136
00:53:07,429 --> 00:53:13,368
kind of understanding how how it figures

1137
00:53:09,829 --> 00:53:16,460
out what a name refers to so this here

1138
00:53:13,369 --> 00:53:19,910
means find better split as to find

1139
00:53:16,460 --> 00:53:22,789
inside this class right and nowhere else

1140
00:53:19,909 --> 00:53:23,989
right well I mean there's a parent class

1141
00:53:22,789 --> 00:53:26,690
but never mind about that

1142
00:53:23,989 --> 00:53:30,258
this one here means find better split

1143
00:53:26,690 --> 00:53:31,579
fou in the global namespace a lot of

1144
00:53:30,259 --> 00:53:36,608
languages don't have a global namespace

1145
00:53:31,579 --> 00:53:39,048
that Python does okay and so the two are

1146
00:53:36,608 --> 00:53:40,578
like even if they happen to have the

1147
00:53:39,048 --> 00:53:42,108
same letters in the same order they're

1148
00:53:40,579 --> 00:53:46,009
not referring in any way to the same

1149
00:53:42,108 --> 00:53:47,509
thing that makes sense it's like this

1150
00:53:46,009 --> 00:53:50,000
family over here may have somebody

1151
00:53:47,509 --> 00:53:52,219
called Jeremy and my family has somebody

1152
00:53:50,000 --> 00:53:54,369
called Jeremy and our names happen to be

1153
00:53:52,219 --> 00:54:00,108
the same but we're not the same person

1154
00:53:54,369 --> 00:54:02,480
okay great so now that we've stuck the

1155
00:54:00,108 --> 00:54:04,639
decision tree sorry I did a fine Bettis

1156
00:54:02,480 --> 00:54:07,130
flip method inside the decision tree

1157
00:54:04,639 --> 00:54:11,088
with his new definition when I now call

1158
00:54:07,130 --> 00:54:12,980
the tree ensemble constructor all right

1159
00:54:11,088 --> 00:54:16,190
the decision tree ensemble instructor

1160
00:54:12,980 --> 00:54:19,909
called create tree create tree

1161
00:54:16,190 --> 00:54:22,730
instantiated decision tree decision tree

1162
00:54:19,909 --> 00:54:24,739
called find vas whit which went through

1163
00:54:22,730 --> 00:54:28,099
every column to see if it could find a

1164
00:54:24,739 --> 00:54:28,818
better split and we've now defined find

1165
00:54:28,099 --> 00:54:31,309
better split

1166
00:54:28,818 --> 00:54:34,639
and therefore tree ensemble when we

1167
00:54:31,309 --> 00:54:36,910
create it has gone ahead and done this

1168
00:54:34,639 --> 00:54:36,909
wet

1169
00:54:37,119 --> 00:54:42,108
that makes sense don't have any anybody

1170
00:54:39,800 --> 00:54:44,570
have any questions uncertainties about

1171
00:54:42,108 --> 00:54:47,880
that like we're only creating one single

1172
00:54:44,570 --> 00:54:51,340
split so far

1173
00:54:47,880 --> 00:54:53,530
all right so this is pretty pretty neat

1174
00:54:51,340 --> 00:54:54,190
right we kind of just do a little bit at

1175
00:54:53,530 --> 00:54:57,160
a time

1176
00:54:54,190 --> 00:55:00,760
testing everything as we go and so it's

1177
00:54:57,159 --> 00:55:02,649
as as as you all implement the random

1178
00:55:00,760 --> 00:55:04,840
forest interpretation techniques you may

1179
00:55:02,650 --> 00:55:08,019
want to try programming this way too

1180
00:55:04,840 --> 00:55:09,370
like every step check that you know what

1181
00:55:08,019 --> 00:55:11,889
you're doing matches up with what

1182
00:55:09,369 --> 00:55:14,409
scikit-learn does or with a test that

1183
00:55:11,889 --> 00:55:18,250
you've built or whatever so at this

1184
00:55:14,409 --> 00:55:21,309
point we should try to go deeper very

1185
00:55:18,250 --> 00:55:24,579
inception right so let's go now max

1186
00:55:21,309 --> 00:55:26,980
depth is two and so here is what

1187
00:55:24,579 --> 00:55:30,250
scikit-learn did after breaking it in

1188
00:55:26,980 --> 00:55:30,900
made 74 it then broke at Machine hours

1189
00:55:30,250 --> 00:55:37,599
later

1190
00:55:30,900 --> 00:55:41,590
29:56 so we had this thing called find

1191
00:55:37,599 --> 00:55:43,690
violet right which just went through

1192
00:55:41,590 --> 00:55:44,530
every column and try to see if there's a

1193
00:55:43,690 --> 00:55:47,470
better split there

1194
00:55:44,530 --> 00:55:49,840
all right but actually we need to go a

1195
00:55:47,469 --> 00:55:52,239
bit further than that not only do we

1196
00:55:49,840 --> 00:55:54,780
have to go through every column and see

1197
00:55:52,239 --> 00:55:57,219
if there's a better split in this node

1198
00:55:54,780 --> 00:55:59,560
but then we also have to see whether

1199
00:55:57,219 --> 00:56:01,199
there's a better split in the left and

1200
00:55:59,559 --> 00:56:04,509
the right sides that we just created

1201
00:56:01,199 --> 00:56:06,279
right in other words the left right side

1202
00:56:04,510 --> 00:56:09,340
and the right-hand side should become

1203
00:56:06,280 --> 00:56:11,140
decision trees themselves right so

1204
00:56:09,340 --> 00:56:13,480
there's no difference at all between

1205
00:56:11,139 --> 00:56:15,099
what we do here to create this tree and

1206
00:56:13,480 --> 00:56:18,460
what we do here to create this tree

1207
00:56:15,099 --> 00:56:23,139
other than this one contains 159 samples

1208
00:56:18,460 --> 00:56:24,699
and this one contains a thousand so this

1209
00:56:23,139 --> 00:56:25,289
row of codes exactly the same as we had

1210
00:56:24,699 --> 00:56:28,569
before

1211
00:56:25,289 --> 00:56:29,860
right and then we check it actually we

1212
00:56:28,570 --> 00:56:34,360
could do this a little bit easier we

1213
00:56:29,860 --> 00:56:37,000
could say if self dot is leaf right

1214
00:56:34,360 --> 00:56:37,660
would be the same thing hey don't leave

1215
00:56:37,000 --> 00:56:40,300
it here for now

1216
00:56:37,659 --> 00:56:43,750
so it's self dot score so if the score

1217
00:56:40,300 --> 00:56:44,900
is infinite still let's write it

1218
00:56:43,750 --> 00:56:48,469
properly

1219
00:56:44,900 --> 00:56:54,048
yes wait so let's go back up and just

1220
00:56:48,469 --> 00:56:57,709
remind ourselves is leaf is self that's

1221
00:56:54,048 --> 00:57:00,998
poor equals in okay so since it's there

1222
00:56:57,710 --> 00:57:04,490
we mostly use it so if it's a leaf node

1223
00:57:00,998 --> 00:57:06,078
then we have nothing further to do right

1224
00:57:04,489 --> 00:57:08,389
so that means we're right at the bottom

1225
00:57:06,079 --> 00:57:09,619
there's no split that's been made okay

1226
00:57:08,389 --> 00:57:11,929
so we don't have to do anything further

1227
00:57:09,619 --> 00:57:13,749
on the other hand if it's not a leaf

1228
00:57:11,929 --> 00:57:16,489
node so it's somewhere back earlier on

1229
00:57:13,748 --> 00:57:18,848
then we need to split it into the left

1230
00:57:16,489 --> 00:57:21,618
hand side and the right hand side now

1231
00:57:18,849 --> 00:57:23,180
earlier on we created a left hand side

1232
00:57:21,619 --> 00:57:23,838
in the right hand side array of

1233
00:57:23,179 --> 00:57:27,768
bullying's

1234
00:57:23,838 --> 00:57:30,498
right now better would be to have here

1235
00:57:27,768 --> 00:57:32,028
we have an array of indexes and that's

1236
00:57:30,498 --> 00:57:34,278
because we don't want to have a full

1237
00:57:32,028 --> 00:57:36,920
array of all the volumes in every single

1238
00:57:34,278 --> 00:57:38,239
node right because remember although it

1239
00:57:36,920 --> 00:57:40,700
doesn't look like there are many nodes

1240
00:57:38,239 --> 00:57:43,998
when you see a tree of this size when

1241
00:57:40,699 --> 00:57:45,739
it's fully expanded the bottom level if

1242
00:57:43,998 --> 00:57:49,308
there's a minimum leaf size of one

1243
00:57:45,739 --> 00:57:51,618
contains the same number of nodes as the

1244
00:57:49,309 --> 00:57:53,720
entire data set and so if every one of

1245
00:57:51,619 --> 00:57:55,910
those contained a full boolean array of

1246
00:57:53,719 --> 00:57:57,889
size of the whole data set you've got

1247
00:57:55,909 --> 00:58:00,230
squared memory requirements which would

1248
00:57:57,889 --> 00:58:02,778
be bad right on the other hand if we

1249
00:58:00,230 --> 00:58:04,190
just store the indexes there for things

1250
00:58:02,778 --> 00:58:04,989
in this node and that's going to get

1251
00:58:04,190 --> 00:58:11,450
smaller and smaller

1252
00:58:04,989 --> 00:58:13,009
okay so NP non zero is exactly the same

1253
00:58:11,449 --> 00:58:15,048
as just this thing which gets the

1254
00:58:13,009 --> 00:58:18,710
boolean array but it turns it into the

1255
00:58:15,048 --> 00:58:20,568
indexes of the truths okay so this is

1256
00:58:18,710 --> 00:58:23,150
now a list of indexes for the left-hand

1257
00:58:20,568 --> 00:58:25,998
side and indexes to the right-hand side

1258
00:58:23,150 --> 00:58:27,139
alright so now that we have the indexes

1259
00:58:25,998 --> 00:58:30,318
the left-hand side and the right-hand

1260
00:58:27,139 --> 00:58:32,298
side we can now just go ahead and create

1261
00:58:30,318 --> 00:58:34,940
a decision tree okay so there's a

1262
00:58:32,298 --> 00:58:37,190
decision tree for the left and there's

1263
00:58:34,940 --> 00:58:38,329
our decision tree for the right okay and

1264
00:58:37,190 --> 00:58:41,679
we don't have to do anything else we've

1265
00:58:38,329 --> 00:58:44,089
already written these we already have a

1266
00:58:41,679 --> 00:58:46,219
function of a constructor that can

1267
00:58:44,088 --> 00:58:48,619
create a decision tree

1268
00:58:46,219 --> 00:58:51,500
so like when you really think about what

1269
00:58:48,619 --> 00:58:54,650
this is doing it kind of hurts your head

1270
00:58:51,500 --> 00:58:57,880
right because the reason the whole

1271
00:58:54,650 --> 00:59:05,450
reason that fine vast bit got called is

1272
00:58:57,880 --> 00:59:08,390
because find vasp lit is called by the

1273
00:59:05,449 --> 00:59:11,118
decision tree constructor but then the

1274
00:59:08,389 --> 00:59:12,980
decision tree that then find vast bit

1275
00:59:11,119 --> 00:59:16,519
itself then causes the decision tree

1276
00:59:12,980 --> 00:59:20,719
constructor so we actually have circular

1277
00:59:16,519 --> 00:59:22,400
recursion and I'm not nearly smart

1278
00:59:20,719 --> 00:59:25,759
enough to be able to think through

1279
00:59:22,400 --> 00:59:29,298
recursion so I just choose not to write

1280
00:59:25,760 --> 00:59:32,180
like I just write what I mean and then I

1281
00:59:29,298 --> 00:59:34,159
don't think about it anymore right like

1282
00:59:32,179 --> 00:59:35,389
what do I want well to find a

1283
00:59:34,159 --> 00:59:37,068
variable-speed I've got to go through a

1284
00:59:35,389 --> 00:59:37,989
few column see if there's something

1285
00:59:37,068 --> 00:59:40,940
better

1286
00:59:37,989 --> 00:59:42,348
it had managed to do a split figure out

1287
00:59:40,940 --> 00:59:45,619
left-hand side of the right-hand side

1288
00:59:42,349 --> 00:59:48,588
and make them into decision trees okay

1289
00:59:45,619 --> 00:59:50,599
but now try to think through how these

1290
00:59:48,588 --> 00:59:52,639
two methods call each other would just

1291
00:59:50,599 --> 00:59:54,200
drive me crazy but I don't need to write

1292
00:59:52,639 --> 00:59:56,538
I know I have a decision tree

1293
00:59:54,199 --> 00:59:59,480
constructor that works no no no I have a

1294
00:59:56,539 --> 01:00:02,480
vine up find basket that works so that's

1295
00:59:59,480 --> 01:00:06,019
it right that's how I do recursive

1296
01:00:02,480 --> 01:00:08,510
programming is by pretending I don't I

1297
01:00:06,019 --> 01:00:10,369
just just ignore it that's my advice

1298
01:00:08,510 --> 01:00:11,660
a lot of you are probably smart enough

1299
01:00:10,369 --> 01:00:14,088
to be able to think through it better

1300
01:00:11,659 --> 01:00:15,528
than I can so that's fine if you can all

1301
01:00:14,088 --> 01:00:17,750
right so now that I've written that

1302
01:00:15,528 --> 01:00:24,019
again I can patch it into the decision

1303
01:00:17,750 --> 01:00:26,358
tree class and as soon as I do the tree

1304
01:00:24,019 --> 01:00:28,759
ensemble constructor will now use that

1305
01:00:26,358 --> 01:00:32,449
right because pythons dynamic right

1306
01:00:28,760 --> 01:00:36,569
that's just happens automatically so now

1307
01:00:32,449 --> 01:00:41,639
I can check my left-hand side

1308
01:00:36,568 --> 01:00:43,858
should have 159 samples right and a

1309
01:00:41,639 --> 01:00:46,768
value of nine point six six

1310
01:00:43,858 --> 01:00:53,038
there it is 159 samples nine point six

1311
01:00:46,768 --> 01:00:56,668
six right hand side huh 841 10.15 the

1312
01:00:53,039 --> 01:01:00,479
left hand side of the left hand side 150

1313
01:00:56,668 --> 01:01:03,058
samples nine point six to 150 samples

1314
01:01:00,478 --> 01:01:06,568
nine point six - okay so you can see

1315
01:01:03,059 --> 01:01:07,890
like I'm because I'm not nearly clever

1316
01:01:06,568 --> 01:01:10,108
enough to write machine learning

1317
01:01:07,889 --> 01:01:11,518
algorithms like not only can I not write

1318
01:01:10,108 --> 01:01:14,130
them correctly the first time

1319
01:01:11,518 --> 01:01:16,228
often like every single line I write

1320
01:01:14,130 --> 01:01:18,959
will be wrong right so I always start

1321
01:01:16,228 --> 01:01:21,088
from the assumption that the the line of

1322
01:01:18,958 --> 01:01:23,418
code I just typed is almost certainly

1323
01:01:21,088 --> 01:01:26,188
wrong and I just have to see why and how

1324
01:01:23,418 --> 01:01:27,838
right and so like I just make sure and

1325
01:01:26,188 --> 01:01:30,088
so eventually I get to the point where

1326
01:01:27,838 --> 01:01:31,409
like much to my surprise it's not broken

1327
01:01:30,088 --> 01:01:33,688
anymore you know

1328
01:01:31,409 --> 01:01:35,068
so here I can feel like okay this it

1329
01:01:33,688 --> 01:01:36,899
would be surprising if all of these

1330
01:01:35,068 --> 01:01:38,579
things accidentally happen to be exactly

1331
01:01:36,900 --> 01:01:44,909
the same as scikit-learn so this is

1332
01:01:38,579 --> 01:01:46,229
looking pretty good okay so now that we

1333
01:01:44,909 --> 01:01:48,479
have something that can build a whole

1334
01:01:46,228 --> 01:01:51,298
tree where you want to have something

1335
01:01:48,478 --> 01:01:53,788
that can calculate predictions right and

1336
01:01:51,298 --> 01:01:55,559
so remind you we already have something

1337
01:01:53,789 --> 01:02:00,119
that calculates predictions for a tree

1338
01:01:55,559 --> 01:02:02,579
ensemble by calling trade-up predict but

1339
01:02:00,119 --> 01:02:05,900
there is nothing called treetop predict

1340
01:02:02,579 --> 01:02:05,900
so we're gonna have to write that

1341
01:02:06,989 --> 01:02:10,229
to make this more interesting let's

1342
01:02:08,699 --> 01:02:15,210
start bringing up the number of columns

1343
01:02:10,230 --> 01:02:17,699
that we use let's create our tree

1344
01:02:15,210 --> 01:02:22,289
ensemble again and this time let's go to

1345
01:02:17,699 --> 01:02:25,489
a maximum depth of three okay so now our

1346
01:02:22,289 --> 01:02:25,489
tree is getting more interesting

1347
01:02:27,599 --> 01:02:34,769
and let's now define how do we create a

1348
01:02:31,829 --> 01:02:36,778
set of predictions for a tree and so a

1349
01:02:34,768 --> 01:02:42,209
set of predictions for a tree is simply

1350
01:02:36,778 --> 01:02:44,099
the prediction for a row for every row

1351
01:02:42,210 --> 01:02:45,869
that's it all right that's our

1352
01:02:44,099 --> 01:02:50,460
predictions so the predictions for a

1353
01:02:45,869 --> 01:02:54,329
tree are every rows predictions in an

1354
01:02:50,460 --> 01:02:56,639
array okay so again we're like skipping

1355
01:02:54,329 --> 01:03:00,889
thinking thinking's hard you know

1356
01:02:56,639 --> 01:03:00,889
so let's just like keep pushing it back

1357
01:03:00,949 --> 01:03:07,879
this is kind of Handy right notice that

1358
01:03:04,079 --> 01:03:07,880
you can do four

1359
01:03:08,150 --> 01:03:15,318
in array with an umpire array regardless

1360
01:03:11,809 --> 01:03:19,039
of the rank of the array regardless of

1361
01:03:15,318 --> 01:03:20,808
the number of axes in the array and what

1362
01:03:19,039 --> 01:03:24,650
it does is it will look through the

1363
01:03:20,809 --> 01:03:26,390
leading axis at least these concepts are

1364
01:03:24,650 --> 01:03:28,250
going to be very very important as we

1365
01:03:26,389 --> 01:03:29,480
get into more and more neural networks

1366
01:03:28,250 --> 01:03:31,909
because we're going to be all doing

1367
01:03:29,480 --> 01:03:34,940
tensor computations all the time so the

1368
01:03:31,909 --> 01:03:37,399
leading axis that the vector is the

1369
01:03:34,940 --> 01:03:40,400
vector itself the leading axis of a

1370
01:03:37,400 --> 01:03:44,269
matrix are the rows the leading access

1371
01:03:40,400 --> 01:03:46,278
axis of a three dimensional tensor the

1372
01:03:44,269 --> 01:03:49,460
matrices that represent the slices and

1373
01:03:46,278 --> 01:03:51,230
so forth right so in this case because X

1374
01:03:49,460 --> 01:03:53,710
is a matrix this is going to look

1375
01:03:51,230 --> 01:03:57,289
through the rows and if you write your

1376
01:03:53,710 --> 01:04:00,679
kind of tensor code this way then it'll

1377
01:03:57,289 --> 01:04:02,240
kind of tend to generalize nicely to

1378
01:04:00,679 --> 01:04:04,338
higher dimensions like it doesn't really

1379
01:04:02,239 --> 01:04:05,959
mention matter how many dimensions are

1380
01:04:04,338 --> 01:04:11,389
in X this is going to loop through each

1381
01:04:05,960 --> 01:04:15,068
of the leading axis okay so we can now

1382
01:04:11,389 --> 01:04:15,068
call that decision tree do I predict

1383
01:04:16,480 --> 01:04:22,579
alright so all I need to do is write

1384
01:04:20,298 --> 01:04:25,099
predict row right and I've delayed

1385
01:04:22,579 --> 01:04:26,359
thinking so much which is great that the

1386
01:04:25,099 --> 01:04:29,359
actual point where I actually have to do

1387
01:04:26,358 --> 01:04:33,528
the work it's now basically trivial so

1388
01:04:29,358 --> 01:04:36,348
if we're at a leaf no then the

1389
01:04:33,528 --> 01:04:39,559
prediction is just equal to whatever

1390
01:04:36,349 --> 01:04:41,510
that value was which we calculated right

1391
01:04:39,559 --> 01:04:43,510
back in the original tree constructor is

1392
01:04:41,510 --> 01:04:46,940
to assist the average of the Y's right

1393
01:04:43,510 --> 01:04:48,049
if it's not a leaf node then we have to

1394
01:04:46,940 --> 01:04:50,088
figure out whether to go down the

1395
01:04:48,048 --> 01:04:56,119
left-hand path or the right-hand path to

1396
01:04:50,088 --> 01:04:59,269
get the prediction right so if this

1397
01:04:56,119 --> 01:05:00,829
variable in this row is less than or

1398
01:04:59,269 --> 01:05:03,528
equal to that thing we decided the

1399
01:05:00,829 --> 01:05:06,048
amount we decided to split on then we go

1400
01:05:03,528 --> 01:05:08,630
down the left path otherwise we go down

1401
01:05:06,048 --> 01:05:10,880
the right path okay and then having

1402
01:05:08,630 --> 01:05:12,798
figured out what path we want which tree

1403
01:05:10,880 --> 01:05:17,809
we want then we can just call predict

1404
01:05:12,798 --> 01:05:19,980
row on that right and again we've

1405
01:05:17,809 --> 01:05:23,519
accidentally created something recursive

1406
01:05:19,980 --> 01:05:27,119
again I don't want to think about how

1407
01:05:23,519 --> 01:05:30,050
that works control flow wise or whatever

1408
01:05:27,119 --> 01:05:32,608
but I don't need to because like I just

1409
01:05:30,050 --> 01:05:34,829
it just does like I just told it what I

1410
01:05:32,608 --> 01:05:37,559
wanted so I'll trust it to work right if

1411
01:05:34,829 --> 01:05:39,180
it's a leaf return the value otherwise

1412
01:05:37,559 --> 01:05:40,380
return the prediction for the left hand

1413
01:05:39,179 --> 01:05:45,328
side or the right hand side as

1414
01:05:40,380 --> 01:05:50,930
appropriate there notice this here this

1415
01:05:45,329 --> 01:05:53,579
if has nothing to do with this if all

1416
01:05:50,929 --> 01:05:57,328
right this if is a control flow

1417
01:05:53,579 --> 01:05:59,220
statement that tells Python to go down

1418
01:05:57,329 --> 01:06:05,880
on that path or that path to do some

1419
01:05:59,219 --> 01:06:09,779
calculation this if is an operator that

1420
01:06:05,880 --> 01:06:12,240
returns a value so those of you that

1421
01:06:09,780 --> 01:06:14,070
have done C or C++ will recognize it as

1422
01:06:12,239 --> 01:06:16,889
being identical to that it's called the

1423
01:06:14,070 --> 01:06:18,630
ternary operator all right if you

1424
01:06:16,889 --> 01:06:20,269
haven't that's fine basically what we're

1425
01:06:18,630 --> 01:06:22,619
doing is we're going to get a value

1426
01:06:20,269 --> 01:06:27,568
where we're going to say it's this value

1427
01:06:22,619 --> 01:06:33,798
if this thing is true and that value

1428
01:06:27,568 --> 01:06:36,199
otherwise and so you could write it

1429
01:06:33,798 --> 01:06:38,958
this way right but that would require

1430
01:06:36,199 --> 01:06:41,688
writing four lines of code to do one

1431
01:06:38,958 --> 01:06:43,219
thing and also require you to code that

1432
01:06:41,688 --> 01:06:45,708
if you read it to yourself or to

1433
01:06:43,219 --> 01:06:47,329
somebody else is not at all naturally

1434
01:06:45,708 --> 01:06:50,149
the way you would express it right I

1435
01:06:47,329 --> 01:06:53,568
want to say the tree I going to go down

1436
01:06:50,150 --> 01:06:55,369
is the left-hand side if the variables

1437
01:06:53,568 --> 01:06:57,829
less than the split or the right-hand

1438
01:06:55,369 --> 01:07:00,048
side otherwise right so I want to write

1439
01:06:57,829 --> 01:07:03,079
my code the way I would think about all

1440
01:07:00,048 --> 01:07:06,469
the way I would say my code okay so this

1441
01:07:03,079 --> 01:07:10,939
kind of ternary operator can be quite

1442
01:07:06,469 --> 01:07:12,499
helpful for that alright so now that

1443
01:07:10,938 --> 01:07:16,728
I've got a prediction for a row I can

1444
01:07:12,498 --> 01:07:21,468
dump that into my class and now I can

1445
01:07:16,728 --> 01:07:23,808
create calculate predictions and I can

1446
01:07:21,469 --> 01:07:27,909
now plot my actuals against my

1447
01:07:23,809 --> 01:07:30,709
predictions when you do a scatter plot

1448
01:07:27,909 --> 01:07:33,048
you'll often have a lot of dots sitting

1449
01:07:30,708 --> 01:07:35,358
on top of each other so a good trick is

1450
01:07:33,048 --> 01:07:37,788
to use alpha alpha means how transparent

1451
01:07:35,358 --> 01:07:39,170
the things not just a map plot lib but

1452
01:07:37,789 --> 01:07:40,969
like in every graphics package in the

1453
01:07:39,170 --> 01:07:43,849
world pretty much and so if you set

1454
01:07:40,969 --> 01:07:45,619
alpha to less than 1 then this is saying

1455
01:07:43,849 --> 01:07:48,349
you would need 20 dots on top of each

1456
01:07:45,619 --> 01:07:50,410
other for it to be fully blue and so

1457
01:07:48,349 --> 01:07:52,429
this is a good way to kind of see how

1458
01:07:50,409 --> 01:07:54,199
much things are sitting on top of each

1459
01:07:52,429 --> 01:07:56,679
other so it's a good trick but trick the

1460
01:07:54,199 --> 01:07:56,679
scatter plots

1461
01:07:57,048 --> 01:08:05,329
there's my R squared not bad

1462
01:08:01,009 --> 01:08:12,670
and so let's now go ahead and do a

1463
01:08:05,329 --> 01:08:17,869
random forest with no max mana spitting

1464
01:08:12,670 --> 01:08:20,559
and our tree ensemble had no max amount

1465
01:08:17,868 --> 01:08:23,960
of spitting we can compare our R squared

1466
01:08:20,559 --> 01:08:26,239
- there are squared and so they're not

1467
01:08:23,960 --> 01:08:29,389
the same but actually ours is a little

1468
01:08:26,238 --> 01:08:31,738
better so I don't know what we did

1469
01:08:29,389 --> 01:08:35,400
differently but we'll take it

1470
01:08:31,738 --> 01:08:39,058
okay so we have now something which for

1471
01:08:35,399 --> 01:08:43,469
a forest with a single tree in is giving

1472
01:08:39,059 --> 01:08:45,779
as good accuracy on a validation set

1473
01:08:43,469 --> 01:08:48,359
using an actual real-world data set you

1474
01:08:45,779 --> 01:08:52,920
know books for pluto's is compared to

1475
01:08:48,359 --> 01:08:55,469
scikit-learn so let's go ahead and round

1476
01:08:52,920 --> 01:08:57,569
this out so what I would want to do now

1477
01:08:55,469 --> 01:08:59,609
is to create a package that has this

1478
01:08:57,569 --> 01:09:01,139
coding and I created it by like creating

1479
01:08:59,609 --> 01:09:03,480
a method here a method here a method

1480
01:09:01,139 --> 01:09:05,219
here and catching them together so what

1481
01:09:03,479 --> 01:09:07,108
I did with now is I went back through in

1482
01:09:05,219 --> 01:09:09,838
my notebook and collected up all the

1483
01:09:07,109 --> 01:09:11,249
cells had implemented methods and pasted

1484
01:09:09,838 --> 01:09:13,498
them all together right and I've just

1485
01:09:11,248 --> 01:09:16,170
pasted them down here so here's this is

1486
01:09:13,498 --> 01:09:17,670
my original tree ensemble and here is

1487
01:09:16,170 --> 01:09:19,769
all the cells and the decision tree I

1488
01:09:17,670 --> 01:09:25,078
just dumped them all into one place

1489
01:09:19,769 --> 01:09:27,389
without any change so that was it that

1490
01:09:25,078 --> 01:09:32,518
was the code we wrote together so now I

1491
01:09:27,389 --> 01:09:35,819
can go ahead and I can create a tree

1492
01:09:32,519 --> 01:09:38,819
ensemble I can calculate my predictions

1493
01:09:35,819 --> 01:09:42,529
I can do my scatter plot I can get my

1494
01:09:38,819 --> 01:09:47,579
r-squared right and this is now with

1495
01:09:42,529 --> 01:09:50,670
five trees right and here we are we have

1496
01:09:47,578 --> 01:09:53,818
a model of blue dog for bulldozers with

1497
01:09:50,670 --> 01:09:57,719
a 71% a squid with a random forest we

1498
01:09:53,819 --> 01:10:00,110
wrote entirely from scratch that's

1499
01:09:57,719 --> 01:10:00,109
pretty cool

1500
01:10:00,538 --> 01:10:04,948
any questions about that and I know

1501
01:10:03,599 --> 01:10:07,380
there's like quite a lot to get through

1502
01:10:04,948 --> 01:10:10,469
so I during the week feel free to ask on

1503
01:10:07,380 --> 01:10:12,779
the forum about any bits of code you

1504
01:10:10,469 --> 01:10:16,158
come across can somebody pass the box to

1505
01:10:12,779 --> 01:10:16,158
Mercia others

1506
01:10:18,760 --> 01:10:26,079
can we get back to the probably to the

1507
01:10:22,000 --> 01:10:28,750
top maybe a decision tree when we said

1508
01:10:26,079 --> 01:10:32,769
the score equal to infinity right yes I

1509
01:10:28,750 --> 01:10:35,279
do a calculator Scott the score for the

1510
01:10:32,770 --> 01:10:40,440
I mean like I lost track of that and

1511
01:10:35,279 --> 01:10:44,889
specifically I wonder when we implement

1512
01:10:40,439 --> 01:10:47,769
when we implement find VAR split we

1513
01:10:44,890 --> 01:10:50,860
check for self score equal to whether

1514
01:10:47,770 --> 01:10:53,520
it's equal to infinity or not it says to

1515
01:10:50,859 --> 01:10:58,630
me it seems like I'm clear whether we

1516
01:10:53,520 --> 01:11:02,980
fall out of this I mean like if we ever

1517
01:10:58,630 --> 01:11:06,640
implement the method if if our initial

1518
01:11:02,979 --> 01:11:10,139
value is infinity so okay let's talk

1519
01:11:06,640 --> 01:11:12,880
sure the logic so so the decision tree

1520
01:11:10,140 --> 01:11:14,530
starts out with a score at infinity so

1521
01:11:12,880 --> 01:11:18,159
in other words at this point when we've

1522
01:11:14,529 --> 01:11:21,460
created the mode there is no split so

1523
01:11:18,159 --> 01:11:24,460
it's infinitely bad okay that's why the

1524
01:11:21,460 --> 01:11:28,480
score is infinity and then we try to

1525
01:11:24,460 --> 01:11:32,710
find a variable and a split that is

1526
01:11:28,479 --> 01:11:37,179
better and do that we look through each

1527
01:11:32,710 --> 01:11:39,760
column and say hey column do you have a

1528
01:11:37,180 --> 01:11:43,780
split which is better than the best one

1529
01:11:39,760 --> 01:11:50,230
we have so far and so then we implement

1530
01:11:43,779 --> 01:11:52,509
that let's do the slow way since it's a

1531
01:11:50,229 --> 01:11:55,359
bit simpler find better split

1532
01:11:52,510 --> 01:11:59,199
we do that by looping through each row

1533
01:11:55,359 --> 01:12:01,630
and finding out this is the current

1534
01:11:59,199 --> 01:12:03,429
score if we split here is it better than

1535
01:12:01,630 --> 01:12:05,980
the current score the current score is

1536
01:12:03,430 --> 01:12:08,289
infinitely bad so yes it is and so now

1537
01:12:05,979 --> 01:12:10,000
we set the new score equal to what we

1538
01:12:08,289 --> 01:12:12,399
just calculated and we keep track of

1539
01:12:10,000 --> 01:12:16,770
which variable we chose and the split we

1540
01:12:12,399 --> 01:12:16,769
spit on okay no worries

1541
01:12:20,988 --> 01:12:27,559
okay great let's take a five-minute

1542
01:12:23,340 --> 01:12:27,560
break and I'll see you back here at 22

1543
01:12:30,618 --> 01:12:38,839
so when I tried comparing the

1544
01:12:33,179 --> 01:12:42,539
performance of this against scikit-learn

1545
01:12:38,840 --> 01:12:46,650
this is quite a lot slower and the

1546
01:12:42,539 --> 01:12:49,560
reason why is that although like a lot

1547
01:12:46,649 --> 01:12:53,279
of the works being done by numpy which

1548
01:12:49,560 --> 01:12:56,150
is nicely optimized c-code think about

1549
01:12:53,279 --> 01:13:01,380
like the very bottom level of a tree if

1550
01:12:56,149 --> 01:13:02,969
we've got a million data points and the

1551
01:13:01,380 --> 01:13:07,739
bottom level of the tree has something

1552
01:13:02,969 --> 01:13:10,109
like 500 thousand decision points with a

1553
01:13:07,738 --> 01:13:13,618
million leaves underneath right and so

1554
01:13:10,109 --> 01:13:15,448
that's like five hundred thousand split

1555
01:13:13,618 --> 01:13:17,189
methods being called each one of

1556
01:13:15,448 --> 01:13:21,809
contained which contains multiple calls

1557
01:13:17,189 --> 01:13:23,519
to numpy which only have like one item

1558
01:13:21,810 --> 01:13:25,920
that's actually being calculated on and

1559
01:13:23,520 --> 01:13:27,690
so it's like that's like very

1560
01:13:25,920 --> 01:13:30,389
inefficient and it's the kind of thing

1561
01:13:27,689 --> 01:13:33,178
that Python is particularly not good at

1562
01:13:30,389 --> 01:13:35,460
performance wise right like calling lots

1563
01:13:33,179 --> 01:13:38,489
of functions lots of times I mean we can

1564
01:13:35,460 --> 01:13:42,899
see it's it's not bad right you know for

1565
01:13:38,488 --> 01:13:44,399
a kind of a random forest which 15 years

1566
01:13:42,899 --> 01:13:46,439
ago would have been considered pretty

1567
01:13:44,399 --> 01:13:48,529
big this would be considered pretty good

1568
01:13:46,439 --> 01:13:51,029
performance right but nowadays this is

1569
01:13:48,529 --> 01:13:55,849
some hundreds of times at least slower

1570
01:13:51,029 --> 01:13:59,519
than than it should be so what the

1571
01:13:55,850 --> 01:14:02,850
scikit-learn folks did to avoid this

1572
01:13:59,520 --> 01:14:04,440
problem was that they wrote their

1573
01:14:02,850 --> 01:14:09,869
implementation in something called

1574
01:14:04,439 --> 01:14:13,939
siphon and siphon is a superset of

1575
01:14:09,868 --> 01:14:20,988
Python so any Python you've written

1576
01:14:13,939 --> 01:14:24,539
pretty much you can use as siphon right

1577
01:14:20,988 --> 01:14:26,428
but then what happens is siphon runs it

1578
01:14:24,539 --> 01:14:29,429
in a very different way rather than

1579
01:14:26,429 --> 01:14:33,260
passing it to the kind of the Python

1580
01:14:29,429 --> 01:14:34,409
interpreter it instead converts it to C

1581
01:14:33,260 --> 01:14:37,110
can

1582
01:14:34,409 --> 01:14:40,050
Kyle's that and then runs that C code

1583
01:14:37,109 --> 01:14:42,149
right which means the first time you run

1584
01:14:40,050 --> 01:14:44,670
it it takes a little long work so it has

1585
01:14:42,149 --> 01:14:47,250
to go through the kind of translation

1586
01:14:44,670 --> 01:14:51,869
and compilation but then after that it

1587
01:14:47,250 --> 01:14:53,130
can be quite a bit faster and so I want

1588
01:14:51,869 --> 01:14:58,079
to just to quickly show you what that

1589
01:14:53,130 --> 01:14:59,940
looks like because you are absolutely

1590
01:14:58,079 --> 01:15:01,699
going to be in a position where siphons

1591
01:14:59,939 --> 01:15:03,719
going to help you with your work and

1592
01:15:01,699 --> 01:15:06,000
most of the people you're working with

1593
01:15:03,720 --> 01:15:07,770
will have never used it may not even

1594
01:15:06,000 --> 01:15:10,289
know it exists and so this is like a

1595
01:15:07,770 --> 01:15:13,020
great superpower to have so to use

1596
01:15:10,289 --> 01:15:17,519
siphon in a notebook you say load next

1597
01:15:13,020 --> 01:15:25,260
load extension siphon right and so

1598
01:15:17,520 --> 01:15:29,520
here's a Python function bit one here is

1599
01:15:25,260 --> 01:15:33,739
the same as a siphon function is exactly

1600
01:15:29,520 --> 01:15:33,740
the same thing with percent % at the top

1601
01:15:33,760 --> 01:15:40,639
this actually runs about twice as fast

1602
01:15:37,118 --> 01:15:45,498
as this right just because it does their

1603
01:15:40,639 --> 01:15:48,400
compilation here is the same version

1604
01:15:45,498 --> 01:15:51,738
again where I've used a special siphon

1605
01:15:48,399 --> 01:15:55,759
extension called C death which defines

1606
01:15:51,738 --> 01:16:00,649
the C data type of the return value and

1607
01:15:55,760 --> 01:16:02,510
of each variable right and so basically

1608
01:16:00,649 --> 01:16:06,109
that's the trick that you can use to

1609
01:16:02,510 --> 01:16:08,030
start making things run quickly right

1610
01:16:06,109 --> 01:16:13,518
and at that point now it knows it's not

1611
01:16:08,029 --> 01:16:16,899
just some Python object called T in fact

1612
01:16:13,519 --> 01:16:16,900
I probably should put one here as well

1613
01:16:17,288 --> 01:16:29,958
let's try that so we've got fib 2 we

1614
01:16:20,090 --> 01:16:31,610
call that 53 so 453 yeah so it's exactly

1615
01:16:29,958 --> 01:16:33,229
the same as before but we say what the

1616
01:16:31,609 --> 01:16:35,868
data type of the thing we passed to it

1617
01:16:33,229 --> 01:16:38,809
was is and then define the data types of

1618
01:16:35,868 --> 01:16:41,469
each of the variables and so then if we

1619
01:16:38,809 --> 01:16:41,469
call that

1620
01:16:45,590 --> 01:16:51,230
okay we've now got something that's 10

1621
01:16:47,329 --> 01:16:52,789
times faster right so yeah it doesn't

1622
01:16:51,229 --> 01:16:55,250
really take that much extra and it's

1623
01:16:52,789 --> 01:16:58,609
just it's just Python with a few little

1624
01:16:55,250 --> 01:17:01,819
bits of markup so that's like it's it's

1625
01:16:58,609 --> 01:17:03,199
good to know that that exists because if

1626
01:17:01,819 --> 01:17:06,109
there's something custom you're trying

1627
01:17:03,199 --> 01:17:07,699
to do it's actually a find it kind of

1628
01:17:06,109 --> 01:17:09,500
painful having to go out and you know

1629
01:17:07,699 --> 01:17:10,699
going to see and compile it and whip it

1630
01:17:09,500 --> 01:17:12,439
back and all that where else doing it

1631
01:17:10,699 --> 01:17:17,630
here is pretty easy can you pass that

1632
01:17:12,439 --> 01:17:20,059
just your right please not sure so when

1633
01:17:17,630 --> 01:17:22,550
you're doing like for the second version

1634
01:17:20,060 --> 01:17:26,990
of it so in the case an array for an NP

1635
01:17:22,550 --> 01:17:30,800
array this is a specific C type of yeah

1636
01:17:26,989 --> 01:17:33,409
so there's like a lot of um specific

1637
01:17:30,800 --> 01:17:39,579
stuff for integrating scythe on with

1638
01:17:33,409 --> 01:17:41,809
numpy and there's a whole page about it

1639
01:17:39,579 --> 01:17:43,159
yeah so we won't worry about going over

1640
01:17:41,810 --> 01:17:45,830
it but you can read that and you can

1641
01:17:43,159 --> 01:17:49,300
basically see the basic ideas there's

1642
01:17:45,829 --> 01:17:52,489
this C import which basically imports a

1643
01:17:49,300 --> 01:17:55,760
certain types of Python library into the

1644
01:17:52,489 --> 01:18:00,789
kind of the C bit of the code and you

1645
01:17:55,760 --> 01:18:04,909
can then use it in your siphon yeah it's

1646
01:18:00,789 --> 01:18:05,300
it's pretty straightforward well good

1647
01:18:04,909 --> 01:18:09,739
question

1648
01:18:05,300 --> 01:18:19,460
thank you all right so your your mission

1649
01:18:09,739 --> 01:18:22,729
now is to implement confidence based on

1650
01:18:19,460 --> 01:18:25,670
tree variance feature importance partial

1651
01:18:22,729 --> 01:18:29,199
dependence in tree interpreter for that

1652
01:18:25,670 --> 01:18:32,270
random first removing redundant features

1653
01:18:29,199 --> 01:18:33,679
doesn't use a random forest at all so

1654
01:18:32,270 --> 01:18:35,300
you don't have to worry about that the

1655
01:18:33,680 --> 01:18:36,650
extrapolation is not an interpretation

1656
01:18:35,300 --> 01:18:38,150
technique so you don't have to worry

1657
01:18:36,649 --> 01:18:40,339
about that so it's just the other ones

1658
01:18:38,149 --> 01:18:42,469
so confidence based on tree variance

1659
01:18:40,340 --> 01:18:44,659
we've already written that code so I

1660
01:18:42,470 --> 01:18:46,430
suspect that the exact same code we

1661
01:18:44,659 --> 01:18:48,289
would have in the notebook should

1662
01:18:46,430 --> 01:18:50,659
continue to work so you can try and make

1663
01:18:48,289 --> 01:18:52,789
sure it get that working feature

1664
01:18:50,659 --> 01:18:55,159
importance is with the variable

1665
01:18:52,789 --> 01:18:57,500
shuffling technique and once you have

1666
01:18:55,159 --> 01:18:59,210
that working partial dependence it will

1667
01:18:57,500 --> 01:19:01,189
just be a couple of lines of code away

1668
01:18:59,210 --> 01:19:03,770
rather than you know rather than

1669
01:19:01,189 --> 01:19:05,449
shuffling a column you're just replacing

1670
01:19:03,770 --> 01:19:08,480
it with a constant value that it's

1671
01:19:05,449 --> 01:19:11,000
nearly the same code and then tree

1672
01:19:08,479 --> 01:19:12,259
interpreter it's going to require you

1673
01:19:11,000 --> 01:19:13,939
writing some code and thinking about

1674
01:19:12,260 --> 01:19:16,190
that well ince you've written tree

1675
01:19:13,939 --> 01:19:18,619
interpreter you're very close if you

1676
01:19:16,189 --> 01:19:22,879
want to to creating the second approach

1677
01:19:18,619 --> 01:19:26,119
to feature importance the one where you

1678
01:19:22,880 --> 01:19:28,430
add up the importance across all of the

1679
01:19:26,119 --> 01:19:32,180
rows which means you would then be very

1680
01:19:28,430 --> 01:19:34,220
close to doing interaction importance so

1681
01:19:32,180 --> 01:19:35,780
it turns out that that there are

1682
01:19:34,220 --> 01:19:37,699
actually there's actually a very good

1683
01:19:35,779 --> 01:19:40,699
library for interaction importance for

1684
01:19:37,699 --> 01:19:42,949
extra boost but there doesn't seem to be

1685
01:19:40,699 --> 01:19:45,050
one for random forests so you could like

1686
01:19:42,949 --> 01:19:46,939
start by getting it working on our

1687
01:19:45,050 --> 01:19:48,409
version and if you want to do

1688
01:19:46,939 --> 01:19:49,879
interaction importance and then you

1689
01:19:48,409 --> 01:19:53,659
could like get it working on the

1690
01:19:49,880 --> 01:19:56,180
original site SK learn version and that

1691
01:19:53,659 --> 01:19:57,649
would be a cool contribution all right

1692
01:19:56,180 --> 01:19:59,240
like sometimes writing it against your

1693
01:19:57,649 --> 01:20:01,159
own implementation is kind of nicer

1694
01:19:59,239 --> 01:20:03,889
because you can see exactly what's going

1695
01:20:01,159 --> 01:20:05,479
on all right so that's that's your job

1696
01:20:03,890 --> 01:20:07,700
now you don't have to rewrite the random

1697
01:20:05,479 --> 01:20:15,469
forest feel free to if you want to you

1698
01:20:07,699 --> 01:20:19,090
know practice so if you get stuck at any

1699
01:20:15,470 --> 01:20:24,170
point you know ask on the forum right

1700
01:20:19,090 --> 01:20:27,380
there is a whole page here on wiki dot

1701
01:20:24,170 --> 01:20:32,300
fast play I about how to ask for help so

1702
01:20:27,380 --> 01:20:34,430
when you ask your co-workers on slack

1703
01:20:32,300 --> 01:20:36,670
for help when you ask people in a

1704
01:20:34,430 --> 01:20:40,010
technical community on github or

1705
01:20:36,670 --> 01:20:42,260
discourse for help or whatever

1706
01:20:40,010 --> 01:20:45,440
asking for help the right way will go a

1707
01:20:42,260 --> 01:20:47,000
long way towards you know having people

1708
01:20:45,439 --> 01:20:51,889
want to help you and be able to help

1709
01:20:47,000 --> 01:20:53,329
here right so so like search for your

1710
01:20:51,890 --> 01:20:54,770
aunt's like search for the arrow you're

1711
01:20:53,329 --> 01:21:00,949
getting see if somebody's already asked

1712
01:20:54,770 --> 01:21:03,260
about it you know how have you tried to

1713
01:21:00,949 --> 01:21:05,899
fix it already what do you think's going

1714
01:21:03,260 --> 01:21:07,550
wrong what kind of computer are you on

1715
01:21:05,899 --> 01:21:10,519
how is it set up what are the software

1716
01:21:07,550 --> 01:21:12,949
versions exactly what did you type at

1717
01:21:10,520 --> 01:21:19,640
exactly what happened right now you

1718
01:21:12,949 --> 01:21:21,079
could do that by taking a screenshot so

1719
01:21:19,640 --> 01:21:22,520
you know make sure you've got some

1720
01:21:21,079 --> 01:21:24,140
screenshot software that's really easy

1721
01:21:22,520 --> 01:21:27,800
to use so if I were to take a screenshot

1722
01:21:24,140 --> 01:21:28,760
I just hit a button select the area copy

1723
01:21:27,800 --> 01:21:33,470
to clipboard

1724
01:21:28,760 --> 01:21:36,110
go to my forum paste it in and there we

1725
01:21:33,470 --> 01:21:38,780
go right that looks a little bit too big

1726
01:21:36,109 --> 01:21:40,009
so let's make it a little smaller all

1727
01:21:38,779 --> 01:21:42,219
right and so now I've got a screenshot

1728
01:21:40,010 --> 01:21:46,159
people can see exactly what happened

1729
01:21:42,220 --> 01:21:48,110
better still if there's a few lines of

1730
01:21:46,159 --> 01:21:53,409
code and error messages to look at and

1731
01:21:48,109 --> 01:21:56,329
create a gist it just is a handy little

1732
01:21:53,409 --> 01:22:00,079
github thing which basically lets you

1733
01:21:56,329 --> 01:22:06,909
share code so if I wanted to create a

1734
01:22:00,079 --> 01:22:09,319
gist of this I actually have a extension

1735
01:22:06,909 --> 01:22:11,710
area that little extension so if I click

1736
01:22:09,319 --> 01:22:11,710
on here

1737
01:22:12,448 --> 01:22:20,399
give it a name say make public okay and

1738
01:22:17,189 --> 01:22:21,149
that takes my Jupiter notebook shares it

1739
01:22:20,399 --> 01:22:24,029
publicly

1740
01:22:21,149 --> 01:22:27,329
I can then grab that URL copy link

1741
01:22:24,029 --> 01:22:30,619
location right and paste it into my

1742
01:22:27,329 --> 01:22:37,729
forum post right and then when people

1743
01:22:30,619 --> 01:22:42,738
click on it then they'll immediately see

1744
01:22:37,729 --> 01:22:42,738
my notebook when it renders

1745
01:22:42,948 --> 01:22:48,960
okay so that's a really good way now

1746
01:22:46,078 --> 01:22:52,288
that particular button is an extension

1747
01:22:48,960 --> 01:22:56,279
so on Jupiter you need to click end the

1748
01:22:52,288 --> 01:22:58,229
extensions and click on just it right

1749
01:22:56,279 --> 01:22:59,880
while you're there you should also click

1750
01:22:58,229 --> 01:23:01,768
on collapsible headiness that's this

1751
01:22:59,880 --> 01:23:05,069
really handy thing I use that lets me

1752
01:23:01,769 --> 01:23:07,949
collapse things and open them up if you

1753
01:23:05,069 --> 01:23:10,049
go to your Jupiter and don't see this MB

1754
01:23:07,948 --> 01:23:11,939
extensions button then just Google for

1755
01:23:10,050 --> 01:23:14,699
Jupiter and B extensions it'll show you

1756
01:23:11,939 --> 01:23:17,178
how to pip install it and and get it set

1757
01:23:14,698 --> 01:23:20,479
up right where those two extensions are

1758
01:23:17,179 --> 01:23:26,149
SuperDuper handy

1759
01:23:20,479 --> 01:23:30,928
alright so other than that assignment

1760
01:23:26,149 --> 01:23:32,670
where we're done with random forests and

1761
01:23:30,929 --> 01:23:34,380
until the next course when you look at

1762
01:23:32,670 --> 01:23:39,179
gPMs we're done with decision tree

1763
01:23:34,380 --> 01:23:43,578
ensembles and so we're going to move on

1764
01:23:39,179 --> 01:23:48,929
to neural networks broadly defined and

1765
01:23:43,578 --> 01:23:52,710
so Dero networks are going to allow us

1766
01:23:48,929 --> 01:23:54,899
to to go beyond just you know the kind

1767
01:23:52,710 --> 01:23:56,550
of nearest neighbors approach of random

1768
01:23:54,899 --> 01:23:59,009
forests you know all around and forests

1769
01:23:56,550 --> 01:24:02,130
can do is to average data that it's

1770
01:23:59,010 --> 01:24:05,940
already seen it can't extrapolate it

1771
01:24:02,130 --> 01:24:08,940
can't they can't calculate right linear

1772
01:24:05,939 --> 01:24:11,939
regression can calculate and can

1773
01:24:08,939 --> 01:24:15,719
extrapolate but only in very limited

1774
01:24:11,939 --> 01:24:20,908
ways neural nets give us the best of

1775
01:24:15,719 --> 01:24:25,019
both worlds we're going to start by

1776
01:24:20,908 --> 01:24:27,268
applying them to unstructured data all

1777
01:24:25,019 --> 01:24:30,150
right so unstructured data means like

1778
01:24:27,269 --> 01:24:33,869
pixels or the amplitudes of sound waves

1779
01:24:30,149 --> 01:24:38,158
or words you know data where everything

1780
01:24:33,868 --> 01:24:40,889
in all the columns are all the same type

1781
01:24:38,158 --> 01:24:42,808
you know as opposed to like a database

1782
01:24:40,889 --> 01:24:45,690
table where you've got like a revenue

1783
01:24:42,809 --> 01:24:48,989
and a cost and a zip code and a state it

1784
01:24:45,689 --> 01:24:50,759
should be structured data we're going to

1785
01:24:48,988 --> 01:24:51,959
use it for structured data as well but

1786
01:24:50,760 --> 01:24:54,719
we're going to do that a little bit

1787
01:24:51,960 --> 01:24:55,710
later so structured data is a little

1788
01:24:54,719 --> 01:24:57,750
easier and

1789
01:24:55,710 --> 01:25:00,180
it's also the area which more people

1790
01:24:57,750 --> 01:25:02,719
have been applying deep learning to for

1791
01:25:00,180 --> 01:25:02,719
longer

1792
01:25:05,920 --> 01:25:13,190
the if you're doing the deep learning

1793
01:25:10,159 --> 01:25:15,439
course as well you know you'll see that

1794
01:25:13,189 --> 01:25:17,299
we're going to be approaching kind of

1795
01:25:15,439 --> 01:25:19,369
the same conclusion from two different

1796
01:25:17,300 --> 01:25:24,230
directions so the deep learning course

1797
01:25:19,369 --> 01:25:26,300
is starting out with big complicated

1798
01:25:24,229 --> 01:25:28,609
convolutional neural networks being

1799
01:25:26,300 --> 01:25:30,650
solved with you know sophisticated

1800
01:25:28,609 --> 01:25:32,238
optimization schemes and we're going to

1801
01:25:30,649 --> 01:25:35,179
kind of gradually drill down into like

1802
01:25:32,238 --> 01:25:37,789
exactly how they work where else with

1803
01:25:35,180 --> 01:25:40,489
the machine learning course we're going

1804
01:25:37,789 --> 01:25:41,810
to be starting out more with like how

1805
01:25:40,488 --> 01:25:44,750
does stochastic gradient descent

1806
01:25:41,810 --> 01:25:46,970
actually work what do we do what can we

1807
01:25:44,750 --> 01:25:48,738
do is like one single layer which would

1808
01:25:46,970 --> 01:25:52,070
allow us to create things like logistic

1809
01:25:48,738 --> 01:25:54,339
regression when we add regularization to

1810
01:25:52,069 --> 01:25:57,559
that how does that give us things like

1811
01:25:54,340 --> 01:26:00,020
Ridge regression elastic net lasso and

1812
01:25:57,560 --> 01:26:03,170
then as we add additional layers to that

1813
01:26:00,020 --> 01:26:05,840
how does that let us handle more complex

1814
01:26:03,170 --> 01:26:07,940
problems and so we're not going to we're

1815
01:26:05,840 --> 01:26:10,789
only going to be looking at fully

1816
01:26:07,939 --> 01:26:14,809
connected layers in this machine

1817
01:26:10,789 --> 01:26:16,670
learning course and then I think next

1818
01:26:14,810 --> 01:26:18,760
semester with your net you're probably

1819
01:26:16,670 --> 01:26:21,440
going to be looking at some more

1820
01:26:18,760 --> 01:26:22,460
sophisticated approaches and so yeah so

1821
01:26:21,439 --> 01:26:23,779
this machine learning we're going to be

1822
01:26:22,460 --> 01:26:25,430
looking much more at like what's

1823
01:26:23,779 --> 01:26:27,289
actually happening with the matrices and

1824
01:26:25,430 --> 01:26:29,210
how they actually calculated and the

1825
01:26:27,289 --> 01:26:31,659
deep learning it's much more like what

1826
01:26:29,210 --> 01:26:34,819
are the best practices for actually

1827
01:26:31,659 --> 01:26:37,430
solving you know at a world-class level

1828
01:26:34,819 --> 01:26:44,449
real-world deep learning problems right

1829
01:26:37,430 --> 01:26:47,390
so next week we're going to be looking

1830
01:26:44,449 --> 01:26:51,819
at like the classic Emnes problem which

1831
01:26:47,390 --> 01:26:54,440
is like how do we recognize digits now

1832
01:26:51,819 --> 01:26:56,359
if you're interested you can like skip

1833
01:26:54,439 --> 01:26:58,069
ahead and like try and do this with a

1834
01:26:56,359 --> 01:27:00,619
random forest and you'll find it's not

1835
01:26:58,069 --> 01:27:02,329
bad but it given that a random forest is

1836
01:27:00,619 --> 01:27:03,979
basically a type of nearest neighbors

1837
01:27:02,329 --> 01:27:07,909
right it's finding like what are the

1838
01:27:03,979 --> 01:27:09,500
nearest neighbors in entry space then a

1839
01:27:07,909 --> 01:27:13,460
random forest could absolutely recognize

1840
01:27:09,500 --> 01:27:15,439
that this nine those pixels you know are

1841
01:27:13,460 --> 01:27:17,359
similar to pixels we've seen in these

1842
01:27:15,439 --> 01:27:19,339
other ones and on average they were

1843
01:27:17,359 --> 01:27:22,549
nines as well right

1844
01:27:19,340 --> 01:27:25,610
so like it can absolutely solve these

1845
01:27:22,550 --> 01:27:28,639
kinds of problems to an extent using

1846
01:27:25,609 --> 01:27:30,469
random forests but we end up being

1847
01:27:28,639 --> 01:27:33,199
rather data limited because every time

1848
01:27:30,469 --> 01:27:36,109
we put in another decision point you

1849
01:27:33,198 --> 01:27:38,750
know we're having our data roughly and

1850
01:27:36,109 --> 01:27:40,539
so this is this limitation and the

1851
01:27:38,750 --> 01:27:44,270
amount of calculation that we can do

1852
01:27:40,539 --> 01:27:47,090
where else with neural nets we're going

1853
01:27:44,270 --> 01:27:50,330
to be able to use lots and lots and lots

1854
01:27:47,090 --> 01:27:51,289
of parameters using these tricks we

1855
01:27:50,329 --> 01:27:53,448
don't learn about with regularization

1856
01:27:51,289 --> 01:27:55,279
and so we're going to be able to do lots

1857
01:27:53,448 --> 01:27:58,609
of computation and there's got to be

1858
01:27:55,279 --> 01:28:00,349
very little limitation on really what we

1859
01:27:58,609 --> 01:28:03,559
can actually end up calculating as a

1860
01:28:00,349 --> 01:28:05,389
result great good luck with your random

1861
01:28:03,560 --> 01:28:07,719
forest interpretation and I will see you

1862
01:28:05,389 --> 01:28:07,719
next time

