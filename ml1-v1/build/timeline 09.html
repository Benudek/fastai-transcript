<p><strong>Lesson 09</strong></p>
<p>Jeremy starts with a selection of students’ posts.</p>
<ul>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=1s">00:00:01</a> Structuring the Unstructured: a visual demo of Bagging with Random Forests.<br>
<a href="http://structuringtheunstructured.blogspot.se/2017/11/coloring-with-random-forests.html">http://structuringtheunstructured.blogspot.se/2017/11/coloring-with-random-forests.html</a></p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=4m1s">00:04:01</a> Parfit: a library for quick and powerful hyper-parameter optimization with visualizations.<br>
. How to make SGD Classifier perfomr as well as Logistic Regression using Parfit<br>
. Intuitive Interpretation of Random Forest<br>
. Statoil/C-Core Iceberg Classifier Challenge on Kaggle: a Keras Model for Beginners + EDA</p>
</li>
</ul>
<p>Back to the course.</p>
<ul>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=9m1s">00:09:01</a> Why write a post on your learning experience, for you and for newcomers.</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=9m50s">00:09:50</a> Using SGD on MNIST for digit recognition<br>
. lesson4-mnist_sgd.ipynb notebook</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=11m30s">00:11:30</a> Training the simplest Neural Network in PyTorch<br>
(long step-by-step demo, 30 mins approx)</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=46m55s">00:46:55</a> Intro to Broadcasting: “The MOST important programming concept in this course and in Machine Learning”<br>
. Performance comparison between C and Python<br>
. SIMD: “Single Instruction Multiple Data”<br>
. Multiple processors/cores and CUDA</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=52m10s">00:52:10</a> Broadcasting in details</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=1h5m50s">01:05:50</a> Broadcasting goes back to the days of APL (1950’s) and Jsoftware<br>
. More on Broadcasting</p>
</li>
<li>
<p><a href="https://youtu.be/PGC0UxakTvM?t=1h12m30s">01:12:30</a> Matrix Multiplication -and not-.<br>
. Writing our own training loop.</p>
</li>
</ul>




