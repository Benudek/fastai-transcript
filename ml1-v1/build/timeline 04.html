<p><strong>Lesson 04</strong></p>
<ul>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=4s">00:00:04</a> How to deal with version control and notebooks ? Make a copy and rename it with “tmp-blablabla” so it’s hidden from Git Pull</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=1m50s">00:01:50</a> Summarize the relationship between hyperparameters in Random Forests, overfitting and colinearity.<br>
‘set_rf_samples()’, ‘oob_score = True’,<br>
‘min_samples_leaf=’ 8m45s,<br>
‘max_features=’ 12m15s</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=18m50s">00:18:50</a> Random Forest Interpretation lesson2-rf_interpretation,<br>
‘rf_feat_importance()’</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=26m50s">00:26:50</a> ‘to_keep = fi[fi.imp&gt;0.005]’ to remove less important features,<br>
high cardinality variables 29m45s,</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=32m15s">00:32:15</a> Two reasons why Validation Score is not good or getting worse: overfitting, and validation set is not a random sample (something peculiar in it, not in Train),<br>
The meaning of the five numbers results in ‘print_score(m)’, RMSE of Training &amp; Validation, R² of Train &amp; Valid &amp; OOB.<br>
We care about the RMSE of Validation set.</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=35m50s">00:35:50</a> How Feature Importance is normally done in Industry and Academics outside ML: they use Logistic Regression Coefficients, not Random Forests Feature/Variable Importance.</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=39m50s">00:39:50</a> Doing One-hot encoding for categorical variables,<br>
Why and how works ‘max_n_cat=7’ based on Cardinality 49m15s, ‘numericalize’</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=55m5s">00:55:05</a> Removing redundant features using a dendogram and '.spearmanr()'for rank correlation, ‘get_oob(df)’, ‘to_drop = []’ variables,  ‘reset_rf_samples()’</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=1h7m15s">01:07:15</a> Partial dependence: how important features relate to the dependent variable, ‘ggplot() + stat_smooth()’, ‘plot_pdp()’</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=1h21m50s">01:21:50</a> What is the purpose of interpretation, what to do with that information ?</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=1h30m15s">01:30:15</a> What is EROPS / OROPS ?</p>
</li>
<li>
<p><a href="https://youtu.be/0v93qHDqq_g?t=1h32m25s">01:32:25</a> Tree interpreter<br>
<br>
</p>
</li>
</ul>


