1
00:00:00,030 --> 00:00:04,799
okay so welcome back so we're going to

2
00:00:02,009 --> 00:00:09,059
start by doing some review and we're

3
00:00:04,799 --> 00:00:14,609
going to talk about test sets training

4
00:00:09,058 --> 00:00:16,589
sets validation sets and oob something

5
00:00:14,609 --> 00:00:19,019
we haven't covered yet but we will cover

6
00:00:16,589 --> 00:00:20,519
in more detail later is also cross

7
00:00:19,019 --> 00:00:25,879
validation but I'm going to talk about

8
00:00:20,519 --> 00:00:29,820
that as well right so we have a data set

9
00:00:25,879 --> 00:00:34,379
with a bunch of rows in it and we've got

10
00:00:29,820 --> 00:00:37,738
some dependent variable and so what's

11
00:00:34,380 --> 00:00:41,820
the difference between my machine

12
00:00:37,738 --> 00:00:44,280
learning and kind of pretty much any

13
00:00:41,820 --> 00:00:46,020
other kind of work that the the

14
00:00:44,280 --> 00:00:48,359
difference is that in machine learning

15
00:00:46,020 --> 00:00:50,280
the thing we care about is the

16
00:00:48,359 --> 00:00:52,350
generalization accuracy or the

17
00:00:50,280 --> 00:00:55,260
generalization error where else in

18
00:00:52,350 --> 00:00:58,050
pretty much everything else all we care

19
00:00:55,259 --> 00:01:01,079
about is is how well we could have

20
00:00:58,049 --> 00:01:04,198
mapped to the observations all stop and

21
00:01:01,079 --> 00:01:08,099
so this this thing about generalization

22
00:01:04,198 --> 00:01:11,250
is the key unique piece of with machine

23
00:01:08,099 --> 00:01:12,989
learning and so if we want to know

24
00:01:11,250 --> 00:01:14,670
whether we could doing a good job of

25
00:01:12,989 --> 00:01:16,319
machine learning we need to do know

26
00:01:14,670 --> 00:01:19,710
whether we're doing a good job of

27
00:01:16,319 --> 00:01:23,118
generalizing if we don't know that we

28
00:01:19,709 --> 00:01:23,118
know nothing right

29
00:01:25,859 --> 00:01:31,180
by generalizing do you mean like scaling

30
00:01:28,150 --> 00:01:34,049
being able to scale larger no III don't

31
00:01:31,180 --> 00:01:36,729
mean scaling at all so scaling is an

32
00:01:34,049 --> 00:01:38,790
important thing in many many areas it's

33
00:01:36,728 --> 00:01:42,299
like okay we've got something that works

34
00:01:38,790 --> 00:01:45,219
I'm on my computer with ten thousand

35
00:01:42,299 --> 00:01:46,720
items I do need to work make it work on

36
00:01:45,219 --> 00:01:49,509
ten thousand items per second or

37
00:01:46,719 --> 00:01:51,429
something so scaling is important but

38
00:01:49,509 --> 00:01:53,310
not just a machine learning for just

39
00:01:51,430 --> 00:01:57,280
about everything we put in production

40
00:01:53,310 --> 00:02:01,179
generalization is where I say okay here

41
00:01:57,280 --> 00:02:03,700
is a model that can predict cats from

42
00:02:01,179 --> 00:02:05,409
dogs I've looked at five pictures of

43
00:02:03,700 --> 00:02:08,560
cats five pictures of dogs and I've

44
00:02:05,409 --> 00:02:10,569
built a model that is perfect and then I

45
00:02:08,560 --> 00:02:13,030
look at a different set of five cats and

46
00:02:10,568 --> 00:02:14,530
dogs and it gets them all wrong so in

47
00:02:13,030 --> 00:02:16,390
that case when it learned was not a good

48
00:02:14,530 --> 00:02:18,310
Street a cat and a dog that it learned

49
00:02:16,389 --> 00:02:21,369
what those five exact cats looked like

50
00:02:18,310 --> 00:02:25,509
in those five exact dogs the play or I

51
00:02:21,370 --> 00:02:30,159
built a model of predicting grocery

52
00:02:25,509 --> 00:02:34,530
sales for a particular product so for

53
00:02:30,159 --> 00:02:37,419
toilet rolls in New Jersey last month

54
00:02:34,530 --> 00:02:39,640
and then I go and put it into production

55
00:02:37,419 --> 00:02:41,949
and it scales great in other words it

56
00:02:39,639 --> 00:02:45,488
can have the great latency I don't have

57
00:02:41,949 --> 00:02:48,849
a high CPU load but it fails to predict

58
00:02:45,489 --> 00:02:50,680
anything well other than toilet rolls in

59
00:02:48,849 --> 00:02:52,329
New Jersey it also it turns out it only

60
00:02:50,680 --> 00:02:54,599
did it well for last month not the next

61
00:02:52,329 --> 00:03:00,549
month so these are all generalization

62
00:02:54,599 --> 00:03:03,669
failures so the most common way that

63
00:03:00,549 --> 00:03:07,750
people check for the ability to

64
00:03:03,669 --> 00:03:11,159
generalize is to create a random sample

65
00:03:07,750 --> 00:03:18,519
so they'll grab a few rows at random and

66
00:03:11,159 --> 00:03:20,709
pull it out into a test set and then

67
00:03:18,519 --> 00:03:24,009
they'll build all of their models on the

68
00:03:20,709 --> 00:03:27,039
rest of the rows and then when they're

69
00:03:24,009 --> 00:03:29,078
finished they'll check that the accuracy

70
00:03:27,039 --> 00:03:30,400
they got on there so the rest of the

71
00:03:29,079 --> 00:03:33,849
rows are called the training set

72
00:03:30,400 --> 00:03:41,188
everything else everything

73
00:03:33,848 --> 00:03:43,810
else we could call the training set and

74
00:03:41,188 --> 00:03:45,998
so at the end of their modeling process

75
00:03:43,810 --> 00:03:48,549
on the training set they got an accuracy

76
00:03:45,998 --> 00:03:50,199
of 99 percent of predicting cats from

77
00:03:48,549 --> 00:03:52,359
dogs at the very end they check it

78
00:03:50,199 --> 00:03:54,759
against a test set to make sure that the

79
00:03:52,359 --> 00:03:59,260
model really does generalize now the

80
00:03:54,759 --> 00:04:01,090
problem is what if it doesn't right so

81
00:03:59,259 --> 00:04:03,358
okay well I could go back and change

82
00:04:01,090 --> 00:04:05,979
some hyper parameters do some data

83
00:04:03,359 --> 00:04:07,419
augmentation and whatever else try to

84
00:04:05,979 --> 00:04:09,818
create a more generalizable model and

85
00:04:07,419 --> 00:04:12,120
then I'll go back again after doing all

86
00:04:09,818 --> 00:04:14,560
that and check and it's still no good

87
00:04:12,120 --> 00:04:18,608
and I'll keep doing this again and again

88
00:04:14,560 --> 00:04:21,220
until eventually after fifty attempts it

89
00:04:18,608 --> 00:04:23,228
does generalize but does it really

90
00:04:21,220 --> 00:04:25,479
generalize because maybe all I've done

91
00:04:23,228 --> 00:04:27,129
is accidentally found this one which

92
00:04:25,478 --> 00:04:28,439
happens to work just for that test set

93
00:04:27,129 --> 00:04:31,899
because I've tried 50 different things

94
00:04:28,439 --> 00:04:36,639
right and so if I've got something which

95
00:04:31,899 --> 00:04:38,620
is like right coincidentally 0.05 5

96
00:04:36,639 --> 00:04:40,478
percent of the time they're not very

97
00:04:38,620 --> 00:04:44,288
likely to accidentally get a good result

98
00:04:40,478 --> 00:04:49,779
so what we generally do is we put aside

99
00:04:44,288 --> 00:04:53,620
a second data set they'll get a couple

100
00:04:49,779 --> 00:04:55,258
more of these and put these aside into a

101
00:04:53,620 --> 00:04:58,300
validation set

102
00:04:55,259 --> 00:04:59,979
it's an audacious set right and then

103
00:04:58,300 --> 00:05:02,259
everything that's not in the validation

104
00:04:59,978 --> 00:05:04,689
or tests is now training and so what we

105
00:05:02,259 --> 00:05:06,479
do is we train a model check it against

106
00:05:04,689 --> 00:05:09,550
the validation to see if it generalizes

107
00:05:06,478 --> 00:05:11,199
do that a few times and then when we

108
00:05:09,550 --> 00:05:13,120
finally got something we were like okay

109
00:05:11,199 --> 00:05:14,770
we think this generalizes successfully

110
00:05:13,120 --> 00:05:16,209
based on the validation set and then at

111
00:05:14,769 --> 00:05:20,620
the end of the project we check it

112
00:05:16,209 --> 00:05:22,299
against the test set yeah so basically

113
00:05:20,620 --> 00:05:24,218
if I making this two layer test that

114
00:05:22,300 --> 00:05:25,718
validation said if he gets one right the

115
00:05:24,218 --> 00:05:28,360
other one wrong you're kind of

116
00:05:25,718 --> 00:05:30,430
double-checking your errors it's

117
00:05:28,360 --> 00:05:32,620
checking that we have an overfit to the

118
00:05:30,430 --> 00:05:35,590
validation set so if we're using the

119
00:05:32,620 --> 00:05:37,149
validation set again and again then we

120
00:05:35,589 --> 00:05:38,679
could end up not coming up with a

121
00:05:37,149 --> 00:05:40,149
generalizable sort of hyper parameters

122
00:05:38,680 --> 00:05:41,889
and a set of private creditors that just

123
00:05:40,149 --> 00:05:46,429
so happened to work on the training set

124
00:05:41,889 --> 00:05:52,160
and the validation set so so if we

125
00:05:46,430 --> 00:05:54,290
try 50 different models against the

126
00:05:52,160 --> 00:05:55,700
validation set and then at the end of

127
00:05:54,290 --> 00:05:57,980
all that we then check that against the

128
00:05:55,699 --> 00:05:59,539
test set and it's still generalized as

129
00:05:57,980 --> 00:06:00,950
well then we're kind of going to say

130
00:05:59,540 --> 00:06:03,080
okay that's good we've actually come up

131
00:06:00,949 --> 00:06:04,610
with generalizable model if it doesn't

132
00:06:03,079 --> 00:06:05,899
then that's going to say okay we've

133
00:06:04,610 --> 00:06:06,590
actually now overfit to the validation

134
00:06:05,899 --> 00:06:08,479
set

135
00:06:06,589 --> 00:06:12,079
at which point you're kind of in trouble

136
00:06:08,480 --> 00:06:15,259
right because you don't you know you

137
00:06:12,079 --> 00:06:19,099
don't have anything left behind right so

138
00:06:15,259 --> 00:06:21,110
the idea is to use effective techniques

139
00:06:19,100 --> 00:06:22,910
during the modeling so that so that

140
00:06:21,110 --> 00:06:24,020
doesn't happen right but but if it's

141
00:06:22,910 --> 00:06:26,270
going to happen you want to find out

142
00:06:24,019 --> 00:06:27,829
about it like you need that test set to

143
00:06:26,269 --> 00:06:30,829
be there because otherwise when you put

144
00:06:27,829 --> 00:06:32,269
it in production and then it turns out

145
00:06:30,829 --> 00:06:34,189
that it doesn't generalize that would be

146
00:06:32,269 --> 00:06:36,889
a really bad outcome right you end up

147
00:06:34,189 --> 00:06:38,560
with less people clicking on your ads or

148
00:06:36,889 --> 00:06:41,029
selling less with your products or

149
00:06:38,560 --> 00:06:44,810
providing car insurance to very risky

150
00:06:41,029 --> 00:06:47,509
vehicles or whatever so just make sure

151
00:06:44,810 --> 00:06:50,329
to need to ever check if the validation

152
00:06:47,509 --> 00:06:53,899
set and the test antics is coherent or

153
00:06:50,329 --> 00:06:55,250
you just keep tested so if you've done

154
00:06:53,899 --> 00:06:57,439
what I've just done here which is to

155
00:06:55,250 --> 00:06:59,269
randomly sample there's no particular

156
00:06:57,439 --> 00:07:00,980
reason to check as long as there as long

157
00:06:59,269 --> 00:07:03,349
as they're big enough right but we're

158
00:07:00,980 --> 00:07:10,060
going to come back to your question in a

159
00:07:03,350 --> 00:07:10,060
different context in just a moment now

160
00:07:10,680 --> 00:07:15,990
another trick we've learned for renin

161
00:07:12,750 --> 00:07:18,418
forests is a way of not needing a

162
00:07:15,990 --> 00:07:22,129
validation set and the way what we

163
00:07:18,418 --> 00:07:26,579
learnt was to use instead use the oob

164
00:07:22,129 --> 00:07:29,219
era for the OO be scored and so this

165
00:07:26,579 --> 00:07:31,769
idea was to say well every time we train

166
00:07:29,220 --> 00:07:33,570
a tree in a random forest there's a

167
00:07:31,769 --> 00:07:35,758
bunch of observations that are held out

168
00:07:33,569 --> 00:07:38,399
anyway because that's how we get some of

169
00:07:35,759 --> 00:07:41,610
the randomness and so let's calculate

170
00:07:38,399 --> 00:07:43,349
our score for each tree based on those

171
00:07:41,610 --> 00:07:46,288
held out samples and therefore the

172
00:07:43,350 --> 00:07:51,270
forest by averaging the trees that that

173
00:07:46,288 --> 00:07:54,870
each row was not part of training okay

174
00:07:51,269 --> 00:07:58,549
and so the oob score gives us something

175
00:07:54,870 --> 00:08:03,090
which is pretty similar to the

176
00:07:58,550 --> 00:08:06,569
validation score but on average it's a

177
00:08:03,089 --> 00:08:08,489
little less good can anybody either

178
00:08:06,569 --> 00:08:12,569
remember or figure out why on average

179
00:08:08,490 --> 00:08:16,710
it's a little less good quite a subtle

180
00:08:12,569 --> 00:08:19,918
one don't give it to Kenji I'm not sure

181
00:08:16,709 --> 00:08:22,969
but is it because you are treating like

182
00:08:19,918 --> 00:08:26,728
you're doing every kind of probe

183
00:08:22,970 --> 00:08:30,060
pre-processing on your tests and so the

184
00:08:26,728 --> 00:08:32,639
OB score is reflecting the performance

185
00:08:30,060 --> 00:08:34,320
on testing set no for the other piece

186
00:08:32,639 --> 00:08:36,718
because not using the test set at all

187
00:08:34,320 --> 00:08:38,789
the other Peace Corps is using the held

188
00:08:36,719 --> 00:08:41,729
out rows in the training set at page

189
00:08:38,788 --> 00:08:44,580
tree so I mean Z you are basically

190
00:08:41,729 --> 00:08:47,490
testing each tree of some data from Z

191
00:08:44,580 --> 00:08:52,050
training set yes so you are you have the

192
00:08:47,490 --> 00:08:54,180
potential of over feeding with agents it

193
00:08:52,049 --> 00:08:57,269
shouldn't cause overfitting because each

194
00:08:54,179 --> 00:08:59,759
one is looking at a held out sample so

195
00:08:57,269 --> 00:09:00,419
it's not an overfitting issue it's quite

196
00:08:59,759 --> 00:09:05,159
a subtle issue

197
00:09:00,419 --> 00:09:08,129
Enes through never trained aren't this

198
00:09:05,159 --> 00:09:12,569
sample is from OB bootstrap samples they

199
00:09:08,129 --> 00:09:16,169
also then you're never gonna grab 63% of

200
00:09:12,570 --> 00:09:19,140
writes chance to OB is one minus 63

201
00:09:16,169 --> 00:09:21,000
percent exactly yeah both you sure so

202
00:09:19,139 --> 00:09:23,370
then if you know why would the score be

203
00:09:21,000 --> 00:09:23,840
lower than the validation school and

204
00:09:23,370 --> 00:09:25,009
then

205
00:09:23,840 --> 00:09:26,600
that you're leaving sort of like a black

206
00:09:25,009 --> 00:09:27,769
hole in the data that there's like there

207
00:09:26,600 --> 00:09:28,909
two points you're never going to sample

208
00:09:27,769 --> 00:09:30,590
and I'm not gonna be represented by the

209
00:09:28,909 --> 00:09:32,029
model ah no that's not true though

210
00:09:30,590 --> 00:09:33,950
because each tree is looking at a

211
00:09:32,029 --> 00:09:36,439
different set right so that I won't be

212
00:09:33,950 --> 00:09:38,750
so like we've got like I don't know

213
00:09:36,440 --> 00:09:43,640
dozens of models right and a niche one

214
00:09:38,750 --> 00:09:48,129
there's a different set of rows which

215
00:09:43,639 --> 00:09:51,620
which happened to be held out right and

216
00:09:48,129 --> 00:09:54,889
so when we calculate the oeob score for

217
00:09:51,620 --> 00:09:57,080
like let's say row three we say okay row

218
00:09:54,889 --> 00:10:00,019
three is in this tree this tree and

219
00:09:57,080 --> 00:10:02,629
that's it and so we calculate the

220
00:10:00,019 --> 00:10:04,129
prediction on that tree and for that

221
00:10:02,629 --> 00:10:08,210
tree and we'd average those two

222
00:10:04,129 --> 00:10:10,009
predictions and so with enough trees you

223
00:10:08,210 --> 00:10:10,670
know each one has a 30 or so percent

224
00:10:10,009 --> 00:10:12,500
chance

225
00:10:10,669 --> 00:10:14,419
sorry forty or so percent chance that

226
00:10:12,500 --> 00:10:17,120
the row is in that tree so if you have

227
00:10:14,419 --> 00:10:18,529
fifty trees it's almost certain that

228
00:10:17,120 --> 00:10:23,110
every row is going to be mentioned

229
00:10:18,529 --> 00:10:25,669
somewhere did you have an idea term

230
00:10:23,110 --> 00:10:27,860
which relevation said we can use the

231
00:10:25,669 --> 00:10:29,990
whole forest to make the predictions but

232
00:10:27,860 --> 00:10:32,899
here we cannot use the whole forest so

233
00:10:29,990 --> 00:10:36,049
we cannot exactly see exactly so every

234
00:10:32,899 --> 00:10:38,179
road is going to be using a subset of

235
00:10:36,049 --> 00:10:40,849
the trees to make its prediction and

236
00:10:38,179 --> 00:10:43,489
with less trees we know we get a less

237
00:10:40,850 --> 00:10:45,950
accurate prediction so that's that's a

238
00:10:43,490 --> 00:10:49,190
subtle one right and if you didn't get

239
00:10:45,950 --> 00:10:52,700
it have a think during the week until

240
00:10:49,190 --> 00:10:54,560
you understand why this is because it's

241
00:10:52,700 --> 00:10:56,930
a really interesting test of your

242
00:10:54,559 --> 00:11:00,259
understanding of random forests it like

243
00:10:56,929 --> 00:11:02,839
why is our B score on average less good

244
00:11:00,259 --> 00:11:07,610
and your validation is for they're both

245
00:11:02,840 --> 00:11:11,810
using random subnet subsets anyway it's

246
00:11:07,610 --> 00:11:15,620
really close enough right so why have a

247
00:11:11,809 --> 00:11:21,439
validation set at all when you're using

248
00:11:15,620 --> 00:11:23,450
random forests if it's a randomly chosen

249
00:11:21,440 --> 00:11:25,460
validation set it's not strictly

250
00:11:23,450 --> 00:11:27,860
speaking necessary but you know you've

251
00:11:25,460 --> 00:11:29,389
got like four levels of things to test

252
00:11:27,860 --> 00:11:31,610
right so you could like test on the oeob

253
00:11:29,389 --> 00:11:33,710
when that's working well you can test on

254
00:11:31,610 --> 00:11:35,180
the validation set you know and

255
00:11:33,710 --> 00:11:37,150
hopefully by the time you check against

256
00:11:35,179 --> 00:11:39,629
the test set there's going to be

257
00:11:37,149 --> 00:11:43,088
surprises so that'll be one good reason

258
00:11:39,629 --> 00:11:44,500
then what cattle do the way they do this

259
00:11:43,089 --> 00:11:46,300
is kind of clever

260
00:11:44,500 --> 00:11:50,409
while CAG will do is they split the test

261
00:11:46,299 --> 00:11:53,439
set into two pieces a public and a

262
00:11:50,409 --> 00:11:56,230
private and they don't tell you which is

263
00:11:53,440 --> 00:12:00,730
rich so you submit your predictions to

264
00:11:56,230 --> 00:12:02,920
cattle and then a random 30% of those

265
00:12:00,730 --> 00:12:06,580
are used to tell you the leaderboard

266
00:12:02,919 --> 00:12:08,588
score but then at the end of the

267
00:12:06,580 --> 00:12:10,629
competition that gets thrown away and

268
00:12:08,589 --> 00:12:15,250
they use the other 70% to calculate your

269
00:12:10,629 --> 00:12:16,689
real score so what that's doing is that

270
00:12:15,250 --> 00:12:18,639
you're making sure that you're not like

271
00:12:16,690 --> 00:12:20,920
continually using that feedback from the

272
00:12:18,639 --> 00:12:22,960
leaderboard to figure out some set of

273
00:12:20,919 --> 00:12:25,088
hyper parameters that happens to do well

274
00:12:22,960 --> 00:12:28,028
on the public that actually doesn't

275
00:12:25,089 --> 00:12:29,560
generalize okay so it's a great test

276
00:12:28,028 --> 00:12:32,830
like this is one of the reasons why it's

277
00:12:29,559 --> 00:12:34,838
good practice to use cattle because at

278
00:12:32,830 --> 00:12:36,310
the end of a competition at some point

279
00:12:34,839 --> 00:12:38,200
this will happen to you and you'll drop

280
00:12:36,309 --> 00:12:39,639
a hundred places on the leaderboard the

281
00:12:38,200 --> 00:12:42,430
last day of the competition when they

282
00:12:39,639 --> 00:12:44,409
use the private test set and say oh okay

283
00:12:42,429 --> 00:12:46,109
that's what it feels like

284
00:12:44,409 --> 00:12:48,519
to overfit and it's much better to

285
00:12:46,110 --> 00:12:50,769
practice and get that sense there than

286
00:12:48,519 --> 00:12:52,028
it is to do it in a company where

287
00:12:50,769 --> 00:12:57,669
there's hundreds of millions of dollars

288
00:12:52,028 --> 00:13:00,009
on the line okay so this is like the

289
00:12:57,669 --> 00:13:04,389
easiest possible situation where you're

290
00:13:00,009 --> 00:13:09,129
able to use a random sample for your

291
00:13:04,389 --> 00:13:10,958
validation set why might I not be able

292
00:13:09,129 --> 00:13:14,458
to use a random sample from my

293
00:13:10,958 --> 00:13:14,458
validation set or possibly fail

294
00:13:16,179 --> 00:13:19,389
in the case of something where we're

295
00:13:17,409 --> 00:13:22,539
forecasting we can't randomly sample

296
00:13:19,389 --> 00:13:26,110
because we need to maintain the temporal

297
00:13:22,539 --> 00:13:27,879
ordering hello what is that because it

298
00:13:26,110 --> 00:13:31,060
doesn't it doesn't make sense so in the

299
00:13:27,879 --> 00:13:32,919
case of like an ARMA model I can't use

300
00:13:31,059 --> 00:13:36,489
like I can't pull out random rows

301
00:13:32,919 --> 00:13:38,009
because there's I'm thinking that

302
00:13:36,490 --> 00:13:40,360
there's like a certain dependency or I'm

303
00:13:38,009 --> 00:13:42,639
trying to model a certain dependency

304
00:13:40,360 --> 00:13:45,129
that relies on like a specific lag turn

305
00:13:42,639 --> 00:13:47,559
and if I randomly sample those things

306
00:13:45,129 --> 00:13:51,000
then that lag term isn't there for me to

307
00:13:47,559 --> 00:13:54,009
okay so it could be like a technical

308
00:13:51,000 --> 00:13:56,440
modeling issue that like I'm using a

309
00:13:54,009 --> 00:13:58,179
model that relies on like yesterday the

310
00:13:56,440 --> 00:13:59,830
day before and the day before that and

311
00:13:58,179 --> 00:14:01,839
if I randomly removed some things I

312
00:13:59,830 --> 00:14:05,259
don't have yesterday and my model might

313
00:14:01,840 --> 00:14:06,970
just fail okay that's true but there's a

314
00:14:05,259 --> 00:14:10,529
more fundamental issue you want to pass

315
00:14:06,970 --> 00:14:12,430
it to Tyler and it's a really good point

316
00:14:10,529 --> 00:14:14,259
although you know in general we're going

317
00:14:12,429 --> 00:14:16,289
to try to build models that are not

318
00:14:14,259 --> 00:14:21,490
little more resilient than that

319
00:14:16,289 --> 00:14:23,860
particularly with yet temporal order we

320
00:14:21,490 --> 00:14:27,279
expect things that are close by in time

321
00:14:23,860 --> 00:14:33,700
to be related to things close to them so

322
00:14:27,279 --> 00:14:36,669
weeks so we destroy the water like if if

323
00:14:33,700 --> 00:14:38,800
we destroy the order we really aren't

324
00:14:36,669 --> 00:14:41,709
going to be able to use that this time

325
00:14:38,799 --> 00:14:43,779
is close to this other time I don't

326
00:14:41,710 --> 00:14:45,759
think that's true because I can pull out

327
00:14:43,779 --> 00:14:48,000
a random sample for a validation set

328
00:14:45,759 --> 00:14:51,960
and still keep everything nicely ordered

329
00:14:48,000 --> 00:14:56,370
well lame reject things in the future

330
00:14:51,960 --> 00:15:00,070
which we would require as much data

331
00:14:56,370 --> 00:15:02,169
close to the hand alert okay that's true

332
00:15:00,070 --> 00:15:05,050
I mean we could be like limiting the

333
00:15:02,169 --> 00:15:08,469
amount of data that we have by taking

334
00:15:05,049 --> 00:15:10,629
some of it out but my claim is stronger

335
00:15:08,470 --> 00:15:14,379
my claim is that by using a random

336
00:15:10,629 --> 00:15:16,990
validation set we could get totally the

337
00:15:14,379 --> 00:15:23,320
wrong idea about our model Caribou wanna

338
00:15:16,990 --> 00:15:25,960
have a try so if our data is imbalanced

339
00:15:23,320 --> 00:15:27,610
for example we can if you're randomly

340
00:15:25,960 --> 00:15:30,790
sampling it we can only

341
00:15:27,610 --> 00:15:33,370
one class in our validation set so our

342
00:15:30,789 --> 00:15:34,929
fitted model maybe that's true as well

343
00:15:33,370 --> 00:15:36,940
so maybe you're trying to predict in a

344
00:15:34,929 --> 00:15:39,009
medical situation who's going to die of

345
00:15:36,940 --> 00:15:40,990
lung cancer and that's only one out of a

346
00:15:39,009 --> 00:15:43,090
hundred people and we pick out a

347
00:15:40,990 --> 00:15:45,759
validation set that we accidentally have

348
00:15:43,090 --> 00:15:49,480
nobody that died of lung cancer that's

349
00:15:45,759 --> 00:15:52,960
also true these are all good niche

350
00:15:49,480 --> 00:15:55,120
examples but none of them quite say like

351
00:15:52,960 --> 00:15:59,070
why could the validation set just be

352
00:15:55,120 --> 00:16:01,419
plain wrong like give you a totally

353
00:15:59,070 --> 00:16:04,110
inaccurate idea of whether this is going

354
00:16:01,419 --> 00:16:07,299
to generalize and so let's talk about

355
00:16:04,110 --> 00:16:11,800
and the closest is is what Tyler was

356
00:16:07,299 --> 00:16:13,089
saying about time closeness in time the

357
00:16:11,799 --> 00:16:16,329
important thing to remember is when you

358
00:16:13,090 --> 00:16:19,690
build a model you're always you always

359
00:16:16,330 --> 00:16:21,639
have a systematic error which is that

360
00:16:19,690 --> 00:16:23,920
you're going to use the model at a later

361
00:16:21,639 --> 00:16:26,350
time than the time that you built it

362
00:16:23,919 --> 00:16:29,199
right like you're going to put it into

363
00:16:26,350 --> 00:16:31,389
production by which time the world is

364
00:16:29,200 --> 00:16:33,340
different to the world that you're in

365
00:16:31,389 --> 00:16:35,559
now and even when you're building the

366
00:16:33,340 --> 00:16:37,570
model you're using data which is older

367
00:16:35,559 --> 00:16:39,939
than today anyway right so there's some

368
00:16:37,570 --> 00:16:41,860
lag between the data that you're

369
00:16:39,940 --> 00:16:43,570
building it on and the data that it's

370
00:16:41,860 --> 00:16:46,539
going to actually be used on your life

371
00:16:43,570 --> 00:16:49,300
and a lot of the time if not most of the

372
00:16:46,539 --> 00:16:52,329
time that matters right so if we're

373
00:16:49,299 --> 00:16:54,519
doing stuff in like predicting who's

374
00:16:52,330 --> 00:16:57,430
going to buy toilet paper in New Jersey

375
00:16:54,519 --> 00:17:01,000
and it takes us two weeks to put it in

376
00:16:57,429 --> 00:17:02,919
production and we did it using data from

377
00:17:01,000 --> 00:17:05,259
the last couple of years and by that

378
00:17:02,919 --> 00:17:09,029
time you know things may look very

379
00:17:05,259 --> 00:17:11,529
different right and particularly our

380
00:17:09,029 --> 00:17:13,930
validation said if we randomly sampled

381
00:17:11,529 --> 00:17:16,088
it right and it was like from a four

382
00:17:13,930 --> 00:17:17,949
year period then the vast majority of

383
00:17:16,088 --> 00:17:21,759
that data is going to be over a year old

384
00:17:17,949 --> 00:17:24,580
right and it may be that the toilet

385
00:17:21,759 --> 00:17:27,369
buying habits of folks in New Jersey may

386
00:17:24,579 --> 00:17:29,169
have dramatically shifted maybe they've

387
00:17:27,369 --> 00:17:31,989
got a terrible recession there now and

388
00:17:29,170 --> 00:17:35,680
they can't afford a high-quality toilet

389
00:17:31,990 --> 00:17:37,690
paper anymore or maybe they know their

390
00:17:35,680 --> 00:17:39,340
paper making industry has gone through

391
00:17:37,690 --> 00:17:40,600
the roof and suddenly you know they

392
00:17:39,339 --> 00:17:42,819
they're buying what's more toilet paper

393
00:17:40,599 --> 00:17:47,139
because it's so cheap or whatever right

394
00:17:42,819 --> 00:17:49,269
so the world changes and therefore if

395
00:17:47,140 --> 00:17:51,490
you use a random sample for your

396
00:17:49,269 --> 00:17:53,769
validation set then you're actually

397
00:17:51,490 --> 00:17:56,559
checking how good are you at predicting

398
00:17:53,769 --> 00:17:58,599
things that are totally obsolete now but

399
00:17:56,559 --> 00:18:00,669
how good are you at predicting things

400
00:17:58,599 --> 00:18:03,819
that happened four years ago that's not

401
00:18:00,670 --> 00:18:07,840
interesting okay so what we want to do

402
00:18:03,819 --> 00:18:13,210
in practice anytime there's some temper

403
00:18:07,839 --> 00:18:19,449
or peace is to instead say assuming that

404
00:18:13,210 --> 00:18:24,029
we've ordered it by time all right so

405
00:18:19,450 --> 00:18:24,029
this is old and this is new

406
00:18:25,279 --> 00:18:33,139
that's our validation set okay or if we

407
00:18:31,220 --> 00:18:33,558
you know I suppose actually do it

408
00:18:33,140 --> 00:18:36,799
properly

409
00:18:33,558 --> 00:18:42,048
that's how a validation set that's our

410
00:18:36,798 --> 00:18:45,319
test set make sense right so here's that

411
00:18:42,048 --> 00:18:47,839
training set and we use that and we try

412
00:18:45,319 --> 00:18:51,470
and be able to model that still works on

413
00:18:47,839 --> 00:18:53,298
stuff that's later in time than anything

414
00:18:51,470 --> 00:18:56,329
the model was built on and so we're not

415
00:18:53,298 --> 00:18:58,730
just testing generalization in some kind

416
00:18:56,329 --> 00:19:01,009
of abstract sense but in a very specific

417
00:18:58,730 --> 00:19:02,960
time sense which is it generalizes to

418
00:19:01,009 --> 00:19:05,140
the future could you pass it to Suraj

419
00:19:02,960 --> 00:19:05,140
please

420
00:19:07,169 --> 00:19:13,269
so when we are as you said as you said

421
00:19:11,589 --> 00:19:15,999
there is some temporal ordering in the

422
00:19:13,269 --> 00:19:18,099
data so in that case is it wise to take

423
00:19:15,999 --> 00:19:21,548
the entire full data for training or

424
00:19:18,099 --> 00:19:25,199
only a few recent data set for

425
00:19:21,548 --> 00:19:27,759
validation test or training training

426
00:19:25,200 --> 00:19:30,999
yeah that's a whole other question all

427
00:19:27,759 --> 00:19:32,858
right so how do you how do you get the

428
00:19:30,999 --> 00:19:35,440
validation set to be good so I build a

429
00:19:32,858 --> 00:19:38,108
random forest on all the training data

430
00:19:35,440 --> 00:19:41,590
it looks good on the training data it

431
00:19:38,108 --> 00:19:43,418
looks good on the oob right and this is

432
00:19:41,589 --> 00:19:45,699
actually a really good reason to have OB

433
00:19:43,419 --> 00:19:48,220
if it looks good on the OB that it means

434
00:19:45,700 --> 00:19:50,710
you're not overfitting in a statistical

435
00:19:48,220 --> 00:19:54,220
sense right like it's it's working well

436
00:19:50,710 --> 00:19:56,649
on a random sample but then it looks bad

437
00:19:54,220 --> 00:19:58,839
on the validation set so what happened

438
00:19:56,648 --> 00:20:02,258
well what happened was that you you

439
00:19:58,839 --> 00:20:04,628
somehow failed to predict the future

440
00:20:02,259 --> 00:20:06,489
you're only predicted the past and so

441
00:20:04,628 --> 00:20:07,988
Suraj had an idea about how we could fix

442
00:20:06,489 --> 00:20:10,179
that would be okay well maybe we should

443
00:20:07,989 --> 00:20:11,739
just train so like maybe we shouldn't

444
00:20:10,179 --> 00:20:14,919
use the whole training set we should try

445
00:20:11,739 --> 00:20:17,919
a recent period only and now it on the

446
00:20:14,919 --> 00:20:19,960
downside we're now using less data so we

447
00:20:17,919 --> 00:20:22,109
can create less rich models on the

448
00:20:19,960 --> 00:20:25,210
upside it's it's more up-to-date data

449
00:20:22,108 --> 00:20:28,749
and this is something you have to play

450
00:20:25,210 --> 00:20:30,879
around with most machine learning

451
00:20:28,749 --> 00:20:34,538
functions have the ability to provide a

452
00:20:30,878 --> 00:20:36,459
weight that is given to each road solve

453
00:20:34,538 --> 00:20:39,220
for example with a random forest rather

454
00:20:36,460 --> 00:20:41,558
than bootstrapping at random you could

455
00:20:39,220 --> 00:20:42,899
have a weight on every row and randomly

456
00:20:41,558 --> 00:20:46,298
pick that row with some probability

457
00:20:42,898 --> 00:20:50,398
right and we could like say here's our

458
00:20:46,298 --> 00:20:54,069
like probability we could like pick a

459
00:20:50,398 --> 00:20:56,618
curve that looks like that so that the

460
00:20:54,069 --> 00:20:59,048
most recent rows have a higher

461
00:20:56,618 --> 00:21:02,349
probability of being selected that can

462
00:20:59,048 --> 00:21:04,358
work really well yeah it's it's

463
00:21:02,349 --> 00:21:06,579
something that you have to try and and

464
00:21:04,358 --> 00:21:08,589
if you don't have a validation set that

465
00:21:06,579 --> 00:21:10,058
represents the future compared to what

466
00:21:08,589 --> 00:21:11,949
you're training on you have no way to

467
00:21:10,058 --> 00:21:13,898
know which of your techniques are

468
00:21:11,950 --> 00:21:16,690
working how do you make the compromise

469
00:21:13,898 --> 00:21:19,229
between amount of data versus recency of

470
00:21:16,690 --> 00:21:19,230
data

471
00:21:19,430 --> 00:21:25,190
so what I tend to do is is when I have

472
00:21:22,940 --> 00:21:28,340
this kind of temporal issue which is

473
00:21:25,190 --> 00:21:30,019
probably most of the time once I have

474
00:21:28,339 --> 00:21:31,069
something that's working well on the

475
00:21:30,019 --> 00:21:32,900
validation set

476
00:21:31,069 --> 00:21:35,480
I wouldn't then go and just use that

477
00:21:32,900 --> 00:21:38,450
model on the test set because the thing

478
00:21:35,480 --> 00:21:40,009
that I've trained on is now like but you

479
00:21:38,450 --> 00:21:40,580
know the test set is much more in the

480
00:21:40,009 --> 00:21:42,470
future

481
00:21:40,579 --> 00:21:45,319
compared to the training set so I would

482
00:21:42,470 --> 00:21:47,860
then replicate building that model again

483
00:21:45,319 --> 00:21:50,589
but this time I would combine the

484
00:21:47,859 --> 00:21:53,990
training and validation sets together

485
00:21:50,589 --> 00:21:57,589
okay and retrain the model and at that

486
00:21:53,990 --> 00:21:59,480
point you've got no way to test against

487
00:21:57,589 --> 00:22:02,959
a validation set so you have to make

488
00:21:59,480 --> 00:22:04,370
sure you have a reproducible script or

489
00:22:02,960 --> 00:22:07,519
notebook that does exactly the same

490
00:22:04,369 --> 00:22:09,679
steps in exactly the same ways because

491
00:22:07,519 --> 00:22:10,970
if you get something wrong then you're

492
00:22:09,680 --> 00:22:16,009
going to find on the test set that

493
00:22:10,970 --> 00:22:19,100
you've you've got a problem so so what

494
00:22:16,009 --> 00:22:23,150
what I do in practice is I need to know

495
00:22:19,099 --> 00:22:26,359
is my validation set a truly

496
00:22:23,150 --> 00:22:29,780
representative of the test set so what I

497
00:22:26,359 --> 00:22:37,429
do is I build five models on the

498
00:22:29,779 --> 00:22:38,839
training set I build five models on the

499
00:22:37,430 --> 00:22:41,330
training set and I try to have them kind

500
00:22:38,839 --> 00:22:45,139
of vary in how good I think they are

501
00:22:41,329 --> 00:22:49,460
right and then and then I score them my

502
00:22:45,140 --> 00:22:52,610
five models on the validation set all

503
00:22:49,460 --> 00:22:55,160
right and then I also score them on the

504
00:22:52,609 --> 00:22:57,169
test set that so I'm not cheating so I'm

505
00:22:55,160 --> 00:22:59,090
not using any feedback from the test set

506
00:22:57,170 --> 00:23:01,190
to change my hyper parameters I'm only

507
00:22:59,089 --> 00:23:03,349
using it for this one thing which is to

508
00:23:01,190 --> 00:23:08,720
check my validation set so I get my five

509
00:23:03,349 --> 00:23:13,269
scores from the test set and then I

510
00:23:08,720 --> 00:23:16,190
check that they fall in a line okay and

511
00:23:13,269 --> 00:23:17,359
if they don't then you're not going to

512
00:23:16,190 --> 00:23:19,370
get good enough feedback from the

513
00:23:17,359 --> 00:23:22,699
validation set so keep doing that

514
00:23:19,369 --> 00:23:26,199
process until you're getting a line and

515
00:23:22,700 --> 00:23:30,069
that can be quite tricky right sometimes

516
00:23:26,200 --> 00:23:31,960
the the test set you know trying to

517
00:23:30,069 --> 00:23:34,329
create something that's as similar to

518
00:23:31,960 --> 00:23:37,358
the real-world outcome as possible it's

519
00:23:34,329 --> 00:23:39,038
difficult right and when you're it kind

520
00:23:37,358 --> 00:23:40,778
of in the real world the same is true of

521
00:23:39,038 --> 00:23:42,908
creating the test set like the test set

522
00:23:40,778 --> 00:23:46,210
has to be a close to production as

523
00:23:42,909 --> 00:23:47,710
possible so like what's the actual mix

524
00:23:46,210 --> 00:23:49,690
of customers that are going to be using

525
00:23:47,710 --> 00:23:50,980
this how much time is there actually

526
00:23:49,690 --> 00:23:51,940
going to be between when you build the

527
00:23:50,980 --> 00:23:53,710
model and when you put it in production

528
00:23:51,940 --> 00:23:55,419
how often you're going to be able to

529
00:23:53,710 --> 00:23:56,619
refresh the model these are all the

530
00:23:55,419 --> 00:24:02,710
things to think about when you build

531
00:23:56,618 --> 00:24:05,108
that test set okay so you want to say

532
00:24:02,710 --> 00:24:07,899
that first make five models on the

533
00:24:05,108 --> 00:24:10,329
training data yeah and then dilute get a

534
00:24:07,898 --> 00:24:12,038
straight-line relationship change your

535
00:24:10,329 --> 00:24:13,658
validation and death set you can't

536
00:24:12,038 --> 00:24:14,980
really change the test set generally so

537
00:24:13,659 --> 00:24:16,570
this is assuming that the test sets

538
00:24:14,980 --> 00:24:19,569
given it changed to change the

539
00:24:16,569 --> 00:24:21,999
validation set so if you start with a

540
00:24:19,569 --> 00:24:23,200
random sample validation set and then

541
00:24:21,999 --> 00:24:24,368
it's all over the place and you realize

542
00:24:23,200 --> 00:24:26,769
oh I should have picked the last two

543
00:24:24,368 --> 00:24:27,699
months and then you pick the last two

544
00:24:26,769 --> 00:24:29,378
months it's still going all over the

545
00:24:27,700 --> 00:24:30,940
place in your eyes oh I should have

546
00:24:29,378 --> 00:24:32,319
picked it so that's also from the first

547
00:24:30,940 --> 00:24:34,808
of the month to the fifteenth of the

548
00:24:32,319 --> 00:24:37,148
month and they'll keep going until

549
00:24:34,808 --> 00:24:38,678
changing your validation set until you

550
00:24:37,148 --> 00:24:43,108
found a validation set which is

551
00:24:38,679 --> 00:24:43,109
indicative of your test set results

552
00:24:44,119 --> 00:24:49,529
no sort of five models like he was

553
00:24:47,130 --> 00:24:51,570
started maybe like just random data and

554
00:24:49,529 --> 00:24:54,899
average and they just make it their own

555
00:24:51,569 --> 00:24:57,029
yeah yeah yeah yeah maybe a exactly

556
00:24:54,900 --> 00:24:59,070
maybe yeah I kind of five like not

557
00:24:57,029 --> 00:25:00,389
terrible ones but you want some variety

558
00:24:59,069 --> 00:25:03,779
and you also particularly want some

559
00:25:00,390 --> 00:25:05,640
variety and like how well they might

560
00:25:03,779 --> 00:25:07,410
generalize through time so one that was

561
00:25:05,640 --> 00:25:08,850
trained on the whole training set one

562
00:25:07,410 --> 00:25:11,250
that was trained on the last two weeks

563
00:25:08,849 --> 00:25:14,609
one that was trained on the last six

564
00:25:11,250 --> 00:25:16,019
weeks one which used as you know lots

565
00:25:14,609 --> 00:25:18,479
and lots of columns and might have a fit

566
00:25:16,019 --> 00:25:20,789
a bit more yeah so you kind of want to

567
00:25:18,480 --> 00:25:23,880
get a sense of like oh if my validation

568
00:25:20,789 --> 00:25:25,019
set fails to generalize temporarily I'd

569
00:25:23,880 --> 00:25:26,640
want to see that if it fell to

570
00:25:25,019 --> 00:25:29,910
generalize statistically I'd want to see

571
00:25:26,640 --> 00:25:31,410
that sorry can you explain a bit more

572
00:25:29,910 --> 00:25:32,910
detail what you mean by change your

573
00:25:31,410 --> 00:25:35,000
validation set so it indicates the test

574
00:25:32,910 --> 00:25:37,860
set like what does that look like

575
00:25:35,000 --> 00:25:39,599
so posit so let's take the groceries

576
00:25:37,859 --> 00:25:42,119
competition where we're trying to

577
00:25:39,599 --> 00:25:44,699
predict the next two weeks of grocery

578
00:25:42,119 --> 00:25:48,178
sales so possible validation sets that

579
00:25:44,700 --> 00:25:55,769
Terrence and I played with was a random

580
00:25:48,179 --> 00:26:00,960
sample the last month of data the last

581
00:25:55,769 --> 00:26:09,779
two weeks of data and the other one we

582
00:26:00,960 --> 00:26:12,870
tried was same day range one month

583
00:26:09,779 --> 00:26:15,019
earlier so that the test set in this

584
00:26:12,869 --> 00:26:19,379
competition was the first to the 15th of

585
00:26:15,019 --> 00:26:23,039
August sorry if this 15 that maybe the

586
00:26:19,380 --> 00:26:24,990
15 to the 30th of August so we tried

587
00:26:23,039 --> 00:26:29,190
like a random sample as four years we

588
00:26:24,990 --> 00:26:31,710
tried the 15th of July to the 15th of

589
00:26:29,190 --> 00:26:35,400
August we tried the 1st of August to the

590
00:26:31,710 --> 00:26:37,980
15th of August and we tried the 15th of

591
00:26:35,400 --> 00:26:40,048
July to the 30th of July and so there

592
00:26:37,980 --> 00:26:42,630
were four different validation sets we

593
00:26:40,048 --> 00:26:44,639
tried and so with random you know our

594
00:26:42,630 --> 00:26:47,669
kind of results were all over the place

595
00:26:44,640 --> 00:26:50,610
with last month you know they were like

596
00:26:47,669 --> 00:26:51,809
not bad but not great the last two weeks

597
00:26:50,609 --> 00:26:53,729
there was a couple that didn't look good

598
00:26:51,808 --> 00:26:55,099
but on the whole they were good and same

599
00:26:53,730 --> 00:26:56,569
day range of months early

600
00:26:55,099 --> 00:26:58,189
they've got a basically perfect line

601
00:26:56,569 --> 00:27:00,259
that's the part I'm talking right there

602
00:26:58,190 --> 00:27:02,269
what exactly are you comparing it to

603
00:27:00,259 --> 00:27:05,509
from the test site I just confused what

604
00:27:02,269 --> 00:27:08,029
you're creating that graph so for each

605
00:27:05,509 --> 00:27:11,379
of those so for each of my so I build

606
00:27:08,029 --> 00:27:14,389
five models right so there might be like

607
00:27:11,380 --> 00:27:16,220
just predict the average do some kind of

608
00:27:14,390 --> 00:27:17,840
simple group mean of the whole data set

609
00:27:16,220 --> 00:27:19,819
do some group mean over the last month

610
00:27:17,839 --> 00:27:21,349
of the data set build a read on forests

611
00:27:19,819 --> 00:27:23,538
of the whole thing build a random forest

612
00:27:21,349 --> 00:27:26,269
from the last three weeks on each of

613
00:27:23,538 --> 00:27:28,788
those I calculate the validation score

614
00:27:26,269 --> 00:27:30,650
and then I retrain the model on the

615
00:27:28,788 --> 00:27:33,980
whole training set and calculate the

616
00:27:30,650 --> 00:27:36,110
same thing on the test set and so each

617
00:27:33,980 --> 00:27:38,029
of these points now she tells me how

618
00:27:36,109 --> 00:27:40,428
about it ago in the validation set how

619
00:27:38,029 --> 00:27:43,129
well did it go in the test set and so if

620
00:27:40,429 --> 00:27:44,690
the validation set is useful we would

621
00:27:43,130 --> 00:27:47,330
say every time the validation set

622
00:27:44,690 --> 00:27:51,919
improves the test set should also score

623
00:27:47,329 --> 00:27:53,689
should also improve yes so you just said

624
00:27:51,919 --> 00:27:55,788
rate ring dreaming rich rings in

625
00:27:53,690 --> 00:27:57,140
modeling on training and validations

626
00:27:55,788 --> 00:27:58,429
yeah that was a step I was talking about

627
00:27:57,140 --> 00:28:00,650
here so once I've got the validation

628
00:27:58,429 --> 00:28:02,780
score based on just the training set and

629
00:28:00,650 --> 00:28:06,019
then retrain it on the train and

630
00:28:02,779 --> 00:28:14,658
validation and check against history

631
00:28:06,019 --> 00:28:18,679
somebody else so just to clarify my test

632
00:28:14,659 --> 00:28:21,559
set you mean submitting it to kaibaland

633
00:28:18,679 --> 00:28:23,630
and checking the school if it's cattle

634
00:28:21,558 --> 00:28:26,658
then your test set is Carol's

635
00:28:23,630 --> 00:28:28,909
leaderboard in the real world the test

636
00:28:26,659 --> 00:28:32,590
set is this third data set that you put

637
00:28:28,909 --> 00:28:35,419
aside and it's that third data set that

638
00:28:32,589 --> 00:28:38,298
having it reflect real world production

639
00:28:35,419 --> 00:28:41,350
differences is the most important step

640
00:28:38,298 --> 00:28:43,569
in a machine learning project

641
00:28:41,349 --> 00:28:46,449
why is it the most important step

642
00:28:43,569 --> 00:28:49,269
because if you screw up everything else

643
00:28:46,450 --> 00:28:51,970
that you don't screw up that you're no

644
00:28:49,269 --> 00:28:54,730
you screwed up right like if you've got

645
00:28:51,970 --> 00:28:56,048
a good test set then you'll know you

646
00:28:54,730 --> 00:28:57,399
screw it up because you screwed up

647
00:28:56,048 --> 00:28:58,569
something else and you tested it and it

648
00:28:57,398 --> 00:29:00,158
didn't work out and it's like okay

649
00:28:58,569 --> 00:29:02,558
you're not going to destroy the company

650
00:29:00,159 --> 00:29:05,769
right if you screwed up creating the

651
00:29:02,558 --> 00:29:07,359
test set that would be awful right

652
00:29:05,769 --> 00:29:10,000
because then you don't know if you've

653
00:29:07,359 --> 00:29:12,069
made a mistake right you try to build a

654
00:29:10,000 --> 00:29:13,898
model you test it on the test set it

655
00:29:12,069 --> 00:29:19,269
looks good but the test set was not

656
00:29:13,898 --> 00:29:20,678
indicative of real-world environment so

657
00:29:19,269 --> 00:29:22,599
you don't actually know if you better

658
00:29:20,679 --> 00:29:23,980
destroy the company right now hopefully

659
00:29:22,599 --> 00:29:25,509
you've got ways to put things into

660
00:29:23,980 --> 00:29:27,639
production gradually so you won't

661
00:29:25,509 --> 00:29:29,378
actually destroy the company but you'll

662
00:29:27,638 --> 00:29:31,569
at least destroy your reputation at work

663
00:29:29,378 --> 00:29:34,240
right it's like Oh Jeremy tried to put

664
00:29:31,569 --> 00:29:36,250
this thing into production and in the

665
00:29:34,240 --> 00:29:38,230
first week the cohort we tried it on

666
00:29:36,250 --> 00:29:39,730
their sales halved and we're never

667
00:29:38,230 --> 00:29:42,700
better give Jeremy machine-learning job

668
00:29:39,730 --> 00:29:44,620
again right but if Jeremy had used a

669
00:29:42,700 --> 00:29:47,259
proper test set then like he would have

670
00:29:44,619 --> 00:29:49,719
known oh this is like half as good as my

671
00:29:47,259 --> 00:29:51,788
validation set said it would be I'll

672
00:29:49,720 --> 00:29:53,169
keep trying right and now I'm not going

673
00:29:51,788 --> 00:29:55,808
to get in any trouble I was actually

674
00:29:53,169 --> 00:29:58,028
like Oh Jeremy is awesome he identifies

675
00:29:55,808 --> 00:30:08,740
ahead of time when there's going to be a

676
00:29:58,028 --> 00:30:12,609
generalization problem okay so this is

677
00:30:08,740 --> 00:30:14,710
like this is something that kind of

678
00:30:12,609 --> 00:30:17,048
everybody talks about a little bit in

679
00:30:14,710 --> 00:30:19,058
machine learning classes but often it

680
00:30:17,048 --> 00:30:20,648
kind of stops at the point where you

681
00:30:19,058 --> 00:30:23,678
learned that there's a thing in SK learn

682
00:30:20,648 --> 00:30:25,569
called make test trains flipped and it

683
00:30:23,679 --> 00:30:29,048
returns these things and off you go

684
00:30:25,569 --> 00:30:32,250
right but the fact that like or here's

685
00:30:29,048 --> 00:30:35,500
the cross-validation function right so

686
00:30:32,250 --> 00:30:39,240
the fact that these things always give

687
00:30:35,500 --> 00:30:41,919
you random samples tells you that like

688
00:30:39,240 --> 00:30:45,638
much if not most of the time you

689
00:30:41,919 --> 00:30:47,889
shouldn't be using them the fact that

690
00:30:45,638 --> 00:30:50,528
random forest gives you an oo B for free

691
00:30:47,888 --> 00:30:52,750
it's useful but it only tells you that

692
00:30:50,528 --> 00:30:54,210
this generalizes in a statistical sense

693
00:30:52,750 --> 00:30:57,089
not in a practice

694
00:30:54,210 --> 00:31:01,160
since right so then finally there's

695
00:30:57,089 --> 00:31:01,159
cross-validation right which

696
00:31:01,230 --> 00:31:05,039
outside of class you guys have been

697
00:31:02,880 --> 00:31:07,470
talking about a lot which makes me feel

698
00:31:05,039 --> 00:31:10,168
somebody's been over emphasizing the

699
00:31:07,470 --> 00:31:12,900
value of this technique so I'll explain

700
00:31:10,169 --> 00:31:14,610
what cross-validation is and then I

701
00:31:12,900 --> 00:31:17,100
explain why you probably shouldn't be

702
00:31:14,609 --> 00:31:19,469
using it most of the time so cross

703
00:31:17,099 --> 00:31:21,659
validation says let's not just pull out

704
00:31:19,470 --> 00:31:25,230
one validation set but let's pull out

705
00:31:21,660 --> 00:31:27,690
five say so let's assume that we're

706
00:31:25,230 --> 00:31:30,419
going to randomly shuffle the data first

707
00:31:27,690 --> 00:31:32,970
all right this is critical right we

708
00:31:30,419 --> 00:31:37,470
first randomly shuffle the data and then

709
00:31:32,970 --> 00:31:42,600
we're going to split it into five groups

710
00:31:37,470 --> 00:31:46,798
and then for model number one we'll call

711
00:31:42,599 --> 00:31:51,928
this the validation set and we'll call

712
00:31:46,798 --> 00:31:53,490
this the training set okay and we'll

713
00:31:51,929 --> 00:31:56,580
train and we'll check against the

714
00:31:53,490 --> 00:31:59,220
validation and we'll get some rmse R

715
00:31:56,579 --> 00:31:59,899
squared whatever and then we'll throw

716
00:31:59,220 --> 00:32:05,039
that away

717
00:31:59,900 --> 00:32:12,919
and we'll call this the validation set

718
00:32:05,039 --> 00:32:16,289
and we'll call this the training set and

719
00:32:12,919 --> 00:32:21,150
we'll get another score we'll do that

720
00:32:16,289 --> 00:32:27,329
five times and then we'll take the

721
00:32:21,150 --> 00:32:32,009
average okay so that's a

722
00:32:27,329 --> 00:32:34,289
cross-validation average accuracy so who

723
00:32:32,009 --> 00:32:38,039
can tell me like a benefit of using

724
00:32:34,289 --> 00:32:39,869
cross-validation over a the kind of

725
00:32:38,039 --> 00:32:48,960
standard validation set I talked about

726
00:32:39,869 --> 00:32:51,689
before how could you pass the phone if

727
00:32:48,960 --> 00:32:53,610
you have a smokiness an chosen course

728
00:32:51,690 --> 00:32:55,590
validation will make you solve with a

729
00:32:53,609 --> 00:32:57,389
data you have yeah you can use all of

730
00:32:55,589 --> 00:32:59,339
the data you don't have to put anything

731
00:32:57,390 --> 00:33:01,559
aside and you kind of get a little

732
00:32:59,339 --> 00:33:03,298
benefit as well in that like you've now

733
00:33:01,558 --> 00:33:06,089
got five models that you could ensemble

734
00:33:03,298 --> 00:33:07,769
together each one of used which used 80%

735
00:33:06,089 --> 00:33:10,759
of the data so you know sometimes that

736
00:33:07,769 --> 00:33:10,759
ensemble lane can be helpful

737
00:33:11,829 --> 00:33:15,699
I'm fun could you tell me like what what

738
00:33:13,990 --> 00:33:19,180
could be some reasons that you wouldn't

739
00:33:15,700 --> 00:33:22,150
use cross-validation we have enough data

740
00:33:19,180 --> 00:33:25,769
so we don't not want the validations and

741
00:33:22,150 --> 00:33:35,110
to be included in the model trainings

742
00:33:25,769 --> 00:33:36,879
process - - like - okay yeah I'm not

743
00:33:35,109 --> 00:33:39,519
sure the cross-validation is necessarily

744
00:33:36,880 --> 00:33:42,400
polluting the model what would be a key

745
00:33:39,519 --> 00:33:44,829
like downside of cross-validation but

746
00:33:42,400 --> 00:33:48,250
like for deepening if you have learned

747
00:33:44,829 --> 00:33:51,159
them P be chosen as annual Network will

748
00:33:48,250 --> 00:33:54,460
know the pictures it's more likely to

749
00:33:51,160 --> 00:33:57,460
predicative as is right so sure but if

750
00:33:54,460 --> 00:33:58,779
we if we put aside some data each time

751
00:33:57,460 --> 00:34:03,940
in the cross-validation can you pass it

752
00:33:58,779 --> 00:34:05,500
to Suraj I'm not so worried about like I

753
00:34:03,940 --> 00:34:09,789
don't think there's like one of these

754
00:34:05,500 --> 00:34:14,079
validation sets is more statistically

755
00:34:09,789 --> 00:34:17,918
accurate yes Suraj Steven will you be

756
00:34:14,079 --> 00:34:19,509
all fitting together late I think that's

757
00:34:17,918 --> 00:34:20,918
what fun was worried about I don't see

758
00:34:19,510 --> 00:34:24,310
why that would happen like each time

759
00:34:20,918 --> 00:34:26,469
we're fitting a model just 100 each time

760
00:34:24,309 --> 00:34:28,690
we're fitting a model we are absolutely

761
00:34:26,469 --> 00:34:31,480
holding in 20 percent of the sample

762
00:34:28,690 --> 00:34:33,130
right so yes the five models between

763
00:34:31,480 --> 00:34:34,780
them have seen all of the data but but

764
00:34:33,130 --> 00:34:36,429
it's kind of like a random forest

765
00:34:34,780 --> 00:34:38,830
independence is a lot like a random

766
00:34:36,429 --> 00:34:41,410
first each model has only been trained

767
00:34:38,829 --> 00:34:43,659
on a subset of the data yes you should

768
00:34:41,409 --> 00:34:45,699
see please David largely received like

769
00:34:43,659 --> 00:34:48,339
it is deep load of time oh yes exactly

770
00:34:45,699 --> 00:34:50,980
right so we have to fit five models

771
00:34:48,340 --> 00:34:55,440
rather than one so here's a key downside

772
00:34:50,980 --> 00:34:57,789
number one it's time and so if we're

773
00:34:55,440 --> 00:35:00,309
doing deep learning and it takes a day

774
00:34:57,789 --> 00:35:03,250
to run suddenly it takes five days or we

775
00:35:00,309 --> 00:35:05,019
need five GPUs okay

776
00:35:03,250 --> 00:35:07,260
what about my earlier issues about

777
00:35:05,019 --> 00:35:12,820
validation sets Jona pass it over there

778
00:35:07,260 --> 00:35:13,090
what's remaining was a so if you had

779
00:35:12,820 --> 00:35:16,300
like

780
00:35:13,090 --> 00:35:18,430
temporal data wouldn't you be like

781
00:35:16,300 --> 00:35:20,050
shuffling when you e breaking that

782
00:35:18,429 --> 00:35:23,139
relation

783
00:35:20,050 --> 00:35:24,760
well we could unravel it afterwards we

784
00:35:23,139 --> 00:35:26,710
could reorder it like we could shuffle

785
00:35:24,760 --> 00:35:28,900
get the training set out and then sort

786
00:35:26,710 --> 00:35:30,730
it by time

787
00:35:28,900 --> 00:35:34,000
like and like this presumably there's a

788
00:35:30,730 --> 00:35:34,990
date column there so I don't think I

789
00:35:34,000 --> 00:35:44,199
don't think it's going to stop us from

790
00:35:34,989 --> 00:35:46,599
building a model did you have with

791
00:35:44,199 --> 00:35:48,129
cross-validation your building five even

792
00:35:46,599 --> 00:35:49,389
validation sets and if there is some

793
00:35:48,130 --> 00:35:51,010
sort of structure that you're trying to

794
00:35:49,389 --> 00:35:53,230
capture in your validation sets of Mary

795
00:35:51,010 --> 00:35:55,380
your test set you're essentially just

796
00:35:53,230 --> 00:35:59,289
throwing that a chance to construct that

797
00:35:55,380 --> 00:36:00,400
yourself right I think you're gonna say

798
00:35:59,289 --> 00:36:02,769
that I think you said the same thing as

799
00:36:00,400 --> 00:36:05,050
I'm gonna say which is which is that our

800
00:36:02,769 --> 00:36:06,820
earlier concerns about why random

801
00:36:05,050 --> 00:36:08,830
validation sets are a problem are

802
00:36:06,820 --> 00:36:12,640
entirely relevant here well these

803
00:36:08,829 --> 00:36:14,409
validation sets a random so if a random

804
00:36:12,639 --> 00:36:18,009
validation set is not appropriate for

805
00:36:14,409 --> 00:36:21,279
your problem most likely because for

806
00:36:18,010 --> 00:36:22,660
example of temporal issues then none of

807
00:36:21,280 --> 00:36:24,340
these four validation set of five

808
00:36:22,659 --> 00:36:29,170
validation sets are any good they're all

809
00:36:24,340 --> 00:36:32,559
random right and so if you have temporal

810
00:36:29,170 --> 00:36:34,750
data like we did here there's no way to

811
00:36:32,559 --> 00:36:36,009
do cross validation really or like

812
00:36:34,750 --> 00:36:40,210
probably no good way to do cross

813
00:36:36,010 --> 00:36:41,920
validation I mean you're wanna have your

814
00:36:40,210 --> 00:36:44,440
validation set be as close to the test

815
00:36:41,920 --> 00:36:48,960
set as possible and so you can't do that

816
00:36:44,440 --> 00:36:53,769
by randomly sampling different things so

817
00:36:48,960 --> 00:36:55,389
so as fone said you may well not need to

818
00:36:53,769 --> 00:36:57,219
do cross validation because most of the

819
00:36:55,389 --> 00:36:59,650
time in the real world we don't really

820
00:36:57,219 --> 00:37:01,959
have that little data right unless your

821
00:36:59,650 --> 00:37:03,849
data is based on some very very

822
00:37:01,960 --> 00:37:05,559
expensive labeling process or some

823
00:37:03,849 --> 00:37:07,380
experiments that take a look cost a lot

824
00:37:05,559 --> 00:37:10,539
to run or whatever but nowadays that's

825
00:37:07,380 --> 00:37:12,640
data scientists are not very often doing

826
00:37:10,539 --> 00:37:13,300
that kind of work some um in which case

827
00:37:12,639 --> 00:37:15,670
this is an issue

828
00:37:13,300 --> 00:37:19,150
it must have assigned so we probably

829
00:37:15,670 --> 00:37:20,260
don't need to as nishan said if we do do

830
00:37:19,150 --> 00:37:22,990
it it's going to take a whole lot of

831
00:37:20,260 --> 00:37:25,930
time all right and then as earnest said

832
00:37:22,989 --> 00:37:27,459
even if we did do it and we took up all

833
00:37:25,929 --> 00:37:29,259
that time it's like it was totally the

834
00:37:27,460 --> 00:37:30,670
wrong answer because random validation

835
00:37:29,260 --> 00:37:33,340
sets are inappropriate for a problem

836
00:37:30,670 --> 00:37:35,470
okay so I'm not going to be spending

837
00:37:33,340 --> 00:37:37,329
much time on cross validation because I

838
00:37:35,469 --> 00:37:39,939
just I think it's an interesting tool to

839
00:37:37,329 --> 00:37:41,608
have it's easy to use Sosuke learn has a

840
00:37:39,940 --> 00:37:46,499
cross validation thing you can go

841
00:37:41,608 --> 00:37:48,358
ahead and use but it's it's it's not

842
00:37:46,498 --> 00:37:50,368
that often that it's going to be an

843
00:37:48,358 --> 00:37:58,858
important part of your toolbox in my

844
00:37:50,369 --> 00:38:03,150
opinion you'll come up some points okay

845
00:37:58,858 --> 00:38:05,548
so that is validation tips so then the

846
00:38:03,150 --> 00:38:11,818
other thing we started talking about

847
00:38:05,548 --> 00:38:15,028
last week and got a little bit stuck on

848
00:38:11,818 --> 00:38:17,579
because I screwed it up was tree

849
00:38:15,028 --> 00:38:22,048
interpretation so I'm actually going to

850
00:38:17,579 --> 00:38:26,339
cover that again without the error and

851
00:38:22,048 --> 00:38:30,380
dig into it in a bit more detail so can

852
00:38:26,338 --> 00:38:35,719
anybody tell me what tree interpreter

853
00:38:30,380 --> 00:38:35,720
does and how it does it

854
00:38:36,440 --> 00:38:40,470
what do you remember it's a difficult

855
00:38:38,969 --> 00:38:42,568
one to explain I don't think I did a

856
00:38:40,469 --> 00:38:43,889
good job of explaining it so don't worry

857
00:38:42,568 --> 00:38:46,548
if you don't do a great job but does

858
00:38:43,889 --> 00:38:52,199
anybody wanna have a go explaining it

859
00:38:46,548 --> 00:38:55,579
well okay that's fine so let's start

860
00:38:52,199 --> 00:38:59,068
with the output of tree interpreter so

861
00:38:55,579 --> 00:39:03,450
if we look at a single model a single

862
00:38:59,068 --> 00:39:07,940
tree in other words here is a single

863
00:39:03,449 --> 00:39:11,469
tree okay

864
00:39:07,940 --> 00:39:15,740
so to remind us the top of a tree is

865
00:39:11,469 --> 00:39:19,299
before there's been any split at all so

866
00:39:15,739 --> 00:39:23,239
ten point one eight nine is the average

867
00:39:19,300 --> 00:39:26,570
log price of all of the options in our

868
00:39:23,239 --> 00:39:30,079
training set so I'm going to go ahead

869
00:39:26,570 --> 00:39:32,420
and draw right here

870
00:39:30,079 --> 00:39:37,159
ten point one a nine eight nine is the

871
00:39:32,420 --> 00:39:38,659
average of all okay and then if I go a

872
00:39:37,159 --> 00:39:42,829
couple of system less than or equal to

873
00:39:38,659 --> 00:39:48,159
0.5 then I get ten point three four five

874
00:39:42,829 --> 00:39:50,090
okay so for this subset of 16,800

875
00:39:48,159 --> 00:39:51,980
coupler is less than or equal to point

876
00:39:50,090 --> 00:39:56,150
five the average is ten point three four

877
00:39:51,980 --> 00:39:57,769
five and then off the people with a

878
00:39:56,150 --> 00:39:59,990
couple of system less than or equal to

879
00:39:57,769 --> 00:40:01,610
point 5 we then take the subset we're

880
00:39:59,989 --> 00:40:04,849
enclosure at less than or equal to two

881
00:40:01,610 --> 00:40:07,519
and the average there of rob sale price

882
00:40:04,849 --> 00:40:10,549
is nine point nine five five against

883
00:40:07,519 --> 00:40:12,980
nine point nine five and then final step

884
00:40:10,550 --> 00:40:16,400
in our tree

885
00:40:12,980 --> 00:40:18,858
as model ID just for this group with no

886
00:40:16,400 --> 00:40:21,470
capitalist system with enclosed lesson

887
00:40:18,858 --> 00:40:23,269
or - then let's just take model ID less

888
00:40:21,469 --> 00:40:26,899
than or equal to forty five seventy

889
00:40:23,269 --> 00:40:32,090
three and that gives us ten point two

890
00:40:26,900 --> 00:40:34,309
two six okay so then we can say all

891
00:40:32,090 --> 00:40:36,320
right starting with ten point one oh

892
00:40:34,309 --> 00:40:38,119
nine one eight nine average for

893
00:40:36,320 --> 00:40:39,950
everybody in our training set for this

894
00:40:38,119 --> 00:40:44,000
particular tree subsample of twenty

895
00:40:39,949 --> 00:40:47,108
thousand adding in the capital decision

896
00:40:44,000 --> 00:40:50,179
or couple or less than a two point five

897
00:40:47,108 --> 00:40:52,069
increased our prediction by point one

898
00:40:50,179 --> 00:40:54,108
five six so if we predict it with a

899
00:40:52,070 --> 00:40:56,630
naive model of just the mean that would

900
00:40:54,108 --> 00:40:59,269
have been ten point when I known adding

901
00:40:56,630 --> 00:41:01,039
in just the coupler decision would have

902
00:40:59,269 --> 00:41:03,530
changed it to ten point three four five

903
00:41:01,039 --> 00:41:05,840
so this variable is responsible for a

904
00:41:03,530 --> 00:41:08,540
point one five six increase in a

905
00:41:05,840 --> 00:41:11,210
prediction from that the enclosure no

906
00:41:08,539 --> 00:41:14,179
decision was responsible for a - point

907
00:41:11,210 --> 00:41:16,070
three nine five decrease the model ID

908
00:41:14,179 --> 00:41:18,829
was responsible for eight point two

909
00:41:16,070 --> 00:41:21,260
seven six increase until eventually that

910
00:41:18,829 --> 00:41:24,108
was our final decision that is our

911
00:41:21,260 --> 00:41:27,440
prediction for this option of this

912
00:41:24,108 --> 00:41:29,929
particular sale price so we can draw

913
00:41:27,440 --> 00:41:32,059
that as what's called a waterfall block

914
00:41:29,929 --> 00:41:34,519
right and what our four plots are one of

915
00:41:32,059 --> 00:41:37,250
the most useful plots I know about and

916
00:41:34,519 --> 00:41:39,170
weirdly enough there's nothing in Python

917
00:41:37,250 --> 00:41:40,250
to do them and this is one of these

918
00:41:39,170 --> 00:41:42,470
things where there's this disconnect

919
00:41:40,250 --> 00:41:44,239
between like the world of management

920
00:41:42,469 --> 00:41:46,209
consulting and business where everybody

921
00:41:44,239 --> 00:41:49,909
uses water for plots all the time and

922
00:41:46,210 --> 00:41:51,740
like academia who have no idea what

923
00:41:49,909 --> 00:41:56,750
these things are but like every time

924
00:41:51,739 --> 00:41:59,299
like you're looking at say here is last

925
00:41:56,750 --> 00:42:01,340
year's sales for Apple and then there

926
00:41:59,300 --> 00:42:02,300
was a change in that iPhones increased

927
00:42:01,340 --> 00:42:05,180
by this amount

928
00:42:02,300 --> 00:42:06,350
max decreased by that amount and iPads

929
00:42:05,179 --> 00:42:08,449
increased by that amount

930
00:42:06,349 --> 00:42:10,159
every time you have a starting point in

931
00:42:08,449 --> 00:42:12,199
a number of changes and a finishing

932
00:42:10,159 --> 00:42:14,059
point waterfall charts are pretty much

933
00:42:12,199 --> 00:42:16,219
always the best way to show it so here

934
00:42:14,059 --> 00:42:17,799
our prediction for price based on

935
00:42:16,219 --> 00:42:19,969
everything ten point one eight nine

936
00:42:17,800 --> 00:42:23,180
there was an increased blue means

937
00:42:19,969 --> 00:42:26,509
increase of 0.156 the coupler decrease

938
00:42:23,179 --> 00:42:29,389
of 0.395 or enclosure increase

939
00:42:26,510 --> 00:42:32,180
model ID of point two seven six so

940
00:42:29,389 --> 00:42:35,119
decrease but I increase decrease

941
00:42:32,179 --> 00:42:37,549
increase to get to our final ten point

942
00:42:35,119 --> 00:42:41,299
two six six so you see how what a porch

943
00:42:37,550 --> 00:42:43,220
light works so with Excel 2016 its

944
00:42:41,300 --> 00:42:45,560
built-in you just click insert waterfall

945
00:42:43,219 --> 00:42:46,699
chart and there it is if you want to be

946
00:42:45,559 --> 00:42:50,750
a hero

947
00:42:46,699 --> 00:42:52,879
create a waterfall chart package format

948
00:42:50,750 --> 00:42:55,309
plot lab put it on pip and everybody

949
00:42:52,880 --> 00:42:58,869
will love you for it there are some like

950
00:42:55,309 --> 00:43:01,489
really crappy gist's and manual

951
00:42:58,869 --> 00:43:04,339
notebooks and stuff around these are

952
00:43:01,489 --> 00:43:06,709
actually super easy to build like you

953
00:43:04,340 --> 00:43:08,860
basically do a stacked column plot where

954
00:43:06,710 --> 00:43:11,750
the the bottom of this is like all white

955
00:43:08,860 --> 00:43:13,430
right like you can kind of do it but if

956
00:43:11,750 --> 00:43:15,829
you can wrap that up or all and put the

957
00:43:13,429 --> 00:43:17,839
data the points in the right spots and

958
00:43:15,829 --> 00:43:19,279
color them nicely that would be totally

959
00:43:17,840 --> 00:43:21,110
awesome I think you've all got the

960
00:43:19,280 --> 00:43:24,190
skills to do it and would make you know

961
00:43:21,110 --> 00:43:28,550
be a terrific thing for your portfolio

962
00:43:24,190 --> 00:43:30,559
so there's an idea could make an

963
00:43:28,550 --> 00:43:32,300
interesting cattle Colonel even like

964
00:43:30,559 --> 00:43:33,889
here's how to build a waterfall plot can

965
00:43:32,300 --> 00:43:38,900
scratch and by the way I've been putting

966
00:43:33,889 --> 00:43:40,969
this up on yep you can all use it so in

967
00:43:38,900 --> 00:43:42,710
general therefore obviously going from

968
00:43:40,969 --> 00:43:45,919
the all and then going through each

969
00:43:42,710 --> 00:43:48,380
change then the some both all of those

970
00:43:45,920 --> 00:43:52,159
is going to be equal to the final

971
00:43:48,380 --> 00:43:54,230
prediction so that's how we could say if

972
00:43:52,159 --> 00:43:55,759
we were just doing a decision tree then

973
00:43:54,230 --> 00:43:58,550
you know you're coming along and saying

974
00:43:55,760 --> 00:44:00,980
like how come this particular option was

975
00:43:58,550 --> 00:44:02,810
this particular price and it's like well

976
00:44:00,980 --> 00:44:05,329
your prediction for it and like oh it's

977
00:44:02,809 --> 00:44:08,239
because of these three things had these

978
00:44:05,329 --> 00:44:11,480
three impacts right so for a random

979
00:44:08,239 --> 00:44:13,459
forest we could do that across all of

980
00:44:11,480 --> 00:44:16,429
the trees right so every time we see

981
00:44:13,460 --> 00:44:17,840
coupler we add up that change every time

982
00:44:16,429 --> 00:44:20,029
we see enclosure we add up that

983
00:44:17,840 --> 00:44:22,610
change every time we see model we add up

984
00:44:20,030 --> 00:44:26,870
that change okay and so then we combine

985
00:44:22,610 --> 00:44:28,880
them all together we get what tree

986
00:44:26,869 --> 00:44:30,109
interpreter does right so you could go

987
00:44:28,880 --> 00:44:32,180
into the source code for tree

988
00:44:30,110 --> 00:44:33,680
interpreter right and it's not at all

989
00:44:32,179 --> 00:44:37,730
complex logic or you could build it

990
00:44:33,679 --> 00:44:39,980
yourself and you can see how it does

991
00:44:37,730 --> 00:44:42,740
exactly this so when you go tree and

992
00:44:39,980 --> 00:44:45,710
predict with a random forest model for

993
00:44:42,739 --> 00:44:49,419
some specific option so I've got a

994
00:44:45,710 --> 00:44:52,519
specific row here this my zero index row

995
00:44:49,420 --> 00:44:55,180
it tells you okay this is the prediction

996
00:44:52,519 --> 00:44:57,949
the same as the random forest prediction

997
00:44:55,179 --> 00:45:01,579
bias this is going to be always the same

998
00:44:57,949 --> 00:45:04,129
it's the average sale price for for

999
00:45:01,579 --> 00:45:09,130
everybody for each of the random samples

1000
00:45:04,130 --> 00:45:12,380
in the tree and then contributions is

1001
00:45:09,130 --> 00:45:14,809
the average of all so the total of all

1002
00:45:12,380 --> 00:45:18,858
our contributions for each time we see

1003
00:45:14,809 --> 00:45:21,980
that specific column appear in a tree

1004
00:45:18,858 --> 00:45:23,539
right so last time I made the mistake of

1005
00:45:21,980 --> 00:45:26,289
not sorting this correctly so this time

1006
00:45:23,539 --> 00:45:29,210
MP dot arc sort is a super handy

1007
00:45:26,289 --> 00:45:32,840
function at sorts it doesn't actually

1008
00:45:29,210 --> 00:45:36,289
sort contribution zero it just tells you

1009
00:45:32,840 --> 00:45:39,289
where each item would move to if it were

1010
00:45:36,289 --> 00:45:47,349
sorted so now by passing ID access to

1011
00:45:39,289 --> 00:45:50,358
each one of the column the level

1012
00:45:47,349 --> 00:45:52,789
contribution I can then print out all

1013
00:45:50,358 --> 00:45:56,779
those in the right order so I can see

1014
00:45:52,789 --> 00:46:00,019
here here's my column here's the level

1015
00:45:56,780 --> 00:46:02,930
and the contribution so the fact that

1016
00:46:00,019 --> 00:46:04,400
it's a small version of this piece of

1017
00:46:02,929 --> 00:46:07,190
industrial equipment meant that it was

1018
00:46:04,400 --> 00:46:09,530
less expensive right but the fact that

1019
00:46:07,190 --> 00:46:11,960
was made pretty recently meant that was

1020
00:46:09,530 --> 00:46:13,730
more expensive the fact that it's pretty

1021
00:46:11,960 --> 00:46:16,960
old however made that it was less

1022
00:46:13,730 --> 00:46:19,639
expensive right so this is not going to

1023
00:46:16,960 --> 00:46:21,559
really help you much at all with like a

1024
00:46:19,639 --> 00:46:23,839
cattle styled situation where you just

1025
00:46:21,559 --> 00:46:26,239
need predictions it's going to help you

1026
00:46:23,840 --> 00:46:27,950
a lot in a production environment or

1027
00:46:26,239 --> 00:46:30,559
even pre production right so like

1028
00:46:27,949 --> 00:46:32,029
something which any good manager should

1029
00:46:30,559 --> 00:46:33,529
you should do if you say here's a

1030
00:46:32,030 --> 00:46:36,560
machine learning model I think we should

1031
00:46:33,530 --> 00:46:39,050
use as they should go away and grab a

1032
00:46:36,559 --> 00:46:42,259
few examples of actual customers or

1033
00:46:39,050 --> 00:46:44,630
actual options or whatever and check

1034
00:46:42,260 --> 00:46:46,970
whether your model looks intuitive

1035
00:46:44,630 --> 00:46:52,630
alright and if it says like my

1036
00:46:46,969 --> 00:46:55,559
prediction is that you know lots of

1037
00:46:52,630 --> 00:46:58,119
if people are going to really enjoy this

1038
00:46:55,559 --> 00:46:59,590
crappy movie you know it is like wow

1039
00:46:58,119 --> 00:47:00,730
that was a really crappy movie then

1040
00:46:59,590 --> 00:47:03,610
they're going to come back to you and

1041
00:47:00,730 --> 00:47:07,420
say like explain why your models telling

1042
00:47:03,610 --> 00:47:09,010
me that I'm going to like this movie

1043
00:47:07,420 --> 00:47:10,119
because I hate that movie and then you

1044
00:47:09,010 --> 00:47:12,400
can go back and you say well it's

1045
00:47:10,119 --> 00:47:14,259
because you like this movie and because

1046
00:47:12,400 --> 00:47:16,599
you're this age range and you're this

1047
00:47:14,260 --> 00:47:21,960
gender on average actually people like

1048
00:47:16,599 --> 00:47:21,960
you did like that movie okay yeah

1049
00:47:24,980 --> 00:47:31,608
what's the second element of each temple

1050
00:47:28,820 --> 00:47:35,519
this is saying for this particular row

1051
00:47:31,608 --> 00:47:38,608
it was a mini and it was 11 years old

1052
00:47:35,519 --> 00:47:42,599
and it was a hydraulic excavator track 3

1053
00:47:38,608 --> 00:47:45,358
to 4 metric tons so it's just feeding

1054
00:47:42,599 --> 00:47:47,699
back and telling you it's because this

1055
00:47:45,358 --> 00:47:51,690
is actually what it was it was these

1056
00:47:47,699 --> 00:47:55,759
numbers so I just went back to the

1057
00:47:51,690 --> 00:48:03,079
original data to actually pull out the

1058
00:47:55,760 --> 00:48:05,430
descriptive versions of each one okay so

1059
00:48:03,079 --> 00:48:11,989
if we sum up all the contributions

1060
00:48:05,429 --> 00:48:14,549
together and then add them to the bias

1061
00:48:11,989 --> 00:48:18,029
then that would be the same as adding up

1062
00:48:14,550 --> 00:48:20,940
those three things adding it to this and

1063
00:48:18,030 --> 00:48:27,140
as we know from our waterfall chart that

1064
00:48:20,940 --> 00:48:29,760
gives us our final prediction this is a

1065
00:48:27,139 --> 00:48:34,440
almost totally unknown technique and

1066
00:48:29,760 --> 00:48:37,320
this particular library is almost

1067
00:48:34,440 --> 00:48:40,230
totally unknown as well so like it's a

1068
00:48:37,320 --> 00:48:42,090
great opportunity to you know show

1069
00:48:40,230 --> 00:48:45,630
something that a lot of people like it's

1070
00:48:42,090 --> 00:48:49,579
totally critical in my opinion but but

1071
00:48:45,630 --> 00:48:49,579
rarely none so that's

1072
00:48:51,588 --> 00:48:54,739
that's kind of the end of the random

1073
00:48:52,998 --> 00:48:56,808
forest interpretation piece and

1074
00:48:54,739 --> 00:48:59,539
hopefully you've now seen enough that

1075
00:48:56,809 --> 00:49:00,950
when somebody says we can't use modern

1076
00:48:59,539 --> 00:49:01,940
machine learning techniques because

1077
00:49:00,949 --> 00:49:03,439
they're black boxes that are

1078
00:49:01,940 --> 00:49:05,269
interpretive all you have enough

1079
00:49:03,440 --> 00:49:08,179
information to say you're full of

1080
00:49:05,268 --> 00:49:09,978
right like they're extremely

1081
00:49:08,179 --> 00:49:11,690
interpretable and the stuff that we've

1082
00:49:09,978 --> 00:49:13,968
just done you know trying to do that

1083
00:49:11,690 --> 00:49:15,528
with a linear model good luck to you you

1084
00:49:13,969 --> 00:49:17,239
know even where you can do something

1085
00:49:15,528 --> 00:49:18,829
similar with a linear model trying to do

1086
00:49:17,239 --> 00:49:20,690
it so that's not giving you totally the

1087
00:49:18,829 --> 00:49:22,249
wrong answer and you had no idea it's a

1088
00:49:20,690 --> 00:49:26,239
wrong answer it's going to be a real

1089
00:49:22,248 --> 00:49:28,129
challenge so the last step we're going

1090
00:49:26,239 --> 00:49:31,099
to do before we try and build up our own

1091
00:49:28,130 --> 00:49:34,869
random forest is deal with this tricky

1092
00:49:31,099 --> 00:49:41,960
issue of extrapolation so in this case

1093
00:49:34,869 --> 00:49:45,818
if we look at our tree let's look at the

1094
00:49:41,960 --> 00:49:45,818
accuracy of our most recent trees

1095
00:49:49,119 --> 00:49:57,528
we still have you know a big difference

1096
00:49:53,268 --> 00:50:04,068
between our validation score and our

1097
00:49:57,528 --> 00:50:07,579
training score the actually in this case

1098
00:50:04,068 --> 00:50:10,548
it's not too bad that the difference

1099
00:50:07,579 --> 00:50:13,099
between the oob and the validation is

1100
00:50:10,548 --> 00:50:14,989
actually pretty close so if there was a

1101
00:50:13,099 --> 00:50:17,509
big difference between validation and

1102
00:50:14,989 --> 00:50:19,248
olb like I'd be very worried about that

1103
00:50:17,509 --> 00:50:24,440
we've dealt with the temporal side of

1104
00:50:19,248 --> 00:50:27,318
things correctly let's just have a look

1105
00:50:24,440 --> 00:50:29,900
at I think the most recent model here it

1106
00:50:27,318 --> 00:50:34,400
was yeah so there's a tiny difference

1107
00:50:29,900 --> 00:50:36,889
right and so on Tagle at least you kind

1108
00:50:34,400 --> 00:50:39,349
of need that last decimal place in the

1109
00:50:36,889 --> 00:50:40,518
real world I probably stopped here but

1110
00:50:39,349 --> 00:50:42,170
quite often you'll see there's a big

1111
00:50:40,518 --> 00:50:44,118
difference between your validation score

1112
00:50:42,170 --> 00:50:47,048
and your OB score now I will show you

1113
00:50:44,119 --> 00:50:47,048
how you would deal with that

1114
00:50:47,289 --> 00:50:51,049
particularly because actually we know

1115
00:50:49,039 --> 00:50:53,269
that the the oeob should be a little

1116
00:50:51,048 --> 00:50:54,619
worse because it's using this less trees

1117
00:50:53,268 --> 00:50:56,659
so it gives me a sense that we should

1118
00:50:54,619 --> 00:50:58,519
get to do a little bit better and so the

1119
00:50:56,659 --> 00:51:00,318
reason we the way we should be able to a

1120
00:50:58,518 --> 00:51:05,348
little bit better is by handling the

1121
00:51:00,318 --> 00:51:08,538
time component a little bit better so

1122
00:51:05,349 --> 00:51:14,079
here's the problem with random forests

1123
00:51:08,539 --> 00:51:14,079
when it comes to extrapolation when you

1124
00:51:14,259 --> 00:51:19,759
when you've got a data set that's like

1125
00:51:17,690 --> 00:51:22,099
you know four got four years of sales

1126
00:51:19,759 --> 00:51:26,298
data in it and you create your tree

1127
00:51:22,099 --> 00:51:28,880
right and it says like oh if these if

1128
00:51:26,298 --> 00:51:31,670
it's in some particular store and at

1129
00:51:28,880 --> 00:51:35,028
some particular item and it is on

1130
00:51:31,670 --> 00:51:37,818
special you know here's the average

1131
00:51:35,028 --> 00:51:40,009
price and it actually tells us the

1132
00:51:37,818 --> 00:51:42,409
average price you know over the whole

1133
00:51:40,009 --> 00:51:47,088
training set which could be pretty old

1134
00:51:42,409 --> 00:51:48,710
right and so when you then want to step

1135
00:51:47,088 --> 00:51:51,980
forwards like what's going to be the

1136
00:51:48,710 --> 00:51:54,079
price next month it's never seen next

1137
00:51:51,980 --> 00:51:56,210
month and and where else with a kind of

1138
00:51:54,079 --> 00:51:58,489
a linear model it can find a

1139
00:51:56,210 --> 00:52:00,710
relationship between time and price

1140
00:51:58,489 --> 00:52:01,130
where even though we only had this much

1141
00:52:00,710 --> 00:52:02,990
day

1142
00:52:01,130 --> 00:52:05,019
when you then go and predict something

1143
00:52:02,989 --> 00:52:07,459
in the future it can extrapolate that

1144
00:52:05,018 --> 00:52:09,078
but a random forest can't do that

1145
00:52:07,460 --> 00:52:11,690
there's no wave if you think about it

1146
00:52:09,079 --> 00:52:14,359
for a tree to be able to say well next

1147
00:52:11,690 --> 00:52:16,670
month it would be higher still so

1148
00:52:14,358 --> 00:52:18,048
there's a few ways to deal with this and

1149
00:52:16,670 --> 00:52:20,630
we'll talk about it over the next couple

1150
00:52:18,048 --> 00:52:27,288
of lessons but one simple way is just to

1151
00:52:20,630 --> 00:52:29,420
try to avoid using time variables as

1152
00:52:27,289 --> 00:52:31,130
predictors if there's something else we

1153
00:52:29,420 --> 00:52:31,759
could use that's going to give us a

1154
00:52:31,130 --> 00:52:33,259
better

1155
00:52:31,759 --> 00:52:35,240
you know something that kind of a

1156
00:52:33,259 --> 00:52:37,909
stronger relationship that's actually

1157
00:52:35,239 --> 00:52:42,048
going to work in the future so in this

1158
00:52:37,909 --> 00:52:44,558
case what I wanted to do was to first of

1159
00:52:42,048 --> 00:52:44,559
all figure out

1160
00:52:47,429 --> 00:52:52,558
what's the difference between our

1161
00:52:49,679 --> 00:52:54,088
validation set and our training set like

1162
00:52:52,559 --> 00:52:55,800
if I understand that difference between

1163
00:52:54,088 --> 00:52:58,650
our validation set and our training set

1164
00:52:55,800 --> 00:53:01,109
then that tells me what are the

1165
00:52:58,650 --> 00:53:03,838
predictors which which have a strong

1166
00:53:01,108 --> 00:53:07,170
temporal component and therefore they

1167
00:53:03,838 --> 00:53:09,779
may be irrelevant by the time I get to

1168
00:53:07,170 --> 00:53:11,970
the future time period so I do something

1169
00:53:09,780 --> 00:53:15,390
really interesting which is I create a

1170
00:53:11,969 --> 00:53:20,689
random forest where my dependent

1171
00:53:15,389 --> 00:53:22,400
variable is is it in the validation set

1172
00:53:20,690 --> 00:53:24,318
right so I've gone back and I've got my

1173
00:53:22,400 --> 00:53:27,349
whole data frame with the training and

1174
00:53:24,318 --> 00:53:30,349
validation altogether and I've created a

1175
00:53:27,349 --> 00:53:33,588
new column Court is valid which I've set

1176
00:53:30,349 --> 00:53:36,140
to one and then for all of the stuff in

1177
00:53:33,588 --> 00:53:37,969
the training set I set it to zero that's

1178
00:53:36,139 --> 00:53:40,338
about a new column which is just is this

1179
00:53:37,969 --> 00:53:42,529
in the validation set or not and then

1180
00:53:40,338 --> 00:53:46,068
I'm going to use that as my dependent

1181
00:53:42,530 --> 00:53:47,930
variable and build a random first so

1182
00:53:46,068 --> 00:53:50,659
this is a random forest not to predict

1183
00:53:47,929 --> 00:53:53,919
price that protect is this in the

1184
00:53:50,659 --> 00:53:57,409
validation set or not and so if your

1185
00:53:53,920 --> 00:53:58,789
variables were not time dependent then

1186
00:53:57,409 --> 00:54:00,139
it shouldn't be possible to figure out

1187
00:53:58,789 --> 00:54:02,450
if something's in the validation set or

1188
00:54:00,139 --> 00:54:06,230
not this is a great trick in cattle

1189
00:54:02,449 --> 00:54:08,629
records in cattle they often won't tell

1190
00:54:06,230 --> 00:54:11,568
you whether the test set is a random

1191
00:54:08,630 --> 00:54:13,970
sample or not so you could put the test

1192
00:54:11,568 --> 00:54:16,219
set and the training set together create

1193
00:54:13,969 --> 00:54:18,889
a new column called is test and see if

1194
00:54:16,219 --> 00:54:20,808
you can predict it if you can you don't

1195
00:54:18,889 --> 00:54:22,308
have a random sample which means you

1196
00:54:20,809 --> 00:54:25,369
have to come and figure out how to

1197
00:54:22,309 --> 00:54:27,769
create a validation set from it right

1198
00:54:25,369 --> 00:54:29,028
and so in this case I can see I don't

1199
00:54:27,769 --> 00:54:31,358
have a random sample because my

1200
00:54:29,028 --> 00:54:33,309
validation set can be predicted with a

1201
00:54:31,358 --> 00:54:37,519
0.9999

1202
00:54:33,309 --> 00:54:39,890
r-squared and so then if I look at

1203
00:54:37,519 --> 00:54:42,019
future importance the top thing is sales

1204
00:54:39,889 --> 00:54:44,538
ID and so this is really interesting it

1205
00:54:42,019 --> 00:54:47,269
tells us very clearly sales ID is not a

1206
00:54:44,539 --> 00:54:49,819
random identifier but probably it's

1207
00:54:47,269 --> 00:54:52,278
something that's just set consecutively

1208
00:54:49,818 --> 00:54:55,788
as time goes on we just increase the

1209
00:54:52,278 --> 00:54:58,608
sales ID so elapsed that was the number

1210
00:54:55,789 --> 00:55:01,010
of days since the first date in our data

1211
00:54:58,608 --> 00:55:05,288
set so not surprisingly that also is a

1212
00:55:01,010 --> 00:55:07,640
good predictor interestingly machine ID

1213
00:55:05,289 --> 00:55:09,770
clearly each machine is being labeled

1214
00:55:07,639 --> 00:55:12,528
with some consecutive identifier as well

1215
00:55:09,769 --> 00:55:14,778
and then there's a big don't just look

1216
00:55:12,528 --> 00:55:19,460
at the order look at the value so 0.7

1217
00:55:14,778 --> 00:55:21,019
0.1 0.0 7.00 - okay stop right these top

1218
00:55:19,460 --> 00:55:23,269
three are hundreds of times more

1219
00:55:21,019 --> 00:55:27,980
important than the rest right so let's

1220
00:55:23,269 --> 00:55:31,889
next grab those top three right and we

1221
00:55:27,980 --> 00:55:35,039
can then have a look at their values

1222
00:55:31,889 --> 00:55:37,259
both from the training set and in the

1223
00:55:35,039 --> 00:55:40,949
validation set and so we can see for

1224
00:55:37,260 --> 00:55:43,950
example sales ID on average is divided

1225
00:55:40,949 --> 00:55:47,879
by thousand on averages 1.8 million in

1226
00:55:43,949 --> 00:55:49,529
the training set and 5.8 million in the

1227
00:55:47,880 --> 00:55:52,230
validation set right so you'd like you

1228
00:55:49,530 --> 00:55:56,640
can see just confirm like okay they're

1229
00:55:52,230 --> 00:55:59,159
very different so let's drop them okay

1230
00:55:56,639 --> 00:56:00,299
so after I drop them let's now see if I

1231
00:55:59,159 --> 00:56:03,349
can predict whether something's in the

1232
00:56:00,300 --> 00:56:06,539
validation set I still can with 0.98

1233
00:56:03,349 --> 00:56:08,789
pass quit

1234
00:56:06,539 --> 00:56:10,619
so once you remove some things then

1235
00:56:08,789 --> 00:56:12,210
other things can like come to the front

1236
00:56:10,619 --> 00:56:15,780
and it now turns out okay that's not

1237
00:56:12,210 --> 00:56:20,220
surprisingly age you know things that

1238
00:56:15,780 --> 00:56:22,710
are old are you know more likely I guess

1239
00:56:20,219 --> 00:56:24,000
to be in the validation set because

1240
00:56:22,710 --> 00:56:26,030
there's you know earlier on in the

1241
00:56:24,000 --> 00:56:32,570
training set yet they can't be old yeah

1242
00:56:26,030 --> 00:56:32,570
yeah made same reason so then we can

1243
00:56:35,900 --> 00:56:39,550
try removing those as well

1244
00:56:40,539 --> 00:56:46,269
and so once we let's see where do we go

1245
00:56:43,568 --> 00:56:47,949
up here yeah so what we can try doing is

1246
00:56:46,268 --> 00:56:50,379
we can then say alright let's take the

1247
00:56:47,949 --> 00:56:54,278
saleslady so let's machine ID from the

1248
00:56:50,380 --> 00:56:56,140
first one the age year made sale day of

1249
00:56:54,278 --> 00:57:02,349
year from the second one and say okay

1250
00:56:56,139 --> 00:57:04,989
these are all time dependent features so

1251
00:57:02,349 --> 00:57:07,838
I still want them in my random forest if

1252
00:57:04,989 --> 00:57:10,418
they're important right but if they're

1253
00:57:07,838 --> 00:57:11,978
not important then taking them out if

1254
00:57:10,418 --> 00:57:14,228
there are some other long-term dependent

1255
00:57:11,978 --> 00:57:16,598
variables that that work just as well

1256
00:57:14,228 --> 00:57:17,379
that would be better right because now

1257
00:57:16,599 --> 00:57:19,539
I'm going to have a model that

1258
00:57:17,380 --> 00:57:20,439
generalizes over time better so here I'm

1259
00:57:19,539 --> 00:57:23,259
just going to go ahead and go through

1260
00:57:20,438 --> 00:57:26,828
each one of those features and drop each

1261
00:57:23,259 --> 00:57:29,489
one one at a time okay retrain a new

1262
00:57:26,829 --> 00:57:32,469
random forest and print out the score

1263
00:57:29,489 --> 00:57:35,349
okay so before we do any of that our

1264
00:57:32,469 --> 00:57:40,110
score was

1265
00:57:35,349 --> 00:57:44,289
point eight eight for our validation

1266
00:57:40,110 --> 00:57:48,280
versus point eight 900 B and you can see

1267
00:57:44,289 --> 00:57:51,460
here when I remove sales ID my score

1268
00:57:48,280 --> 00:57:53,350
goes up and this this is like what we're

1269
00:57:51,460 --> 00:57:55,059
hoping for we've removed a time

1270
00:57:53,349 --> 00:57:56,799
dependent variable there were other

1271
00:57:55,059 --> 00:57:58,239
variables that could find similar

1272
00:57:56,800 --> 00:58:00,940
relationships without the time

1273
00:57:58,239 --> 00:58:04,169
dependency so removing it cost our

1274
00:58:00,940 --> 00:58:06,220
validation to go up now oob didn't go up

1275
00:58:04,170 --> 00:58:08,230
right because this is genuinely

1276
00:58:06,219 --> 00:58:10,959
statistically you're useful predictor

1277
00:58:08,230 --> 00:58:12,550
right but it's a time dependent one when

1278
00:58:10,960 --> 00:58:15,369
we have a time dependent validation set

1279
00:58:12,550 --> 00:58:17,410
so this is like really subtle but it can

1280
00:58:15,369 --> 00:58:19,859
be really important right it's trying to

1281
00:58:17,409 --> 00:58:21,789
find the things that gives you a

1282
00:58:19,860 --> 00:58:23,110
generalizable time across time

1283
00:58:21,789 --> 00:58:25,719
prediction and here's how you can see it

1284
00:58:23,110 --> 00:58:29,410
so it's like okay we should remove sales

1285
00:58:25,719 --> 00:58:32,589
ID for sure right but sale elapsed

1286
00:58:29,409 --> 00:58:35,379
didn't get better okay so we don't want

1287
00:58:32,590 --> 00:58:36,640
that machine ID did get better right

1288
00:58:35,380 --> 00:58:38,470
from eight eight eight to eight nine

1289
00:58:36,639 --> 00:58:40,679
three right so it's actually quite a bit

1290
00:58:38,469 --> 00:58:40,679
better

1291
00:58:41,659 --> 00:58:49,489
age got a bit better you made got worse

1292
00:58:46,099 --> 00:58:53,028
sale day of year got a bit better okay

1293
00:58:49,489 --> 00:58:57,348
so now we can say alright let's get rid

1294
00:58:53,028 --> 00:59:00,199
of the three where we know that getting

1295
00:58:57,349 --> 00:59:02,329
rid of it actually made it better okay

1296
00:59:00,199 --> 00:59:05,538
and as a result look at this we're now

1297
00:59:02,329 --> 00:59:07,670
up to nine one five okay so we've got

1298
00:59:05,539 --> 00:59:11,930
rid of three time dependent things and

1299
00:59:07,670 --> 00:59:14,559
now as expected validation is better

1300
00:59:11,929 --> 00:59:16,719
than our Obi

1301
00:59:14,559 --> 00:59:18,489
okay so that was a super successful

1302
00:59:16,719 --> 00:59:22,659
approach there right and so now we can

1303
00:59:18,489 --> 00:59:24,819
check the feature importance and let's

1304
00:59:22,659 --> 00:59:26,230
go ahead and say all right that was

1305
00:59:24,820 --> 00:59:29,200
pretty damn good

1306
00:59:26,230 --> 00:59:31,539
let's now leave it for a while so give

1307
00:59:29,199 --> 00:59:33,369
it a hundred and sixty trees don't show

1308
00:59:31,539 --> 00:59:36,579
it and see how that goes

1309
00:59:33,369 --> 00:59:38,710
okay and so as you can see like we did

1310
00:59:36,579 --> 00:59:41,349
all of our interpretation all of our

1311
00:59:38,710 --> 00:59:43,539
fine-tuning basically with smaller

1312
00:59:41,349 --> 00:59:45,069
models subsets and at the end we run the

1313
00:59:43,539 --> 00:59:50,079
whole thing you actually still only took

1314
00:59:45,070 --> 00:59:53,710
16 seconds and so we've now got an RMS

1315
00:59:50,079 --> 00:59:59,369
see of 0.21 okay so now we can check

1316
00:59:53,710 --> 01:00:02,889
that against cattle again we can't we

1317
00:59:59,369 --> 01:00:04,210
unfortunately this older competition

1318
01:00:02,889 --> 01:00:05,650
we're not allowed to enter anymore to

1319
01:00:04,210 --> 01:00:08,559
see how he would have gone so the best

1320
01:00:05,650 --> 01:00:09,700
we can do is check whether it looks like

1321
01:00:08,559 --> 01:00:11,980
we could have done we're all based on

1322
01:00:09,699 --> 01:00:14,469
their validation set so it should be in

1323
01:00:11,980 --> 01:00:16,880
the right area and yeah based on that we

1324
01:00:14,469 --> 01:00:20,929
would have come first

1325
01:00:16,880 --> 01:00:24,079
okay so you know I think this is an

1326
01:00:20,929 --> 01:00:26,328
interesting series of steps right so you

1327
01:00:24,079 --> 01:00:29,329
can go through the same series of steps

1328
01:00:26,329 --> 01:00:31,640
in your cattle projects and more

1329
01:00:29,329 --> 01:00:33,769
importantly your real-world projects so

1330
01:00:31,639 --> 01:00:35,298
one of the challenges is once you leave

1331
01:00:33,768 --> 01:00:37,399
this learning environment

1332
01:00:35,298 --> 01:00:39,018
suddenly you're surrounded by people who

1333
01:00:37,400 --> 01:00:40,729
they they've had not have enough time

1334
01:00:39,018 --> 01:00:43,429
they always want you to be in a hurry

1335
01:00:40,728 --> 01:00:44,960
they're always telling you you know do

1336
01:00:43,429 --> 01:00:47,239
this and then do that you need to find

1337
01:00:44,960 --> 01:00:49,548
the time to step away right and go back

1338
01:00:47,239 --> 01:00:52,369
because this is a genuine real-world

1339
01:00:49,548 --> 01:00:54,440
modeling process you can use and it

1340
01:00:52,369 --> 01:00:57,200
gives when I said kids world-class

1341
01:00:54,440 --> 01:01:00,048
results I mean it right like this guy

1342
01:00:57,199 --> 01:01:05,498
who won this lista costs sadly he's

1343
01:01:00,048 --> 01:01:09,139
passed away but he is the top kaggle

1344
01:01:05,498 --> 01:01:11,808
competitor of all time like he he won I

1345
01:01:09,139 --> 01:01:14,328
believe like dozens of competitions so

1346
01:01:11,809 --> 01:01:18,849
we can get a score even within cuy of

1347
01:01:14,329 --> 01:01:21,469
him then we are doing really really well

1348
01:01:18,849 --> 01:01:23,359
okay so let's take a five-minute break

1349
01:01:21,469 --> 01:01:33,380
and we're going to come back and build

1350
01:01:23,358 --> 01:01:36,380
our own random first I just wanted to

1351
01:01:33,380 --> 01:01:43,309
clarify something quickly a very good

1352
01:01:36,380 --> 01:01:50,108
point during the break was going back to

1353
01:01:43,309 --> 01:01:53,210
the change in R squared between here and

1354
01:01:50,108 --> 01:01:58,728
here it's not just due to the fact that

1355
01:01:53,210 --> 01:02:01,278
we removed these three predictors we

1356
01:01:58,728 --> 01:02:02,899
also went reset our F samples right so

1357
01:02:01,278 --> 01:02:07,150
they actually see the impact of just

1358
01:02:02,900 --> 01:02:09,619
removing we need to compare it to the

1359
01:02:07,150 --> 01:02:11,719
final step earlier so it's actually

1360
01:02:09,619 --> 01:02:16,390
compared to 907 so removing those three

1361
01:02:11,719 --> 01:02:16,389
things took us from 907

1362
01:02:20,309 --> 01:02:24,699
nine one five okay so I mean and you

1363
01:02:23,590 --> 01:02:27,160
know in the end of course what matters

1364
01:02:24,699 --> 01:02:35,589
is our final model that yep just to

1365
01:02:27,159 --> 01:02:37,149
clarify okay so um some of you have

1366
01:02:35,590 --> 01:02:38,650
asked me about writing your own random

1367
01:02:37,150 --> 01:02:40,630
forests from scratch I don't know if any

1368
01:02:38,650 --> 01:02:44,800
of you have given it a try

1369
01:02:40,630 --> 01:02:46,990
yet my original plan here was to do it

1370
01:02:44,800 --> 01:02:48,460
in real time and then as I started to do

1371
01:02:46,989 --> 01:02:50,500
it I realized that that would have kind

1372
01:02:48,460 --> 01:02:52,510
of been boring because to you because I

1373
01:02:50,500 --> 01:02:55,000
screw things up all the time so instead

1374
01:02:52,510 --> 01:02:58,050
we might do more of like a walk through

1375
01:02:55,000 --> 01:02:58,050
the code together

1376
01:02:59,050 --> 01:03:04,789
just as an aside this reminds me talking

1377
01:03:03,380 --> 01:03:06,950
about the exam hammock she somebody

1378
01:03:04,789 --> 01:03:08,750
asked on the forum about like what what

1379
01:03:06,949 --> 01:03:13,309
can you expect on the exam the basic

1380
01:03:08,750 --> 01:03:14,869
plan is to make it a exam be very

1381
01:03:13,309 --> 01:03:16,909
similar to these notebooks so it'll

1382
01:03:14,869 --> 01:03:20,659
probably be a notebook that you have to

1383
01:03:16,909 --> 01:03:23,599
you know get a data set create a model

1384
01:03:20,659 --> 01:03:26,269
trainer feature importance whatever

1385
01:03:23,599 --> 01:03:28,279
right and the plan is that it'll be open

1386
01:03:26,269 --> 01:03:29,809
block open Internet you can use whatever

1387
01:03:28,280 --> 01:03:32,300
resources you like so basically if

1388
01:03:29,809 --> 01:03:35,210
you're entering competitions the exam

1389
01:03:32,300 --> 01:03:37,730
should be very straightforward I also

1390
01:03:35,210 --> 01:03:40,519
expect that there will be some pieces

1391
01:03:37,730 --> 01:03:42,199
about like here's a partially completed

1392
01:03:40,519 --> 01:03:45,139
random forest or something you know

1393
01:03:42,199 --> 01:03:47,989
finish finish writing this step here or

1394
01:03:45,139 --> 01:03:50,900
here's a random forest implement feature

1395
01:03:47,989 --> 01:03:53,539
importance or in you know implement one

1396
01:03:50,900 --> 01:03:55,730
of the things we've talked about so it

1397
01:03:53,539 --> 01:03:57,500
open it you know the exam will be much

1398
01:03:55,730 --> 01:03:59,320
like what we do in class and what you're

1399
01:03:57,500 --> 01:04:03,920
expected to be doing during the week

1400
01:03:59,320 --> 01:04:05,240
there won't be any define this or tell

1401
01:04:03,920 --> 01:04:06,710
me the difference between this word and

1402
01:04:05,239 --> 01:04:07,879
that word or whatever there's not going

1403
01:04:06,710 --> 01:04:09,320
to be any rote learning it'll be

1404
01:04:07,880 --> 01:04:11,869
entirely like are you an effective

1405
01:04:09,320 --> 01:04:14,840
machine learning practitioner ie can use

1406
01:04:11,869 --> 01:04:16,579
the algorithms do you know can you

1407
01:04:14,840 --> 01:04:19,280
create an effective validation set and

1408
01:04:16,579 --> 01:04:21,920
can you can you create parts of the

1409
01:04:19,280 --> 01:04:23,740
algorithm implement them from scratch so

1410
01:04:21,920 --> 01:04:27,289
it'll be all about writing code

1411
01:04:23,739 --> 01:04:29,869
basically so if you're not comfortable

1412
01:04:27,289 --> 01:04:33,019
writing code to practice machine

1413
01:04:29,869 --> 01:04:34,549
learning then you should be practicing

1414
01:04:33,019 --> 01:04:35,719
that all the time if you are comfortable

1415
01:04:34,550 --> 01:04:37,970
you should be practicing that all the

1416
01:04:35,719 --> 01:04:40,819
time also whatever you're doing write

1417
01:04:37,969 --> 01:04:46,929
code to implement random to do machine

1418
01:04:40,820 --> 01:04:46,930
learning okay

1419
01:04:48,340 --> 01:04:54,880
so I I kind of have a particular way of

1420
01:04:51,570 --> 01:04:56,410
writing code and I'm not going to claim

1421
01:04:54,880 --> 01:04:58,329
it's the only way of writing code but it

1422
01:04:56,409 --> 01:05:00,039
might be a little bit different to what

1423
01:04:58,329 --> 01:05:01,829
you're used to and hopefully you'll find

1424
01:05:00,039 --> 01:05:04,659
it at least interesting

1425
01:05:01,829 --> 01:05:08,139
creating implementing random forest

1426
01:05:04,659 --> 01:05:10,059
algorithms is actually quite tricky not

1427
01:05:08,139 --> 01:05:12,059
because the codes tricky like generally

1428
01:05:10,059 --> 01:05:14,460
speaking

1429
01:05:12,059 --> 01:05:17,789
most random first algorithms are pretty

1430
01:05:14,460 --> 01:05:21,570
conceptually easy at all that generally

1431
01:05:17,789 --> 01:05:23,840
speaking academic papers and books have

1432
01:05:21,570 --> 01:05:26,550
a knack of making them look difficult

1433
01:05:23,840 --> 01:05:28,530
but they're not difficult conceptually

1434
01:05:26,550 --> 01:05:31,470
what's difficult is getting all the

1435
01:05:28,530 --> 01:05:33,900
details right and knowing and knowing

1436
01:05:31,469 --> 01:05:37,289
when you're right and so in other words

1437
01:05:33,900 --> 01:05:41,730
we need a good way of doing testing so

1438
01:05:37,289 --> 01:05:43,369
if we're going to reimplemented a we

1439
01:05:41,730 --> 01:05:47,070
want to create a random forest in some

1440
01:05:43,369 --> 01:05:48,779
different framework different language

1441
01:05:47,070 --> 01:05:50,070
different operating system you know I

1442
01:05:48,780 --> 01:05:52,080
would always start with something that

1443
01:05:50,070 --> 01:05:53,070
does exist right so in this case we're

1444
01:05:52,079 --> 01:05:54,840
just going to do is learning its

1445
01:05:53,070 --> 01:05:56,970
exercise writing a random forest in

1446
01:05:54,840 --> 01:05:59,519
Python so for testing I'm going to

1447
01:05:56,969 --> 01:06:02,399
compare it to an existing random forest

1448
01:05:59,519 --> 01:06:05,210
implementation okay so that's like

1449
01:06:02,400 --> 01:06:07,950
critical anytime you're doing anything

1450
01:06:05,210 --> 01:06:10,170
involving like non-trivial amounts of

1451
01:06:07,949 --> 01:06:12,089
code and machine learning knowing

1452
01:06:10,170 --> 01:06:14,760
whether you've got it right or wrong is

1453
01:06:12,090 --> 01:06:16,410
kind of the hardest fit I always assume

1454
01:06:14,760 --> 01:06:18,420
that I've screwed everything up at every

1455
01:06:16,409 --> 01:06:20,759
step and so I'm thinking like okay

1456
01:06:18,420 --> 01:06:22,200
assuming that I screwed it up how do I

1457
01:06:20,760 --> 01:06:24,300
figure out that I screwed it up

1458
01:06:22,199 --> 01:06:25,980
right and then much to my surprise from

1459
01:06:24,300 --> 01:06:28,560
time to time I actually get something

1460
01:06:25,980 --> 01:06:31,969
right and then I can move on okay but

1461
01:06:28,559 --> 01:06:33,449
most of the time I get it wrong so

1462
01:06:31,969 --> 01:06:35,250
unfortunately with machine learning

1463
01:06:33,449 --> 01:06:37,769
there's a lot of ways you can get things

1464
01:06:35,250 --> 01:06:40,050
wrong that don't give you an error they

1465
01:06:37,769 --> 01:06:43,259
just make your result like slightly less

1466
01:06:40,050 --> 01:06:46,110
good and so that's that's what you want

1467
01:06:43,260 --> 01:06:47,880
to pick up so given that I want to kind

1468
01:06:46,110 --> 01:06:49,650
of compare it to an existing

1469
01:06:47,880 --> 01:06:51,599
implementation I'm going to use our

1470
01:06:49,650 --> 01:06:53,760
existing data set our existing

1471
01:06:51,599 --> 01:06:55,699
validation set and then to simplify

1472
01:06:53,760 --> 01:07:00,750
things I'm just going to use two columns

1473
01:06:55,699 --> 01:07:03,539
to start with so let's go ahead and

1474
01:07:00,750 --> 01:07:07,050
start writing a random forest so my way

1475
01:07:03,539 --> 01:07:09,420
of writing nearly all code is top-down

1476
01:07:07,050 --> 01:07:12,650
just let my teaching and so if I

1477
01:07:09,420 --> 01:07:16,940
top-down I start by assuming that

1478
01:07:12,650 --> 01:07:19,700
everything I want already exists

1479
01:07:16,940 --> 01:07:20,690
so in other words the first thing I want

1480
01:07:19,699 --> 01:07:22,669
to do I'm going to call this a tree

1481
01:07:20,690 --> 01:07:27,400
ensemble right so to create a random

1482
01:07:22,670 --> 01:07:30,760
forest the first question I have is

1483
01:07:27,400 --> 01:07:33,789
what do I need to pass in right why I

1484
01:07:30,760 --> 01:07:35,109
need to initialize my random first so

1485
01:07:33,789 --> 01:07:39,069
I'm going to need some independent

1486
01:07:35,108 --> 01:07:41,858
variables some dependent variable pick

1487
01:07:39,068 --> 01:07:43,568
how many trees I want I'm going to use

1488
01:07:41,858 --> 01:07:45,429
the sample size parameter from the start

1489
01:07:43,568 --> 01:07:48,308
here so how big you want each sample to

1490
01:07:45,429 --> 01:07:50,199
be and then maybe some optional

1491
01:07:48,309 --> 01:07:55,750
parameter of what's the smallest leaf

1492
01:07:50,199 --> 01:07:57,939
size okay for testing it's nice to use a

1493
01:07:55,750 --> 01:07:59,920
constant random seed so we'll get the

1494
01:07:57,940 --> 01:08:03,818
same result each time so this is just

1495
01:07:59,920 --> 01:08:05,108
how you set a random seed okay maybe

1496
01:08:03,818 --> 01:08:07,568
it's worth mentioning is for those of

1497
01:08:05,108 --> 01:08:09,940
you unfamiliar with it random number

1498
01:08:07,568 --> 01:08:12,038
generators on computers aren't random at

1499
01:08:09,940 --> 01:08:14,619
all now actually constitute a random

1500
01:08:12,039 --> 01:08:16,869
number generators and what they do is

1501
01:08:14,619 --> 01:08:20,380
given some initial starting point in

1502
01:08:16,869 --> 01:08:22,298
this case 42 a pseudo-random number

1503
01:08:20,380 --> 01:08:25,088
generator is a mathematical function

1504
01:08:22,298 --> 01:08:28,000
that generates a deterministic always

1505
01:08:25,088 --> 01:08:30,039
the same sequence of numbers such that

1506
01:08:28,000 --> 01:08:32,319
those numbers are designed to be as

1507
01:08:30,039 --> 01:08:34,420
uncorrelated with the previous number as

1508
01:08:32,319 --> 01:08:38,920
possible okay

1509
01:08:34,420 --> 01:08:41,259
and as unpredictable as possible and as

1510
01:08:38,920 --> 01:08:43,449
uncorrelated as possible with something

1511
01:08:41,259 --> 01:08:45,488
with a different random seed so the

1512
01:08:43,448 --> 01:08:47,229
second number in in the sequence

1513
01:08:45,488 --> 01:08:48,488
starting with 42 should be very

1514
01:08:47,229 --> 01:08:51,099
different to the second number starting

1515
01:08:48,488 --> 01:08:55,838
with 41 and generally they involve kind

1516
01:08:51,100 --> 01:08:58,779
of like taking you know you know using

1517
01:08:55,838 --> 01:09:00,698
big prime numbers and taking mods and

1518
01:08:58,779 --> 01:09:04,390
stuff like that it's kind of an

1519
01:09:00,698 --> 01:09:06,309
interesting area of math if you want

1520
01:09:04,390 --> 01:09:08,009
real random numbers the only way to do

1521
01:09:06,310 --> 01:09:10,569
that is again you can actually buy

1522
01:09:08,009 --> 01:09:12,189
hardware called a hardware random number

1523
01:09:10,569 --> 01:09:14,339
generator that'll have inside them like

1524
01:09:12,189 --> 01:09:16,719
a little bit of some radioactive

1525
01:09:14,338 --> 01:09:18,640
substance and and like something that

1526
01:09:16,719 --> 01:09:19,899
detects how many things it's spitting

1527
01:09:18,640 --> 01:09:23,250
out or you know there will be some

1528
01:09:19,899 --> 01:09:23,250
hardware thing

1529
01:09:25,060 --> 01:09:33,589
any current system time is is it a valid

1530
01:09:30,520 --> 01:09:35,930
random like random number generation no

1531
01:09:33,588 --> 01:09:37,759
sense so that would be for maybe for a

1532
01:09:35,930 --> 01:09:39,710
random seed right so this thing of like

1533
01:09:37,759 --> 01:09:41,930
what do we start the function with so

1534
01:09:39,710 --> 01:09:43,850
one of the really interesting areas is

1535
01:09:41,930 --> 01:09:47,739
like in your computer if you don't set

1536
01:09:43,850 --> 01:09:51,289
the random seed what is it set to and

1537
01:09:47,738 --> 01:09:54,500
yeah quite often people use the current

1538
01:09:51,289 --> 01:09:55,760
time for security like obviously we use

1539
01:09:54,500 --> 01:09:57,319
a lot of random number stuff for

1540
01:09:55,760 --> 01:10:00,260
security stuff like if you're generating

1541
01:09:57,319 --> 01:10:03,619
an SSH key you need some it needs to be

1542
01:10:00,260 --> 01:10:06,320
random it turns out like you know people

1543
01:10:03,619 --> 01:10:08,510
can figure out roughly when you created

1544
01:10:06,319 --> 01:10:11,238
a key like they could look at like oid

1545
01:10:08,510 --> 01:10:13,280
RSA has a timestamp and they could try

1546
01:10:11,238 --> 01:10:15,199
you know all the different nanoseconds

1547
01:10:13,279 --> 01:10:16,609
starting points for a random number

1548
01:10:15,199 --> 01:10:20,449
generator around that time step and

1549
01:10:16,609 --> 01:10:25,429
figure out your key so in practice a lot

1550
01:10:20,449 --> 01:10:26,779
of like really random high randomness

1551
01:10:25,430 --> 01:10:29,030
requiring applications actually have a

1552
01:10:26,779 --> 01:10:30,920
step that say please move your mouse and

1553
01:10:29,029 --> 01:10:33,349
type random stuff at the keyboard for a

1554
01:10:30,920 --> 01:10:34,579
while and so it like gets you to be a

1555
01:10:33,350 --> 01:10:37,640
sort that's called entropy to be a

1556
01:10:34,579 --> 01:10:39,949
source of entropy other approaches is

1557
01:10:37,640 --> 01:10:43,720
they'll look at like you know the hash

1558
01:10:39,949 --> 01:10:46,699
of some of your log files or you know

1559
01:10:43,720 --> 01:10:50,390
stuff like that it's a really really fun

1560
01:10:46,699 --> 01:10:51,800
area so in our case our purpose actually

1561
01:10:50,390 --> 01:10:53,930
is to remove randomness

1562
01:10:51,800 --> 01:10:55,430
so we're saying okay generate a series

1563
01:10:53,930 --> 01:11:00,739
of pseudo-random numbers starting with

1564
01:10:55,430 --> 01:11:02,720
42 so it always should be the same so if

1565
01:11:00,738 --> 01:11:05,029
you haven't done much stuff in Python oo

1566
01:11:02,720 --> 01:11:06,920
this is a basically standard idiom at

1567
01:11:05,029 --> 01:11:10,309
least I mean I write it this way most

1568
01:11:06,920 --> 01:11:12,140
people don't but if you pass in like 1 2

1569
01:11:10,310 --> 01:11:14,570
3 4 5 things that you're going to want

1570
01:11:12,140 --> 01:11:17,210
to keep inside this object then you

1571
01:11:14,569 --> 01:11:19,250
basically have to say self dot x equals

1572
01:11:17,210 --> 01:11:22,699
x self dot y equals y self that sample

1573
01:11:19,250 --> 01:11:27,140
equals sample right and so we can assign

1574
01:11:22,699 --> 01:11:28,729
to a tuple from at a port so you know

1575
01:11:27,140 --> 01:11:30,020
okay this is like my way of coding most

1576
01:11:28,729 --> 01:11:32,119
people think this is horrible but I

1577
01:11:30,020 --> 01:11:34,400
prefer to be able to see everything at

1578
01:11:32,119 --> 01:11:35,988
once and so I know in my code anytime I

1579
01:11:34,399 --> 01:11:37,729
see something that looks like this it's

1580
01:11:35,988 --> 01:11:39,769
always all of the

1581
01:11:37,729 --> 01:11:41,359
stuff in the method being set if I did

1582
01:11:39,770 --> 01:11:43,670
it a different way than half the codes

1583
01:11:41,359 --> 01:11:49,039
now come off the bottom of the page and

1584
01:11:43,670 --> 01:11:50,180
you can't see it all right so um so that

1585
01:11:49,039 --> 01:11:51,920
was the first thing I thought about is

1586
01:11:50,180 --> 01:11:53,810
like okay to create a random forest what

1587
01:11:51,920 --> 01:11:55,340
information do you need then I'm going

1588
01:11:53,810 --> 01:11:59,120
to need to store that information inside

1589
01:11:55,340 --> 01:11:59,840
my object and so then I need to create

1590
01:11:59,119 --> 01:12:01,880
some treats

1591
01:11:59,840 --> 01:12:03,140
I had a random forest is something that

1592
01:12:01,880 --> 01:12:05,140
creates and is something that has some

1593
01:12:03,140 --> 01:12:07,789
trees so I fit basically figured okay

1594
01:12:05,140 --> 01:12:10,310
list comprehension to create a list of

1595
01:12:07,789 --> 01:12:13,579
trees how many trees do we have or you

1596
01:12:10,310 --> 01:12:16,370
put n trees trees that's what we asked

1597
01:12:13,579 --> 01:12:20,449
for so range entries gives me the

1598
01:12:16,369 --> 01:12:22,880
numbers from 0 up to n trees minus 1 ok

1599
01:12:20,449 --> 01:12:26,000
so if I create a list comprehension that

1600
01:12:22,880 --> 01:12:29,569
lips through that range calling create

1601
01:12:26,000 --> 01:12:33,470
tree each time I now have entries trees

1602
01:12:29,569 --> 01:12:35,090
and also I add to write that I didn't

1603
01:12:33,470 --> 01:12:38,840
have to think at all

1604
01:12:35,090 --> 01:12:41,119
like that's all like obvious and so I've

1605
01:12:38,840 --> 01:12:43,430
kind of delayed the thinking to the

1606
01:12:41,119 --> 01:12:46,309
point where it's like well wait we don't

1607
01:12:43,430 --> 01:12:48,739
have something to create a tree okay no

1608
01:12:46,310 --> 01:12:51,080
worries but let's pretend we did if we

1609
01:12:48,738 --> 01:12:53,479
did we've now created a random forest

1610
01:12:51,079 --> 01:12:55,880
okay we'd still need to like do a few

1611
01:12:53,479 --> 01:12:58,159
things on top of that for example once

1612
01:12:55,880 --> 01:12:59,600
we have it we need a predict function so

1613
01:12:58,159 --> 01:13:02,988
okay well let's write a prediction

1614
01:12:59,600 --> 01:13:07,970
function how do you predict in a random

1615
01:13:02,988 --> 01:13:09,500
forest can somebody tell me either based

1616
01:13:07,970 --> 01:13:11,539
on their own understanding or based on

1617
01:13:09,500 --> 01:13:13,729
this line of code what would be like

1618
01:13:11,539 --> 01:13:16,329
your one or two-sentence answer how do

1619
01:13:13,729 --> 01:13:19,629
you make a prediction in a random forest

1620
01:13:16,329 --> 01:13:19,630
positive Spencer

1621
01:13:20,158 --> 01:13:25,529
uh you would want to over every tree for

1622
01:13:23,578 --> 01:13:28,679
your like the row that you're trying to

1623
01:13:25,529 --> 01:13:30,448
predict on average the values that your

1624
01:13:28,679 --> 01:13:33,359
that each tree would produce for that

1625
01:13:30,448 --> 01:13:35,248
book good and so you know that's a

1626
01:13:33,359 --> 01:13:37,918
summary of what this says right so for a

1627
01:13:35,248 --> 01:13:43,130
particular row right or maybe this is a

1628
01:13:37,918 --> 01:13:45,359
number of rows go through each tree

1629
01:13:43,130 --> 01:13:47,819
calculate its prediction so here is a

1630
01:13:45,359 --> 01:13:51,208
list comprehension that is calculating

1631
01:13:47,819 --> 01:13:52,978
the prediction for every tree for X I

1632
01:13:51,208 --> 01:13:55,038
don't know if X is one row or multiple

1633
01:13:52,979 --> 01:13:58,168
rows it doesn't matter right

1634
01:13:55,038 --> 01:14:01,078
as long as as long as trade I predict

1635
01:13:58,168 --> 01:14:03,689
works on it and then once you've got a

1636
01:14:01,078 --> 01:14:07,349
list of things a cool trick to know is

1637
01:14:03,689 --> 01:14:10,229
you can pass numpy dot mean a regular

1638
01:14:07,349 --> 01:14:12,360
non mum pie list okay

1639
01:14:10,229 --> 01:14:15,719
and it'll take the mean you just need to

1640
01:14:12,359 --> 01:14:18,868
tell it access equals zero means everage

1641
01:14:15,719 --> 01:14:22,469
it across the lists okay so this is

1642
01:14:18,868 --> 01:14:26,788
going to return the average of that

1643
01:14:22,469 --> 01:14:29,578
predict for each tree and so I find list

1644
01:14:26,788 --> 01:14:32,340
comprehensions allow me to write the

1645
01:14:29,578 --> 01:14:35,578
code in the way that the brain was like

1646
01:14:32,340 --> 01:14:37,380
you could take the word Spencer said and

1647
01:14:35,578 --> 01:14:38,998
like translate them into this code or

1648
01:14:37,380 --> 01:14:40,650
you could take this code and translate

1649
01:14:38,998 --> 01:14:42,929
them into words like the one Spencer

1650
01:14:40,649 --> 01:14:45,089
said right and so when I write code I

1651
01:14:42,929 --> 01:14:46,559
want it to be as much like that as

1652
01:14:45,090 --> 01:14:49,409
possible all right I want it to be

1653
01:14:46,559 --> 01:14:50,939
readable and so hopefully you'll find

1654
01:14:49,408 --> 01:14:52,379
like when you look at the past AI code

1655
01:14:50,939 --> 01:14:54,869
you can understand how to journey

1656
01:14:52,380 --> 01:14:56,699
through X I try to write things in a way

1657
01:14:54,868 --> 01:15:00,018
that you can read it and like it kind of

1658
01:14:56,698 --> 01:15:00,018
turn it into English in your head

1659
01:15:01,729 --> 01:15:08,719
so if I say correctly that predict

1660
01:15:04,520 --> 01:15:10,700
method is recursive it's no it's calling

1661
01:15:08,720 --> 01:15:14,030
trade predict and we haven't written a

1662
01:15:10,699 --> 01:15:18,019
tree yet so self trees is going to

1663
01:15:14,029 --> 01:15:20,689
contain a tree object so this is tree

1664
01:15:18,020 --> 01:15:23,150
Ensemble dot predict and inside the

1665
01:15:20,689 --> 01:15:25,129
trees is a tree not a tree ensemble so

1666
01:15:23,149 --> 01:15:27,529
this is called an trade product not tree

1667
01:15:25,130 --> 01:15:32,329
ensemble dotted it

1668
01:15:27,529 --> 01:15:33,949
the question okay so we nearly finished

1669
01:15:32,329 --> 01:15:35,720
riding around and for our seventh week

1670
01:15:33,949 --> 01:15:42,250
all we need to do now is write create

1671
01:15:35,720 --> 01:15:45,440
tree right so um based on this code here

1672
01:15:42,250 --> 01:15:48,199
or on your own understanding of how we

1673
01:15:45,439 --> 01:15:51,559
create trees in a random forest can

1674
01:15:48,199 --> 01:15:53,329
somebody tell me let's take a few

1675
01:15:51,560 --> 01:15:54,500
seconds have a raid have to think and

1676
01:15:53,329 --> 01:15:57,979
then I'm going to try and come up with a

1677
01:15:54,500 --> 01:16:01,239
way of saying how do you create a tree

1678
01:15:57,979 --> 01:16:01,239
in a random forest

1679
01:16:01,829 --> 01:16:09,500
okay who wants to tell me yes

1680
01:16:05,399 --> 01:16:09,500
okay let's tireless work cluster

1681
01:16:09,710 --> 01:16:17,359
you take your you're essentially taking

1682
01:16:14,060 --> 01:16:20,710
a random sample or of the original data

1683
01:16:17,359 --> 01:16:23,149
and then you're just it just

1684
01:16:20,710 --> 01:16:26,600
constructing a tree however that happens

1685
01:16:23,149 --> 01:16:29,359
so construct a decision tree like a non

1686
01:16:26,600 --> 01:16:33,590
random tree from a random sample of the

1687
01:16:29,359 --> 01:16:35,630
data ok so again like we've delayed any

1688
01:16:33,590 --> 01:16:37,970
actual thought process here we've

1689
01:16:35,630 --> 01:16:40,130
basically said ok we could pick some

1690
01:16:37,970 --> 01:16:43,820
random IDs this is a good trick to know

1691
01:16:40,130 --> 01:16:47,829
if you call NP random permutation

1692
01:16:43,819 --> 01:16:51,319
passing in an inch it'll give you back a

1693
01:16:47,829 --> 01:16:53,720
randomly shuffled sequence from zero to

1694
01:16:51,319 --> 01:16:58,819
that inch right and so then if you grab

1695
01:16:53,720 --> 01:17:01,970
the first : n items of that that's now a

1696
01:16:58,819 --> 01:17:03,380
random subsample so this is not doing

1697
01:17:01,970 --> 01:17:07,789
bootstrapping we're not doing sampling

1698
01:17:03,380 --> 01:17:10,550
with replacement here which i think is

1699
01:17:07,789 --> 01:17:11,659
fine you know for my random forest I'm

1700
01:17:10,550 --> 01:17:13,340
deciding that it's going to be something

1701
01:17:11,659 --> 01:17:14,000
where we do subsampling not

1702
01:17:13,340 --> 01:17:17,569
bootstrapping

1703
01:17:14,000 --> 01:17:21,140
ok so here's a good line of code to know

1704
01:17:17,569 --> 01:17:22,929
how to write because it comes up all the

1705
01:17:21,140 --> 01:17:26,630
time like I find in machine learning

1706
01:17:22,930 --> 01:17:28,730
most algorithms I use are somewhat

1707
01:17:26,630 --> 01:17:30,560
random and so often I need some kind of

1708
01:17:28,729 --> 01:17:37,969
random sample can you pass that tartaric

1709
01:17:30,560 --> 01:17:40,120
entry won't they give you 1 1 extra

1710
01:17:37,970 --> 01:17:45,800
because the easier it will go from 0 to

1711
01:17:40,119 --> 01:17:50,210
length no so this will give you if lens

1712
01:17:45,800 --> 01:17:53,869
self dot y is of size n this will give

1713
01:17:50,210 --> 01:17:57,050
you n a sequence of length n so 0 to n

1714
01:17:53,869 --> 01:18:00,529
minus 1 and then from that I'm picking

1715
01:17:57,050 --> 01:18:07,699
out : self dot sample size so the first

1716
01:18:00,529 --> 01:18:09,739
sample size ladies I have a comment on

1717
01:18:07,699 --> 01:18:12,349
bootstrapping I think this method is

1718
01:18:09,739 --> 01:18:16,159
better because we have transfer giving

1719
01:18:12,350 --> 01:18:18,770
more weights to each observation or am I

1720
01:18:16,159 --> 01:18:20,479
thinking wrong I think you proposed

1721
01:18:18,770 --> 01:18:23,389
wrapping we could also give weights I

1722
01:18:20,479 --> 01:18:25,218
mean we

1723
01:18:23,389 --> 01:18:28,429
single observations more than they are

1724
01:18:25,219 --> 01:18:30,230
like without one thing that weights

1725
01:18:28,429 --> 01:18:33,289
because I'm bootstrapping with with

1726
01:18:30,229 --> 01:18:36,169
replacement we can have a single

1727
01:18:33,289 --> 01:18:36,979
observation and dr. pitz of it yeah the

1728
01:18:36,170 --> 01:18:41,920
same tree

1729
01:18:36,979 --> 01:18:41,919
yeah it just feel weird but I think

1730
01:18:43,279 --> 01:18:47,750
the actual theory or empirical results

1731
01:18:45,979 --> 01:18:51,198
backs up higher intuition that it's

1732
01:18:47,750 --> 01:18:55,429
worse it'd be interesting to look look

1733
01:18:51,198 --> 01:18:57,259
back at that actually personally I

1734
01:18:55,429 --> 01:19:00,500
prefer this because I feel like most of

1735
01:18:57,260 --> 01:19:02,659
the time we have more data than we want

1736
01:19:00,500 --> 01:19:04,429
to put a tree at once I feel like back

1737
01:19:02,658 --> 01:19:06,198
when Bremen created random forests it

1738
01:19:04,429 --> 01:19:08,239
was 1999 it was kind of a very different

1739
01:19:06,198 --> 01:19:09,828
world you know where we pretty much

1740
01:19:08,238 --> 01:19:12,368
always wanted to use all the data we had

1741
01:19:09,828 --> 01:19:15,259
but nowadays I would say that's

1742
01:19:12,368 --> 01:19:16,969
generally not what we want we normally

1743
01:19:15,260 --> 01:19:19,250
have too much data and so what people

1744
01:19:16,969 --> 01:19:20,689
tend to do is they'll like fire up a

1745
01:19:19,250 --> 01:19:24,229
spark cluster and they'll run it on

1746
01:19:20,689 --> 01:19:25,819
hundreds of machines when it makes no

1747
01:19:24,229 --> 01:19:27,319
sense because if they had just used a

1748
01:19:25,819 --> 01:19:29,509
subsample each time they could have done

1749
01:19:27,319 --> 01:19:32,719
it on one machine and like the the

1750
01:19:29,510 --> 01:19:34,760
overhead of like spark is a huge amount

1751
01:19:32,719 --> 01:19:36,618
of i/o overhead like I know you guys are

1752
01:19:34,760 --> 01:19:37,849
doing distributed computing now if you

1753
01:19:36,618 --> 01:19:42,529
if you've looked at some of the

1754
01:19:37,849 --> 01:19:44,210
benchmarks yeah yeah exactly so if you

1755
01:19:42,529 --> 01:19:46,300
do something on a single machine it can

1756
01:19:44,210 --> 01:19:48,920
often be hundreds of times faster

1757
01:19:46,300 --> 01:19:51,079
because you don't have all this this i/o

1758
01:19:48,920 --> 01:19:52,609
overhead it also tends to be easier to

1759
01:19:51,078 --> 01:19:56,058
write the algorithms like you can use

1760
01:19:52,609 --> 01:20:00,259
like SK learn easier to visualize and

1761
01:19:56,059 --> 01:20:02,210
cheaper so forth so like I almost always

1762
01:20:00,260 --> 01:20:04,099
avoid distributed computing and I have

1763
01:20:02,210 --> 01:20:06,288
my whole life like even 25 years ago

1764
01:20:04,099 --> 01:20:09,619
when I was studying in machine learning

1765
01:20:06,288 --> 01:20:11,960
I you know still didn't use clusters

1766
01:20:09,618 --> 01:20:14,328
because I so I always feel like whatever

1767
01:20:11,960 --> 01:20:15,969
I could do with a cluster now I could do

1768
01:20:14,328 --> 01:20:18,558
with a single machine in five years time

1769
01:20:15,969 --> 01:20:19,969
so one of us focus on always being as

1770
01:20:18,559 --> 01:20:21,500
good as possible with the single machine

1771
01:20:19,969 --> 01:20:24,260
you know and that's going to be more

1772
01:20:21,500 --> 01:20:29,359
interactive and more iterative and work

1773
01:20:24,260 --> 01:20:32,809
for me so ah okay so so again we've like

1774
01:20:29,359 --> 01:20:34,819
delayed thinking to the point where we

1775
01:20:32,809 --> 01:20:36,380
have to write decision tree and so

1776
01:20:34,819 --> 01:20:38,210
hopefully you get an idea that this

1777
01:20:36,380 --> 01:20:39,170
top-down approach that goal is going to

1778
01:20:38,210 --> 01:20:42,050
be that we're going to keep delaying

1779
01:20:39,170 --> 01:20:42,469
thinking so long that that we delay it

1780
01:20:42,050 --> 01:20:44,690
forever

1781
01:20:42,469 --> 01:20:46,158
like like eventually we've somehow

1782
01:20:44,689 --> 01:20:48,169
written the whole thing without actually

1783
01:20:46,158 --> 01:20:49,638
having to think right and that's that's

1784
01:20:48,170 --> 01:20:52,670
kind of what I need is I'm kind of slow

1785
01:20:49,639 --> 01:20:54,650
right so this is why I write code this

1786
01:20:52,670 --> 01:20:56,569
way and notice like you never have to

1787
01:20:54,649 --> 01:20:57,649
design anything in

1788
01:20:56,569 --> 01:20:59,719
you just say hey what if somebody

1789
01:20:57,649 --> 01:21:02,539
already gave me the exact API I needed

1790
01:20:59,719 --> 01:21:04,899
how would I use it okay and then and

1791
01:21:02,539 --> 01:21:07,279
then okay to implement that next stage

1792
01:21:04,899 --> 01:21:09,049
what would be the exact API I would need

1793
01:21:07,279 --> 01:21:10,729
to implement that right you keep going

1794
01:21:09,050 --> 01:21:14,929
down until eventually you're like oh

1795
01:21:10,729 --> 01:21:17,118
that already exists okay so this assumes

1796
01:21:14,929 --> 01:21:21,260
we've got a class port decision tree so

1797
01:21:17,118 --> 01:21:25,488
we're going to have to create that so a

1798
01:21:21,260 --> 01:21:26,989
decision tree is something so we already

1799
01:21:25,488 --> 01:21:28,848
know what we're going to have to pass it

1800
01:21:26,988 --> 01:21:32,828
because we just passed it right so we're

1801
01:21:28,849 --> 01:21:36,260
passing in a random sample of X's a

1802
01:21:32,828 --> 01:21:38,319
random sample of Y's

1803
01:21:36,260 --> 01:21:38,320
um

1804
01:21:38,488 --> 01:21:40,518
uhh

1805
01:21:40,689 --> 01:21:46,550
indexers is actually so we know that

1806
01:21:43,668 --> 01:21:48,590
down the track so I've got a plan a tiny

1807
01:21:46,550 --> 01:21:51,260
bit we know that a decision tree is

1808
01:21:48,590 --> 01:21:52,998
going to contain decision trees which

1809
01:21:51,260 --> 01:21:55,070
themselves contain decision trees and so

1810
01:21:52,998 --> 01:21:56,658
as we go down the decision tree there's

1811
01:21:55,069 --> 01:21:59,389
going to be some subset of the original

1812
01:21:56,658 --> 01:22:02,268
data that we've kind of got and so I'm

1813
01:21:59,389 --> 01:22:03,769
going to pass in the indexes of the data

1814
01:22:02,269 --> 01:22:07,429
that we're actually going to use here

1815
01:22:03,769 --> 01:22:09,860
okay so initially it's the entire random

1816
01:22:07,429 --> 01:22:15,529
sample all right so I've got the whole

1817
01:22:09,859 --> 01:22:17,630
team I've got the whole range and I turn

1818
01:22:15,529 --> 01:22:19,880
that into an array so that's 0 the

1819
01:22:17,630 --> 01:22:22,458
indexes from 0 to the size of the sample

1820
01:22:19,880 --> 01:22:24,949
and then what is passed down the mean

1821
01:22:22,458 --> 01:22:27,078
left side so everything that we got for

1822
01:22:24,948 --> 01:22:29,058
constructing the random forest where to

1823
01:22:27,078 --> 01:22:31,099
pass down the decision tree except of

1824
01:22:29,059 --> 01:22:34,219
course num trees which is irrelevant for

1825
01:22:31,099 --> 01:22:35,899
the decision tree so again now that we

1826
01:22:34,219 --> 01:22:38,179
know that's the information we need we

1827
01:22:35,899 --> 01:22:42,349
can go ahead and store it inside this

1828
01:22:38,179 --> 01:22:46,458
object so I'm pretty likely to need to

1829
01:22:42,349 --> 01:22:49,130
know how many rows we have in this tree

1830
01:22:46,458 --> 01:22:51,380
which I generally call n how many

1831
01:22:49,130 --> 01:22:54,050
columns do I have which I generally call

1832
01:22:51,380 --> 01:22:56,599
C so the number of rows is just equal to

1833
01:22:54,050 --> 01:22:58,369
the number of indexes well given and the

1834
01:22:56,599 --> 01:23:00,439
number of columns is just like however

1835
01:22:58,368 --> 01:23:04,969
many columns there are in our

1836
01:23:00,439 --> 01:23:11,229
independent variables so then we're

1837
01:23:04,969 --> 01:23:11,229
going to need this value here

1838
01:23:11,310 --> 01:23:20,220
we need to know for this tree

1839
01:23:14,760 --> 01:23:23,810
what's its prediction right so the

1840
01:23:20,220 --> 01:23:29,340
prediction for this tree is the mean of

1841
01:23:23,810 --> 01:23:31,440
our dependent variable or those indexes

1842
01:23:29,340 --> 01:23:34,619
which are inside this part of the tree

1843
01:23:31,439 --> 01:23:38,759
alright so at the very top of the tree

1844
01:23:34,619 --> 01:23:40,229
it contains all the indexes right I'm

1845
01:23:38,760 --> 01:23:42,270
assuming that by the time we've got to

1846
01:23:40,229 --> 01:23:47,549
this point remember we've already done

1847
01:23:42,270 --> 01:23:49,440
the random sampling right so when we

1848
01:23:47,550 --> 01:23:51,600
talk about indexes we're not talking

1849
01:23:49,439 --> 01:23:53,789
about the random sampling to create the

1850
01:23:51,600 --> 01:23:57,000
tree we're assuming this tree now has

1851
01:23:53,789 --> 01:23:58,739
some random sample inside decision tree

1852
01:23:57,000 --> 01:24:01,020
this is this is the one of the nice

1853
01:23:58,739 --> 01:24:02,880
things right inside decision tree hole

1854
01:24:01,020 --> 01:24:04,860
random sampling things gone right that

1855
01:24:02,880 --> 01:24:06,480
was done by the random forest right so

1856
01:24:04,859 --> 01:24:08,429
at this point we're building something

1857
01:24:06,479 --> 01:24:10,379
that's just a plain old decision tree

1858
01:24:08,430 --> 01:24:11,940
it's not in any way a random sampling

1859
01:24:10,380 --> 01:24:15,210
anything it's just a plain old position

1860
01:24:11,939 --> 01:24:19,019
tree right so the indexes is literally

1861
01:24:15,210 --> 01:24:21,149
like which subset of the data that we

1862
01:24:19,020 --> 01:24:23,040
got to so far in this tree and so at the

1863
01:24:21,149 --> 01:24:25,609
top of the decision tree it's all the

1864
01:24:23,039 --> 01:24:31,380
data right so it's all of the indexes

1865
01:24:25,609 --> 01:24:34,170
okay so all of the indexes so this is

1866
01:24:31,380 --> 01:24:36,720
therefore all of the dependent variable

1867
01:24:34,170 --> 01:24:40,800
that are in this part of the tree and so

1868
01:24:36,720 --> 01:24:41,400
this is the value mean of that that

1869
01:24:40,800 --> 01:24:42,690
makes sense

1870
01:24:41,399 --> 01:24:49,729
anybody could be any questions about

1871
01:24:42,689 --> 01:24:49,729
about that so ah yes hey pastor Chen Qi

1872
01:24:50,359 --> 01:24:55,649
actually just to let you know there's a

1873
01:24:52,529 --> 01:24:59,729
large portion of us don't have a over B

1874
01:24:55,649 --> 01:25:03,659
I mean all P experiments okay yeah sure

1875
01:24:59,729 --> 01:25:04,699
so so quick so quick over P prenup would

1876
01:25:03,659 --> 01:25:08,750
be helpful

1877
01:25:04,699 --> 01:25:08,750
great yeah okay

1878
01:25:08,989 --> 01:25:16,369
who is done object-oriented programming

1879
01:25:11,579 --> 01:25:16,369
in some programming language okay

1880
01:25:18,350 --> 01:25:23,640
so you've all used actually lots of

1881
01:25:21,630 --> 01:25:26,640
object-oriented programming in terms of

1882
01:25:23,640 --> 01:25:31,800
using existing classes right so every

1883
01:25:26,640 --> 01:25:34,199
time we've created a random forest we've

1884
01:25:31,800 --> 01:25:38,250
called the random forests constructor

1885
01:25:34,198 --> 01:25:42,149
and it's returned an object and then

1886
01:25:38,250 --> 01:25:45,359
we've called methods and attributes on

1887
01:25:42,149 --> 01:25:46,948
that object so fit is a method you can

1888
01:25:45,359 --> 01:25:52,409
tell because it's got parentheses after

1889
01:25:46,948 --> 01:25:56,639
it right where else yeah

1890
01:25:52,409 --> 01:25:58,469
oh I'll be score is a property or an

1891
01:25:56,640 --> 01:25:59,640
attribute doesn't have parentheses after

1892
01:25:58,469 --> 01:26:01,590
it okay

1893
01:25:59,640 --> 01:26:03,360
so inside an object there are kind of

1894
01:26:01,590 --> 01:26:07,529
two kinds of things there the functions

1895
01:26:03,359 --> 01:26:10,889
that you can call so you have object dot

1896
01:26:07,529 --> 01:26:12,599
function parentheses arguments or there

1897
01:26:10,890 --> 01:26:16,469
are the properties or attributes you can

1898
01:26:12,600 --> 01:26:19,199
grab which is object dot and then just

1899
01:26:16,469 --> 01:26:21,539
the attribute name no parentheses so

1900
01:26:19,198 --> 01:26:26,519
when and then the other thing that we do

1901
01:26:21,539 --> 01:26:28,590
with objects is we create them okay we

1902
01:26:26,520 --> 01:26:30,540
pass in the name of a class and it

1903
01:26:28,590 --> 01:26:32,659
returns us the object and you have to

1904
01:26:30,539 --> 01:26:37,529
tell it all of the parameters necessary

1905
01:26:32,659 --> 01:26:46,649
to get constructed so let's just copy

1906
01:26:37,529 --> 01:26:49,559
this code and see how we're going to go

1907
01:26:46,649 --> 01:26:52,049
ahead and build this so the first step

1908
01:26:49,560 --> 01:26:53,610
is we're not going to go n equals random

1909
01:26:52,050 --> 01:26:56,820
forest regressor we're going to go M

1910
01:26:53,609 --> 01:26:58,889
equals tree ensemble we're creating a

1911
01:26:56,819 --> 01:27:01,639
classical tree ensemble and we're going

1912
01:26:58,890 --> 01:27:01,640
to pass in

1913
01:27:04,289 --> 01:27:12,550
various bits of information okay so

1914
01:27:09,130 --> 01:27:15,220
maybe we'll have ten trees sample size

1915
01:27:12,550 --> 01:27:17,260
of a thousand or maybe a min leaf of

1916
01:27:15,220 --> 01:27:19,510
three okay and you can always like

1917
01:27:17,260 --> 01:27:21,159
choose to name your admits or not so

1918
01:27:19,510 --> 01:27:23,590
when you've got quite a few it's kind of

1919
01:27:21,159 --> 01:27:27,880
nice to name them so that just so we can

1920
01:27:23,590 --> 01:27:32,199
see what each one means it's always

1921
01:27:27,880 --> 01:27:35,109
optional so we're going to try and

1922
01:27:32,199 --> 01:27:39,550
create a class that we can use like this

1923
01:27:35,109 --> 01:27:41,979
and then the notional we're going to

1924
01:27:39,550 --> 01:27:44,260
bother with dot fit because we've passed

1925
01:27:41,979 --> 01:27:46,599
in the X and the y right like in

1926
01:27:44,260 --> 01:27:48,070
scikit-learn they use an approach where

1927
01:27:46,600 --> 01:27:49,750
first of all you construct something

1928
01:27:48,069 --> 01:27:52,689
without telling it what they did here is

1929
01:27:49,750 --> 01:27:53,829
and then you pass in the day we're doing

1930
01:27:52,689 --> 01:27:55,509
these two steps at once

1931
01:27:53,829 --> 01:27:57,729
we're actually passing in the data right

1932
01:27:55,510 --> 01:28:01,480
and so then after that we're going to be

1933
01:27:57,729 --> 01:28:06,189
going and dot so we're going to go creds

1934
01:28:01,479 --> 01:28:09,099
equals m predict passing in maybe some

1935
01:28:06,189 --> 01:28:11,529
validations there okay so we that's

1936
01:28:09,100 --> 01:28:14,770
that's the API we're kind of creating

1937
01:28:11,529 --> 01:28:16,509
here so this thing here is called a

1938
01:28:14,770 --> 01:28:19,350
constructor something that creates an

1939
01:28:16,510 --> 01:28:23,949
object is called a constructor and

1940
01:28:19,350 --> 01:28:26,620
Python there's a lot of ugly hideous

1941
01:28:23,949 --> 01:28:30,750
things about Python one of which is they

1942
01:28:26,619 --> 01:28:33,309
it uses these special magic method names

1943
01:28:30,750 --> 01:28:35,680
underscore underscore init underscore

1944
01:28:33,310 --> 01:28:37,030
underscore is a special magic method

1945
01:28:35,680 --> 01:28:40,300
that's caught it's called

1946
01:28:37,029 --> 01:28:43,210
when you try to construct a class so

1947
01:28:40,300 --> 01:28:45,789
when I call tree ensemble parentheses it

1948
01:28:43,210 --> 01:28:47,829
actually calls tree ensemble dot they

1949
01:28:45,789 --> 01:28:49,479
see people say dunder init I kind of

1950
01:28:47,829 --> 01:28:52,300
hate it but anyway timed it you know

1951
01:28:49,479 --> 01:28:54,629
double underscore in it double

1952
01:28:52,300 --> 01:28:56,980
underscore dunder init

1953
01:28:54,630 --> 01:28:59,770
so that's why we've got this method

1954
01:28:56,979 --> 01:29:01,209
called dunder init okay so when I call

1955
01:28:59,770 --> 01:29:02,880
tree ensemble is going to call this

1956
01:29:01,210 --> 01:29:06,630
method

1957
01:29:02,880 --> 01:29:10,619
another hideously ugly thing about

1958
01:29:06,630 --> 01:29:13,140
pythons oo is that there's this special

1959
01:29:10,619 --> 01:29:14,550
thing where if you have a class and to

1960
01:29:13,140 --> 01:29:17,630
create a class you just wrecked class in

1961
01:29:14,550 --> 01:29:20,220
the name of us all of its methods

1962
01:29:17,630 --> 01:29:23,579
automatically get sent one extra

1963
01:29:20,220 --> 01:29:25,680
parameter when extra arguments which is

1964
01:29:23,579 --> 01:29:27,840
the first argument and you can call it

1965
01:29:25,680 --> 01:29:30,060
anything you like if you call it

1966
01:29:27,840 --> 01:29:33,000
anything other than self everybody will

1967
01:29:30,060 --> 01:29:34,920
hate you and you're a bad person so call

1968
01:29:33,000 --> 01:29:40,800
it anything you like as long as it's

1969
01:29:34,920 --> 01:29:42,720
self so so that's why you always see

1970
01:29:40,800 --> 01:29:45,900
this and in fact I can immediately see

1971
01:29:42,720 --> 01:29:48,300
here I have a bug anybody see the bug in

1972
01:29:45,899 --> 01:29:52,769
my predict function I should have so

1973
01:29:48,300 --> 01:29:54,690
right I like it always do it right so

1974
01:29:52,770 --> 01:29:56,190
anytime you try and call a method on

1975
01:29:54,689 --> 01:29:58,439
your own class and you get something

1976
01:29:56,189 --> 01:30:00,599
saying you're passed in two parameters

1977
01:29:58,439 --> 01:30:04,229
and it was only expecting one you forgot

1978
01:30:00,600 --> 01:30:06,180
so okay so like this is a really dumb

1979
01:30:04,229 --> 01:30:08,069
way to add oh okay to a programming

1980
01:30:06,180 --> 01:30:10,470
language but the older languages like

1981
01:30:08,069 --> 01:30:12,269
Python often did this because they kind

1982
01:30:10,470 --> 01:30:15,150
of needed to they started out not being

1983
01:30:12,270 --> 01:30:17,580
oo and then they kind of added oo in a

1984
01:30:15,149 --> 01:30:20,219
way that was hideously ugly so Perl

1985
01:30:17,579 --> 01:30:22,739
which predates plaything by a little bit

1986
01:30:20,220 --> 01:30:24,869
kind of I think really came up with this

1987
01:30:22,739 --> 01:30:28,039
approach and unfortunately other

1988
01:30:24,869 --> 01:30:31,260
languages of that era stuck with it so

1989
01:30:28,039 --> 01:30:35,069
you have to add in this magic self so

1990
01:30:31,260 --> 01:30:39,060
the magic self now when you're inside

1991
01:30:35,069 --> 01:30:42,210
this class you can now pretend as if any

1992
01:30:39,060 --> 01:30:43,470
property name you like exists so I can

1993
01:30:42,210 --> 01:30:46,529
now pretend there's something called

1994
01:30:43,470 --> 01:30:48,720
self dot X I can read from it I can

1995
01:30:46,529 --> 01:30:50,880
write to it right but if I read from it

1996
01:30:48,720 --> 01:30:55,350
and I haven't yet written to it I'll get

1997
01:30:50,880 --> 01:30:58,140
an error so the stuff that's passed to

1998
01:30:55,350 --> 01:30:59,820
the constructor gets thrown away by

1999
01:30:58,140 --> 01:31:02,190
default like there's nothing that like

2000
01:30:59,819 --> 01:31:04,139
says you need to rip this class needs to

2001
01:31:02,189 --> 01:31:06,649
remember what these things are but

2002
01:31:04,140 --> 01:31:09,510
anything that we stick inside self is

2003
01:31:06,649 --> 01:31:12,210
remembered for all time you know as long

2004
01:31:09,510 --> 01:31:15,829
as this object exists you can access it

2005
01:31:12,210 --> 01:31:17,118
it's remembered so now that I've gone

2006
01:31:15,828 --> 01:31:21,878
in fact let's do this right so that

2007
01:31:17,118 --> 01:31:26,898
let's create the tree ensemble class and

2008
01:31:21,878 --> 01:31:31,658
let's now instantiate it okay of course

2009
01:31:26,899 --> 01:31:39,800
we haven't got X we need to call X train

2010
01:31:31,658 --> 01:31:42,938
y trade ok decision tree is not defined

2011
01:31:39,800 --> 01:31:42,939
so let's

2012
01:31:43,659 --> 01:31:47,639
we had a really minimal decision tree

2013
01:31:51,090 --> 01:31:56,920
there we go okay so here is enough to

2014
01:31:54,880 --> 01:31:59,829
actually instantiate our tree ensemble

2015
01:31:56,920 --> 01:32:01,750
okay so we have to find the inert for it

2016
01:31:59,829 --> 01:32:03,880
we have to find the inert for decision

2017
01:32:01,750 --> 01:32:06,550
tree we need decision trees in it to be

2018
01:32:03,880 --> 01:32:08,560
defined because inside our ensemble in

2019
01:32:06,550 --> 01:32:11,350
it they're called self directory and

2020
01:32:08,560 --> 01:32:13,690
then self create tree called the

2021
01:32:11,350 --> 01:32:16,660
decision tree constructor and then

2022
01:32:13,689 --> 01:32:18,099
decision tree constructor basically does

2023
01:32:16,659 --> 01:32:20,949
nothing at all other than save some

2024
01:32:18,100 --> 01:32:27,579
information right so at this point we

2025
01:32:20,949 --> 01:32:31,479
can now go m dot okay and if I press tab

2026
01:32:27,579 --> 01:32:34,649
at this point can anybody tell me what I

2027
01:32:31,479 --> 01:32:40,419
would expect to see press it to Taylor

2028
01:32:34,649 --> 01:32:42,099
tension could you possibly say like we

2029
01:32:40,420 --> 01:32:44,909
would see a drop-down of all available

2030
01:32:42,100 --> 01:32:48,039
methods for that class okay it would be

2031
01:32:44,909 --> 01:32:49,569
in this case so if M is a tree ensemble

2032
01:32:48,039 --> 01:32:53,619
we would have create tree and predict

2033
01:32:49,569 --> 01:32:55,899
okay anything else what

2034
01:32:53,619 --> 01:32:59,189
oh yeah as well as earnest whispered to

2035
01:32:55,899 --> 01:33:01,059
variables as well yeah so that the

2036
01:32:59,189 --> 01:33:03,099
variable could made a lot of things well

2037
01:33:01,060 --> 01:33:06,039
attributes so the things that we put

2038
01:33:03,100 --> 01:33:07,840
inside self so if I hit tab right there

2039
01:33:06,039 --> 01:33:10,210
they are right as Taylor said there's

2040
01:33:07,840 --> 01:33:11,739
create tree there's predict and then

2041
01:33:10,210 --> 01:33:19,600
there's everything else we put inside so

2042
01:33:11,739 --> 01:33:24,760
all right so if I look at m dot min leaf

2043
01:33:19,600 --> 01:33:26,620
if I hit shift enter what will I see yep

2044
01:33:24,760 --> 01:33:29,050
the number that I just put there I put

2045
01:33:26,619 --> 01:33:31,809
in leaf is three so that went up the air

2046
01:33:29,050 --> 01:33:33,159
dam in leaf this here is a default

2047
01:33:31,810 --> 01:33:34,840
argument such as if I don't pass

2048
01:33:33,159 --> 01:33:37,510
anything it'll be five but I did pass

2049
01:33:34,840 --> 01:33:41,199
something right so three self dot min

2050
01:33:37,510 --> 01:33:45,190
leaf here is it going to be equal to min

2051
01:33:41,199 --> 01:33:47,769
leaf yeah so something which like

2052
01:33:45,189 --> 01:33:49,529
because of this rather annoying way of

2053
01:33:47,770 --> 01:33:51,510
doing oh oh

2054
01:33:49,529 --> 01:33:55,289
it does mean that it's very easy to

2055
01:33:51,510 --> 01:33:57,930
accidentally forget so do that right so

2056
01:33:55,289 --> 01:34:02,550
if I don't assign it to self dot min

2057
01:33:57,930 --> 01:34:04,530
leaf right then I get an error and so

2058
01:34:02,550 --> 01:34:06,930
here tree ensemble doesn't happen in

2059
01:34:04,529 --> 01:34:07,859
leaf right so how do I create that

2060
01:34:06,930 --> 01:34:12,780
attribute

2061
01:34:07,859 --> 01:34:14,759
I just put something in it okay so if

2062
01:34:12,779 --> 01:34:16,920
you want to like if you don't know what

2063
01:34:14,760 --> 01:34:18,539
a value of it should be yet but you kind

2064
01:34:16,920 --> 01:34:21,440
of need to be able to refer to it you

2065
01:34:18,539 --> 01:34:24,689
can always feel like self dot min leaf

2066
01:34:21,439 --> 01:34:25,979
equals none that's at least there's

2067
01:34:24,689 --> 01:34:34,039
something you can read check for

2068
01:34:25,979 --> 01:34:36,929
numbness and not have an error great now

2069
01:34:34,039 --> 01:34:40,529
interestingly I was able to instantiate

2070
01:34:36,930 --> 01:34:42,810
tree ensemble even if I predict refers

2071
01:34:40,529 --> 01:34:45,300
to a method of decision tree that

2072
01:34:42,810 --> 01:34:48,330
doesn't exist and this is actually

2073
01:34:45,300 --> 01:34:52,860
something very nice about the dynamic

2074
01:34:48,329 --> 01:34:55,380
nature of Python is that because it's

2075
01:34:52,859 --> 01:34:58,199
not like compiling it it's not checking

2076
01:34:55,380 --> 01:35:01,170
anything unless you're using it right so

2077
01:34:58,199 --> 01:35:02,399
we can go ahead and create decision to

2078
01:35:01,170 --> 01:35:05,699
predict later

2079
01:35:02,399 --> 01:35:08,039
and then our our instantiated object

2080
01:35:05,699 --> 01:35:10,470
will magically start working right it

2081
01:35:08,039 --> 01:35:12,630
doesn't actually look up that functions

2082
01:35:10,470 --> 01:35:14,840
that methods details until you use it

2083
01:35:12,630 --> 01:35:17,840
and so it really helps with top-down

2084
01:35:14,840 --> 01:35:17,840
programming

2085
01:35:18,729 --> 01:35:24,729
okay so when you're inside a class

2086
01:35:22,869 --> 01:35:27,460
definition in other words you're at that

2087
01:35:24,729 --> 01:35:29,469
indentation level you know indented one

2088
01:35:27,460 --> 01:35:32,859
in so these are all class definitions

2089
01:35:29,470 --> 01:35:34,720
any function that you create unless you

2090
01:35:32,859 --> 01:35:37,269
do some special things that we're not

2091
01:35:34,720 --> 01:35:40,210
going to talk about yet is automatically

2092
01:35:37,270 --> 01:35:42,840
a method of that class and so every

2093
01:35:40,210 --> 01:35:49,329
method of that class magically gets a

2094
01:35:42,840 --> 01:35:50,949
self passed to it so we could call since

2095
01:35:49,329 --> 01:35:54,069
we've got a tree ensemble we could call

2096
01:35:50,949 --> 01:35:56,079
em create tree and we don't put anything

2097
01:35:54,069 --> 01:35:58,149
inside those parentheses because the

2098
01:35:56,079 --> 01:36:03,430
magic self will be passed and the magic

2099
01:35:58,149 --> 01:36:06,789
self will be whatever M is okay so m dot

2100
01:36:03,430 --> 01:36:09,420
create tree returns a decision tree just

2101
01:36:06,789 --> 01:36:15,039
like we asked it to right so m dot

2102
01:36:09,420 --> 01:36:17,440
create tree dot e excess will give us

2103
01:36:15,039 --> 01:36:23,260
the self ID access inside the decision

2104
01:36:17,439 --> 01:36:29,500
tree okay which is set to NP dot a range

2105
01:36:23,260 --> 01:36:30,970
range self dot sample size Y is data

2106
01:36:29,500 --> 01:36:34,420
scientists do we care about

2107
01:36:30,970 --> 01:36:37,060
object-oriented programming because a

2108
01:36:34,420 --> 01:36:40,539
lot of the stuff you use is going to

2109
01:36:37,060 --> 01:36:44,560
require you to implement stuff with oo P

2110
01:36:40,539 --> 01:36:47,649
for example every single PI torch model

2111
01:36:44,560 --> 01:36:50,860
of any kind is created with olp it's the

2112
01:36:47,649 --> 01:36:55,779
only way to create by torch models um

2113
01:36:50,859 --> 01:36:58,179
good news is what you see here is the

2114
01:36:55,779 --> 01:36:59,710
entirety of what you need to know so you

2115
01:36:58,180 --> 01:37:02,770
this is all you need to know you need to

2116
01:36:59,710 --> 01:37:04,689
know to create some in code in it to

2117
01:37:02,770 --> 01:37:07,360
assign the things to the pasta in it to

2118
01:37:04,689 --> 01:37:09,039
something call it self and then just

2119
01:37:07,359 --> 01:37:11,889
stick the word self after it give your

2120
01:37:09,039 --> 01:37:14,920
methods okay and so the nice thing is

2121
01:37:11,890 --> 01:37:17,380
like now to think as an AOP programmer

2122
01:37:14,920 --> 01:37:20,050
is to realize you don't now have to pass

2123
01:37:17,380 --> 01:37:22,150
around X Y sample size and min leaf to

2124
01:37:20,050 --> 01:37:25,510
every function that uses them by

2125
01:37:22,149 --> 01:37:29,170
assigning them to attributes itself

2126
01:37:25,510 --> 01:37:31,270
they're now available like magic all

2127
01:37:29,170 --> 01:37:32,029
right so this is why our peas super

2128
01:37:31,270 --> 01:37:34,280
handy

2129
01:37:32,029 --> 01:37:35,809
if you're particularly I started trying

2130
01:37:34,279 --> 01:37:38,000
to create a decision tree initially

2131
01:37:35,810 --> 01:37:41,600
without using oot and try to like keep

2132
01:37:38,000 --> 01:37:43,279
track of like what that decision tree

2133
01:37:41,600 --> 01:37:45,770
was meant to know about it was very

2134
01:37:43,279 --> 01:37:48,139
difficult you know where else with our P

2135
01:37:45,770 --> 01:37:50,090
you can just say even side the decision

2136
01:37:48,140 --> 01:37:54,140
tree you know self indexes equals this

2137
01:37:50,090 --> 01:37:55,489
and everything displace okay okay that's

2138
01:37:54,140 --> 01:37:59,289
great so we're out of time I think

2139
01:37:55,489 --> 01:38:02,239
that's that's great timing because

2140
01:37:59,289 --> 01:38:05,300
there's an introduction 200 P but this

2141
01:38:02,239 --> 01:38:07,639
week you know next class I'm going to

2142
01:38:05,300 --> 01:38:09,949
assume that you can use it right so you

2143
01:38:07,640 --> 01:38:12,350
should create some classes instantiate

2144
01:38:09,949 --> 01:38:15,199
some classes look at their methods and

2145
01:38:12,350 --> 01:38:17,810
properties have them call each other and

2146
01:38:15,199 --> 01:38:20,090
so forth until you feel comfortable with

2147
01:38:17,810 --> 01:38:22,520
them and maybe for those of you doesn't

2148
01:38:20,090 --> 01:38:24,500
haven't done our P before you can find

2149
01:38:22,520 --> 01:38:26,000
some other useful resources you could

2150
01:38:24,500 --> 01:38:28,479
flop them onto the wiki thread so that

2151
01:38:26,000 --> 01:38:32,170
other people know what you find useful

2152
01:38:28,479 --> 01:38:32,169
right thanks everybody

