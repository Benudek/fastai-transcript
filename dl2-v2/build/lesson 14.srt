1
00:00:02,029 --> 00:00:06,769
welcome to the last lesson lesson 14

2
00:00:07,099 --> 00:00:11,359
we're going to be looking at image

3
00:00:09,089 --> 00:00:16,289
segmentation today amongst other things

4
00:00:11,359 --> 00:00:19,250
but before we do a bit of show-and-tell

5
00:00:16,289 --> 00:00:21,929
from last week

6
00:00:19,250 --> 00:00:23,670
Elena Ali did something really

7
00:00:21,929 --> 00:00:25,350
interesting which was she tried finding

8
00:00:23,670 --> 00:00:28,679
out what would happen if you did cycle

9
00:00:25,350 --> 00:00:30,449
gain on just three or 400 images and I

10
00:00:28,679 --> 00:00:32,219
really like these projects where people

11
00:00:30,449 --> 00:00:34,530
just go to Google Image Search you know

12
00:00:32,219 --> 00:00:36,120
using the the API you're one of the

13
00:00:34,530 --> 00:00:37,439
libraries out there some of our students

14
00:00:36,119 --> 00:00:39,378
have created some very good libraries

15
00:00:37,439 --> 00:00:41,399
for interacting with Google images API

16
00:00:39,378 --> 00:00:44,039
download a bunch of stuff that they're

17
00:00:41,399 --> 00:00:48,359
interested in in this case some photos

18
00:00:44,039 --> 00:00:49,649
and some stained glass windows and yeah

19
00:00:48,359 --> 00:00:51,899
with three or four hundred photos of

20
00:00:49,649 --> 00:00:53,250
that she trained a model she trained

21
00:00:51,899 --> 00:00:55,109
actually a few different models this is

22
00:00:53,250 --> 00:00:57,149
what I particularly liked and as you can

23
00:00:55,109 --> 00:00:58,549
see with quite a small number of images

24
00:00:57,149 --> 00:01:01,859
you know she gets some very nice

25
00:00:58,549 --> 00:01:04,829
stained-glass effects so I thought that

26
00:01:01,859 --> 00:01:06,659
was a interesting example of yeah using

27
00:01:04,829 --> 00:01:08,459
pretty small amounts of data that was

28
00:01:06,659 --> 00:01:11,010
readily available that she was able to

29
00:01:08,459 --> 00:01:12,750
download pretty quickly and there's more

30
00:01:11,010 --> 00:01:17,219
information about that on the forum if

31
00:01:12,750 --> 00:01:18,599
you're interested yeah it's it's

32
00:01:17,219 --> 00:01:20,219
interesting to wonder about what kinds

33
00:01:18,599 --> 00:01:23,219
of things people will come up with with

34
00:01:20,219 --> 00:01:26,969
this kind of generative model it's

35
00:01:23,219 --> 00:01:29,700
clearly a great artistic medium it's

36
00:01:26,969 --> 00:01:33,359
clearly a great medium for forgeries and

37
00:01:29,700 --> 00:01:35,759
bakeries I wonder what other kinds of

38
00:01:33,359 --> 00:01:37,368
things before will realize they can do

39
00:01:35,759 --> 00:01:40,129
with these kind of generative models I

40
00:01:37,368 --> 00:01:44,609
think audio is going to be the next big

41
00:01:40,129 --> 00:01:47,548
area and also very like interactive type

42
00:01:44,609 --> 00:01:50,969
stuff that Nvidia I just released a

43
00:01:47,549 --> 00:01:53,060
paper showing a interactive kind of

44
00:01:50,969 --> 00:01:56,609
photo repair tour where you just like

45
00:01:53,060 --> 00:01:59,549
brush over an object and it replaces it

46
00:01:56,609 --> 00:02:01,828
with you know a deep learning generated

47
00:01:59,549 --> 00:02:03,360
replacement very nicely those kinds of

48
00:02:01,828 --> 00:02:07,618
interactive tools I think would be very

49
00:02:03,359 --> 00:02:09,780
interesting too so before we talk about

50
00:02:07,618 --> 00:02:12,930
segmentation we've got some stuff to

51
00:02:09,780 --> 00:02:13,439
finish up from last time which is that

52
00:02:12,930 --> 00:02:17,879
we look

53
00:02:13,439 --> 00:02:22,829
at doing style transfer they actually

54
00:02:17,879 --> 00:02:24,719
directly optimizing pixels and you know

55
00:02:22,830 --> 00:02:27,290
like with most of the things in part two

56
00:02:24,719 --> 00:02:32,219
it's not so much that I'm wanting you to

57
00:02:27,289 --> 00:02:35,430
understand style transfer per se but the

58
00:02:32,219 --> 00:02:38,310
kind of idea of optimizing your input

59
00:02:35,430 --> 00:02:40,219
directly and using activations as part

60
00:02:38,310 --> 00:02:47,189
of a loss function is really the key

61
00:02:40,219 --> 00:02:49,400
kind of takeaway here so it's

62
00:02:47,189 --> 00:02:52,109
interesting then to kind of see the

63
00:02:49,400 --> 00:02:53,520
photos effectively the follow-up paper

64
00:02:52,110 --> 00:02:55,980
you know not from the same people but

65
00:02:53,520 --> 00:02:57,600
the paper that kind of came next in the

66
00:02:55,979 --> 00:02:59,539
in the sequence of these kind of vision

67
00:02:57,599 --> 00:03:04,460
generative models with this one from

68
00:02:59,539 --> 00:03:08,519
Justin Johnson and folks at Stanford and

69
00:03:04,460 --> 00:03:10,080
it it actually does the same thing style

70
00:03:08,520 --> 00:03:13,650
transfer but it does it in a different

71
00:03:10,080 --> 00:03:15,900
way rather than optimizing the pixels

72
00:03:13,650 --> 00:03:17,670
we're going to go back to something much

73
00:03:15,900 --> 00:03:20,340
more familiar and optimize some weights

74
00:03:17,669 --> 00:03:24,019
and so specifically we're going to train

75
00:03:20,340 --> 00:03:27,810
a model which learns to take a photo and

76
00:03:24,020 --> 00:03:29,969
translate it into a photo on this in the

77
00:03:27,810 --> 00:03:34,280
style of a particular artwork

78
00:03:29,969 --> 00:03:41,250
so each ComNet will learn to produce one

79
00:03:34,280 --> 00:03:42,780
kind of style now it turns out that

80
00:03:41,250 --> 00:03:44,939
getting to that point there's an

81
00:03:42,780 --> 00:03:48,959
intermediate point which is I actually

82
00:03:44,939 --> 00:03:51,030
think kind of more more useful and Texas

83
00:03:48,959 --> 00:03:52,979
halfway there which is something called

84
00:03:51,030 --> 00:03:55,709
super resolution so we're actually going

85
00:03:52,979 --> 00:03:56,789
to start with super resolution because

86
00:03:55,709 --> 00:03:58,319
then we'll build on top of super

87
00:03:56,789 --> 00:04:01,759
resolution to finish off the style

88
00:03:58,319 --> 00:04:04,680
transfer ComNet based I'll transfer and

89
00:04:01,759 --> 00:04:07,259
so super resolution is where we take a

90
00:04:04,680 --> 00:04:11,939
low res image we're going to take 72 by

91
00:04:07,259 --> 00:04:17,159
72 and upscale up to a larger image 288

92
00:04:11,939 --> 00:04:20,089
by 288 in our case trying to create you

93
00:04:17,160 --> 00:04:25,080
know a higher res image that looks as

94
00:04:20,089 --> 00:04:26,819
real as possible and so this is a pretty

95
00:04:25,079 --> 00:04:29,310
challenging thing to do because at 72

96
00:04:26,819 --> 00:04:31,379
by 72 there's not that much information

97
00:04:29,310 --> 00:04:33,660
about a lot of the details and the cool

98
00:04:31,379 --> 00:04:36,089
thing is that we're going to do it in a

99
00:04:33,660 --> 00:04:39,210
way as we tend to do with vision models

100
00:04:36,089 --> 00:04:40,709
which is not tied to the input size so

101
00:04:39,209 --> 00:04:44,489
you could totally then take this model

102
00:04:40,709 --> 00:04:46,829
that and apply it to a 288 by 288 image

103
00:04:44,490 --> 00:04:48,840
and get something that's four times

104
00:04:46,829 --> 00:04:52,680
bigger on each side so 16 times bigger

105
00:04:48,839 --> 00:04:54,899
than that and and often it even kind of

106
00:04:52,680 --> 00:04:57,300
works better at that level because

107
00:04:54,899 --> 00:04:59,639
you're really introducing a lot of a lot

108
00:04:57,300 --> 00:05:00,840
of detail into the finer details and you

109
00:04:59,639 --> 00:05:03,389
could really print out a high resolution

110
00:05:00,839 --> 00:05:08,479
print of something which earlier on was

111
00:05:03,389 --> 00:05:13,289
pretty big so later so this is the

112
00:05:08,480 --> 00:05:17,819
notebook or enhance and it is a lot like

113
00:05:13,290 --> 00:05:18,720
that kind of CSI style enhancement where

114
00:05:17,819 --> 00:05:21,569
we're going to take something that

115
00:05:18,720 --> 00:05:25,560
appears like the information is just not

116
00:05:21,569 --> 00:05:27,360
there and we kind of invent it but the

117
00:05:25,560 --> 00:05:28,829
confidence going to learn to invent it

118
00:05:27,360 --> 00:05:30,720
in a way that's consistent with the

119
00:05:28,829 --> 00:05:32,159
information that is there so hopefully

120
00:05:30,720 --> 00:05:34,440
you know it's kind of inventing the

121
00:05:32,160 --> 00:05:37,680
right information one of the really nice

122
00:05:34,439 --> 00:05:40,560
things about this kind of problem is

123
00:05:37,680 --> 00:05:43,170
that we can create our own data set as

124
00:05:40,560 --> 00:05:45,300
big as we like without any labeling

125
00:05:43,170 --> 00:05:47,970
requirements because we can easily

126
00:05:45,300 --> 00:05:50,210
create a low res image from a high-res

127
00:05:47,970 --> 00:05:54,210
image just by down sampling our images

128
00:05:50,209 --> 00:05:56,699
so something I would love some of you to

129
00:05:54,209 --> 00:06:00,209
try doing the week would be to through

130
00:05:56,699 --> 00:06:03,560
other types of imaged image translation

131
00:06:00,209 --> 00:06:05,459
where you can invent kind of late labels

132
00:06:03,560 --> 00:06:09,360
invent your dependent variable for

133
00:06:05,459 --> 00:06:11,699
example D skewing you know so either

134
00:06:09,360 --> 00:06:14,040
recognize things that have been rotated

135
00:06:11,699 --> 00:06:16,430
by 90 degrees or better still that have

136
00:06:14,040 --> 00:06:20,520
been rotated by five degrees and

137
00:06:16,430 --> 00:06:21,689
straighten them colorization so turn

138
00:06:20,519 --> 00:06:24,149
make a bunch of images into

139
00:06:21,689 --> 00:06:28,620
black-and-white and learn to put the

140
00:06:24,149 --> 00:06:32,849
color back again noise reduction you

141
00:06:28,620 --> 00:06:38,250
know maybe do a really low quality JPEG

142
00:06:32,850 --> 00:06:39,930
save and learn to put it back to how it

143
00:06:38,250 --> 00:06:43,740
should have been

144
00:06:39,930 --> 00:06:44,939
and so forth or yeah maybe taking

145
00:06:43,740 --> 00:06:47,460
something that's like in a 16 color

146
00:06:44,939 --> 00:06:50,009
palette and put it back to a higher

147
00:06:47,459 --> 00:06:52,079
color palette I think these things are

148
00:06:50,009 --> 00:06:56,639
all interesting because they can like be

149
00:06:52,079 --> 00:06:58,288
used to take you know pictures that you

150
00:06:56,639 --> 00:07:00,060
may have taken back on crappy old

151
00:06:58,288 --> 00:07:01,769
digital cameras before there are high

152
00:07:00,060 --> 00:07:04,680
resolution or you may have scanned in

153
00:07:01,769 --> 00:07:06,359
some old photos that kind of faded or

154
00:07:04,680 --> 00:07:08,879
whatever you know I think it's really

155
00:07:06,360 --> 00:07:10,530
useful thing to go to do and also it's

156
00:07:08,879 --> 00:07:12,209
but it's a good project because it's

157
00:07:10,529 --> 00:07:13,679
like really similar to what we're doing

158
00:07:12,209 --> 00:07:14,909
here but different enough that you'll

159
00:07:13,680 --> 00:07:19,949
come come across some interesting

160
00:07:14,910 --> 00:07:22,110
challenges on the way I'm sure so I'm

161
00:07:19,949 --> 00:07:24,150
going to use some imagenet again again

162
00:07:22,110 --> 00:07:25,800
you don't need to use all of image net

163
00:07:24,149 --> 00:07:27,538
at all I just happened to have it lying

164
00:07:25,800 --> 00:07:29,310
around you can download the one percent

165
00:07:27,538 --> 00:07:31,949
sample of image net from faster faster

166
00:07:29,310 --> 00:07:36,089
they are you can use any set of pictures

167
00:07:31,949 --> 00:07:38,430
you have lying around honestly and in

168
00:07:36,089 --> 00:07:42,209
this case as I say we don't really have

169
00:07:38,430 --> 00:07:44,668
labels per se so I just got a give

170
00:07:42,209 --> 00:07:46,500
everything a label of zero just so we

171
00:07:44,668 --> 00:07:50,668
can use it with our existing

172
00:07:46,500 --> 00:07:53,129
infrastructure more easily now because

173
00:07:50,668 --> 00:07:54,448
I'm in this case pointing at a folder

174
00:07:53,129 --> 00:07:55,800
that contains all of image net I

175
00:07:54,449 --> 00:07:57,960
certainly don't want to wait for all of

176
00:07:55,800 --> 00:08:01,439
image net to finish to run an epoch so

177
00:07:57,959 --> 00:08:04,079
here I'm just most of the time I would

178
00:08:01,439 --> 00:08:06,719
set keep percent to like one or two

179
00:08:04,079 --> 00:08:09,060
percent and then I just generate a bunch

180
00:08:06,720 --> 00:08:11,550
of random numbers and then I just grab

181
00:08:09,060 --> 00:08:14,990
those keeps those which are less than

182
00:08:11,550 --> 00:08:23,460
0.02 and so that lets be quickly

183
00:08:14,990 --> 00:08:30,780
subsample my rows all right so we're

184
00:08:23,459 --> 00:08:32,278
going to use vgg 16 and vgg 16 is

185
00:08:30,779 --> 00:08:36,889
something that we haven't really looked

186
00:08:32,278 --> 00:08:40,820
at in this class but it's a very simple

187
00:08:36,889 --> 00:08:44,639
very simple model where we take and

188
00:08:40,820 --> 00:08:49,709
normal as you apply three-channel input

189
00:08:44,639 --> 00:08:53,199
and we basically run it through a number

190
00:08:49,708 --> 00:08:55,599
of 3x3 convolutions

191
00:08:53,200 --> 00:09:00,430
and then from time to time we put it

192
00:08:55,600 --> 00:09:08,529
through a 2x2 Maps pool and then we do a

193
00:09:00,429 --> 00:09:13,599
few more 3x3 convolutions max Paul so on

194
00:09:08,529 --> 00:09:22,990
so forth and then this is kind of our

195
00:09:13,600 --> 00:09:25,750
backbone I guess and then we we don't do

196
00:09:22,990 --> 00:09:28,029
an average pooling layer in a deputy of

197
00:09:25,750 --> 00:09:30,970
average pooling layer after a few of

198
00:09:28,029 --> 00:09:34,149
these we end up with this you know 7x7

199
00:09:30,970 --> 00:09:37,060
grid as usual I think it's about 7 by 7

200
00:09:34,149 --> 00:09:38,649
by 512 something like that and so rather

201
00:09:37,059 --> 00:09:41,139
than average polling we do something

202
00:09:38,649 --> 00:09:45,519
different which is reflect the whole

203
00:09:41,139 --> 00:09:49,330
thing so that spits out a very long

204
00:09:45,519 --> 00:09:53,110
vector of activations of size 7 times 7

205
00:09:49,330 --> 00:09:57,070
times 512 memory says correctly and then

206
00:09:53,110 --> 00:10:03,330
that gets fed into two fully connected

207
00:09:57,070 --> 00:10:05,740
layers each one of which has 409 6

208
00:10:03,330 --> 00:10:08,460
activations and then one more fully

209
00:10:05,740 --> 00:10:12,399
connected layer which has however many

210
00:10:08,460 --> 00:10:18,910
classes so if you think about it the

211
00:10:12,399 --> 00:10:25,480
weight matrix here is huge it's you know

212
00:10:18,909 --> 00:10:28,559
7 by 7 by 512 by 409 6 and it's because

213
00:10:25,480 --> 00:10:31,720
of that weight matrix really that V gge

214
00:10:28,559 --> 00:10:33,849
went out of favor pretty quickly because

215
00:10:31,720 --> 00:10:36,750
it takes a lot of memory and takes a lot

216
00:10:33,850 --> 00:10:39,850
of computation and it's really slow and

217
00:10:36,750 --> 00:10:43,210
there's a lot of redundant stuff going

218
00:10:39,850 --> 00:10:47,710
on here because really those 512

219
00:10:43,210 --> 00:10:49,900
activations are not that specific to

220
00:10:47,710 --> 00:10:52,210
which of those 7x7 grid cells they're in

221
00:10:49,899 --> 00:10:55,240
right but when you have this entire

222
00:10:52,210 --> 00:10:58,230
weight matrix here of every possible

223
00:10:55,240 --> 00:11:01,299
combination it treats all of them

224
00:10:58,230 --> 00:11:03,580
uniquely right and so that'll can also

225
00:11:01,299 --> 00:11:04,929
lead to generalization core ones because

226
00:11:03,580 --> 00:11:06,930
there's just a lot of weights and so

227
00:11:04,929 --> 00:11:10,299
forth

228
00:11:06,929 --> 00:11:12,519
my view is that there's you know that

229
00:11:10,299 --> 00:11:16,289
the approach that's used in every modern

230
00:11:12,519 --> 00:11:19,419
Network which is here we do an adaptive

231
00:11:16,289 --> 00:11:21,759
average pulling care ask that we be

232
00:11:19,419 --> 00:11:23,828
known as a global average calling for in

233
00:11:21,759 --> 00:11:28,088
fast AI we didn't really do a concat

234
00:11:23,828 --> 00:11:32,169
adaptive concat pooling which spits it

235
00:11:28,089 --> 00:11:34,769
straight down to a 512 long activation

236
00:11:32,169 --> 00:11:38,229
I think that's throwing away too much

237
00:11:34,769 --> 00:11:40,120
geometry so to me probably the correct

238
00:11:38,230 --> 00:11:42,459
answer is somewhere in between and will

239
00:11:40,120 --> 00:11:45,250
involve some kind of um factored

240
00:11:42,458 --> 00:11:48,338
convolution or some kind of tensor

241
00:11:45,250 --> 00:11:50,139
decomposition which yeah maybe some of

242
00:11:48,339 --> 00:11:53,230
us can think about in the coming months

243
00:11:50,139 --> 00:11:55,089
so for now anyway we've gone from one

244
00:11:53,230 --> 00:11:57,399
extreme which is the adaptive average

245
00:11:55,089 --> 00:11:59,680
pulling to the other extreme which is

246
00:11:57,399 --> 00:12:02,769
this huge flattened collocation player

247
00:11:59,679 --> 00:12:05,049
so a couple of things which are

248
00:12:02,769 --> 00:12:08,948
interesting about vgg that make it still

249
00:12:05,049 --> 00:12:13,719
useful today the first one is that

250
00:12:08,948 --> 00:12:17,198
there's there's more interesting layers

251
00:12:13,720 --> 00:12:19,449
going on here with with most modern

252
00:12:17,198 --> 00:12:22,659
networks including the resident family

253
00:12:19,448 --> 00:12:26,469
we the very first layer generally is a

254
00:12:22,659 --> 00:12:29,469
seven by seven pawns or something

255
00:12:26,470 --> 00:12:32,139
similar which means we and that's tried

256
00:12:29,470 --> 00:12:35,110
to right which means we throw away half

257
00:12:32,139 --> 00:12:38,490
the grid size straight away and so this

258
00:12:35,110 --> 00:12:40,690
little opportunity to use the the fine

259
00:12:38,490 --> 00:12:45,399
detail because we never do any

260
00:12:40,690 --> 00:12:49,480
computation with it and so that's a bit

261
00:12:45,399 --> 00:12:52,059
of a problem for things like

262
00:12:49,480 --> 00:12:54,699
segmentation or super resolution models

263
00:12:52,059 --> 00:12:57,669
because the fine detail matters right we

264
00:12:54,698 --> 00:13:00,729
actually want to restore it and then the

265
00:12:57,669 --> 00:13:03,610
second problem is that the adaptive

266
00:13:00,730 --> 00:13:05,440
average polling layer entirely throws

267
00:13:03,610 --> 00:13:07,120
away the geometry in the last few

268
00:13:05,440 --> 00:13:09,370
sections which means that the rest of

269
00:13:07,120 --> 00:13:10,959
the moral doesn't really have as much

270
00:13:09,370 --> 00:13:13,778
interesting kind of learning that

271
00:13:10,958 --> 00:13:15,909
geometry is it otherwise might and so

272
00:13:13,778 --> 00:13:18,338
therefore for things which dependent on

273
00:13:15,909 --> 00:13:19,719
position any kind of localization based

274
00:13:18,339 --> 00:13:20,559
approach tor anything that requires

275
00:13:19,720 --> 00:13:24,459
generative model

276
00:13:20,558 --> 00:13:26,078
is going to be less effective so one of

277
00:13:24,458 --> 00:13:28,058
the things I'm hoping you're hearing is

278
00:13:26,078 --> 00:13:30,149
I describe this is that probably none of

279
00:13:28,058 --> 00:13:33,818
the existing architectures are actually

280
00:13:30,149 --> 00:13:35,859
ideal we can invent a new one then

281
00:13:33,818 --> 00:13:38,998
actually I just tried inventing a new

282
00:13:35,859 --> 00:13:45,099
one over the week which was to take the

283
00:13:38,999 --> 00:13:48,819
the vgg head and attach it to a resonate

284
00:13:45,099 --> 00:13:51,549
that one and interestingly I found I

285
00:13:48,818 --> 00:13:54,488
actually got a slightly better

286
00:13:51,548 --> 00:13:55,629
classifier than a normal ResNet but it

287
00:13:54,489 --> 00:13:57,908
also was something with a little bit

288
00:13:55,629 --> 00:14:00,009
more useful information you know it took

289
00:13:57,908 --> 00:14:02,438
I don't know five or ten percent longer

290
00:14:00,009 --> 00:14:07,028
to Train but nothing worth worrying

291
00:14:02,438 --> 00:14:08,708
about yeah I think you know maybe we

292
00:14:07,028 --> 00:14:10,119
couldn't in Resident replace this as

293
00:14:08,708 --> 00:14:12,638
we've talked about briefly before this

294
00:14:10,119 --> 00:14:14,649
very early convolution with something

295
00:14:12,639 --> 00:14:16,778
more like an inceptions dam which has a

296
00:14:14,649 --> 00:14:19,599
bit more computation I think there's

297
00:14:16,778 --> 00:14:22,958
definitely room for some nice little

298
00:14:19,599 --> 00:14:25,449
tweaks to these architectures so that we

299
00:14:22,958 --> 00:14:27,248
can build some models which are maybe

300
00:14:25,448 --> 00:14:28,719
more versatile you know at the moment

301
00:14:27,249 --> 00:14:30,129
people tend to build architectures that

302
00:14:28,720 --> 00:14:32,259
just do one thing they don't really

303
00:14:30,129 --> 00:14:34,629
think you know what am i throwing away

304
00:14:32,259 --> 00:14:36,339
in terms of opportunity because that's

305
00:14:34,629 --> 00:14:37,688
that's how publishing works you know you

306
00:14:36,339 --> 00:14:39,339
published like they've got the state of

307
00:14:37,688 --> 00:14:40,928
the art and this one thing rather than

308
00:14:39,339 --> 00:14:44,289
you have created something that's good

309
00:14:40,928 --> 00:14:46,688
at lots of things so um so for these

310
00:14:44,288 --> 00:14:48,788
reasons we're going to use vgg today

311
00:14:46,688 --> 00:14:51,068
even though it's it's ancient and it's

312
00:14:48,788 --> 00:14:53,168
missing lots of great stuff one thing we

313
00:14:51,068 --> 00:14:55,389
are going to do though is use a slightly

314
00:14:53,168 --> 00:14:58,298
more modern version which is a version

315
00:14:55,389 --> 00:15:00,759
of vgg where batch norm has been added

316
00:14:58,298 --> 00:15:03,608
after all the convolutions and so in

317
00:15:00,759 --> 00:15:05,408
fast AI actually when you ask for a vgg

318
00:15:03,609 --> 00:15:07,959
Network you always get the best norm one

319
00:15:05,408 --> 00:15:10,720
because that's basically always what you

320
00:15:07,958 --> 00:15:13,598
want so this is actually very Gigi with

321
00:15:10,720 --> 00:15:16,449
batch mode and there's a 16 in the 19

322
00:15:13,599 --> 00:15:18,879
the 19 is way bigger and heavier and

323
00:15:16,448 --> 00:15:23,649
doesn't really is really any better so

324
00:15:18,879 --> 00:15:26,859
we no one really uses it okay so we're

325
00:15:23,649 --> 00:15:29,828
going to go from 72 by 72 LR is low

326
00:15:26,859 --> 00:15:31,720
resolution input size low resolution

327
00:15:29,828 --> 00:15:34,149
we're going to initially scale it up by

328
00:15:31,720 --> 00:15:37,960
x 2 we're the batch size of 60

329
00:15:34,149 --> 00:15:42,549
or to get a two times 72 so one by 44 by

330
00:15:37,960 --> 00:15:47,350
144 output so that's gonna be our stage

331
00:15:42,549 --> 00:15:50,559
stage one we'll create our own data set

332
00:15:47,350 --> 00:15:54,159
for this and the data set it's very

333
00:15:50,559 --> 00:15:56,169
worthwhile looking inside the faster I

334
00:15:54,159 --> 00:15:59,949
dot data set module and seeing what's

335
00:15:56,169 --> 00:16:02,049
there because just about anything you'd

336
00:15:59,950 --> 00:16:04,750
want we probably have something that's

337
00:16:02,049 --> 00:16:08,469
almost what you want so in this case I

338
00:16:04,750 --> 00:16:11,139
want a data set where my X's are images

339
00:16:08,470 --> 00:16:12,850
and my y's also images so there's

340
00:16:11,139 --> 00:16:15,580
already a files data set we can inherit

341
00:16:12,850 --> 00:16:17,440
from where the x's are images and then i

342
00:16:15,580 --> 00:16:20,230
just inherit from that and i just copied

343
00:16:17,440 --> 00:16:23,650
and pasted the get x and turn that into

344
00:16:20,230 --> 00:16:25,300
get y so i just opens an image so now

345
00:16:23,649 --> 00:16:27,399
I've got something where that X is an

346
00:16:25,299 --> 00:16:29,379
image and the y is an image and in both

347
00:16:27,399 --> 00:16:33,699
cases what we're passing in is an array

348
00:16:29,379 --> 00:16:36,159
of flower names I'm going to do some

349
00:16:33,700 --> 00:16:37,570
data augmentation obviously with all of

350
00:16:36,159 --> 00:16:39,370
image net we don't really need it but

351
00:16:37,570 --> 00:16:41,080
this is mainly here for you know anybody

352
00:16:39,370 --> 00:16:42,720
who's using smaller data sets to make

353
00:16:41,080 --> 00:16:47,379
the most of it

354
00:16:42,720 --> 00:16:49,269
random dihedral is referring to every

355
00:16:47,379 --> 00:16:51,269
possible 90-degree rotation and plus

356
00:16:49,269 --> 00:16:55,620
optional left/right flipping so though

357
00:16:51,269 --> 00:16:57,819
the dihedral group of eight symmetries

358
00:16:55,620 --> 00:17:00,429
normally we don't use this

359
00:16:57,820 --> 00:17:01,600
transformation for image net pictures

360
00:17:00,429 --> 00:17:04,809
because like you don't normally flip

361
00:17:01,600 --> 00:17:07,360
blobs upside down but in this case we're

362
00:17:04,809 --> 00:17:08,889
not trying to classify whether it's a

363
00:17:07,359 --> 00:17:10,569
dog or a cat we're just trying to keep

364
00:17:08,890 --> 00:17:14,020
the general structure of it

365
00:17:10,569 --> 00:17:17,109
so actually you know every possible flip

366
00:17:14,019 --> 00:17:21,369
is a reasonably sensible thing to do for

367
00:17:17,109 --> 00:17:23,588
this problem so a creative validation

368
00:17:21,369 --> 00:17:25,838
set in the usual way

369
00:17:23,588 --> 00:17:27,730
and you can see I'm kind of like using a

370
00:17:25,838 --> 00:17:29,889
few more slightly lower level functions

371
00:17:27,730 --> 00:17:31,900
generally speaking I just copy and paste

372
00:17:29,890 --> 00:17:34,960
them out of the faster source code to

373
00:17:31,900 --> 00:17:37,590
you know find the bits I want so here's

374
00:17:34,960 --> 00:17:42,480
the bit which takes an array of

375
00:17:37,589 --> 00:17:47,019
validation set indexes and one or more

376
00:17:42,480 --> 00:17:47,950
arrays of variables and simply splits so

377
00:17:47,019 --> 00:17:50,980
in this case the

378
00:17:47,950 --> 00:17:53,710
into a training and a validation set and

379
00:17:50,980 --> 00:17:55,809
this into a training novella bit sorry

380
00:17:53,710 --> 00:17:58,930
it yeah the training validation set you

381
00:17:55,809 --> 00:18:01,539
give us our X's and our whites now in

382
00:17:58,930 --> 00:18:04,600
this case the Train are the X and the y

383
00:18:01,539 --> 00:18:06,099
at the same import image and our output

384
00:18:04,599 --> 00:18:08,349
image of the same we're going to use

385
00:18:06,099 --> 00:18:10,929
transformations to make one of them

386
00:18:08,349 --> 00:18:18,639
lower resolution so that's why these are

387
00:18:10,930 --> 00:18:21,190
the same the same thing okay so the next

388
00:18:18,640 --> 00:18:24,000
thing that we need to do is to create

389
00:18:21,190 --> 00:18:26,470
our transformations as per usual and

390
00:18:24,000 --> 00:18:29,319
we're going to use this transform Y

391
00:18:26,470 --> 00:18:31,980
parameter like we did for bounding boxes

392
00:18:29,319 --> 00:18:34,869
but rather than use transform type dot

393
00:18:31,980 --> 00:18:40,319
coordinate we're going to use transform

394
00:18:34,869 --> 00:18:43,599
type pixel and so that tells our

395
00:18:40,319 --> 00:18:47,259
transformations framework that your Y

396
00:18:43,599 --> 00:18:50,259
values are images with normal pixels in

397
00:18:47,259 --> 00:18:52,629
them and so anything you do the X you

398
00:18:50,259 --> 00:18:53,710
also need to do so the way do the same

399
00:18:52,630 --> 00:18:55,600
thing okay

400
00:18:53,710 --> 00:18:58,059
and you need to make sure any data

401
00:18:55,599 --> 00:19:06,759
augmentation transforms you use have the

402
00:18:58,059 --> 00:19:08,259
same parameter as well okay so you can

403
00:19:06,759 --> 00:19:09,670
see the possible transform types you

404
00:19:08,259 --> 00:19:10,720
basically you've got classification

405
00:19:09,670 --> 00:19:12,400
which we're about to use the

406
00:19:10,720 --> 00:19:16,630
segmentation in the second half of today

407
00:19:12,400 --> 00:19:22,380
coordinates no transformation at all or

408
00:19:16,630 --> 00:19:26,680
pixel alright so once we've got a

409
00:19:22,380 --> 00:19:29,560
dataset class and some X&amp;Y training and

410
00:19:26,680 --> 00:19:31,570
validation sets there's a handy little

411
00:19:29,559 --> 00:19:34,929
method called get datasets which

412
00:19:31,569 --> 00:19:36,460
basically runs that constructor over all

413
00:19:34,930 --> 00:19:39,190
the different things that you have to

414
00:19:36,460 --> 00:19:41,230
return all the datasets you need in

415
00:19:39,190 --> 00:19:43,450
exactly the right format to pass pass to

416
00:19:41,230 --> 00:19:45,519
a model data constructor as a

417
00:19:43,450 --> 00:19:47,410
constructor in this case the image data

418
00:19:45,519 --> 00:19:50,349
constructor so we're kind of like going

419
00:19:47,410 --> 00:19:52,060
back under the covers of fast AI a

420
00:19:50,349 --> 00:19:54,909
little bit and building it up from

421
00:19:52,059 --> 00:19:57,099
scratch and you know in the next few

422
00:19:54,910 --> 00:19:58,720
weeks this will all be wrapped up and

423
00:19:57,099 --> 00:20:00,639
refactored into something that you can

424
00:19:58,720 --> 00:20:01,420
do in a single step in fast AI but the

425
00:20:00,640 --> 00:20:04,180
point of this

426
00:20:01,420 --> 00:20:06,750
is to learn you know a bit about going

427
00:20:04,180 --> 00:20:06,750
under the covers

428
00:20:07,470 --> 00:20:15,579
so something we've briefly seen before

429
00:20:12,190 --> 00:20:17,950
is that when we take images in we

430
00:20:15,579 --> 00:20:21,039
transform them not just the data

431
00:20:17,950 --> 00:20:23,890
augmentation that we also move the

432
00:20:21,039 --> 00:20:25,629
channels dimension up to the start we

433
00:20:23,890 --> 00:20:28,180
subtract the mean divided by the

434
00:20:25,630 --> 00:20:29,950
standard deviation whatever so if we

435
00:20:28,180 --> 00:20:32,380
want to be able to display those

436
00:20:29,950 --> 00:20:33,670
pictures that have come out of our data

437
00:20:32,380 --> 00:20:36,250
sets or data loaders we need to

438
00:20:33,670 --> 00:20:41,019
denormalize them and so the model data

439
00:20:36,250 --> 00:20:42,579
objects data set has ad norm function

440
00:20:41,019 --> 00:20:44,920
that knows how to do that so I'm just

441
00:20:42,579 --> 00:20:46,960
going to give that a short name for

442
00:20:44,920 --> 00:20:48,490
convenience so now I'm going to create a

443
00:20:46,960 --> 00:20:51,009
function that can show an image from a

444
00:20:48,490 --> 00:20:53,740
data set and if you pass in something

445
00:20:51,009 --> 00:20:57,730
saying this is a normalized image then

446
00:20:53,740 --> 00:21:00,240
won'ting on it okay so we can go ahead

447
00:20:57,730 --> 00:21:03,910
and have a look at that you'll see here

448
00:21:00,240 --> 00:21:07,390
we've passed in size low-res as our size

449
00:21:03,910 --> 00:21:10,330
for the transforms and size high-res as

450
00:21:07,390 --> 00:21:13,090
this is something new the size Y

451
00:21:10,329 --> 00:21:15,099
parameter okay so the two bits are going

452
00:21:13,089 --> 00:21:17,649
to get different sizes and so here you

453
00:21:15,099 --> 00:21:20,589
can see the two different resolutions of

454
00:21:17,650 --> 00:21:25,120
our X and our Y for a whole bunch of

455
00:21:20,589 --> 00:21:28,269
fish okay as you know as per usual plot

456
00:21:25,119 --> 00:21:29,769
subplots to create our two plots and

457
00:21:28,269 --> 00:21:33,069
then we can just use the different axes

458
00:21:29,769 --> 00:21:41,019
that came back to the stuff next to each

459
00:21:33,069 --> 00:21:42,250
other so we can then have a look at a

460
00:21:41,019 --> 00:21:44,019
few different versions of the data

461
00:21:42,250 --> 00:21:45,160
transformation and there you can see

462
00:21:44,019 --> 00:21:48,509
them being clicked in all different

463
00:21:45,160 --> 00:21:57,670
directions okay

464
00:21:48,509 --> 00:22:04,299
so let's create our model so we're going

465
00:21:57,670 --> 00:22:08,050
to have an image coming in small image

466
00:22:04,299 --> 00:22:13,450
coming in and we want to have a big

467
00:22:08,049 --> 00:22:14,759
image coming out and so we need to do

468
00:22:13,450 --> 00:22:18,130
some computation

469
00:22:14,759 --> 00:22:20,170
between those two to calculate what the

470
00:22:18,130 --> 00:22:21,520
big image would look like and so

471
00:22:20,170 --> 00:22:23,830
essentially there's kind of two ways of

472
00:22:21,519 --> 00:22:27,549
doing that computation we could first of

473
00:22:23,829 --> 00:22:31,839
all do some up sampling and then do a

474
00:22:27,549 --> 00:22:35,889
few straight one kind of layers to do

475
00:22:31,839 --> 00:22:38,109
lots of computation or we could first do

476
00:22:35,890 --> 00:22:40,420
lots of straight one layers to do other

477
00:22:38,109 --> 00:22:43,990
computation and then at the end do some

478
00:22:40,420 --> 00:22:46,840
up sampling we've got to pick the second

479
00:22:43,990 --> 00:22:50,529
approach because we want to do lots of

480
00:22:46,839 --> 00:22:53,169
computation on something smaller because

481
00:22:50,529 --> 00:22:55,210
it's much faster to do it that way and

482
00:22:53,170 --> 00:22:57,460
also like all that computation we get to

483
00:22:55,210 --> 00:23:04,240
kind of leverage during the up sampling

484
00:22:57,460 --> 00:23:06,039
process so that's sampling we know a

485
00:23:04,240 --> 00:23:09,730
couple of possible ways to do that we

486
00:23:06,039 --> 00:23:13,139
can use transposed or fractionally

487
00:23:09,730 --> 00:23:17,319
straited convolutions or we can use

488
00:23:13,140 --> 00:23:23,500
nearest neighbor up sampling followed by

489
00:23:17,319 --> 00:23:25,919
a one by one conf and then in in the

490
00:23:23,500 --> 00:23:28,779
kind of do lots of computation section

491
00:23:25,920 --> 00:23:31,800
we could just have a whole bunch of 3x3

492
00:23:28,779 --> 00:23:35,440
coms right but in this case particular

493
00:23:31,799 --> 00:23:37,690
it seems likely that ResNet blocks are

494
00:23:35,440 --> 00:23:43,660
going to be better because really the

495
00:23:37,690 --> 00:23:46,240
output and the input are very very

496
00:23:43,660 --> 00:23:48,700
similar right so we really want a kind

497
00:23:46,240 --> 00:23:51,430
of a flow through path that allows as

498
00:23:48,700 --> 00:23:53,289
little fussing around as possible except

499
00:23:51,430 --> 00:23:56,320
kind of a minimal amount necessary to do

500
00:23:53,289 --> 00:23:59,829
our super resolution and so if we use

501
00:23:56,319 --> 00:24:03,009
ResNet blocks then they have an identity

502
00:23:59,829 --> 00:24:04,659
path already right so like you can

503
00:24:03,009 --> 00:24:09,609
imagine the most simple version where it

504
00:24:04,660 --> 00:24:10,930
does like a you know bilinear sampling

505
00:24:09,609 --> 00:24:12,549
kind of approach or something it could

506
00:24:10,930 --> 00:24:14,230
basically just go through identity box

507
00:24:12,549 --> 00:24:15,970
all the way through and then in the up

508
00:24:14,230 --> 00:24:18,039
sampling blocks just learn to take the

509
00:24:15,970 --> 00:24:22,390
averages of the inputs and get something

510
00:24:18,039 --> 00:24:23,559
that's like not too terrible so that's

511
00:24:22,390 --> 00:24:26,830
what we're going to do we're going to

512
00:24:23,559 --> 00:24:28,279
create something with five ResNet blocks

513
00:24:26,829 --> 00:24:32,869
and then

514
00:24:28,279 --> 00:24:38,839
for each 2x scale-up we have to do we'll

515
00:24:32,869 --> 00:24:41,929
have 1/2 sampling look so they're all

516
00:24:38,839 --> 00:24:43,849
going to consist of obviously as per

517
00:24:41,930 --> 00:24:45,860
usual convolution layers possibly with

518
00:24:43,849 --> 00:24:50,179
activation functions after many of them

519
00:24:45,859 --> 00:24:52,849
so I kind of like to put my standard

520
00:24:50,180 --> 00:24:56,660
convolution block into a function so I

521
00:24:52,849 --> 00:24:58,459
can refactor it more easily as per usual

522
00:24:56,660 --> 00:25:00,529
I just won't worry about passing in

523
00:24:58,460 --> 00:25:04,549
padding and just calculate it directly

524
00:25:00,529 --> 00:25:05,990
as kernel size over two so one

525
00:25:04,549 --> 00:25:08,829
interesting thing about a little comic

526
00:25:05,990 --> 00:25:12,559
block here is that there's no that's not

527
00:25:08,829 --> 00:25:15,799
which is pretty unusual for ResNet type

528
00:25:12,559 --> 00:25:18,409
models and the reason there's no batch

529
00:25:15,799 --> 00:25:21,500
norm it because I'm stealing ideas from

530
00:25:18,410 --> 00:25:24,620
this fantastic recent paper which

531
00:25:21,500 --> 00:25:29,059
actually won a recent competition in

532
00:25:24,619 --> 00:25:31,279
super resolution performance and to see

533
00:25:29,059 --> 00:25:33,109
how good this paper is here's kind of a

534
00:25:31,279 --> 00:25:35,660
previous state of the art there's SR

535
00:25:33,109 --> 00:25:38,719
ResNet right and what they've done here

536
00:25:35,660 --> 00:25:42,620
is they've zoomed way in to a an up

537
00:25:38,720 --> 00:25:45,710
sampled kind of natural or fence this is

538
00:25:42,619 --> 00:25:47,299
the original and you can see in the kind

539
00:25:45,710 --> 00:25:48,980
of previous best approach there's a

540
00:25:47,299 --> 00:25:51,649
whole lot of distortion and blurring

541
00:25:48,980 --> 00:25:55,279
going on right or else in their approach

542
00:25:51,650 --> 00:25:58,600
it's it's nearly perfect alright so like

543
00:25:55,279 --> 00:26:01,430
it was a really big step up this paper

544
00:25:58,599 --> 00:26:04,129
they call their model EDS are enhanced

545
00:26:01,430 --> 00:26:07,670
deep residual networks and they did two

546
00:26:04,130 --> 00:26:11,180
things differently to the kind of

547
00:26:07,670 --> 00:26:13,070
previous standard approaches one was to

548
00:26:11,180 --> 00:26:15,080
take the ResNet blocks this is a regular

549
00:26:13,069 --> 00:26:18,859
resident block and throw away the better

550
00:26:15,079 --> 00:26:20,779
not so why would they throw away the

551
00:26:18,859 --> 00:26:23,059
veteran or well the reason they would

552
00:26:20,779 --> 00:26:26,629
throw away the batch norm is because

553
00:26:23,059 --> 00:26:29,690
batch norm changes stuff and we want a

554
00:26:26,630 --> 00:26:33,020
nice straight through path that doesn't

555
00:26:29,690 --> 00:26:34,700
change stuff okay so the idea basically

556
00:26:33,019 --> 00:26:36,289
here is like hey if you don't want to

557
00:26:34,700 --> 00:26:38,630
fit all with the input more than you

558
00:26:36,289 --> 00:26:40,159
have to then don't force it to have to

559
00:26:38,630 --> 00:26:41,990
calculate things like batching on

560
00:26:40,160 --> 00:26:44,630
parameters so throw away the

561
00:26:41,990 --> 00:26:47,149
and the second trick we'll see shortly

562
00:26:44,630 --> 00:26:51,850
alright so here's a con with no batch

563
00:26:47,148 --> 00:26:55,719
norm and so then we're going to create a

564
00:26:51,849 --> 00:26:59,209
residual block containing as per usual

565
00:26:55,720 --> 00:27:00,649
two convolutions and as you see in their

566
00:26:59,210 --> 00:27:02,750
approach they'd even they don't even

567
00:27:00,648 --> 00:27:04,308
have a rail you after their second conf

568
00:27:02,750 --> 00:27:14,509
okay so that's why I've only got

569
00:27:04,308 --> 00:27:17,028
activation on the first one so a couple

570
00:27:14,509 --> 00:27:21,849
of interesting things here one is that

571
00:27:17,028 --> 00:27:25,460
this idea of like having some kind of

572
00:27:21,849 --> 00:27:28,250
main ResNet path like conv relia cons

573
00:27:25,460 --> 00:27:29,899
and then turning that into a rail you

574
00:27:28,250 --> 00:27:32,298
block by adding it back to the identity

575
00:27:29,898 --> 00:27:33,678
it's something we do so often I kind of

576
00:27:32,298 --> 00:27:36,918
factored it out into a tiny little

577
00:27:33,679 --> 00:27:39,980
module called res sequential which

578
00:27:36,919 --> 00:27:43,509
simply takes a bunch of layers that you

579
00:27:39,980 --> 00:27:47,240
want to put into your residual path

580
00:27:43,509 --> 00:27:49,640
turns that into a sequential model runs

581
00:27:47,240 --> 00:27:52,640
it and then adds it back to the input

582
00:27:49,640 --> 00:27:56,750
right so with this tat all module we can

583
00:27:52,640 --> 00:27:59,659
now turn anything like conf activation

584
00:27:56,750 --> 00:28:04,909
cons into a resonate lock just by

585
00:27:59,659 --> 00:28:06,830
wrapping it in res sequential okay but

586
00:28:04,909 --> 00:28:09,890
that's not quite all I'm doing because

587
00:28:06,829 --> 00:28:14,798
like normally a res block just has that

588
00:28:09,890 --> 00:28:17,899
and it's forward but I've also got that

589
00:28:14,798 --> 00:28:22,849
what's risco Briscoe is the number zero

590
00:28:17,898 --> 00:28:25,759
point one why is it there I'm not sure

591
00:28:22,849 --> 00:28:29,538
anybody quite notice but the short

592
00:28:25,759 --> 00:28:33,259
answer is that the guy who invented

593
00:28:29,538 --> 00:28:35,960
batch norm also somewhat more recently

594
00:28:33,259 --> 00:28:37,849
did a paper in which he showed for I

595
00:28:35,960 --> 00:28:40,370
think the first time the ability to

596
00:28:37,849 --> 00:28:44,569
Train imagenet in under an hour

597
00:28:40,369 --> 00:28:47,418
and the way he did it was fire up lots

598
00:28:44,569 --> 00:28:49,819
and lots of machines and have them work

599
00:28:47,419 --> 00:28:52,460
in parallel to create really large batch

600
00:28:49,819 --> 00:28:55,398
sizes now generally when you increase

601
00:28:52,460 --> 00:28:57,348
the batch size by order n

602
00:28:55,398 --> 00:28:59,418
you also increase the learning rate by

603
00:28:57,348 --> 00:29:01,460
order n to go with it so generally a

604
00:28:59,419 --> 00:29:04,369
very large batch size training means

605
00:29:01,460 --> 00:29:07,369
very high learning rate training as well

606
00:29:04,368 --> 00:29:11,298
and he found that with these very large

607
00:29:07,368 --> 00:29:13,908
batch sizes of like 8,000 plus or even

608
00:29:11,298 --> 00:29:15,918
up to 32,000 that at the start of

609
00:29:13,909 --> 00:29:19,159
training his activations would basically

610
00:29:15,919 --> 00:29:20,299
go straight to infinity and a lot of

611
00:29:19,159 --> 00:29:22,219
other people have found that we actually

612
00:29:20,298 --> 00:29:24,618
found that when we were competing in

613
00:29:22,219 --> 00:29:26,629
dawn bench both on the sofa and the

614
00:29:24,618 --> 00:29:29,088
imagenet competitions that you know we

615
00:29:26,628 --> 00:29:30,949
really struggled to make the most of

616
00:29:29,088 --> 00:29:32,269
even the eight GPUs that we were trying

617
00:29:30,950 --> 00:29:35,690
to take advantage of because of these

618
00:29:32,269 --> 00:29:37,838
kind of challenges with these larger

619
00:29:35,690 --> 00:29:40,278
batch sizes and taking advantage of them

620
00:29:37,838 --> 00:29:42,888
so something that a Christian found this

621
00:29:40,278 --> 00:29:44,628
research was that if he in the ResNet

622
00:29:42,888 --> 00:29:46,968
blocks if he multiplied them by some

623
00:29:44,628 --> 00:29:49,848
number smaller than one something like

624
00:29:46,969 --> 00:29:55,489
point one or point two it really helped

625
00:29:49,848 --> 00:29:58,460
stabilize training start and that's kind

626
00:29:55,489 --> 00:30:00,710
of weird because let mathematically it's

627
00:29:58,460 --> 00:30:02,139
kind of identical right because

628
00:30:00,710 --> 00:30:06,499
obviously whatever I'm multiplying it by

629
00:30:02,138 --> 00:30:08,118
here you know I could just scale the

630
00:30:06,499 --> 00:30:11,719
weights by the opposite amount here and

631
00:30:08,118 --> 00:30:15,168
have the same number okay so but it's

632
00:30:11,719 --> 00:30:17,028
kind of like we're not dealing with

633
00:30:15,169 --> 00:30:21,109
abstract math you know we're dealing

634
00:30:17,028 --> 00:30:25,098
with like you know real optimization

635
00:30:21,108 --> 00:30:27,858
problems and different initializations

636
00:30:25,098 --> 00:30:32,388
and learning rates and whatever else and

637
00:30:27,858 --> 00:30:33,949
so the problem of kind of whites

638
00:30:32,388 --> 00:30:35,658
disappearing off into infinity

639
00:30:33,950 --> 00:30:37,729
I guess generally is really about that

640
00:30:35,659 --> 00:30:39,619
they're kind of the discrete and finite

641
00:30:37,729 --> 00:30:42,889
nature of computers in in practice

642
00:30:39,618 --> 00:30:46,098
partly and so often

643
00:30:42,888 --> 00:30:47,418
yeah these kind of little tricks can can

644
00:30:46,098 --> 00:30:50,479
make the difference alright so in this

645
00:30:47,419 --> 00:30:53,589
case we're just kind of toning things

646
00:30:50,479 --> 00:30:55,669
down based at least based on our initial

647
00:30:53,588 --> 00:30:59,148
initialization and so there probably

648
00:30:55,669 --> 00:31:01,879
other ways to do this for example one

649
00:30:59,148 --> 00:31:04,218
approach from some folks at Nvidia

650
00:31:01,878 --> 00:31:06,798
called Lars le RS which I briefly

651
00:31:04,219 --> 00:31:09,259
mentioned last week is an approach which

652
00:31:06,798 --> 00:31:11,779
uses discriminative learning rates

653
00:31:09,259 --> 00:31:14,410
calculated in real time basically

654
00:31:11,779 --> 00:31:18,589
looking at the ratio between the

655
00:31:14,410 --> 00:31:21,170
gradients and the activations to scale

656
00:31:18,589 --> 00:31:24,319
all learning rates by layer and so they

657
00:31:21,170 --> 00:31:26,480
found that they didn't need this trick

658
00:31:24,319 --> 00:31:31,579
to scale it scale up the batch sizes a

659
00:31:26,480 --> 00:31:35,120
lot maybe a different initialization

660
00:31:31,579 --> 00:31:37,339
which would be all that's necessary the

661
00:31:35,119 --> 00:31:38,719
reason I mentioned this is not so much

662
00:31:37,339 --> 00:31:41,389
because I think a lot of you are likely

663
00:31:38,720 --> 00:31:44,089
to want to train on massive clusters of

664
00:31:41,390 --> 00:31:46,220
computers but rather that I think a lot

665
00:31:44,089 --> 00:31:48,740
of you want to train models quickly and

666
00:31:46,220 --> 00:31:52,100
that means using high learning rates and

667
00:31:48,740 --> 00:31:55,370
ideally getting super convergence and I

668
00:31:52,099 --> 00:31:57,500
think these kinds of tricks are the

669
00:31:55,369 --> 00:31:59,839
tricks that we'll need to be able to get

670
00:31:57,500 --> 00:32:01,700
super convergence across more different

671
00:31:59,839 --> 00:32:08,059
architectures and so forth

672
00:32:01,700 --> 00:32:09,559
and you know other than Leslie Smith no

673
00:32:08,059 --> 00:32:11,359
one else is really working on super

674
00:32:09,559 --> 00:32:13,399
convergence other than some fast AI

675
00:32:11,359 --> 00:32:15,559
students nowadays so these kind of

676
00:32:13,400 --> 00:32:17,269
things about how do we train at very

677
00:32:15,559 --> 00:32:18,859
very high learning rates we're going to

678
00:32:17,269 --> 00:32:21,680
be have to be the ones who figure it out

679
00:32:18,859 --> 00:32:26,750
because as far as I can tell nobody else

680
00:32:21,680 --> 00:32:28,910
cares yet so so I think you know looking

681
00:32:26,750 --> 00:32:30,829
at the literature around you know

682
00:32:28,910 --> 00:32:32,240
training imagenet in one hour or more

683
00:32:30,829 --> 00:32:35,899
recently there's now a train image net

684
00:32:32,240 --> 00:32:38,269
in 15 minutes these papers actually tell

685
00:32:35,900 --> 00:32:40,100
I think have some of the tricks to allow

686
00:32:38,269 --> 00:32:42,940
us to train things at home learning

687
00:32:40,099 --> 00:32:46,279
rates and so here's one of them and so

688
00:32:42,940 --> 00:32:48,380
interestingly other than the train image

689
00:32:46,279 --> 00:32:51,889
net1 our paper the only other place I've

690
00:32:48,380 --> 00:32:54,880
seen this mentioned was in this PDS our

691
00:32:51,890 --> 00:32:58,790
paper and it's really cool because like

692
00:32:54,880 --> 00:33:01,550
I know people who win competitions I

693
00:32:58,789 --> 00:33:03,649
just find them to be very pragmatic and

694
00:33:01,549 --> 00:33:07,069
well-read you know lucky they actually

695
00:33:03,650 --> 00:33:08,750
have to get things to work and so this

696
00:33:07,069 --> 00:33:10,220
paper describes an approach which

697
00:33:08,750 --> 00:33:12,049
actually worked better than anybody

698
00:33:10,220 --> 00:33:13,490
else's approach and they did these

699
00:33:12,049 --> 00:33:17,720
pathetic things like throw away batch

700
00:33:13,490 --> 00:33:19,809
norm and use this little scaling factor

701
00:33:17,720 --> 00:33:22,819
which almost nobody seems to know about

702
00:33:19,809 --> 00:33:25,419
and stuff like that ok

703
00:33:22,819 --> 00:33:29,599
so that's where the point one comes from

704
00:33:25,420 --> 00:33:32,630
so basically our super-resolution ResNet

705
00:33:29,599 --> 00:33:34,639
is down and do a convolution to go from

706
00:33:32,630 --> 00:33:37,490
our three channels to 64 channels just

707
00:33:34,640 --> 00:33:40,670
to rich nut the space a little bit then

708
00:33:37,490 --> 00:33:43,099
also we've got actually a cannot 5h lots

709
00:33:40,670 --> 00:33:44,330
of these res blocks and we're just going

710
00:33:43,099 --> 00:33:47,629
to keep remember every one of these res

711
00:33:44,329 --> 00:33:49,519
blocks is strike one so the grid size

712
00:33:47,630 --> 00:33:51,410
doesn't change the number of filters

713
00:33:49,519 --> 00:33:55,759
doesn't change it's just 64 all the way

714
00:33:51,410 --> 00:33:57,860
through well do one more convolution and

715
00:33:55,759 --> 00:34:01,309
then we'll do our app sampling by

716
00:33:57,859 --> 00:34:04,129
however much scale we asked for and then

717
00:34:01,309 --> 00:34:06,679
something I've added which is a little

718
00:34:04,130 --> 00:34:08,660
idea is just one batch norm here because

719
00:34:06,680 --> 00:34:11,720
it kind of felt like it might be helpful

720
00:34:08,659 --> 00:34:13,489
just to scale the last layer and then

721
00:34:11,719 --> 00:34:17,149
finally a comb to go back to the three

722
00:34:13,489 --> 00:34:18,709
channels we want so you can see that's

723
00:34:17,150 --> 00:34:21,349
basically here's lots and lots of

724
00:34:18,710 --> 00:34:26,800
computation and then a little bit of our

725
00:34:21,349 --> 00:34:26,799
sampling just like we kind of described

726
00:34:31,239 --> 00:34:37,579
so the only other piece here then is and

727
00:34:35,750 --> 00:34:39,679
I also just dimension you know as you

728
00:34:37,579 --> 00:34:42,139
can see as I'm tending to do now this

729
00:34:39,679 --> 00:34:45,110
whole thing is done by creating just a

730
00:34:42,139 --> 00:34:47,418
list with layers and then at the end

731
00:34:45,110 --> 00:34:50,030
turning that into a sequential model and

732
00:34:47,418 --> 00:34:56,210
so my forward function is as simple as

733
00:34:50,030 --> 00:34:59,780
can be so here's our app sampling and up

734
00:34:56,210 --> 00:35:04,720
sampling is a bit interesting because it

735
00:34:59,780 --> 00:35:09,610
is not doing either of these two things

736
00:35:04,719 --> 00:35:09,609
so let's talk a bit about up sampling

737
00:35:12,880 --> 00:35:17,450
here is a picture from the paper from

738
00:35:15,829 --> 00:35:20,690
not from the competition winning paper

739
00:35:17,449 --> 00:35:22,219
but from this original paper and so

740
00:35:20,690 --> 00:35:24,530
they're saying hey our approach is so

741
00:35:22,219 --> 00:35:29,809
much better but look at their approach

742
00:35:24,530 --> 00:35:32,390
it's got goddamn artifacts in it alright

743
00:35:29,809 --> 00:35:34,190
these just pop up everywhere and so one

744
00:35:32,389 --> 00:35:36,079
of the reasons for this is that they use

745
00:35:34,190 --> 00:35:39,880
transposed convolutions and we all know

746
00:35:36,079 --> 00:35:42,650
don't use transposed convolutions okay

747
00:35:39,880 --> 00:35:44,780
so here are transposed convolutions this

748
00:35:42,650 --> 00:35:47,510
is from this fantastic convolutional

749
00:35:44,780 --> 00:35:49,820
arithmetic paper that was shown also in

750
00:35:47,510 --> 00:35:52,790
the Theano Docs if we're going from the

751
00:35:49,820 --> 00:35:56,840
blue is the original image so 3x3 image

752
00:35:52,789 --> 00:35:58,969
up to a 5x5 image right or a 6x6 if we

753
00:35:56,840 --> 00:36:01,640
added a layer of padding then all a

754
00:35:58,969 --> 00:36:05,750
transpose convolution does is it uses a

755
00:36:01,639 --> 00:36:08,960
regular 3x3 cons but it sticks white you

756
00:36:05,750 --> 00:36:11,360
know zero pixels between every pair of

757
00:36:08,960 --> 00:36:12,949
pixels alright so that makes the input

758
00:36:11,360 --> 00:36:14,960
image bigger and when we run this

759
00:36:12,949 --> 00:36:17,480
convolution life over it therefore gives

760
00:36:14,960 --> 00:36:19,909
us a larger output okay but I mean

761
00:36:17,480 --> 00:36:23,059
that's obviously stupid because when we

762
00:36:19,909 --> 00:36:26,449
get here for example of the nine pixels

763
00:36:23,059 --> 00:36:27,949
coming in eight of them a zero so like

764
00:36:26,449 --> 00:36:29,960
we're just wasting a whole lot of

765
00:36:27,949 --> 00:36:32,089
computation and then on the other hand

766
00:36:29,960 --> 00:36:35,869
if we're slightly off over here then

767
00:36:32,090 --> 00:36:40,519
four of our nine and on zero but yet we

768
00:36:35,869 --> 00:36:42,769
only have one filter like one kernel to

769
00:36:40,519 --> 00:36:44,509
use so it can't like change depending on

770
00:36:42,769 --> 00:36:49,009
how many zeros are coming in so it has

771
00:36:44,510 --> 00:36:51,260
to kind of be suitable for both and it's

772
00:36:49,010 --> 00:36:54,500
just not possible right so we end up

773
00:36:51,260 --> 00:36:56,090
with these artifacts so one approach

774
00:36:54,500 --> 00:36:59,539
we've learnt to make it a bit better is

775
00:36:56,090 --> 00:37:02,690
to not put white things here but instead

776
00:36:59,539 --> 00:37:04,820
to copy this pixels value to each of

777
00:37:02,690 --> 00:37:06,500
these three locations alright so that's

778
00:37:04,820 --> 00:37:08,960
a just a nearest neighbor up sampling

779
00:37:06,500 --> 00:37:10,760
that's certainly a bit better all right

780
00:37:08,960 --> 00:37:12,970
but it's still pretty crappy because now

781
00:37:10,760 --> 00:37:15,430
still when we get to these nine here

782
00:37:12,969 --> 00:37:18,369
four of them are exactly the same number

783
00:37:15,429 --> 00:37:23,119
all right and when we move across one

784
00:37:18,369 --> 00:37:25,730
then now we've got you know a different

785
00:37:23,119 --> 00:37:28,368
situation entirely right and so to

786
00:37:25,730 --> 00:37:29,960
on where we are so in particular if

787
00:37:28,369 --> 00:37:32,030
we're here you know there's going to be

788
00:37:29,960 --> 00:37:34,639
a lot less repetition so again we have

789
00:37:32,030 --> 00:37:36,830
this problem where there's like wasted

790
00:37:34,639 --> 00:37:38,629
computation and too much structure in

791
00:37:36,829 --> 00:37:41,779
the data and it's going to lead to RFS

792
00:37:38,630 --> 00:37:43,400
again so up sampling is better than

793
00:37:41,780 --> 00:37:45,230
transposed convolutions it's you know

794
00:37:43,400 --> 00:37:48,079
better to copy them rather than replace

795
00:37:45,230 --> 00:37:57,920
them with zeros but it's still not quite

796
00:37:48,079 --> 00:38:01,670
good enough so instead we're gonna do

797
00:37:57,920 --> 00:38:05,269
the pixel shuffle so the pixel shuffle

798
00:38:01,670 --> 00:38:07,990
is an operation in this sub pixel

799
00:38:05,269 --> 00:38:11,389
convolutional neural network and it's a

800
00:38:07,989 --> 00:38:14,209
little bit mind-bending but it's kind of

801
00:38:11,389 --> 00:38:16,730
fascinating and so we start with our

802
00:38:14,210 --> 00:38:18,710
input we go through some convolutions to

803
00:38:16,730 --> 00:38:22,010
create some feature Maps for a while

804
00:38:18,710 --> 00:38:24,769
until eventually we get to layer and I

805
00:38:22,010 --> 00:38:27,830
we go to this layer I minus one which

806
00:38:24,769 --> 00:38:30,139
has n I minus one feature Maps we're

807
00:38:27,829 --> 00:38:33,940
going to do another 3x3 cons and our

808
00:38:30,139 --> 00:38:37,039
goal here is to go from a 7x7 grid cell

809
00:38:33,940 --> 00:38:40,639
we're going to go a 3x3 up scaling so

810
00:38:37,039 --> 00:38:43,190
we're going to go up to a 21 by 21 grid

811
00:38:40,639 --> 00:38:47,299
cell so how do we what's another way we

812
00:38:43,190 --> 00:38:50,750
could do that to make it simpler let's

813
00:38:47,300 --> 00:38:52,700
just pick one face just one filter so

814
00:38:50,750 --> 00:38:54,679
we'll just take the topmost filter and

815
00:38:52,699 --> 00:38:56,809
just do a convolution over that just to

816
00:38:54,679 --> 00:38:59,809
see what happens and what we're going to

817
00:38:56,809 --> 00:39:03,170
do is we're going to use a convolution

818
00:38:59,809 --> 00:39:09,519
where the kernel size is is the number

819
00:39:03,170 --> 00:39:13,300
of filters is nine times bigger than we

820
00:39:09,519 --> 00:39:15,289
strictly speaking need so if we needed

821
00:39:13,300 --> 00:39:18,440
64 filters

822
00:39:15,289 --> 00:39:22,699
we're actually going to do 64 times nine

823
00:39:18,440 --> 00:39:24,740
filters why is that right and so uh here

824
00:39:22,699 --> 00:39:28,039
are is the scale effect uh so three

825
00:39:24,739 --> 00:39:32,269
right so a squared 3 squared is 9 so

826
00:39:28,039 --> 00:39:35,300
here are the nine filters to cover one

827
00:39:32,269 --> 00:39:37,509
of these input layers one of these input

828
00:39:35,300 --> 00:39:40,619
slices

829
00:39:37,509 --> 00:39:44,048
but what we can do is we started with

830
00:39:40,619 --> 00:39:47,979
seven by seven and we turn it into seven

831
00:39:44,048 --> 00:39:54,809
by seven by nine right well the output

832
00:39:47,978 --> 00:39:57,879
that we want is equal to 7 times 3 by 7

833
00:39:54,809 --> 00:40:00,699
times 3 so in other words there's an

834
00:39:57,880 --> 00:40:03,489
equal number of pixels here activations

835
00:40:00,699 --> 00:40:07,509
here as there are our activations here

836
00:40:03,489 --> 00:40:11,259
so we can literally reshuffle these

837
00:40:07,509 --> 00:40:17,498
seven by seven by nine activations to

838
00:40:11,259 --> 00:40:18,338
create this 7 by 3 by 7 by 3 Matt and so

839
00:40:17,498 --> 00:40:21,338
what we're going to do is we're going to

840
00:40:18,338 --> 00:40:25,298
take one little kind of tube here on the

841
00:40:21,338 --> 00:40:27,518
top left hand of each grid and we're

842
00:40:25,298 --> 00:40:30,969
going to put the purple one up in the

843
00:40:27,518 --> 00:40:33,129
top left and then the blue one one to

844
00:40:30,969 --> 00:40:35,769
the right and then the light blue one

845
00:40:33,130 --> 00:40:37,929
one to the right of that and then the

846
00:40:35,768 --> 00:40:40,238
slightly darker blue one and the middle

847
00:40:37,929 --> 00:40:42,369
of the far left the green one in the

848
00:40:40,239 --> 00:40:46,329
middle and so forth so each of these

849
00:40:42,369 --> 00:40:49,568
nine cells in the top left are going to

850
00:40:46,329 --> 00:40:52,719
end up in this little 3x3 section of our

851
00:40:49,568 --> 00:40:55,418
grid and then we're going to take you

852
00:40:52,719 --> 00:40:59,438
know 2 comma 1 and take all of those 9

853
00:40:55,418 --> 00:41:01,808
and move them to these 3 by 3 part of

854
00:40:59,438 --> 00:41:03,759
the grid and so on and so forth right

855
00:41:01,809 --> 00:41:06,089
and so we're going to end up having

856
00:41:03,759 --> 00:41:10,380
every one of these 7 by 7 by 9

857
00:41:06,088 --> 00:41:14,818
activations inside this 7 by 3 by 7 by 3

858
00:41:10,380 --> 00:41:17,769
image so the first thing to realize is

859
00:41:14,818 --> 00:41:19,958
yes of course this works under some

860
00:41:17,768 --> 00:41:23,618
definition of works because we have a

861
00:41:19,958 --> 00:41:25,629
learn herbal convolution here and it's

862
00:41:23,619 --> 00:41:27,429
going to get some gradients which is

863
00:41:25,630 --> 00:41:29,349
going to do the best job it can of

864
00:41:27,429 --> 00:41:32,338
filling in the correct activation such

865
00:41:29,349 --> 00:41:35,399
that this output is the thing we want

866
00:41:32,338 --> 00:41:37,688
alright so the first step is to realize

867
00:41:35,398 --> 00:41:40,418
there's nothing particularly magical

868
00:41:37,688 --> 00:41:41,858
here you know we can we can create any

869
00:41:40,418 --> 00:41:44,318
architecture we like we can move things

870
00:41:41,858 --> 00:41:46,989
around any how we want to and you know

871
00:41:44,318 --> 00:41:49,268
our wipes in the convolution will do

872
00:41:46,989 --> 00:41:51,309
their best to do all we asked the real

873
00:41:49,268 --> 00:41:53,739
question is is it

874
00:41:51,309 --> 00:41:56,529
good idea you know is this an easier

875
00:41:53,739 --> 00:41:58,779
thing for it to do you know and a more

876
00:41:56,530 --> 00:42:00,880
flexible thing for it to do then the

877
00:41:58,780 --> 00:42:02,980
transposed convolution or the up

878
00:42:00,880 --> 00:42:07,269
sampling followed by one by one month

879
00:42:02,980 --> 00:42:11,139
and the short answer is yes it is and

880
00:42:07,269 --> 00:42:13,690
the reason it's better in short is that

881
00:42:11,139 --> 00:42:15,879
the convolution here is happening in the

882
00:42:13,690 --> 00:42:18,490
low resolution seven by seven space

883
00:42:15,880 --> 00:42:21,430
which is quite efficient where else if

884
00:42:18,489 --> 00:42:24,129
we first of all up sampled and then did

885
00:42:21,429 --> 00:42:28,269
our cons then our con would be happening

886
00:42:24,130 --> 00:42:31,630
in the 21 by 21 space which is a lot of

887
00:42:28,269 --> 00:42:34,239
computation right and furthermore as we

888
00:42:31,630 --> 00:42:36,130
discuss there's a lot of replication in

889
00:42:34,239 --> 00:42:41,859
redundancy in the nearest neighbor

890
00:42:36,130 --> 00:42:43,269
sample version so they actually show in

891
00:42:41,860 --> 00:42:44,890
this paper they actually in fact I think

892
00:42:43,269 --> 00:42:46,989
they have a follow-up technical note

893
00:42:44,889 --> 00:42:49,960
where they kind of provide some more

894
00:42:46,989 --> 00:42:51,729
mathematical details as to exactly what

895
00:42:49,960 --> 00:42:53,860
work is being done and show that the

896
00:42:51,730 --> 00:42:59,199
work really is more efficient this way

897
00:42:53,860 --> 00:43:01,450
okay so that's what we're going to do

898
00:42:59,199 --> 00:43:03,189
all right so we're going to have for our

899
00:43:01,449 --> 00:43:07,239
app sampling we have two steps the first

900
00:43:03,190 --> 00:43:10,150
will be a three by three cons with R

901
00:43:07,239 --> 00:43:12,699
squared times more channels than we

902
00:43:10,150 --> 00:43:15,940
originally wanted and then a pixel

903
00:43:12,699 --> 00:43:19,799
shuffle operation which moves everything

904
00:43:15,940 --> 00:43:23,320
in each grid cell into the little by our

905
00:43:19,800 --> 00:43:29,860
grids that are located throughout here

906
00:43:23,320 --> 00:43:33,280
okay so here it is it's one line of code

907
00:43:29,860 --> 00:43:36,519
right and so here's the cons from number

908
00:43:33,280 --> 00:43:39,790
of in to number of filters out times

909
00:43:36,519 --> 00:43:42,599
four because we're doing a scale to that

910
00:43:39,789 --> 00:43:45,610
sample all right so two squared is four

911
00:43:42,599 --> 00:43:47,889
so that's our convolution and then here

912
00:43:45,610 --> 00:43:50,170
is our pixel shuffle it's built into

913
00:43:47,889 --> 00:43:52,509
high touch pixel shuffle is the thing

914
00:43:50,170 --> 00:43:58,119
that moves each thing into its right

915
00:43:52,510 --> 00:44:00,970
spot so that will increase will up

916
00:43:58,119 --> 00:44:04,269
sample by a scale factor of two and so

917
00:44:00,969 --> 00:44:04,868
we need to do that log base two scale

918
00:44:04,269 --> 00:44:09,460
time

919
00:44:04,869 --> 00:44:13,059
so if scale is for two times to go two

920
00:44:09,460 --> 00:44:22,509
times two you go okay so that's what

921
00:44:13,059 --> 00:44:25,089
this up sample here does great guess

922
00:44:22,509 --> 00:44:27,940
what that does not get rid of the

923
00:44:25,088 --> 00:44:31,420
checkerboard patterns we still have

924
00:44:27,940 --> 00:44:33,729
checkerboard patterns so I'm sure in

925
00:44:31,420 --> 00:44:35,409
great fury and frustration this same

926
00:44:33,728 --> 00:44:36,848
team from Twitter I think this is back

927
00:44:35,409 --> 00:44:39,518
when they used to be at a startup called

928
00:44:36,849 --> 00:44:42,219
magic Pony that Twitter thought came

929
00:44:39,518 --> 00:44:45,008
back again with another paper saying

930
00:44:42,219 --> 00:44:54,429
okay this time we've got rid of the

931
00:44:45,009 --> 00:44:57,190
checkerboard okay so so why do we still

932
00:44:54,429 --> 00:45:00,669
have as you can see here you still have

933
00:44:57,190 --> 00:45:04,599
a checkerboard right and so the reason

934
00:45:00,670 --> 00:45:07,269
we still have a checkerboard even after

935
00:45:04,599 --> 00:45:09,999
doing this is that when we randomly

936
00:45:07,268 --> 00:45:12,669
initialize this convolutional kernel at

937
00:45:09,998 --> 00:45:15,459
the start it means that each of these

938
00:45:12,670 --> 00:45:17,440
nine pixels in this little 3x3 grid over

939
00:45:15,460 --> 00:45:20,409
here are going to be totally randomly

940
00:45:17,440 --> 00:45:23,170
different but then the next set of three

941
00:45:20,409 --> 00:45:25,989
pixels will be randomly different to

942
00:45:23,170 --> 00:45:27,489
each other but will be very similar to

943
00:45:25,989 --> 00:45:29,889
their corresponding pixel in the

944
00:45:27,489 --> 00:45:32,949
previous 3x3 section so we're going to

945
00:45:29,889 --> 00:45:35,460
have repeating 3x3 things all the way

946
00:45:32,949 --> 00:45:38,498
across and so then as we try to learn

947
00:45:35,460 --> 00:45:41,679
something better it's starting from this

948
00:45:38,498 --> 00:45:44,468
like repeating 3x3 starting point which

949
00:45:41,679 --> 00:45:46,568
is not what we want right what we

950
00:45:44,469 --> 00:45:50,469
actually would want is for these three

951
00:45:46,568 --> 00:45:52,150
by three pixels to be the same to start

952
00:45:50,469 --> 00:45:54,159
with so to make these three by three

953
00:45:52,150 --> 00:45:59,858
pixels the same we would need to make

954
00:45:54,159 --> 00:46:04,288
these nine channels the same here right

955
00:45:59,858 --> 00:46:07,838
for each filter and so the solution and

956
00:46:04,289 --> 00:46:11,109
his paper is very simple it's that when

957
00:46:07,838 --> 00:46:13,538
we initialize this convolution that

958
00:46:11,108 --> 00:46:15,759
start when we randomly initialize it we

959
00:46:13,539 --> 00:46:18,670
don't totally randomly initialize it we

960
00:46:15,759 --> 00:46:21,639
randomly initialize one of the

961
00:46:18,670 --> 00:46:25,240
the r-squared sets of channels and then

962
00:46:21,639 --> 00:46:27,190
we copy that to the other R squared so

963
00:46:25,239 --> 00:46:29,229
they're all the same and that way

964
00:46:27,190 --> 00:46:36,460
initially each of these three by threes

965
00:46:29,230 --> 00:46:39,219
will be the same and so that is called I

966
00:46:36,460 --> 00:46:44,170
CNN okay and that's what we're going to

967
00:46:39,219 --> 00:46:46,299
use in a moment so before we do let's

968
00:46:44,170 --> 00:46:48,250
take a quick look so we've got this

969
00:46:46,300 --> 00:46:50,350
super resolution resinate which just

970
00:46:48,250 --> 00:46:51,849
does lots of computation you know with

971
00:46:50,349 --> 00:46:53,679
lots of ResNet blocks and then it does

972
00:46:51,849 --> 00:46:57,759
some up sampling and gets our final

973
00:46:53,679 --> 00:47:00,250
three channels out and then to make life

974
00:46:57,760 --> 00:47:04,150
faster we're going to run this in

975
00:47:00,250 --> 00:47:06,849
parallel one reason we want to run it in

976
00:47:04,150 --> 00:47:09,639
parallel is because Jurado told us that

977
00:47:06,849 --> 00:47:13,869
he has six GPUs and this is what his

978
00:47:09,639 --> 00:47:15,819
computer looks like right now and so I'm

979
00:47:13,869 --> 00:47:20,409
sure anybody who has more than one GPU

980
00:47:15,820 --> 00:47:22,990
has had this experience before so how do

981
00:47:20,409 --> 00:47:29,379
we get how do we get these men working

982
00:47:22,989 --> 00:47:33,819
in together all you need to do is to

983
00:47:29,380 --> 00:47:37,420
take your PI torch module and wrap it

984
00:47:33,820 --> 00:47:40,539
with N n data parallel okay and once

985
00:47:37,420 --> 00:47:43,750
you've done that it copies it to each of

986
00:47:40,539 --> 00:47:46,840
your GPUs and will automatically run it

987
00:47:43,750 --> 00:47:52,000
in parallel it scales pretty well done

988
00:47:46,840 --> 00:47:54,550
to two GPUs okay to three GPUs better

989
00:47:52,000 --> 00:47:57,750
than nothing to four GPUs and beyond

990
00:47:54,550 --> 00:48:01,660
that performance does two go backwards

991
00:47:57,750 --> 00:48:04,570
the by default it will copy it to all of

992
00:48:01,659 --> 00:48:08,079
your GPUs you can add an array of GPUs

993
00:48:04,570 --> 00:48:09,880
otherwise if you want to avoid getting

994
00:48:08,079 --> 00:48:12,099
in trouble for example I have to share

995
00:48:09,880 --> 00:48:13,809
our box with you net and if I didn't put

996
00:48:12,099 --> 00:48:16,420
this here then she would be yelling at

997
00:48:13,809 --> 00:48:18,789
me right now well maybe you know or

998
00:48:16,420 --> 00:48:21,780
according my plus so this is how you

999
00:48:18,789 --> 00:48:25,659
avoid getting into trouble with you net

1000
00:48:21,780 --> 00:48:28,120
so one thing to be aware of here is that

1001
00:48:25,659 --> 00:48:30,519
once you do this it actually modifies

1002
00:48:28,119 --> 00:48:32,319
your module so if you now print out your

1003
00:48:30,519 --> 00:48:34,449
module let's say previously it was

1004
00:48:32,320 --> 00:48:36,010
just an endless sequential now you'll

1005
00:48:34,449 --> 00:48:41,829
find it's an N in dots as Crenshaw

1006
00:48:36,010 --> 00:48:45,340
embedded inside a module called module

1007
00:48:41,829 --> 00:48:48,190
right and so in other words if you save

1008
00:48:45,340 --> 00:48:50,289
something which you had n end updated

1009
00:48:48,190 --> 00:48:52,000
paralleled and then tried and load it

1010
00:48:50,289 --> 00:48:54,219
back into something that you hadn't and

1011
00:48:52,000 --> 00:48:55,869
end up beta paralleled it'll say it

1012
00:48:54,219 --> 00:48:58,089
doesn't match up because one of them is

1013
00:48:55,869 --> 00:49:01,210
embedded inside this module attribute

1014
00:48:58,090 --> 00:49:04,539
and the other one isn't it may also

1015
00:49:01,210 --> 00:49:06,059
depend even on which GPU IDs you have

1016
00:49:04,539 --> 00:49:11,949
had a coffee too

1017
00:49:06,059 --> 00:49:15,519
so two possible solutions one is don't

1018
00:49:11,949 --> 00:49:18,339
save the module M but instead save the

1019
00:49:15,519 --> 00:49:19,900
module attribute m dot module because

1020
00:49:18,340 --> 00:49:23,559
that's actually the the non data

1021
00:49:19,900 --> 00:49:26,470
parallel bit or always put it on the

1022
00:49:23,559 --> 00:49:29,199
same GPU IDs and then use data parallel

1023
00:49:26,469 --> 00:49:31,719
and load and save that every time that's

1024
00:49:29,199 --> 00:49:33,879
what I was using this will be an easy

1025
00:49:31,719 --> 00:49:35,709
thing for me to fix automatically in

1026
00:49:33,880 --> 00:49:37,390
fast AI and I'll do it pretty soon so

1027
00:49:35,710 --> 00:49:39,490
it'll look for that module attribution

1028
00:49:37,389 --> 00:49:42,460
and deal with it automatically but for

1029
00:49:39,489 --> 00:49:43,779
now we have to do it manually it's

1030
00:49:42,460 --> 00:49:46,750
probably useful to know what's going on

1031
00:49:43,780 --> 00:49:49,510
behind the scenes anyway alright so

1032
00:49:46,750 --> 00:49:52,000
we've got our module you know I find it

1033
00:49:49,510 --> 00:49:55,750
overrun like 50 or 60 percent faster on

1034
00:49:52,000 --> 00:49:59,980
a 1080 TI if you're running on voltar it

1035
00:49:55,750 --> 00:50:02,079
actually paralyzes a bit better there's

1036
00:49:59,980 --> 00:50:03,969
a there much faster ways to parallel

1037
00:50:02,079 --> 00:50:06,670
parallel lives but this is like a super

1038
00:50:03,969 --> 00:50:09,189
super easy way all right so we created

1039
00:50:06,670 --> 00:50:11,860
our learner in the usual way we could

1040
00:50:09,190 --> 00:50:13,539
use MSA loss here so that's just going

1041
00:50:11,860 --> 00:50:17,440
to compare the pixels of the output to

1042
00:50:13,539 --> 00:50:18,969
the pixels you know that we expected and

1043
00:50:17,440 --> 00:50:22,210
we can run our learning rate finder and

1044
00:50:18,969 --> 00:50:26,500
we can train it for awhile and here's

1045
00:50:22,210 --> 00:50:28,900
our input and here's our output and you

1046
00:50:26,500 --> 00:50:30,969
can see that what we've managed to do is

1047
00:50:28,900 --> 00:50:32,680
to train a very advanced residual

1048
00:50:30,969 --> 00:50:37,480
convolutional net work that's learnt to

1049
00:50:32,679 --> 00:50:39,539
blur things why is that well because

1050
00:50:37,480 --> 00:50:43,000
it's what we asked for we said to

1051
00:50:39,539 --> 00:50:45,940
minimize MSE loss right an MSA lost

1052
00:50:43,000 --> 00:50:48,789
between pixels really the best way to

1053
00:50:45,940 --> 00:50:52,000
that is just average the pixels I eat a

1054
00:50:48,789 --> 00:50:57,039
blur so that's why pixel lusts no good

1055
00:50:52,000 --> 00:50:59,440
so we want to use our perceptual loss so

1056
00:50:57,039 --> 00:51:02,170
let's try perceptual us right

1057
00:50:59,440 --> 00:51:05,980
so with perceptual loss we're basically

1058
00:51:02,170 --> 00:51:08,019
going to take our vgg network and just

1059
00:51:05,980 --> 00:51:12,369
like we did last week we're going to

1060
00:51:08,019 --> 00:51:15,068
find the block index just before we get

1061
00:51:12,369 --> 00:51:18,250
a max ball okay so here are the ends of

1062
00:51:15,068 --> 00:51:21,159
each kind of block of the same grid size

1063
00:51:18,250 --> 00:51:22,900
and if we just print them out as we'd

1064
00:51:21,159 --> 00:51:28,690
expect every one of those is a value

1065
00:51:22,900 --> 00:51:31,720
module and so in this case these last

1066
00:51:28,690 --> 00:51:33,429
two blocks are less interesting to us

1067
00:51:31,719 --> 00:51:36,789
they're kind of the grid size there is

1068
00:51:33,429 --> 00:51:38,919
small enough you know kind of coarse

1069
00:51:36,789 --> 00:51:40,119
enough that it's not as useful for super

1070
00:51:38,920 --> 00:51:43,150
resolution so we're just going to use

1071
00:51:40,119 --> 00:51:45,519
the first three and so just to save

1072
00:51:43,150 --> 00:51:48,579
unnecessary computation we're just going

1073
00:51:45,519 --> 00:51:50,068
to use those first 23 layers or vgg

1074
00:51:48,579 --> 00:51:53,769
we'll throw a way to look at the rest

1075
00:51:50,068 --> 00:51:55,690
we'll stick it on the GPU we're not

1076
00:51:53,769 --> 00:51:57,940
going to be training this speech EG

1077
00:51:55,690 --> 00:52:00,369
model at all we're just using it to

1078
00:51:57,940 --> 00:52:02,920
compare activations so we'll stick it in

1079
00:52:00,369 --> 00:52:08,530
eval mode and we will set it to not

1080
00:52:02,920 --> 00:52:11,200
trainable okay just like last week we

1081
00:52:08,530 --> 00:52:14,019
will use a save features class to

1082
00:52:11,199 --> 00:52:15,669
through a forward hook which saves the

1083
00:52:14,019 --> 00:52:18,130
output activations at each of those

1084
00:52:15,670 --> 00:52:20,710
layers and so now we've got everything

1085
00:52:18,130 --> 00:52:23,170
we need to create our perceptual loss so

1086
00:52:20,710 --> 00:52:26,019
as I call it here feature loss plus

1087
00:52:23,170 --> 00:52:28,568
right and so we're going to pass in a

1088
00:52:26,019 --> 00:52:31,809
list of layer IDs

1089
00:52:28,568 --> 00:52:34,059
you know the layers where we want the

1090
00:52:31,809 --> 00:52:37,150
content loss to be calculated and array

1091
00:52:34,059 --> 00:52:40,150
of weights a list of weights for each of

1092
00:52:37,150 --> 00:52:43,720
those layers so we can just go through

1093
00:52:40,150 --> 00:52:45,760
each of those layer IDs and create an

1094
00:52:43,719 --> 00:52:46,838
object which is going to store which is

1095
00:52:45,760 --> 00:52:48,220
you know I've got the book function

1096
00:52:46,838 --> 00:52:52,328
forward hook function to store the

1097
00:52:48,219 --> 00:52:55,480
activations and so in our forward then

1098
00:52:52,329 --> 00:52:58,450
we can just go ahead and call the

1099
00:52:55,480 --> 00:53:00,190
forward pass of our model with the

1100
00:52:58,449 --> 00:53:01,179
target so the target is the hi

1101
00:53:00,190 --> 00:53:04,088
whereas image we're trying to create

1102
00:53:01,179 --> 00:53:05,529
okay and so the reason we do that is

1103
00:53:04,088 --> 00:53:09,279
because that's going to then call that

1104
00:53:05,530 --> 00:53:12,970
book function and store in soft

1105
00:53:09,280 --> 00:53:15,190
save features the activations we want

1106
00:53:12,969 --> 00:53:20,199
right now we're going to need to do that

1107
00:53:15,190 --> 00:53:22,568
for our confident output as well right

1108
00:53:20,199 --> 00:53:24,250
so we need to clone these because

1109
00:53:22,568 --> 00:53:25,750
otherwise the confident output is going

1110
00:53:24,250 --> 00:53:26,608
to go ahead and just plop up what I

1111
00:53:25,750 --> 00:53:29,139
already had

1112
00:53:26,608 --> 00:53:31,179
okay so now we can do the same thing for

1113
00:53:29,139 --> 00:53:34,690
the confident output which is the input

1114
00:53:31,179 --> 00:53:37,568
to the loss function and so now we've

1115
00:53:34,690 --> 00:53:40,720
got those two things we can zip them all

1116
00:53:37,568 --> 00:53:42,880
together along with the weights so we've

1117
00:53:40,719 --> 00:53:45,459
got inputs targets and weights and then

1118
00:53:42,880 --> 00:53:46,809
we can do the l1 loss between the inputs

1119
00:53:45,460 --> 00:53:49,659
and the targets and multiply by the

1120
00:53:46,809 --> 00:53:54,549
layer weights the only other thing I do

1121
00:53:49,659 --> 00:53:56,980
is I also grab the pixel loss right but

1122
00:53:54,550 --> 00:53:59,170
I weight it down quite a bit okay and

1123
00:53:56,980 --> 00:54:01,139
most people don't do this I haven't seen

1124
00:53:59,170 --> 00:54:04,269
papers that do this but in my opinion

1125
00:54:01,139 --> 00:54:06,818
it's maybe a little bit better because

1126
00:54:04,269 --> 00:54:10,210
you've got you know the perceptual

1127
00:54:06,818 --> 00:54:12,789
content lost activation stuff but you

1128
00:54:10,210 --> 00:54:18,309
know the really finest level it also

1129
00:54:12,789 --> 00:54:20,769
cares about the individual pixels okay

1130
00:54:18,309 --> 00:54:23,529
so that's our last function we create

1131
00:54:20,769 --> 00:54:29,259
our super resolution ResNet telling it

1132
00:54:23,530 --> 00:54:33,180
how much to scale up by and then we're

1133
00:54:29,260 --> 00:54:36,660
going to do our I see in our

1134
00:54:33,179 --> 00:54:40,239
initialization of that pixel shuffle

1135
00:54:36,659 --> 00:54:42,009
convolution right so there's really like

1136
00:54:40,239 --> 00:54:44,318
it's this is very very boring code I

1137
00:54:42,010 --> 00:54:47,680
actually stole it from from somebody

1138
00:54:44,318 --> 00:54:52,019
else like literally all it does is just

1139
00:54:47,679 --> 00:54:56,139
say okay you've got some weight tensor X

1140
00:54:52,019 --> 00:54:58,750
that you want to initialize so we're

1141
00:54:56,139 --> 00:55:01,328
going to treat it as if it had shape

1142
00:54:58,750 --> 00:55:05,440
divided by so number of features divided

1143
00:55:01,329 --> 00:55:09,700
by scale squared features in practice so

1144
00:55:05,440 --> 00:55:12,068
like you know this might be 2 squared

1145
00:55:09,699 --> 00:55:13,960
before because we actually want to copy

1146
00:55:12,068 --> 00:55:15,969
you know we want to just keep

1147
00:55:13,960 --> 00:55:18,250
set with them and then copy them four

1148
00:55:15,969 --> 00:55:20,949
times so we divide it by four and we

1149
00:55:18,250 --> 00:55:24,579
create something of that size and we

1150
00:55:20,949 --> 00:55:28,269
initialize that with by default timing

1151
00:55:24,579 --> 00:55:31,300
normal initialization and then we just

1152
00:55:28,269 --> 00:55:34,269
make scale squared copies of it okay and

1153
00:55:31,300 --> 00:55:36,430
the rest of its just kind of moving axes

1154
00:55:34,269 --> 00:55:39,009
around a little bit all right so that's

1155
00:55:36,429 --> 00:55:44,469
kind of return a new weight matrix where

1156
00:55:39,010 --> 00:55:47,109
each each initialized sub kernel is

1157
00:55:44,469 --> 00:55:51,219
repeated R squared or scale squared

1158
00:55:47,108 --> 00:55:52,960
times so that details don't matter very

1159
00:55:51,219 --> 00:55:54,759
much all that matters here is that I

1160
00:55:52,960 --> 00:55:58,420
just looked through to find what was the

1161
00:55:54,760 --> 00:56:01,450
actual layer the cone flower just before

1162
00:55:58,420 --> 00:56:04,000
the pixel shuffle and stored it away and

1163
00:56:01,449 --> 00:56:06,818
then I called I see an R on its weight

1164
00:56:04,000 --> 00:56:08,739
matrix to get my new weight matrix and

1165
00:56:06,818 --> 00:56:14,409
then I copied that new weight matrix

1166
00:56:08,739 --> 00:56:18,519
back into that layer ok so as you can

1167
00:56:14,409 --> 00:56:21,088
see I went to quite a lot of trouble in

1168
00:56:18,519 --> 00:56:24,159
this exercise to really try to implement

1169
00:56:21,088 --> 00:56:25,869
all the best practices right and I kind

1170
00:56:24,159 --> 00:56:27,129
of tend to do things a bit one extreme

1171
00:56:25,869 --> 00:56:28,809
or the other I show you like a really

1172
00:56:27,130 --> 00:56:30,818
happy version that only slightly works

1173
00:56:28,809 --> 00:56:33,190
or I go to the enth degree to make it

1174
00:56:30,818 --> 00:56:35,349
work really well right and so this is a

1175
00:56:33,190 --> 00:56:36,780
version where I'm claiming that this is

1176
00:56:35,349 --> 00:56:38,470
pretty much a state of the art

1177
00:56:36,780 --> 00:56:40,900
implementation it's a competition

1178
00:56:38,469 --> 00:56:43,209
winning or at least my reimplementation

1179
00:56:40,900 --> 00:56:45,039
of a competition winning approach and

1180
00:56:43,210 --> 00:56:46,990
the reason I'm doing that is because I

1181
00:56:45,039 --> 00:56:49,900
think like this is one of those rare

1182
00:56:46,989 --> 00:56:51,489
papers where they actually get a lot of

1183
00:56:49,900 --> 00:56:53,920
the details right and I kind of want you

1184
00:56:51,489 --> 00:56:56,769
to get a feel of what does it feel like

1185
00:56:53,920 --> 00:56:58,690
to get all the details right and you

1186
00:56:56,769 --> 00:57:01,690
know remember getting the details right

1187
00:56:58,690 --> 00:57:04,838
is the difference between this hideous

1188
00:57:01,690 --> 00:57:14,980
blurry mess you know and this really

1189
00:57:04,838 --> 00:57:16,298
pretty exquisite result okay so so we're

1190
00:57:14,980 --> 00:57:18,639
gonna have a to do potato parallel on

1191
00:57:16,298 --> 00:57:20,980
that again we're going to set our

1192
00:57:18,639 --> 00:57:23,769
criterion to be feature loss using our

1193
00:57:20,980 --> 00:57:26,318
vgg model grab the first few blocks and

1194
00:57:23,769 --> 00:57:27,369
these are assets of layer weights that I

1195
00:57:26,318 --> 00:57:32,108
found worked pretty

1196
00:57:27,369 --> 00:57:35,499
well do a learning rate finder fit it

1197
00:57:32,108 --> 00:57:36,730
for a while and I fiddled around for a

1198
00:57:35,498 --> 00:57:41,980
little while trying to kind of get some

1199
00:57:36,730 --> 00:57:46,119
of these details right but here's the my

1200
00:57:41,980 --> 00:57:49,858
favorite part if the paper is what

1201
00:57:46,119 --> 00:57:53,970
happens next now that we've done it for

1202
00:57:49,858 --> 00:57:56,798
scale equals to progressive resizing

1203
00:57:53,969 --> 00:57:59,679
right so progressive resizing is the

1204
00:57:56,798 --> 00:58:01,509
trick that let us get the best single

1205
00:57:59,679 --> 00:58:03,399
computer result for image net training

1206
00:58:01,509 --> 00:58:05,980
on one bench it's this idea of starting

1207
00:58:03,400 --> 00:58:07,920
small gradually making bigger I only

1208
00:58:05,980 --> 00:58:11,318
know of two papers that have used this

1209
00:58:07,920 --> 00:58:14,019
idea one is the progressive resizing of

1210
00:58:11,318 --> 00:58:16,829
gans paper which allows training a very

1211
00:58:14,018 --> 00:58:20,048
high resolution gains and the other one

1212
00:58:16,829 --> 00:58:23,470
is the ideas are and the cool thing

1213
00:58:20,048 --> 00:58:26,980
about progressive resizing is not only

1214
00:58:23,469 --> 00:58:30,389
are your earlier epochs assuming you've

1215
00:58:26,980 --> 00:58:33,039
got two by two smaller four times faster

1216
00:58:30,389 --> 00:58:35,768
you can also make the batch size maybe

1217
00:58:33,039 --> 00:58:38,019
three or four times bigger but more

1218
00:58:35,768 --> 00:58:40,358
importantly they're going to generalize

1219
00:58:38,018 --> 00:58:43,058
better because you're feeding your model

1220
00:58:40,358 --> 00:58:46,808
different sized images during training

1221
00:58:43,059 --> 00:58:49,960
right so we were able to Train like half

1222
00:58:46,809 --> 00:58:52,599
as many epochs for imagenet as most

1223
00:58:49,960 --> 00:58:54,880
people so our epochs were faster and

1224
00:58:52,599 --> 00:58:59,349
they were fewer of them so progressive

1225
00:58:54,880 --> 00:59:00,849
resizing is something that you know

1226
00:58:59,349 --> 00:59:02,980
particularly if your training from

1227
00:59:00,849 --> 00:59:04,539
scratch I'm not so sure if it's useful

1228
00:59:02,980 --> 00:59:05,588
for fine-tuning transfer learning but if

1229
00:59:04,539 --> 00:59:07,799
you're training from scratch you

1230
00:59:05,588 --> 00:59:09,969
probably want to do nearly all the time

1231
00:59:07,798 --> 00:59:15,068
so the next step is to go all the way

1232
00:59:09,969 --> 00:59:18,518
back to the top right and change to full

1233
00:59:15,068 --> 00:59:20,710
scale thirty-two batch size right like

1234
00:59:18,518 --> 00:59:22,508
restart so I saved the model before I do

1235
00:59:20,710 --> 00:59:27,940
that go back and that's why there's a

1236
00:59:22,509 --> 00:59:30,099
little bit of fussing around in here

1237
00:59:27,940 --> 00:59:32,079
with reloading because what I needed to

1238
00:59:30,099 --> 00:59:36,059
do now is I needed to load my saved

1239
00:59:32,079 --> 00:59:40,150
model back in but there's a slight issue

1240
00:59:36,059 --> 00:59:40,930
which is I now have one more up sampling

1241
00:59:40,150 --> 00:59:43,300
layer than I used to

1242
00:59:40,929 --> 00:59:51,029
have to go from two by two to four by

1243
00:59:43,300 --> 00:59:53,710
four my little my little loop here is

1244
00:59:51,030 --> 00:59:55,390
now looping through twice not once

1245
00:59:53,710 --> 00:59:58,539
and therefore it's added an extra

1246
00:59:55,389 --> 01:00:01,900
convent an extra pixel shuffle so how am

1247
00:59:58,539 --> 01:00:04,838
I going to load in weights for a

1248
01:00:01,900 --> 01:00:07,389
different network and the answer is that

1249
01:00:04,838 --> 01:00:10,269
I use a very handy thing in pi torch

1250
01:00:07,389 --> 01:00:15,338
which is if I call that this is what

1251
01:00:10,269 --> 01:00:18,670
this is basically what learned load

1252
01:00:15,338 --> 01:00:20,739
calls behind the scenes load state

1253
01:00:18,670 --> 01:00:23,789
kicked if I pass this parameter strict

1254
01:00:20,739 --> 01:00:27,729
equals false if I pass in this parameter

1255
01:00:23,789 --> 01:00:31,329
strict equals false that it says okay if

1256
01:00:27,730 --> 01:00:34,900
you can't fill in all of the layers just

1257
01:00:31,329 --> 01:00:37,599
fill in the lay as you can so after

1258
01:00:34,900 --> 01:00:38,889
loading the model back in this way we're

1259
01:00:37,599 --> 01:00:40,180
going to end up with something where

1260
01:00:38,889 --> 01:00:43,750
it's loaded in all the layers that it

1261
01:00:40,179 --> 01:00:46,298
can and that one comp layer that's new

1262
01:00:43,750 --> 01:00:49,599
is going to be randomly initialized all

1263
01:00:46,298 --> 01:00:54,088
right and so then I freeze all my layers

1264
01:00:49,599 --> 01:00:59,048
and then unfreeze that upsampling part

1265
01:00:54,088 --> 01:01:03,130
right and then use I CNR on my newly

1266
01:00:59,048 --> 01:01:07,449
added extra layer right and then I can

1267
01:01:03,130 --> 01:01:09,369
go ahead and wear again and so then the

1268
01:01:07,449 --> 01:01:11,980
rest is the same so if you're trying to

1269
01:01:09,369 --> 01:01:12,460
replicate this don't just run this top

1270
01:01:11,980 --> 01:01:14,369
to bottom

1271
01:01:12,460 --> 01:01:21,639
okay realize it involves a bit of

1272
01:01:14,369 --> 01:01:23,200
jumping around okay yeah the longer you

1273
01:01:21,639 --> 01:01:25,750
train the better it gets

1274
01:01:23,199 --> 01:01:27,068
I ended up training it for about 10

1275
01:01:25,750 --> 01:01:30,099
hours but you'll still get very good

1276
01:01:27,068 --> 01:01:33,279
results much more quickly if you're less

1277
01:01:30,099 --> 01:01:36,519
patient and so we can try it out and

1278
01:01:33,280 --> 01:01:38,740
here is the result here is my pixelated

1279
01:01:36,519 --> 01:01:42,039
bird and look here it's like totally

1280
01:01:38,739 --> 01:01:45,239
random e pixels and here's the upsampled

1281
01:01:42,039 --> 01:01:49,509
version it's like it's literally

1282
01:01:45,239 --> 01:01:51,989
invented color it coloration but it

1283
01:01:49,510 --> 01:01:54,760
figured out what kind of bird it is

1284
01:01:51,989 --> 01:01:57,159
right and it knows what the

1285
01:01:54,760 --> 01:02:00,190
feathers are metal look like and so it

1286
01:01:57,159 --> 01:02:03,609
has imagined a set of feathers which are

1287
01:02:00,190 --> 01:02:05,670
compatible with these exact pixels which

1288
01:02:03,610 --> 01:02:08,079
is like genius like saying here at

1289
01:02:05,670 --> 01:02:11,079
there's no way you can tell what these

1290
01:02:08,079 --> 01:02:13,210
blue dots are meant to represent but if

1291
01:02:11,079 --> 01:02:16,090
you know that this kind of bird has an

1292
01:02:13,210 --> 01:02:17,769
array of feathers here you know that's

1293
01:02:16,090 --> 01:02:19,240
what they must be right and then you can

1294
01:02:17,769 --> 01:02:20,920
figure out where the feathers would have

1295
01:02:19,239 --> 01:02:23,169
to be such that when they were pixelated

1296
01:02:20,920 --> 01:02:26,970
they'd end up in these pots all right so

1297
01:02:23,170 --> 01:02:30,159
it's like literally reverse engineered

1298
01:02:26,969 --> 01:02:33,579
like given its knowledge of this exact

1299
01:02:30,159 --> 01:02:36,849
species of bird how it would have to

1300
01:02:33,579 --> 01:02:41,069
have looked to create this output and so

1301
01:02:36,849 --> 01:02:43,449
this is like so amazing it also knows

1302
01:02:41,070 --> 01:02:47,650
from all the kind of signs around it

1303
01:02:43,449 --> 01:02:50,669
that this area here was was almost

1304
01:02:47,650 --> 01:02:55,720
certainly blurred out so it's actually

1305
01:02:50,670 --> 01:02:57,369
reconstructed blurred vegetation and you

1306
01:02:55,719 --> 01:02:59,619
know if it if it hadn't have done all of

1307
01:02:57,369 --> 01:03:01,299
those things it wouldn't have got such a

1308
01:02:59,619 --> 01:03:05,349
good loss function right because in the

1309
01:03:01,300 --> 01:03:07,390
end it had to match you know the

1310
01:03:05,349 --> 01:03:08,829
activations saying like oh there's a

1311
01:03:07,389 --> 01:03:10,569
feather over here and it's kind of

1312
01:03:08,829 --> 01:03:19,179
fluffy looking and it's you know in this

1313
01:03:10,570 --> 01:03:20,500
direction and all that all right well

1314
01:03:19,179 --> 01:03:23,739
that brings us to the end of super

1315
01:03:20,500 --> 01:03:26,199
resolution don't forget to check out the

1316
01:03:23,739 --> 01:03:28,509
ask Jeremy anything's threaded and we

1317
01:03:26,199 --> 01:03:31,569
will do some Astro me anything after the

1318
01:03:28,510 --> 01:03:33,720
break but see you back here a quarter to

1319
01:03:31,570 --> 01:03:33,720
eight

1320
01:03:48,449 --> 01:03:59,549
okay so we are going to do ask Jeremy

1321
01:03:58,210 --> 01:04:04,539
anything

1322
01:03:59,550 --> 01:04:11,920
Rachel will tell me the most voted up of

1323
01:04:04,539 --> 01:04:14,320
your questions yes Rachel what are the

1324
01:04:11,920 --> 01:04:17,260
future plans for fast AI in this course

1325
01:04:14,320 --> 01:04:18,700
will there be a part three if there is a

1326
01:04:17,260 --> 01:04:23,860
part three I would really love to take

1327
01:04:18,699 --> 01:04:26,559
it oh I'm not quite sure I always had to

1328
01:04:23,860 --> 01:04:29,769
guess I hope there'll be some kind of

1329
01:04:26,559 --> 01:04:32,619
follow-up last year after part two one

1330
01:04:29,769 --> 01:04:34,630
of the students started up a weekly book

1331
01:04:32,619 --> 01:04:36,849
club going through the Ian Goodfellow

1332
01:04:34,630 --> 01:04:39,730
deep learning book and Ian actually came

1333
01:04:36,849 --> 01:04:41,139
in and presented quite a few of the

1334
01:04:39,730 --> 01:04:43,269
chapters and other people like there's

1335
01:04:41,139 --> 01:04:45,250
somebody an expert who presented every

1336
01:04:43,269 --> 01:04:47,230
chapter that was really that was like a

1337
01:04:45,250 --> 01:04:49,570
really cool part three and four that

1338
01:04:47,230 --> 01:04:52,780
extended will depend on I'm you the

1339
01:04:49,570 --> 01:04:56,170
community to come up with ideas and help

1340
01:04:52,780 --> 01:04:58,450
make them happen and yeah and I'm

1341
01:04:56,170 --> 01:04:59,950
definitely keen to to help I've got a

1342
01:04:58,449 --> 01:05:01,210
bunch of ideas but I'm nervous about

1343
01:04:59,949 --> 01:05:02,889
saying them because I'm not sure which

1344
01:05:01,210 --> 01:05:06,639
ones will happen and which ones won't

1345
01:05:02,889 --> 01:05:07,989
but the more support I have in making

1346
01:05:06,639 --> 01:05:13,869
things happen that you want to happen

1347
01:05:07,989 --> 01:05:15,609
from you the more likely they are what

1348
01:05:13,869 --> 01:05:17,619
was your experience like starting down

1349
01:05:15,610 --> 01:05:19,269
the path of entrepreneurship have you

1350
01:05:17,619 --> 01:05:21,130
always been an entrepreneur or did you

1351
01:05:19,269 --> 01:05:23,380
start at it start out at a big company

1352
01:05:21,130 --> 01:05:25,510
in transition to a startup did you go

1353
01:05:23,380 --> 01:05:27,849
from academia to startups or startup

1354
01:05:25,510 --> 01:05:32,200
stack edenia no I was definitely not an

1355
01:05:27,849 --> 01:05:34,839
academia I'm totally a fake academic I I

1356
01:05:32,199 --> 01:05:38,500
I started at McKinsey and company which

1357
01:05:34,840 --> 01:05:40,090
is a strategy firm when I was 18 which

1358
01:05:38,500 --> 01:05:42,670
meant I couldn't really go to university

1359
01:05:40,090 --> 01:05:44,620
so I didn't really turn up and then yeah

1360
01:05:42,670 --> 01:05:46,619
spent eight years in business helping

1361
01:05:44,619 --> 01:05:48,920
really big companies on strategic

1362
01:05:46,619 --> 01:05:49,929
questions

1363
01:05:48,920 --> 01:05:51,920
I always wanted to be an entrepreneur

1364
01:05:49,929 --> 01:05:54,619
planter on you spend two years in

1365
01:05:51,920 --> 01:05:56,630
McKinsey only thing I really regret in

1366
01:05:54,619 --> 01:05:59,900
my life was not sticking to that plan

1367
01:05:56,630 --> 01:06:02,059
and wasting eight years instead so two

1368
01:05:59,900 --> 01:06:04,700
years would have been perfect but yeah

1369
01:06:02,059 --> 01:06:08,570
then I went into burner ship started two

1370
01:06:04,699 --> 01:06:10,969
companies in Australia and the best part

1371
01:06:08,570 --> 01:06:13,940
about that was that I didn't get any

1372
01:06:10,969 --> 01:06:16,369
funding so all the money that I made was

1373
01:06:13,940 --> 01:06:19,610
mine or the decisions were mine and my

1374
01:06:16,369 --> 01:06:22,549
you know and my partner's you know I

1375
01:06:19,610 --> 01:06:26,840
focused entirely on on profit and

1376
01:06:22,550 --> 01:06:28,580
product and customer and service whereas

1377
01:06:26,840 --> 01:06:32,930
I find in San Francisco I'm glad you

1378
01:06:28,579 --> 01:06:36,110
know I'm glad I came here and so the two

1379
01:06:32,929 --> 01:06:41,960
of us from you know came here for cable

1380
01:06:36,110 --> 01:06:43,099
and EMI and raised you know ridiculous

1381
01:06:41,960 --> 01:06:47,449
amount of money eleven million dollars

1382
01:06:43,099 --> 01:06:49,400
for this really new company that was

1383
01:06:47,449 --> 01:06:51,559
really interesting but it's also really

1384
01:06:49,400 --> 01:06:55,880
distracting you know trying to worry

1385
01:06:51,559 --> 01:06:57,590
about scaling and VC's wanting to see

1386
01:06:55,880 --> 01:06:59,420
what your business development plans are

1387
01:06:57,590 --> 01:07:02,990
and also just not having any real need

1388
01:06:59,420 --> 01:07:04,220
to actually make a profit and yeah so I

1389
01:07:02,989 --> 01:07:08,089
had a bit of the same problem at

1390
01:07:04,219 --> 01:07:11,239
analytic where I again raised a lot of

1391
01:07:08,090 --> 01:07:16,390
money fifteen million dollars pretty

1392
01:07:11,239 --> 01:07:22,299
quickly and yeah a lot of distractions

1393
01:07:16,389 --> 01:07:26,480
so yeah I think you know trying to

1394
01:07:22,300 --> 01:07:28,539
bootstrap your own company and focus on

1395
01:07:26,480 --> 01:07:32,630
making money by selling something at a

1396
01:07:28,539 --> 01:07:34,730
better profit and then you know plowing

1397
01:07:32,630 --> 01:07:37,220
that back into the company it worked

1398
01:07:34,730 --> 01:07:40,429
really well right because within like

1399
01:07:37,219 --> 01:07:42,169
five years you know we were making a

1400
01:07:40,429 --> 01:07:44,599
profit from three months in and within

1401
01:07:42,170 --> 01:07:46,400
five years we're making you know enough

1402
01:07:44,599 --> 01:07:48,170
for profit not just to pay all of us in

1403
01:07:46,400 --> 01:07:50,900
their own wages but also to see my bank

1404
01:07:48,170 --> 01:07:52,519
account growing and after ten years sold

1405
01:07:50,900 --> 01:07:55,910
it for a big chunk of money not enough

1406
01:07:52,519 --> 01:07:57,500
that a VC would be excited but enough

1407
01:07:55,909 --> 01:08:00,920
that I didn't have to worry that money

1408
01:07:57,500 --> 01:08:02,420
again you know so I think yeah

1409
01:08:00,920 --> 01:08:04,608
bootstrapping a company

1410
01:08:02,420 --> 01:08:07,670
something which people in the Bay Area's

1411
01:08:04,608 --> 01:08:12,199
don't seem to appreciate how good our

1412
01:08:07,670 --> 01:08:14,358
idea that is if you were 25 years old

1413
01:08:12,199 --> 01:08:16,818
today and still know what you know where

1414
01:08:14,358 --> 01:08:18,380
which of you looking to use AI what are

1415
01:08:16,819 --> 01:08:20,679
you working on right now are looking to

1416
01:08:18,380 --> 01:08:23,210
work on in the next two years

1417
01:08:20,679 --> 01:08:24,798
you should ignore the last part of that

1418
01:08:23,210 --> 01:08:27,560
I won't even answer it doesn't matter

1419
01:08:24,798 --> 01:08:31,069
where I'm looking like what you should

1420
01:08:27,560 --> 01:08:33,529
do is leverage your knowledge about your

1421
01:08:31,069 --> 01:08:36,520
domain so like one of the main reasons

1422
01:08:33,529 --> 01:08:40,489
we do this is to get people who have

1423
01:08:36,520 --> 01:08:44,839
backgrounds in whatever recruiting you

1424
01:08:40,488 --> 01:08:50,079
know oil field surveys journalism

1425
01:08:44,838 --> 01:08:52,149
activism whatever right and solve your

1426
01:08:50,079 --> 01:08:54,588
problems

1427
01:08:52,149 --> 01:08:56,778
it'll be really obvious to you what real

1428
01:08:54,588 --> 01:08:58,338
problems are and it'll be really obvious

1429
01:08:56,779 --> 01:09:00,949
to you what data you have and where to

1430
01:08:58,338 --> 01:09:02,359
find it those are all the bits that for

1431
01:09:00,948 --> 01:09:04,729
everybody else that's really hard so

1432
01:09:02,359 --> 01:09:06,710
people who start out with like oh I know

1433
01:09:04,729 --> 01:09:09,559
deep learning now I'll go and find

1434
01:09:06,710 --> 01:09:12,588
something to apply it to basically never

1435
01:09:09,560 --> 01:09:15,440
succeed where else people who are like

1436
01:09:12,588 --> 01:09:17,539
oh I've been spending 25 years doing

1437
01:09:15,439 --> 01:09:19,909
specialized recruiting for legal firms

1438
01:09:17,539 --> 01:09:21,769
and I know that the key issue is this

1439
01:09:19,909 --> 01:09:23,750
thing and I know that this piece of data

1440
01:09:21,770 --> 01:09:25,850
totally solves it and so I'm just going

1441
01:09:23,750 --> 01:09:27,588
to do that now and I already know who to

1442
01:09:25,850 --> 01:09:30,650
call who actually start selling it to

1443
01:09:27,588 --> 01:09:35,059
you know they're the ones who who tend

1444
01:09:30,649 --> 01:09:39,309
to win so yeah and and and you know if

1445
01:09:35,060 --> 01:09:41,539
you if you've done nothing but like

1446
01:09:39,310 --> 01:09:43,759
academic stuff that it's more maybe

1447
01:09:41,539 --> 01:09:47,778
about your your hobbies and interests

1448
01:09:43,759 --> 01:09:50,539
you know so everybody has hobbies the

1449
01:09:47,779 --> 01:09:52,850
main thing I would say is please don't

1450
01:09:50,539 --> 01:09:55,310
focus on building tools for data

1451
01:09:52,850 --> 01:09:57,320
scientists to use or for software

1452
01:09:55,310 --> 01:10:00,620
engineers to use because every data

1453
01:09:57,319 --> 01:10:02,988
scientist knows about the market of data

1454
01:10:00,619 --> 01:10:07,460
scientists whereas only you know about

1455
01:10:02,988 --> 01:10:10,419
the market for you know analyzing oil

1456
01:10:07,460 --> 01:10:13,899
survey world walks or you know

1457
01:10:10,420 --> 01:10:15,600
understanding audiology studies or

1458
01:10:13,899 --> 01:10:20,879
whatever it is that

1459
01:10:15,600 --> 01:10:22,590
you do given what you've shown us about

1460
01:10:20,880 --> 01:10:24,989
applying transfer learning from image

1461
01:10:22,590 --> 01:10:27,000
recognition to NLP there looks to be a

1462
01:10:24,989 --> 01:10:28,469
lot of value in paying attention to all

1463
01:10:27,000 --> 01:10:30,510
of the developments that happen across

1464
01:10:28,470 --> 01:10:31,890
the whole machine learning field and

1465
01:10:30,510 --> 01:10:33,329
that if you were to focus in one area

1466
01:10:31,890 --> 01:10:35,400
you might miss out on some great

1467
01:10:33,329 --> 01:10:37,229
advances in other concentrations

1468
01:10:35,399 --> 01:10:38,819
how do you stay aware of all the

1469
01:10:37,229 --> 01:10:40,859
advancements across the field while

1470
01:10:38,819 --> 01:10:43,979
still having time to dig in deep to your

1471
01:10:40,859 --> 01:10:45,569
specific domains yes awesome I mean

1472
01:10:43,979 --> 01:10:47,309
that's kind of the message of this

1473
01:10:45,569 --> 01:10:50,189
course one of the key messages this

1474
01:10:47,310 --> 01:10:51,930
course yeah it's like lots of good works

1475
01:10:50,189 --> 01:10:54,000
being done in different places and

1476
01:10:51,930 --> 01:10:56,490
people are so specialized most people

1477
01:10:54,000 --> 01:10:58,500
don't know about it like if I can get

1478
01:10:56,489 --> 01:11:01,039
stated that results in an LP within six

1479
01:10:58,500 --> 01:11:03,359
months of starting to look at NLP and I

1480
01:11:01,039 --> 01:11:03,899
think that says more about NLP than it

1481
01:11:03,359 --> 01:11:08,849
does about me

1482
01:11:03,899 --> 01:11:10,489
thankfully so yeah it's kind of like the

1483
01:11:08,850 --> 01:11:13,920
Entrepreneurship thing it's like you

1484
01:11:10,489 --> 01:11:16,260
pick that the areas you see that you

1485
01:11:13,920 --> 01:11:17,880
know about and kind of transfer stuff

1486
01:11:16,260 --> 01:11:20,280
like oh we could use deep learning to

1487
01:11:17,880 --> 01:11:23,909
solve this problem or in this case like

1488
01:11:20,279 --> 01:11:26,420
we could use you know this idea can

1489
01:11:23,909 --> 01:11:28,920
compute a vision to solve that problem

1490
01:11:26,420 --> 01:11:30,989
so things like trendier may transfer

1491
01:11:28,920 --> 01:11:32,819
learning i'm sure there's like a

1492
01:11:30,989 --> 01:11:35,189
thousand things opportunities for you to

1493
01:11:32,819 --> 01:11:38,789
do in other fields to do what Sebastian

1494
01:11:35,189 --> 01:11:41,069
and I did in NLP with NLP classification

1495
01:11:38,789 --> 01:11:42,630
so the short answer to your question is

1496
01:11:41,069 --> 01:11:46,139
the way to stay ahead of what's going on

1497
01:11:42,630 --> 01:11:49,230
would be to follow my feed of Twitter

1498
01:11:46,140 --> 01:11:50,880
favorites and my approach is to and

1499
01:11:49,229 --> 01:11:52,469
follow lots and lots of people on

1500
01:11:50,880 --> 01:11:55,109
Twitter and put them into the Twitter

1501
01:11:52,470 --> 01:11:56,220
favorites for you like literally I every

1502
01:11:55,109 --> 01:11:58,829
time I come across something interesting

1503
01:11:56,220 --> 01:12:00,390
I click favorite and there are two

1504
01:11:58,829 --> 01:12:02,640
reasons I do it the first is that when

1505
01:12:00,390 --> 01:12:04,440
the next course comes along I go through

1506
01:12:02,640 --> 01:12:06,810
my favorites to find which things I want

1507
01:12:04,439 --> 01:12:13,079
to study the second is so that you know

1508
01:12:06,810 --> 01:12:14,820
you can do the same thing and then you

1509
01:12:13,079 --> 01:12:16,859
know which do you go deep into it almost

1510
01:12:14,819 --> 01:12:18,329
doesn't matter like I find every time I

1511
01:12:16,859 --> 01:12:20,159
look at something it turns out to be

1512
01:12:18,329 --> 01:12:24,720
super interesting and important so tiss

1513
01:12:20,159 --> 01:12:26,189
like pick something which is like you

1514
01:12:24,720 --> 01:12:28,500
feel like solving that problem would be

1515
01:12:26,189 --> 01:12:29,469
actually useful to some reason and it

1516
01:12:28,500 --> 01:12:31,420
doesn't seem to be

1517
01:12:29,470 --> 01:12:32,949
popular which is kind of the opposite

1518
01:12:31,420 --> 01:12:35,579
with what everybody else does everybody

1519
01:12:32,949 --> 01:12:37,659
else works on the problems which

1520
01:12:35,579 --> 01:12:38,920
everybody else is already working on

1521
01:12:37,659 --> 01:12:42,010
because they're the ones that seem

1522
01:12:38,920 --> 01:12:43,480
popular and I don't know I can't quite

1523
01:12:42,010 --> 01:12:47,409
understand this chain of thinking but it

1524
01:12:43,479 --> 01:12:50,229
seems to be very common is deep learning

1525
01:12:47,409 --> 01:12:51,460
and overkill to use on tabular data when

1526
01:12:50,229 --> 01:12:53,319
is it better to use deep learning

1527
01:12:51,460 --> 01:13:00,640
instead of machine learning on tabular

1528
01:12:53,319 --> 01:13:02,649
data is that a real question or did you

1529
01:13:00,640 --> 01:13:04,450
just put that there so that I would

1530
01:13:02,649 --> 01:13:12,549
point out that Rachel Thomas just wrote

1531
01:13:04,449 --> 01:13:15,340
an article so yes so Rachel's just

1532
01:13:12,550 --> 01:13:16,840
written about this and and original and

1533
01:13:15,340 --> 01:13:19,300
I spent a long time talking about it and

1534
01:13:16,840 --> 01:13:23,369
the short answer is we think it's great

1535
01:13:19,300 --> 01:13:27,460
to use deep learning on tabular data

1536
01:13:23,369 --> 01:13:28,989
actually of all the rich complex

1537
01:13:27,460 --> 01:13:31,149
important and interesting things that

1538
01:13:28,989 --> 01:13:34,630
appear in Rachel's Twitter stream

1539
01:13:31,149 --> 01:13:38,079
covering everything from the genocide of

1540
01:13:34,630 --> 01:13:41,109
the Inga through to latest ethics

1541
01:13:38,079 --> 01:13:44,079
violations in AI companies the one by

1542
01:13:41,109 --> 01:13:45,909
far that got the most attention and

1543
01:13:44,079 --> 01:13:48,250
engagement from the community was their

1544
01:13:45,909 --> 01:13:52,420
question about is it called tabular data

1545
01:13:48,250 --> 01:13:55,029
or structured data so ya ask computer

1546
01:13:52,420 --> 01:13:58,779
Pires people how to name things and

1547
01:13:55,029 --> 01:14:00,639
you'll get plenty of interest yeah and

1548
01:13:58,779 --> 01:14:02,529
there's some really good links here to

1549
01:14:00,640 --> 01:14:06,010
stuff from instacart and pinterest and

1550
01:14:02,529 --> 01:14:07,509
other folks in this area any of you that

1551
01:14:06,010 --> 01:14:08,710
went to the data institute conference

1552
01:14:07,510 --> 01:14:10,720
will have seen Jeremy Stanley's

1553
01:14:08,710 --> 01:14:14,409
presentation about the really cool work

1554
01:14:10,720 --> 01:14:17,140
they did and instacart yes we're sure so

1555
01:14:14,409 --> 01:14:19,779
I relied heavily on lessons 3 and 4 from

1556
01:14:17,140 --> 01:14:22,890
part one and writing this post so yes

1557
01:14:19,779 --> 01:14:26,229
much of that may be familiar to you yeah

1558
01:14:22,890 --> 01:14:28,570
Rachel asked me during the post like how

1559
01:14:26,229 --> 01:14:31,359
to tell whether you should use the

1560
01:14:28,569 --> 01:14:33,819
decision tree ensemble like GBM or

1561
01:14:31,359 --> 01:14:36,789
random forest or or a neural net and my

1562
01:14:33,819 --> 01:14:38,500
answer is I still don't know nobody to

1563
01:14:36,789 --> 01:14:40,899
my nobody I'm aware of has done that

1564
01:14:38,500 --> 01:14:42,609
research and any particularly meaningful

1565
01:14:40,899 --> 01:14:45,779
way so there's

1566
01:14:42,609 --> 01:14:48,250
a question to be answered there I guess

1567
01:14:45,779 --> 01:14:49,599
my approach has been to try to make both

1568
01:14:48,250 --> 01:14:51,130
of those things as accessible as

1569
01:14:49,600 --> 01:14:52,840
possible through the faster your library

1570
01:14:51,130 --> 01:15:00,819
so you can try them both both and see

1571
01:14:52,840 --> 01:15:03,550
what works yes that's what I do and that

1572
01:15:00,819 --> 01:15:11,519
is it for the top voted questions thank

1573
01:15:03,550 --> 01:15:15,220
you okay so just quickly to go from

1574
01:15:11,520 --> 01:15:19,210
super resolution to style transfer it's

1575
01:15:15,220 --> 01:15:21,789
kind of oh I think I miss the one on

1576
01:15:19,210 --> 01:15:23,470
reinforcement learning and reinforcement

1577
01:15:21,789 --> 01:15:26,979
learning popularity has been on a

1578
01:15:23,470 --> 01:15:28,270
gradual rise in the recent past what's

1579
01:15:26,979 --> 01:15:30,699
your take on reinforcement learning

1580
01:15:28,270 --> 01:15:32,770
which fast day I consider covering some

1581
01:15:30,699 --> 01:15:37,599
ground and popular RL techniques in the

1582
01:15:32,770 --> 01:15:42,570
future I'm still not a believer in

1583
01:15:37,600 --> 01:15:45,970
reinforcement learning I think it's a an

1584
01:15:42,569 --> 01:15:47,469
interesting problem to solve but it's

1585
01:15:45,970 --> 01:15:49,150
not at all clear that we have a good way

1586
01:15:47,470 --> 01:15:51,730
of solving this problem so the problem

1587
01:15:49,149 --> 01:15:54,189
it really is the delayed credit problem

1588
01:15:51,729 --> 01:15:57,579
so you know I want to learn to play pong

1589
01:15:54,189 --> 01:15:59,979
I've moved up or down and three minutes

1590
01:15:57,579 --> 01:16:04,119
later I find out whether I won the game

1591
01:15:59,979 --> 01:16:06,369
of pong which actions I took were

1592
01:16:04,119 --> 01:16:08,170
actually useful and so to me the idea of

1593
01:16:06,369 --> 01:16:10,420
calculating the gradients of those

1594
01:16:08,170 --> 01:16:11,770
inputs with respect you know the app so

1595
01:16:10,420 --> 01:16:14,649
the gradient of the output with respect

1596
01:16:11,770 --> 01:16:16,660
to those inputs the credit is so delayed

1597
01:16:14,649 --> 01:16:20,859
that those derivatives don't seem very

1598
01:16:16,659 --> 01:16:22,840
interesting and there's been you know

1599
01:16:20,859 --> 01:16:24,909
kind of been I get this question quite

1600
01:16:22,840 --> 01:16:26,590
regularly in every one of these four

1601
01:16:24,909 --> 01:16:29,889
courses so far I've always it the same

1602
01:16:26,590 --> 01:16:31,539
thing I'm rather pleased but finally

1603
01:16:29,890 --> 01:16:33,579
recently there's been some results

1604
01:16:31,539 --> 01:16:36,630
showing that actually basically random

1605
01:16:33,579 --> 01:16:39,399
search often does better than

1606
01:16:36,630 --> 01:16:42,190
reinforcement learning so basically

1607
01:16:39,399 --> 01:16:44,139
what's happened is very well-funded

1608
01:16:42,189 --> 01:16:46,659
companies with vast amounts of

1609
01:16:44,140 --> 01:16:49,119
computational power throw all of it at

1610
01:16:46,659 --> 01:16:51,729
reinforcement learning problems and get

1611
01:16:49,119 --> 01:16:53,109
good results and people then say oh it's

1612
01:16:51,729 --> 01:16:55,929
because of the reinforcement learning

1613
01:16:53,109 --> 01:16:56,618
rather than the vast amounts of compute

1614
01:16:55,930 --> 01:17:01,360
power

1615
01:16:56,618 --> 01:17:04,029
or they use extremely thoughtful and

1616
01:17:01,359 --> 01:17:06,009
clever algorithms like a combination of

1617
01:17:04,029 --> 01:17:08,109
convolutional neural nets and Monte

1618
01:17:06,010 --> 01:17:10,119
Carlo tree search like they did with the

1619
01:17:08,109 --> 01:17:13,059
alpha girl stuff to get great results

1620
01:17:10,118 --> 01:17:14,799
and people incorrectly say oh that's

1621
01:17:13,060 --> 01:17:16,780
because of reinforcement learning when

1622
01:17:14,800 --> 01:17:21,340
it wasn't really reinforcement learning

1623
01:17:16,779 --> 01:17:25,809
at all so I'm very interested like in

1624
01:17:21,340 --> 01:17:27,819
solving these kind of more generic

1625
01:17:25,810 --> 01:17:29,500
optimization type problems rather than

1626
01:17:27,819 --> 01:17:30,939
just prediction problems and that's what

1627
01:17:29,500 --> 01:17:34,988
these delay to credit problems tend to

1628
01:17:30,939 --> 01:17:37,899
look like but I don't think we've yet

1629
01:17:34,988 --> 01:17:41,439
got good enough best practices that I

1630
01:17:37,899 --> 01:17:42,729
have anything on ready to teach and say

1631
01:17:41,439 --> 01:17:44,198
like I've got to teach you this thing

1632
01:17:42,729 --> 01:17:47,888
because I think it's still going to be

1633
01:17:44,198 --> 01:17:58,089
useful next year so we'll keep watching

1634
01:17:47,889 --> 01:18:00,279
and yeah see see what happens ok so

1635
01:17:58,090 --> 01:18:03,119
we're going to now turn the super

1636
01:18:00,279 --> 01:18:05,380
resolution Network basically into a

1637
01:18:03,118 --> 01:18:08,139
style transfer network and what do this

1638
01:18:05,380 --> 01:18:10,359
pretty quickly we basically already have

1639
01:18:08,139 --> 01:18:13,300
something so here's my input image and

1640
01:18:10,359 --> 01:18:16,960
I'm going to have some loss function and

1641
01:18:13,300 --> 01:18:18,010
I've got some neural net again so

1642
01:18:16,960 --> 01:18:19,960
instead of a neural net that does a

1643
01:18:18,010 --> 01:18:22,900
whole lot of compute and then does up

1644
01:18:19,960 --> 01:18:25,270
sampling at the end our input this time

1645
01:18:22,899 --> 01:18:27,158
is just as big as our output so we're

1646
01:18:25,270 --> 01:18:29,679
going to do some down sampling first and

1647
01:18:27,158 --> 01:18:31,420
then our compute and then our settlement

1648
01:18:29,679 --> 01:18:32,859
okay so that's the first change we're

1649
01:18:31,420 --> 01:18:35,469
going to make is going to add some down

1650
01:18:32,859 --> 01:18:37,750
sampling so since tried to convolution

1651
01:18:35,469 --> 01:18:41,109
layers to the front of our network the

1652
01:18:37,750 --> 01:18:43,238
second is rather than just comparing YC

1653
01:18:41,109 --> 01:18:45,698
and X to the same thing here right so

1654
01:18:43,238 --> 01:18:49,689
we're going to basically say our input

1655
01:18:45,698 --> 01:18:51,368
image should look like itself by the end

1656
01:18:49,689 --> 01:18:53,348
and so specifically we're going to

1657
01:18:51,368 --> 01:18:55,149
compare it by checking it through vgg

1658
01:18:53,349 --> 01:18:58,569
and comparing it at one of the content

1659
01:18:55,149 --> 01:19:02,138
at one of the activation layers and then

1660
01:18:58,569 --> 01:19:04,029
its style should look like some painting

1661
01:19:02,139 --> 01:19:06,159
which brought to it just like we did

1662
01:19:04,029 --> 01:19:08,408
with the gaddy's approach by looking at

1663
01:19:06,158 --> 01:19:10,268
the grand Matrix correspondence at a

1664
01:19:08,408 --> 01:19:13,719
number of layers

1665
01:19:10,269 --> 01:19:16,119
so that's basically it and so that that

1666
01:19:13,719 --> 01:19:17,800
ought to be super straightforward it's

1667
01:19:16,118 --> 01:19:21,279
really just combining two things we've

1668
01:19:17,800 --> 01:19:23,498
already done and so all this code starts

1669
01:19:21,279 --> 01:19:26,460
identical except we don't have high res

1670
01:19:23,498 --> 01:19:31,748
and low res we just have one size 256

1671
01:19:26,460 --> 01:19:36,038
well this is the same my model is the

1672
01:19:31,748 --> 01:19:39,639
same one thing I did here is I I made I

1673
01:19:36,038 --> 01:19:41,368
did not do any kind of fancy best

1674
01:19:39,639 --> 01:19:43,840
practices for this one at all

1675
01:19:41,368 --> 01:19:45,998
partly because there doesn't seem to be

1676
01:19:43,840 --> 01:19:50,679
any like there's been very little follow

1677
01:19:45,998 --> 01:19:53,019
up in this approach compared to the

1678
01:19:50,679 --> 01:19:55,569
super resolution stuff and we'll talk

1679
01:19:53,019 --> 01:19:57,909
about why in a moment so you'll see this

1680
01:19:55,569 --> 01:20:02,109
is like much more normal looking you

1681
01:19:57,908 --> 01:20:06,969
know I've got batch norm layers I don't

1682
01:20:02,109 --> 01:20:08,679
have the scaling factor here you know I

1683
01:20:06,969 --> 01:20:10,300
don't have a pixel shuffle that's just

1684
01:20:08,679 --> 01:20:13,239
using a normal up sampling followed by

1685
01:20:10,300 --> 01:20:15,369
one by one cons so it's kind of it's

1686
01:20:13,238 --> 01:20:17,348
just more normal

1687
01:20:15,368 --> 01:20:21,189
one thing they mentioned in the paper is

1688
01:20:17,349 --> 01:20:23,739
they had a lot of problems with zero

1689
01:20:21,189 --> 01:20:26,259
padding creating artifacts and the way

1690
01:20:23,738 --> 01:20:28,899
they solve that was by adding 40 pixels

1691
01:20:26,260 --> 01:20:31,210
of reflection padding at the start so I

1692
01:20:28,899 --> 01:20:34,328
did the same thing and then they used

1693
01:20:31,210 --> 01:20:37,059
zero padding in there convolutions in

1694
01:20:34,328 --> 01:20:38,679
there red blocks now if you've got zero

1695
01:20:37,059 --> 01:20:41,349
padding in your convolution in your red

1696
01:20:38,679 --> 01:20:42,880
blocks then that means that you're the

1697
01:20:41,349 --> 01:20:46,328
two parts of your resin it won't add up

1698
01:20:42,880 --> 01:20:47,828
anymore because you've lost a pixel from

1699
01:20:46,328 --> 01:20:51,429
each side on each of your two

1700
01:20:47,828 --> 01:20:53,710
convolutions so my my red sequential has

1701
01:20:51,429 --> 01:20:56,828
become res sequential Center and I've

1702
01:20:53,710 --> 01:20:59,469
removed the last two pixels on each side

1703
01:20:56,828 --> 01:21:00,998
of those good sus okay so other than

1704
01:20:59,469 --> 01:21:04,538
that this is basically the same as what

1705
01:21:00,998 --> 01:21:08,380
we had thought so then we can bring in

1706
01:21:04,538 --> 01:21:10,868
our starry night picture we can resize

1707
01:21:08,380 --> 01:21:16,868
it we can throw it through our

1708
01:21:10,868 --> 01:21:18,189
transformations just to make the method

1709
01:21:16,868 --> 01:21:19,089
a little bit easier for my brain to

1710
01:21:18,189 --> 01:21:21,969
handle

1711
01:21:19,090 --> 01:21:24,219
I took my transformation image which

1712
01:21:21,969 --> 01:21:26,529
after transfer our transform style in

1713
01:21:24,219 --> 01:21:29,859
after transformations of three by 256 by

1714
01:21:26,529 --> 01:21:32,889
256 and I made a mini batch my batch

1715
01:21:29,859 --> 01:21:34,359
size is 24 24 copies of it now it just

1716
01:21:32,889 --> 01:21:36,880
makes it a little bit easier to do the

1717
01:21:34,359 --> 01:21:38,589
kind of batch arithmetic without

1718
01:21:36,880 --> 01:21:41,440
worrying about some of the broadcasting

1719
01:21:38,590 --> 01:21:46,960
they're not really 24 copies are used MP

1720
01:21:41,439 --> 01:21:53,018
dot broadcast to to basically fake 24

1721
01:21:46,960 --> 01:21:57,279
piece okay so just like before we create

1722
01:21:53,019 --> 01:21:59,670
a V Gigi grab the last block this time

1723
01:21:57,279 --> 01:22:01,840
we're going to use all of these layers

1724
01:21:59,670 --> 01:22:05,979
so we keep everything up to the

1725
01:22:01,840 --> 01:22:08,229
forty-third layer and so now our

1726
01:22:05,979 --> 01:22:12,309
combined lasts is going to add together

1727
01:22:08,229 --> 01:22:15,159
a content loss for the third block plus

1728
01:22:12,309 --> 01:22:17,440
the gramm loss for all of our blocks

1729
01:22:15,158 --> 01:22:19,268
with different weights and so the gram

1730
01:22:17,439 --> 01:22:23,018
loss against that kind of going back to

1731
01:22:19,269 --> 01:22:24,820
everything being is like normal as

1732
01:22:23,019 --> 01:22:27,639
possible I've gone back to using MSA

1733
01:22:24,819 --> 01:22:28,808
here basically what happened as I had a

1734
01:22:27,639 --> 01:22:30,788
lot of trouble getting this to train

1735
01:22:28,809 --> 01:22:32,199
properly so I gradually removed trick

1736
01:22:30,788 --> 01:22:33,939
after trick and eventually just went ok

1737
01:22:32,198 --> 01:22:36,988
that's good I believe make it as as

1738
01:22:33,939 --> 01:22:36,988
bland as possible

1739
01:22:37,288 --> 01:22:44,559
last week's Graham matrix was wrong by

1740
01:22:42,880 --> 01:22:46,269
the way it only worked for a batch size

1741
01:22:44,559 --> 01:22:50,139
of one and we only had a batch size of

1742
01:22:46,269 --> 01:22:54,070
one so that was fine I was using matrix

1743
01:22:50,139 --> 01:22:55,929
multiply which meant that every batch

1744
01:22:54,069 --> 01:22:59,018
was being compared to every other batch

1745
01:22:55,929 --> 01:23:01,239
you actually need to use batch matrix

1746
01:22:59,019 --> 01:23:04,659
multiply which does a matrix multiply

1747
01:23:01,238 --> 01:23:08,348
per batch ok so that's something to be

1748
01:23:04,658 --> 01:23:10,569
aware of there ok so so I've got my

1749
01:23:08,349 --> 01:23:13,479
grand matrices I do my MSE loss between

1750
01:23:10,569 --> 01:23:17,889
the gram matrices I weight them my style

1751
01:23:13,479 --> 01:23:20,349
weights so I create that ResNet so

1752
01:23:17,889 --> 01:23:23,109
create my style my combined loss passing

1753
01:23:20,349 --> 01:23:27,819
in the vgg Network passing in the block

1754
01:23:23,109 --> 01:23:30,279
IDs passing in the transformed starry

1755
01:23:27,819 --> 01:23:33,308
night image and so you'll see the very

1756
01:23:30,279 --> 01:23:35,529
start here I do a forward pass through

1757
01:23:33,309 --> 01:23:38,590
both vtg model with that starry night

1758
01:23:35,529 --> 01:23:41,579
image in order that I can

1759
01:23:38,590 --> 01:23:43,840
the features for it right now notice

1760
01:23:41,579 --> 01:23:46,090
it's really important now that I don't

1761
01:23:43,840 --> 01:23:48,789
do any data augmentation because I've

1762
01:23:46,090 --> 01:23:52,090
saved the style features for a

1763
01:23:48,789 --> 01:23:55,420
particular you know non Augmented

1764
01:23:52,090 --> 01:23:58,929
version and so if I augmented it it

1765
01:23:55,420 --> 01:24:00,279
might make some minor problems but

1766
01:23:58,929 --> 01:24:02,319
that's fine because I've got all of

1767
01:24:00,279 --> 01:24:06,840
imagenet to deal with I don't really

1768
01:24:02,319 --> 01:24:09,609
need to do data augmentation anyway okay

1769
01:24:06,840 --> 01:24:11,890
so I've got my loss function and I can

1770
01:24:09,609 --> 01:24:14,969
go ahead and fit and there's really

1771
01:24:11,890 --> 01:24:17,650
nothing flavor here at all at the end I

1772
01:24:14,969 --> 01:24:19,869
have my some layers equals false so I

1773
01:24:17,649 --> 01:24:22,238
can see what each part looks like and

1774
01:24:19,869 --> 01:24:27,909
see that there is some we balanced and I

1775
01:24:22,238 --> 01:24:32,139
can finally pop it out so I mentioned

1776
01:24:27,909 --> 01:24:36,779
that should be pretty easy and yet it

1777
01:24:32,140 --> 01:24:40,420
took me about 4 days because it just I

1778
01:24:36,779 --> 01:24:43,389
just found this incredibly fiddly to

1779
01:24:40,420 --> 01:24:45,279
actually get it to work so like when I

1780
01:24:43,390 --> 01:24:47,469
finally got up in the morning I said to

1781
01:24:45,279 --> 01:24:50,349
Rachel guess what they're trained

1782
01:24:47,469 --> 01:24:54,100
correctly Rachel was like I never

1783
01:24:50,350 --> 01:24:57,640
thought that was going to happen it just

1784
01:24:54,100 --> 01:24:59,440
it just looked awful all the time and

1785
01:24:57,640 --> 01:25:01,539
it's really about getting the exact

1786
01:24:59,439 --> 01:25:03,159
right mix of content lossless a style

1787
01:25:01,539 --> 01:25:05,619
loss of the mix of the layers of the

1788
01:25:03,159 --> 01:25:09,130
style loss and that the worst part was

1789
01:25:05,619 --> 01:25:12,579
it takes a really long time to train the

1790
01:25:09,130 --> 01:25:14,920
damn CNN and I don't didn't really know

1791
01:25:12,579 --> 01:25:17,260
how long to train it before before I

1792
01:25:14,920 --> 01:25:22,510
decided it wasn't doing well like should

1793
01:25:17,260 --> 01:25:25,329
I just train it for longer or what and I

1794
01:25:22,510 --> 01:25:26,920
don't know all the little details didn't

1795
01:25:25,329 --> 01:25:29,079
seem to like slightly change it but just

1796
01:25:26,920 --> 01:25:34,840
like it would totally fall apart all the

1797
01:25:29,079 --> 01:25:37,809
time so I kind of mentioned this partly

1798
01:25:34,840 --> 01:25:41,199
to say like just remember the final

1799
01:25:37,810 --> 01:25:43,719
answer you see here is after me driving

1800
01:25:41,198 --> 01:25:45,460
myself crazy or weak over nearly always

1801
01:25:43,719 --> 01:25:48,819
not working until finally the last

1802
01:25:45,460 --> 01:25:51,310
minute it finally does for even for

1803
01:25:48,819 --> 01:25:51,880
things which just seemed like they

1804
01:25:51,310 --> 01:25:53,560
couldn't pass

1805
01:25:51,880 --> 01:25:56,289
be difficult because that is combining

1806
01:25:53,560 --> 01:25:58,539
two things we already have working the

1807
01:25:56,289 --> 01:26:11,140
other is like to be careful about how we

1808
01:25:58,539 --> 01:26:14,439
interpret what authors claim yeah so it

1809
01:26:11,140 --> 01:26:18,130
was so fiddly getting this style

1810
01:26:14,439 --> 01:26:21,189
transfer to work and like after doing it

1811
01:26:18,130 --> 01:26:23,230
it left me thinking why did I bother

1812
01:26:21,189 --> 01:26:26,889
because now I've got something that

1813
01:26:23,229 --> 01:26:30,879
takes hours to create a network that can

1814
01:26:26,890 --> 01:26:33,789
turn any kind of photo into one specific

1815
01:26:30,880 --> 01:26:35,949
style it just seems very unlikely I

1816
01:26:33,789 --> 01:26:37,449
would want that for anything like about

1817
01:26:35,949 --> 01:26:40,179
the only reason I could think that being

1818
01:26:37,449 --> 01:26:42,250
useful would be to like do some art and

1819
01:26:40,180 --> 01:26:44,409
stuff on a video rather to turn every

1820
01:26:42,250 --> 01:26:47,890
frame into some style like it's

1821
01:26:44,409 --> 01:26:50,439
incredibly interesting to what to do but

1822
01:26:47,890 --> 01:26:52,329
you know when I looked at the paper that

1823
01:26:50,439 --> 01:26:55,509
you know their tables saying like oh

1824
01:26:52,329 --> 01:26:58,920
we're a thousand times faster than the

1825
01:26:55,510 --> 01:27:01,810
Gattis approach which is like it's just

1826
01:26:58,920 --> 01:27:04,980
such an obviously meaningless thing to

1827
01:27:01,810 --> 01:27:07,360
say in such an incredibly kind of

1828
01:27:04,979 --> 01:27:09,759
misleading thing to say because it

1829
01:27:07,359 --> 01:27:13,539
ignores all the hours of training for

1830
01:27:09,760 --> 01:27:15,390
each individual style and I don't know I

1831
01:27:13,539 --> 01:27:18,609
find this frustrating because like a

1832
01:27:15,390 --> 01:27:20,680
groups like this Stanford group clearly

1833
01:27:18,609 --> 01:27:23,649
know better or ought to know better but

1834
01:27:20,680 --> 01:27:26,400
still I guess the academic community he

1835
01:27:23,649 --> 01:27:29,469
kind of encourages people to make these

1836
01:27:26,399 --> 01:27:32,710
ridiculously grand plans and it also

1837
01:27:29,470 --> 01:27:40,720
completely ignores this incredibly

1838
01:27:32,710 --> 01:27:42,819
sensitive fiddly training process so you

1839
01:27:40,720 --> 01:27:44,860
know this paper was just so well

1840
01:27:42,819 --> 01:27:46,239
accepted when it came out you know I

1841
01:27:44,859 --> 01:27:47,859
remember everybody getting on Twitter

1842
01:27:46,239 --> 01:27:49,389
and being like wow you know these

1843
01:27:47,859 --> 01:27:51,519
Stanford people have found this way of

1844
01:27:49,390 --> 01:27:55,660
doing style transfer a thousand times

1845
01:27:51,520 --> 01:27:57,700
faster and clearly you know the people

1846
01:27:55,659 --> 01:28:00,039
saying this would like all like top

1847
01:27:57,699 --> 01:28:01,960
researchers in the field clearly like

1848
01:28:00,039 --> 01:28:05,680
none of them actually understood because

1849
01:28:01,960 --> 01:28:07,899
nobody said you know I don't

1850
01:28:05,680 --> 01:28:09,430
see why this is remotely useful and also

1851
01:28:07,899 --> 01:28:11,679
I tried it and it was incredibly fiddly

1852
01:28:09,430 --> 01:28:13,869
to get it all to work and so it's not

1853
01:28:11,680 --> 01:28:15,490
until like what is this they're like

1854
01:28:13,869 --> 01:28:17,229
eighteen months later or something that

1855
01:28:15,489 --> 01:28:20,380
I finally coming back to it and kind of

1856
01:28:17,229 --> 01:28:24,489
thinking like wait a minute this is kind

1857
01:28:20,380 --> 01:28:25,779
of stupid and so so this is the answer I

1858
01:28:24,489 --> 01:28:27,429
think to the question of like well why

1859
01:28:25,779 --> 01:28:29,139
haven't people don't follow ups on this

1860
01:28:27,430 --> 01:28:30,700
to like create really amazing best

1861
01:28:29,140 --> 01:28:32,110
practices and better approaches like

1862
01:28:30,699 --> 01:28:33,250
with a super resolution part of the

1863
01:28:32,109 --> 01:28:40,420
paper and they I think the answer is

1864
01:28:33,250 --> 01:28:42,609
because it's done so I think this part

1865
01:28:40,420 --> 01:28:45,220
of the paper is clearly not fun you know

1866
01:28:42,609 --> 01:28:48,069
and it's been improved and improved and

1867
01:28:45,220 --> 01:28:50,140
improved and now we have great super

1868
01:28:48,069 --> 01:28:52,000
resolution and I think we can derive

1869
01:28:50,140 --> 01:28:54,910
from that great noise reduction great

1870
01:28:52,000 --> 01:29:00,250
colorization great you know slant

1871
01:28:54,909 --> 01:29:05,139
removal great interactive and effective

1872
01:29:00,250 --> 01:29:07,390
or whatever so I think there's a lot of

1873
01:29:05,140 --> 01:29:08,890
really cool techniques here and it's

1874
01:29:07,390 --> 01:29:10,000
also delivering a lot of stuff that

1875
01:29:08,890 --> 01:29:14,230
we've been learning and getting better

1876
01:29:10,000 --> 01:29:17,470
and better at okay so then finally let's

1877
01:29:14,229 --> 01:29:20,379
talk about segmentation this is from the

1878
01:29:17,470 --> 01:29:22,030
famous some cam vid data set which is a

1879
01:29:20,380 --> 01:29:24,369
classic example of an academic

1880
01:29:22,029 --> 01:29:25,750
segmentation data set and basically you

1881
01:29:24,369 --> 01:29:27,819
can see what we do is we start with a

1882
01:29:25,750 --> 01:29:31,659
picture they're actually video frames in

1883
01:29:27,819 --> 01:29:37,420
this data set like here and we construct

1884
01:29:31,659 --> 01:29:39,880
we have some labels where they're not

1885
01:29:37,420 --> 01:29:42,069
actually colors that each one has an ID

1886
01:29:39,880 --> 01:29:44,350
and the IDS of math two colors so like

1887
01:29:42,069 --> 01:29:48,670
red might be one purple might be two

1888
01:29:44,350 --> 01:29:52,780
like pink might be three and so all the

1889
01:29:48,670 --> 01:29:55,449
buildings you know one class or the cars

1890
01:29:52,779 --> 01:29:57,489
or another class or the people or

1891
01:29:55,449 --> 01:29:59,920
another class or the road is another

1892
01:29:57,489 --> 01:30:03,460
class and so what we're actually doing

1893
01:29:59,920 --> 01:30:07,180
here is multi-class classification for

1894
01:30:03,460 --> 01:30:09,180
every pixel okay and so you can see

1895
01:30:07,180 --> 01:30:11,829
sometimes that model class specification

1896
01:30:09,180 --> 01:30:14,380
really is quite tricky there's you know

1897
01:30:11,829 --> 01:30:16,119
like like these branches well though

1898
01:30:14,380 --> 01:30:18,210
sometimes the labels are really not that

1899
01:30:16,119 --> 01:30:22,369
great you know this is very coarse

1900
01:30:18,210 --> 01:30:25,890
as you can see so here at traffic lights

1901
01:30:22,369 --> 01:30:26,988
so forth so but that's what we're going

1902
01:30:25,890 --> 01:30:29,130
to do we're going to do this is

1903
01:30:26,988 --> 01:30:33,509
segmentation and so it's a look like

1904
01:30:29,130 --> 01:30:36,359
bounding boxes okay but you know rather

1905
01:30:33,510 --> 01:30:38,400
than just finding you know a box around

1906
01:30:36,359 --> 01:30:40,409
each thing we're actually going to label

1907
01:30:38,399 --> 01:30:43,339
every single pixel with its plus and

1908
01:30:40,409 --> 01:30:49,920
really that's actually a lot easier

1909
01:30:43,340 --> 01:30:51,690
because it fits our CNN style so nicely

1910
01:30:49,920 --> 01:30:57,409
that we've basically we can create any

1911
01:30:51,689 --> 01:31:00,179
CNN where the output is an N by M grid

1912
01:30:57,409 --> 01:31:02,340
containing the integers from 0 to C

1913
01:31:00,180 --> 01:31:03,900
where there are C categories and then we

1914
01:31:02,340 --> 01:31:06,659
can use cross-entropy loss with a

1915
01:31:03,899 --> 01:31:08,579
softmax activation and we're done right

1916
01:31:06,659 --> 01:31:11,010
so like I could actually stop the class

1917
01:31:08,579 --> 01:31:12,659
there and you can go and use exactly the

1918
01:31:11,010 --> 01:31:15,409
approaches you've learnt in like lessons

1919
01:31:12,659 --> 01:31:17,279
1 &amp; 2 and you'll get a perfectly okay

1920
01:31:15,409 --> 01:31:19,109
result ok

1921
01:31:17,279 --> 01:31:21,420
so the first thing to say is like this

1922
01:31:19,109 --> 01:31:23,009
is not actually a terribly hard thing to

1923
01:31:21,420 --> 01:31:28,230
do but we're going to try and do it

1924
01:31:23,010 --> 01:31:30,390
really well and so let's start by doing

1925
01:31:28,229 --> 01:31:33,179
it the really simple way and we're going

1926
01:31:30,390 --> 01:31:35,010
to use the CAG or carvanha competition

1927
01:31:33,180 --> 01:31:36,450
so you could go cable car Varner to find

1928
01:31:35,010 --> 01:31:38,550
it you can download it with the caracal

1929
01:31:36,449 --> 01:31:40,559
api as per usual

1930
01:31:38,550 --> 01:31:43,170
now basically there's a train folder

1931
01:31:40,560 --> 01:31:44,969
containing a bunch of images which is

1932
01:31:43,170 --> 01:31:46,980
the independent variable and a train

1933
01:31:44,969 --> 01:31:49,439
masks folder there's the dependent

1934
01:31:46,979 --> 01:31:50,849
variable and they look like this here's

1935
01:31:49,439 --> 01:31:58,049
the here's one of the independent

1936
01:31:50,850 --> 01:32:01,170
variable and here's one of the dependent

1937
01:31:58,050 --> 01:32:03,930
variable okay so in this case just like

1938
01:32:01,170 --> 01:32:05,190
cats and dogs we're going simple rather

1939
01:32:03,930 --> 01:32:07,020
than doing multi-class classification

1940
01:32:05,189 --> 01:32:09,869
we're going to do binary classification

1941
01:32:07,020 --> 01:32:11,750
but of course multi-class is just the

1942
01:32:09,869 --> 01:32:13,680
more general version you know

1943
01:32:11,750 --> 01:32:15,750
categorical cross-entropy your binary

1944
01:32:13,680 --> 01:32:17,820
cross-entropy okay so there's no

1945
01:32:15,750 --> 01:32:20,689
differences conceptually so we've got

1946
01:32:17,819 --> 01:32:25,289
this is just you know zeros and ones

1947
01:32:20,689 --> 01:32:27,869
where else this is a regular image so in

1948
01:32:25,289 --> 01:32:30,390
order to do this well it would really

1949
01:32:27,869 --> 01:32:31,590
help to know what cars look like right

1950
01:32:30,390 --> 01:32:33,929
because you know really

1951
01:32:31,590 --> 01:32:36,150
we just what to do is figure out this is

1952
01:32:33,929 --> 01:32:37,949
a car and its orientation and then color

1953
01:32:36,149 --> 01:32:39,839
you know put white pixels where we

1954
01:32:37,948 --> 01:32:41,698
expect the part of e based on the

1955
01:32:39,840 --> 01:32:46,500
picture and their understanding of what

1956
01:32:41,698 --> 01:32:48,448
cars will plug the original data set

1957
01:32:46,500 --> 01:32:50,219
came with these CSV files as well I

1958
01:32:48,448 --> 01:32:52,250
don't really use them for very much

1959
01:32:50,219 --> 01:33:01,889
other than getting the list of images

1960
01:32:52,250 --> 01:33:06,149
from them each each image after the car

1961
01:33:01,889 --> 01:33:08,250
ID has a 0 1 0 2 etc of which I've

1962
01:33:06,149 --> 01:33:09,750
printed out all 16 of them for one car

1963
01:33:08,250 --> 01:33:13,198
and as you can see if basically those

1964
01:33:09,750 --> 01:33:17,789
numbers are the 16 orientations of one

1965
01:33:13,198 --> 01:33:19,609
car that is and I don't think anybody in

1966
01:33:17,789 --> 01:33:21,899
this competition actually used this

1967
01:33:19,609 --> 01:33:25,109
orientation information I believe they

1968
01:33:21,899 --> 01:33:28,439
all kick the cars images just treated

1969
01:33:25,109 --> 01:33:31,259
them separately these images are pretty

1970
01:33:28,439 --> 01:33:36,229
big like over a thousand by thousand in

1971
01:33:31,260 --> 01:33:42,360
size and just opening the JPEGs and

1972
01:33:36,229 --> 01:33:46,439
resizing them is slow so I processed

1973
01:33:42,359 --> 01:33:48,988
them all also OpenCV can't handle gif

1974
01:33:46,439 --> 01:33:50,879
files so I converted them yes Rachel the

1975
01:33:48,988 --> 01:33:53,039
question how would somebody get these

1976
01:33:50,880 --> 01:33:55,920
masks for training initially Mechanical

1977
01:33:53,039 --> 01:34:02,130
Turk or something yeah yeah just a lot

1978
01:33:55,920 --> 01:34:03,449
of boring work you know probably some

1979
01:34:02,130 --> 01:34:05,670
tools that help you with a bit of edge

1980
01:34:03,448 --> 01:34:07,469
snapping and stuff so that the human can

1981
01:34:05,670 --> 01:34:14,130
kind of do it roughly and then just find

1982
01:34:07,469 --> 01:34:16,679
you in the bits it gets wrong yeah these

1983
01:34:14,130 --> 01:34:18,150
kinds of labels are expensive you know

1984
01:34:16,679 --> 01:34:22,368
and so one of the things I really want

1985
01:34:18,149 --> 01:34:26,069
to work on is deep learning enhanced

1986
01:34:22,368 --> 01:34:31,920
interactive labeling tools because you

1987
01:34:26,069 --> 01:34:33,149
know yeah so I've got a little section

1988
01:34:31,920 --> 01:34:35,099
here that you can run if you want to you

1989
01:34:33,149 --> 01:34:38,670
probably want to which converts the

1990
01:34:35,099 --> 01:34:41,489
gifts into pngs so just open it up with

1991
01:34:38,670 --> 01:34:44,789
PIL and then save it as PNG because open

1992
01:34:41,488 --> 01:34:45,539
CV doesn't have give support and as per

1993
01:34:44,789 --> 01:34:47,310
usual for this

1994
01:34:45,539 --> 01:34:48,779
stuff I do it with a thread pool so I

1995
01:34:47,310 --> 01:34:51,780
can take advantage of parallel

1996
01:34:48,779 --> 01:34:54,659
processing and then also create a

1997
01:34:51,779 --> 01:34:57,269
separate directory train - 128 and train

1998
01:34:54,659 --> 01:35:00,720
masks 128 which contains the 128 by 128

1999
01:34:57,270 --> 01:35:03,570
resized versions of them and this is the

2000
01:35:00,720 --> 01:35:05,159
kind of stuff that keeps you sane if you

2001
01:35:03,569 --> 01:35:06,869
do it early in the process so anytime

2002
01:35:05,159 --> 01:35:10,019
you get a new data set you know

2003
01:35:06,869 --> 01:35:13,099
seriously think about creating a you

2004
01:35:10,020 --> 01:35:15,270
know smaller version to make life fast

2005
01:35:13,100 --> 01:35:17,100
anytime you find yourself waiting on

2006
01:35:15,270 --> 01:35:20,310
your computer you know try and think of

2007
01:35:17,100 --> 01:35:21,720
a way to create a smaller version so

2008
01:35:20,310 --> 01:35:23,640
yeah after you grab it from cowboy you

2009
01:35:21,720 --> 01:35:24,960
probably want to run this stuff by way

2010
01:35:23,640 --> 01:35:27,170
to have lunch come back and when you're

2011
01:35:24,960 --> 01:35:28,980
done you'll have these smaller

2012
01:35:27,170 --> 01:35:31,890
directories which we're going to use

2013
01:35:28,979 --> 01:35:37,259
here 128 by 128 pixel versions to start

2014
01:35:31,890 --> 01:35:40,950
with so here's a cool trick if you use

2015
01:35:37,260 --> 01:35:43,739
the same access object to plot an image

2016
01:35:40,949 --> 01:35:44,939
twice and the second time you use alpha

2017
01:35:43,739 --> 01:35:46,679
which as you might know means

2018
01:35:44,939 --> 01:35:49,739
transparency in the computer vision

2019
01:35:46,680 --> 01:35:52,860
world then you can actually plot the

2020
01:35:49,739 --> 01:35:54,329
mask over the top of the photo and so

2021
01:35:52,859 --> 01:35:57,000
there here's a nice way to see all the

2022
01:35:54,329 --> 01:36:00,000
masks on top of the photos for all of

2023
01:35:57,000 --> 01:36:01,619
the cars in one group this is the same

2024
01:36:00,000 --> 01:36:04,229
match files data set we've seen twice

2025
01:36:01,619 --> 01:36:06,659
already this is all the same code we

2026
01:36:04,229 --> 01:36:10,109
used - and here's something important

2027
01:36:06,659 --> 01:36:12,779
though if we had something that was in

2028
01:36:10,109 --> 01:36:15,929
the training set go to this image and

2029
01:36:12,779 --> 01:36:17,759
then the validation had that image that

2030
01:36:15,930 --> 01:36:23,070
would kind of be cheating because it's

2031
01:36:17,760 --> 01:36:27,119
the same Cup so we use a contiguous set

2032
01:36:23,069 --> 01:36:30,119
of car IDs and since each set is a set

2033
01:36:27,119 --> 01:36:32,970
of 16 we make sure that's evenly

2034
01:36:30,119 --> 01:36:35,430
divisible by 16 so we make sure that our

2035
01:36:32,970 --> 01:36:38,670
validation set contains different car

2036
01:36:35,430 --> 01:36:40,260
IDs to our training set this is the kind

2037
01:36:38,670 --> 01:36:42,899
of stuff but you've got to be careful of

2038
01:36:40,260 --> 01:36:44,220
on Kaggle it's not so bad you'll know

2039
01:36:42,899 --> 01:36:45,989
about it because you'll submit your

2040
01:36:44,220 --> 01:36:48,300
result and you'll get a very different

2041
01:36:45,989 --> 01:36:51,389
result on your leaderboard compared to

2042
01:36:48,300 --> 01:36:53,940
your validation set but in the real

2043
01:36:51,390 --> 01:36:56,400
world you won't know until you put it in

2044
01:36:53,939 --> 01:36:58,579
production and send your company

2045
01:36:56,399 --> 01:37:00,889
bankrupt and lose your job

2046
01:36:58,579 --> 01:37:03,819
so you might want to think carefully

2047
01:37:00,890 --> 01:37:05,900
about your validation set in that case

2048
01:37:03,819 --> 01:37:09,859
so here we're going to use transform

2049
01:37:05,899 --> 01:37:11,929
type classification it's basically the

2050
01:37:09,859 --> 01:37:13,849
same as transform type dot pixel but if

2051
01:37:11,930 --> 01:37:15,950
you think about it we with a pixel

2052
01:37:13,850 --> 01:37:17,450
version if we rotate a little bit then

2053
01:37:15,949 --> 01:37:19,340
we probably want to like average the

2054
01:37:17,449 --> 01:37:21,859
pixels in between the two but the

2055
01:37:19,340 --> 01:37:23,569
classification obviously we we don't we

2056
01:37:21,859 --> 01:37:26,210
use nearest neighbor so the slight

2057
01:37:23,569 --> 01:37:28,630
difference there also for classification

2058
01:37:26,210 --> 01:37:33,460
you know lighting doesn't kick in

2059
01:37:28,630 --> 01:37:33,460
normalization to the dependent variable

2060
01:37:34,239 --> 01:37:43,099
okay they're already square images so we

2061
01:37:37,460 --> 01:37:44,630
don't have to do any cropping so here

2062
01:37:43,100 --> 01:37:46,760
you can see different versions of the

2063
01:37:44,630 --> 01:37:50,409
Augmented you know move around a bit

2064
01:37:46,760 --> 01:37:50,409
when they're rotating a bit and so forth

2065
01:37:51,039 --> 01:37:55,640
yeah I get a lot of questions kind of

2066
01:37:53,420 --> 01:37:59,270
like during our study group and stuff

2067
01:37:55,640 --> 01:38:01,329
about like how do I debug things and fix

2068
01:37:59,270 --> 01:38:03,980
things that aren't working and like a I

2069
01:38:01,329 --> 01:38:06,439
never have a great answer other than

2070
01:38:03,979 --> 01:38:09,319
like every time I fix a problem is

2071
01:38:06,439 --> 01:38:12,109
because of stuff like this that I do all

2072
01:38:09,319 --> 01:38:16,009
the time you know I just always print

2073
01:38:12,109 --> 01:38:17,869
out everything as I go and then the one

2074
01:38:16,010 --> 01:38:19,220
thing that I screw up always turns out

2075
01:38:17,869 --> 01:38:22,159
to be the one thing that I forgot to

2076
01:38:19,220 --> 01:38:23,420
check along the way so yeah the more of

2077
01:38:22,159 --> 01:38:24,590
this kind of thing you can do the better

2078
01:38:23,420 --> 01:38:26,690
if you're not looking at all of your

2079
01:38:24,590 --> 01:38:31,970
intermediate results I mean I have

2080
01:38:26,689 --> 01:38:34,609
troubles okay so given that we want

2081
01:38:31,970 --> 01:38:36,470
something that knows what cars look like

2082
01:38:34,609 --> 01:38:40,219
we probably want to start with a pre

2083
01:38:36,470 --> 01:38:43,490
trained imagenet network so we're going

2084
01:38:40,220 --> 01:38:45,409
to start with ResNet 34 and so with

2085
01:38:43,489 --> 01:38:49,429
confident builder we can grab our resin

2086
01:38:45,409 --> 01:38:50,840
at 34 and we can add a custom head and

2087
01:38:49,430 --> 01:38:52,970
so the custom head is going to be

2088
01:38:50,840 --> 01:38:55,430
something that up samples a bunch of

2089
01:38:52,970 --> 01:38:57,199
plants and we're going to do things

2090
01:38:55,430 --> 01:39:00,140
really done for now which is we're just

2091
01:38:57,199 --> 01:39:03,559
going to do a commons pose to addy batch

2092
01:39:00,140 --> 01:39:06,680
norm value okay

2093
01:39:03,560 --> 01:39:08,539
and so here's like this is what I'm

2094
01:39:06,680 --> 01:39:10,760
saying you could any of you could have

2095
01:39:08,539 --> 01:39:11,960
built this without looking at any of

2096
01:39:10,760 --> 01:39:14,150
this

2097
01:39:11,960 --> 01:39:16,010
or at least like you have the

2098
01:39:14,149 --> 01:39:18,189
information from previous classes

2099
01:39:16,010 --> 01:39:23,420
there's nothing new at all

2100
01:39:18,189 --> 01:39:28,488
okay and so at the very end we have a

2101
01:39:23,420 --> 01:39:30,020
single filter okay and now that's going

2102
01:39:28,488 --> 01:39:35,238
to give us something which is batch size

2103
01:39:30,020 --> 01:39:37,550
by 1 by 128 by 128 but we want something

2104
01:39:35,238 --> 01:39:39,889
which is batch sized by 128 by 128 so we

2105
01:39:37,550 --> 01:39:42,920
have to remove that unit axis so I've

2106
01:39:39,890 --> 01:39:44,869
got a lambda layer here lambda layers

2107
01:39:42,920 --> 01:39:47,270
are incredibly helpful right because

2108
01:39:44,869 --> 01:39:50,569
without the lambda layer here which is

2109
01:39:47,270 --> 01:39:53,060
simply removing that unit axis by just

2110
01:39:50,569 --> 01:39:54,679
indexing into it at 0 without the lambda

2111
01:39:53,060 --> 01:39:57,440
layer I would have to have created a

2112
01:39:54,680 --> 01:40:00,650
custom class with a custom forward

2113
01:39:57,439 --> 01:40:02,029
method and so forth but by creating a

2114
01:40:00,649 --> 01:40:04,039
lambda layer that does like the one

2115
01:40:02,029 --> 01:40:05,929
custom bit I can notice chocolate from

2116
01:40:04,039 --> 01:40:09,500
the sequential and so that just makes

2117
01:40:05,930 --> 01:40:10,610
life easier so the PI torch people are

2118
01:40:09,500 --> 01:40:13,670
kind of snooty

2119
01:40:10,609 --> 01:40:14,779
about this approach lambda is actually

2120
01:40:13,670 --> 01:40:16,340
something that's part of the first day I

2121
01:40:14,779 --> 01:40:19,039
library not part of the pad torch

2122
01:40:16,340 --> 01:40:23,029
library and like literally people on the

2123
01:40:19,039 --> 01:40:25,219
pad watch discussion board like yes we

2124
01:40:23,029 --> 01:40:26,899
could give people this yes it is only a

2125
01:40:25,219 --> 01:40:29,060
single line of code but they never like

2126
01:40:26,899 --> 01:40:37,488
encourage them to use sequential too

2127
01:40:29,060 --> 01:40:39,260
often so there you go okay so so this is

2128
01:40:37,488 --> 01:40:41,539
that custom head right so we're gonna

2129
01:40:39,260 --> 01:40:43,010
have a rest at 34 that goes down sample

2130
01:40:41,539 --> 01:40:45,469
and then a really simple custom here

2131
01:40:43,010 --> 01:40:48,440
that very quickly up samples and that

2132
01:40:45,469 --> 01:40:50,000
hopefully will do something and we're

2133
01:40:48,439 --> 01:40:53,238
going to use accuracy with a threshold

2134
01:40:50,000 --> 01:40:55,010
of 0.5 to print out metrics and so after

2135
01:40:53,238 --> 01:40:56,238
a few a pops we've got 96 percent

2136
01:40:55,010 --> 01:41:00,020
accurate okay

2137
01:40:56,238 --> 01:41:02,659
so is that good is 96 percent accurate

2138
01:41:00,020 --> 01:41:05,560
good and hopefully the answer to your

2139
01:41:02,659 --> 01:41:08,840
question that question is it depends

2140
01:41:05,560 --> 01:41:11,180
what's it for right and the answer is

2141
01:41:08,840 --> 01:41:15,730
qivana wanted this because they wanted

2142
01:41:11,180 --> 01:41:19,039
to be able to take their car images and

2143
01:41:15,729 --> 01:41:21,709
cut them out and paste them on you know

2144
01:41:19,039 --> 01:41:24,319
exotic monte-carlo backgrounds or

2145
01:41:21,710 --> 01:41:30,079
whatever that's multicolor the place

2146
01:41:24,319 --> 01:41:32,719
the simulation so to do that you need a

2147
01:41:30,079 --> 01:41:34,970
really good mask but you don't want to

2148
01:41:32,720 --> 01:41:38,240
like leave the rearview mirrors behind

2149
01:41:34,970 --> 01:41:40,460
or like you know kind of have one wheel

2150
01:41:38,239 --> 01:41:42,229
missing or include a little bit of

2151
01:41:40,460 --> 01:41:44,659
background or something that would look

2152
01:41:42,229 --> 01:41:45,109
stupid so you would beat something very

2153
01:41:44,659 --> 01:41:47,479
good

2154
01:41:45,109 --> 01:41:50,779
so only having 96 percent of the pixels

2155
01:41:47,479 --> 01:41:53,059
correct doesn't sound great but we won't

2156
01:41:50,779 --> 01:41:56,090
really know until we look at it so let's

2157
01:41:53,060 --> 01:41:58,690
look at it so there's the correct

2158
01:41:56,090 --> 01:42:03,500
version that we want to cut out

2159
01:41:58,689 --> 01:42:05,899
that's the 96% expert version okay so

2160
01:42:03,500 --> 01:42:06,439
like where do you look at it you guys oh

2161
01:42:05,899 --> 01:42:09,109
yeah

2162
01:42:06,439 --> 01:42:11,029
getting 90% 96% of the pixels accurate

2163
01:42:09,109 --> 01:42:12,949
is actually easy because like all the

2164
01:42:11,029 --> 01:42:14,779
outside bits not care at all the inside

2165
01:42:12,949 --> 01:42:17,630
bit is car and really really interesting

2166
01:42:14,779 --> 01:42:19,179
bit is the edge okay so we need to do

2167
01:42:17,630 --> 01:42:22,340
better

2168
01:42:19,180 --> 01:42:23,990
so let's unfreeze because what we've

2169
01:42:22,340 --> 01:42:27,260
done so far is trained the customer here

2170
01:42:23,989 --> 01:42:30,289
okay let's do more and so after a bit

2171
01:42:27,260 --> 01:42:33,440
more we've got 99.1 percent okay so is

2172
01:42:30,289 --> 01:42:38,479
that good I don't know let's take a look

2173
01:42:33,439 --> 01:42:41,149
and so actually no it's totally missed

2174
01:42:38,479 --> 01:42:44,119
the rearview vision mirror here and

2175
01:42:41,149 --> 01:42:45,949
missed a lot of it here and it's clearly

2176
01:42:44,119 --> 01:42:48,349
got an edge wrong here and these things

2177
01:42:45,949 --> 01:42:49,819
are totally going to matter when we try

2178
01:42:48,350 --> 01:42:52,520
to cut it out so it's still not good

2179
01:42:49,819 --> 01:42:53,869
enough so let's try upscaling and the

2180
01:42:52,520 --> 01:42:56,120
nice thing is that when we upscale to

2181
01:42:53,869 --> 01:42:57,680
512 by 512 make sure you decrease the

2182
01:42:56,119 --> 01:43:01,569
batch size because you'll run out of

2183
01:42:57,680 --> 01:43:04,850
memory you know here's the true ones

2184
01:43:01,569 --> 01:43:06,619
it's quite a lot more this is all

2185
01:43:04,850 --> 01:43:08,090
identical it's quite a lot more

2186
01:43:06,619 --> 01:43:11,840
information Everett go on so our

2187
01:43:08,090 --> 01:43:14,119
accuracy increases to 99.4% and things

2188
01:43:11,840 --> 01:43:17,420
keep getting better but we've still got

2189
01:43:14,119 --> 01:43:19,699
quite a few little black blocky bits so

2190
01:43:17,420 --> 01:43:23,029
let's go to 124 by 124 down to batch

2191
01:43:19,699 --> 01:43:26,119
size of four this is pretty high res now

2192
01:43:23,029 --> 01:43:32,239
and train a bit more ninety nine point

2193
01:43:26,119 --> 01:43:35,479
six ninety-nine point eight and so now

2194
01:43:32,239 --> 01:43:37,819
if we look at the masks they're actually

2195
01:43:35,479 --> 01:43:40,579
looking not bad

2196
01:43:37,819 --> 01:43:44,869
okay that's looking pretty good right so

2197
01:43:40,579 --> 01:43:48,979
can we do better and the answer is yes

2198
01:43:44,869 --> 01:43:50,750
we can so we're moving from the carbonyl

2199
01:43:48,979 --> 01:43:53,779
nut book to the carbonyl unit notebook

2200
01:43:50,750 --> 01:43:57,109
now and the unit Network is quite

2201
01:43:53,779 --> 01:43:59,539
magnificent right you see with that

2202
01:43:57,109 --> 01:44:01,639
previous approach our pre-trained

2203
01:43:59,539 --> 01:44:03,739
imagenet network was being squished down

2204
01:44:01,640 --> 01:44:05,810
all the way down to seven by seven and

2205
01:44:03,739 --> 01:44:08,719
then expand it out all the way back up

2206
01:44:05,810 --> 01:44:10,400
to you know well it's two to four go to

2207
01:44:08,720 --> 01:44:11,900
seven by seven but one or two four is

2208
01:44:10,399 --> 01:44:15,199
going quite a bit bigger and then

2209
01:44:11,899 --> 01:44:17,210
expanded out again or this way which

2210
01:44:15,199 --> 01:44:19,010
means it has to somehow store all the

2211
01:44:17,210 --> 01:44:21,619
information about the much bigger

2212
01:44:19,010 --> 01:44:24,470
version in the small version right and

2213
01:44:21,619 --> 01:44:25,699
actually most of the information about

2214
01:44:24,470 --> 01:44:29,270
the bigger version was really in the

2215
01:44:25,699 --> 01:44:30,559
original picture anyway so it doesn't

2216
01:44:29,270 --> 01:44:35,090
seem like a great approach this

2217
01:44:30,560 --> 01:44:37,070
squishing and I'm squishing so the unit

2218
01:44:35,090 --> 01:44:39,560
idea comes from this fantastic paper

2219
01:44:37,069 --> 01:44:42,829
where like it was literally invented in

2220
01:44:39,560 --> 01:44:45,140
this you know very domain-specific area

2221
01:44:42,829 --> 01:44:48,529
of biomedical image segmentation but in

2222
01:44:45,140 --> 01:44:50,390
fact basically every cattle winner in in

2223
01:44:48,529 --> 01:44:53,719
anything even vaguely related to

2224
01:44:50,390 --> 01:44:55,100
segmentation has ended up using unit as

2225
01:44:53,720 --> 01:44:57,020
one of these things that like everybody

2226
01:44:55,100 --> 01:45:00,890
in Carroll knows is the best practice

2227
01:44:57,020 --> 01:45:02,660
but in more of an academic circles like

2228
01:45:00,890 --> 01:45:04,400
even now this has been around for a

2229
01:45:02,659 --> 01:45:06,979
couple of years at least a lot of people

2230
01:45:04,399 --> 01:45:11,479
still don't realize it's like this is by

2231
01:45:06,979 --> 01:45:13,459
far the best approach and here's the

2232
01:45:11,479 --> 01:45:20,509
basic idea here's the downward path

2233
01:45:13,460 --> 01:45:23,060
right where we basically start start at

2234
01:45:20,510 --> 01:45:24,890
five 72 by 5 3 2 in this case and then

2235
01:45:23,060 --> 01:45:26,690
kind of half the grid size half the grid

2236
01:45:24,890 --> 01:45:30,289
size half the grid size half the grid

2237
01:45:26,689 --> 01:45:31,549
size right and then here's the upward

2238
01:45:30,289 --> 01:45:36,500
path where we double the grid size

2239
01:45:31,550 --> 01:45:41,270
double double double double no but the

2240
01:45:36,500 --> 01:45:43,250
thing that we also do is we take you

2241
01:45:41,270 --> 01:45:45,860
know at every point where we've half the

2242
01:45:43,250 --> 01:45:48,590
grid size we actually copy those

2243
01:45:45,859 --> 01:45:50,420
activations over to the upward path and

2244
01:45:48,590 --> 01:45:55,219
and concatenate the

2245
01:45:50,420 --> 01:45:58,399
together and so you can see here these

2246
01:45:55,219 --> 01:46:02,210
red blobs of maps polling operations the

2247
01:45:58,399 --> 01:46:06,469
green blobs are upward sampling and then

2248
01:46:02,210 --> 01:46:08,750
these gray bits here are copying right

2249
01:46:06,469 --> 01:46:11,149
and so we copy and can cat so basically

2250
01:46:08,750 --> 01:46:14,270
in other words the input image after a

2251
01:46:11,149 --> 01:46:18,198
couple of poems is copied over to the

2252
01:46:14,270 --> 01:46:20,600
output concatenated together and so now

2253
01:46:18,198 --> 01:46:21,919
we get to use all of the informations

2254
01:46:20,600 --> 01:46:24,140
gone through all the down and all the

2255
01:46:21,920 --> 01:46:27,529
app plus also a slightly modified

2256
01:46:24,140 --> 01:46:29,300
version of the input pixels right and a

2257
01:46:27,529 --> 01:46:30,800
slightly modified version of one thing

2258
01:46:29,300 --> 01:46:32,659
down from the input pixels because they

2259
01:46:30,800 --> 01:46:36,350
came out through yes right so we have

2260
01:46:32,659 --> 01:46:38,448
like all of the richness of going all

2261
01:46:36,350 --> 01:46:40,760
the way down and up but also like a

2262
01:46:38,448 --> 01:46:42,439
slightly less coarse version and a

2263
01:46:40,760 --> 01:46:44,420
slightly less cost version and then this

2264
01:46:42,439 --> 01:46:47,448
really kind of simple version and they

2265
01:46:44,420 --> 01:46:51,590
can all be combined together okay and so

2266
01:46:47,448 --> 01:46:54,469
that's unit it's such a cool idea so

2267
01:46:51,590 --> 01:46:56,090
here we are in the in the carvanha unit

2268
01:46:54,469 --> 01:47:02,710
notebook all this is the same code as

2269
01:46:56,090 --> 01:47:05,600
before and at the start I've got a

2270
01:47:02,710 --> 01:47:07,789
simple up sample version just to kind of

2271
01:47:05,600 --> 01:47:09,890
show you again the the non unit version

2272
01:47:07,789 --> 01:47:13,100
this time I'm going to add in something

2273
01:47:09,890 --> 01:47:17,449
called the dice metric dice is very

2274
01:47:13,100 --> 01:47:19,400
similar as you see to jacquard or I over

2275
01:47:17,448 --> 01:47:25,149
you it's just a minor difference it's

2276
01:47:19,399 --> 01:47:27,979
basically intersection over Union with a

2277
01:47:25,149 --> 01:47:30,920
minor tweak and the reason we're going

2278
01:47:27,979 --> 01:47:33,319
to use dice is that's the metric that

2279
01:47:30,920 --> 01:47:36,109
the caracal competition used and it's

2280
01:47:33,319 --> 01:47:37,849
kind of it's a little bit harder to get

2281
01:47:36,109 --> 01:47:40,250
a high score than a high accuracy

2282
01:47:37,850 --> 01:47:42,230
because it's really looking at like what

2283
01:47:40,250 --> 01:47:45,109
the overlap of the correct pixels are

2284
01:47:42,229 --> 01:47:48,139
with with your pixels but it's pretty

2285
01:47:45,109 --> 01:47:50,960
similar so in the Carroll competition

2286
01:47:48,140 --> 01:47:52,730
people that we're doing okay we're

2287
01:47:50,960 --> 01:47:54,679
getting about ninety nine point six dice

2288
01:47:52,729 --> 01:47:58,579
and the winners for about nine nine

2289
01:47:54,679 --> 01:48:01,670
point seven days so here's our standard

2290
01:47:58,579 --> 01:48:03,828
up sample this is all as before and so

2291
01:48:01,670 --> 01:48:06,739
now we can check our dice metric

2292
01:48:03,828 --> 01:48:09,679
and so you can see on dice metric we're

2293
01:48:06,738 --> 01:48:13,549
getting like nine six eight at 128 by

2294
01:48:09,679 --> 01:48:18,408
128 and so that's not great

2295
01:48:13,550 --> 01:48:20,659
okay so so let's try unit and I'm

2296
01:48:18,408 --> 01:48:23,779
calling it unit ish because that's per

2297
01:48:20,658 --> 01:48:25,969
usual I'm creating my own someone hacky

2298
01:48:23,779 --> 01:48:27,378
version right kind of trying to keep

2299
01:48:25,969 --> 01:48:29,538
things as similar to what you're used to

2300
01:48:27,378 --> 01:48:32,448
as possible and doing things that I

2301
01:48:29,538 --> 01:48:34,998
think makes sense and so there should be

2302
01:48:32,448 --> 01:48:37,009
plenty of opportunity for you to at

2303
01:48:34,998 --> 01:48:39,858
least make this more authentically unit

2304
01:48:37,010 --> 01:48:42,439
by looking at the exact kind of grid

2305
01:48:39,859 --> 01:48:43,999
sizes and like see how here the size is

2306
01:48:42,439 --> 01:48:47,269
going down a little bit so they're

2307
01:48:43,998 --> 01:48:48,648
obviously not adding any padding and

2308
01:48:47,269 --> 01:48:50,748
then they're doing here they've got some

2309
01:48:48,649 --> 01:48:54,769
cropping going on there's a few

2310
01:48:50,748 --> 01:48:56,418
differences right but one of the things

2311
01:48:54,769 --> 01:48:59,030
is because I want to take advantage of

2312
01:48:56,418 --> 01:49:01,939
transfer learning that means I can't

2313
01:48:59,029 --> 01:49:06,168
quite use unit so here's another big

2314
01:49:01,939 --> 01:49:10,878
opportunity is what if you create the

2315
01:49:06,168 --> 01:49:13,038
unit down path and then add a classifier

2316
01:49:10,878 --> 01:49:16,698
on the end and then train that on

2317
01:49:13,038 --> 01:49:19,788
imagenet and you've now got an image net

2318
01:49:16,698 --> 01:49:21,908
trained classifier which is specifically

2319
01:49:19,788 --> 01:49:24,228
designed to be a good backbone for unit

2320
01:49:21,908 --> 01:49:27,888
right and then you should be able to now

2321
01:49:24,229 --> 01:49:30,829
come back and get pretty close to

2322
01:49:27,889 --> 01:49:32,088
winning this old competition is actually

2323
01:49:30,828 --> 01:49:34,698
not that old it's fairly recent

2324
01:49:32,088 --> 01:49:38,359
competition because you know that pre

2325
01:49:34,698 --> 01:49:40,398
train network didn't exist before but if

2326
01:49:38,359 --> 01:49:42,859
you think about like what Yolo v3 did

2327
01:49:40,399 --> 01:49:45,050
it's basically that right they create a

2328
01:49:42,859 --> 01:49:46,609
darknet they pre trained it on image net

2329
01:49:45,050 --> 01:49:51,498
and then they used it as the basis for

2330
01:49:46,609 --> 01:49:55,429
their bounding boxes so again this kind

2331
01:49:51,498 --> 01:49:58,639
of idea of free training things which

2332
01:49:55,429 --> 01:50:00,618
are designed not just for classification

2333
01:49:58,639 --> 01:50:02,599
but to find for other things is just

2334
01:50:00,618 --> 01:50:09,108
something that nobody's nobody's done

2335
01:50:02,599 --> 01:50:11,109
yet and let's weave but as we've

2336
01:50:09,109 --> 01:50:16,949
shown you know you can train image net

2337
01:50:11,109 --> 01:50:18,600
for 25 bucks in three hours now so

2338
01:50:16,948 --> 01:50:20,159
and if people in the community are

2339
01:50:18,600 --> 01:50:21,840
interested in doing this you know

2340
01:50:20,159 --> 01:50:24,059
hopefully I'll have credits I can help

2341
01:50:21,840 --> 01:50:25,409
you with as well so if you do you know

2342
01:50:24,060 --> 01:50:30,420
the work to get it set up and give me a

2343
01:50:25,409 --> 01:50:31,800
script I can probably run it for you so

2344
01:50:30,420 --> 01:50:38,369
for now though we don't have that so

2345
01:50:31,800 --> 01:50:40,890
we're going to use resonate so so we're

2346
01:50:38,369 --> 01:50:45,420
basically going to start with this let's

2347
01:50:40,890 --> 01:50:48,449
see with get base and so base is our

2348
01:50:45,420 --> 01:50:50,130
base network and that was defined back

2349
01:50:48,448 --> 01:50:53,428
up for this first section right so get

2350
01:50:50,130 --> 01:50:56,369
base is going to be something that calls

2351
01:50:53,429 --> 01:50:58,079
whatever this is and this is resna 34 so

2352
01:50:56,369 --> 01:51:00,329
we're going to grab our ResNet 34 and

2353
01:50:58,079 --> 01:51:02,189
cut model is the first thing that our

2354
01:51:00,329 --> 01:51:04,319
confident builder does it basically

2355
01:51:02,189 --> 01:51:06,839
removes everything from the adaptive

2356
01:51:04,319 --> 01:51:09,988
pulling onwards and so that gives us

2357
01:51:06,840 --> 01:51:17,850
back the backbone of resna 34 okay so

2358
01:51:09,988 --> 01:51:19,619
get base is going to give us okay and

2359
01:51:17,850 --> 01:51:22,500
then we're going to take that rest at 30

2360
01:51:19,619 --> 01:51:26,159
for backbone and turn it into a I call

2361
01:51:22,500 --> 01:51:30,840
it a unit 34 so what that's going to do

2362
01:51:26,159 --> 01:51:33,389
is it's going to save that ResNet that

2363
01:51:30,840 --> 01:51:35,880
we passed in and then we're going to use

2364
01:51:33,390 --> 01:51:38,219
a forward hook just like before to save

2365
01:51:35,880 --> 01:51:42,750
the results at the second fourth fifth

2366
01:51:38,219 --> 01:51:44,760
and sixth blocks which as before is the

2367
01:51:42,750 --> 01:51:48,270
basically before each straight to

2368
01:51:44,760 --> 01:51:49,739
convolution then we're going to create a

2369
01:51:48,270 --> 01:51:51,840
bunch of these things we're calling unit

2370
01:51:49,738 --> 01:51:54,899
blocks and the unit block basically says

2371
01:51:51,840 --> 01:51:59,369
so these unit blocks are these things

2372
01:51:54,899 --> 01:52:01,679
these are unit blocks so the the unit

2373
01:51:59,369 --> 01:52:04,079
block tells us you know we have to tell

2374
01:52:01,679 --> 01:52:06,899
it how many things are coming from the

2375
01:52:04,079 --> 01:52:08,609
from the kind of previous layer that

2376
01:52:06,899 --> 01:52:10,920
we're up sampling how many are coming

2377
01:52:08,609 --> 01:52:15,869
across and then how many do we want to

2378
01:52:10,920 --> 01:52:20,279
come out right and so the amount coming

2379
01:52:15,869 --> 01:52:22,079
across is entirely defined by whatever

2380
01:52:20,279 --> 01:52:25,189
the base network was right it's like

2381
01:52:22,079 --> 01:52:28,738
whatever whatever the downward path was

2382
01:52:25,189 --> 01:52:30,279
we need that many layers and so this is

2383
01:52:28,738 --> 01:52:33,309
a little bit awkward

2384
01:52:30,279 --> 01:52:34,809
actually one of our master students here

2385
01:52:33,310 --> 01:52:38,920
kerim has actually created something

2386
01:52:34,810 --> 01:52:42,160
called dynamic unit that you'll find in

2387
01:52:38,920 --> 01:52:44,079
fast AI unit dynamic unit and it

2388
01:52:42,159 --> 01:52:46,449
actually calculates this all for you

2389
01:52:44,079 --> 01:52:49,779
and automatically creates the whole unit

2390
01:52:46,449 --> 01:52:52,149
from your base model it's got some minor

2391
01:52:49,779 --> 01:52:54,279
quirks still that I want to fix by the

2392
01:52:52,149 --> 01:52:57,099
time the videos out it'll definitely be

2393
01:52:54,279 --> 01:52:58,750
working and I will at least have a

2394
01:52:57,100 --> 01:53:02,650
notebook showing how to use it and

2395
01:52:58,750 --> 01:53:04,449
possibly add additional video but for

2396
01:53:02,649 --> 01:53:05,679
now you know you'll just have to go

2397
01:53:04,449 --> 01:53:07,929
through and do it yourself you can

2398
01:53:05,680 --> 01:53:11,320
easily see it just by once you've got a

2399
01:53:07,930 --> 01:53:12,850
reson it you can just go you know just

2400
01:53:11,319 --> 01:53:15,279
type in its name and it'll print out all

2401
01:53:12,850 --> 01:53:19,140
the layers and you can see how big how

2402
01:53:15,279 --> 01:53:23,469
many activations there are in each block

2403
01:53:19,140 --> 01:53:24,670
or you can even have a printed out for

2404
01:53:23,470 --> 01:53:27,190
you for each for each block

2405
01:53:24,670 --> 01:53:28,500
automatically anyway I just did this

2406
01:53:27,189 --> 01:53:33,939
manually

2407
01:53:28,500 --> 01:53:36,250
and so the unit block is works like this

2408
01:53:33,939 --> 01:53:37,929
so you said okay right this penny coming

2409
01:53:36,250 --> 01:53:40,149
up from the previous layer I've got this

2410
01:53:37,930 --> 01:53:42,700
penny coming across this X I'm using

2411
01:53:40,149 --> 01:53:46,199
across across from the the downward path

2412
01:53:42,699 --> 01:53:48,909
this is the amount I want coming out now

2413
01:53:46,199 --> 01:53:50,079
what I do is they then say okay we're

2414
01:53:48,909 --> 01:53:52,180
going to create a certain amount of

2415
01:53:50,079 --> 01:53:53,890
convolutions from the upward path in a

2416
01:53:52,180 --> 01:53:55,960
certain amount from the cross path and

2417
01:53:53,890 --> 01:53:58,539
so I'm going to be concatenated them

2418
01:53:55,960 --> 01:54:01,779
together so let's divide the number we

2419
01:53:58,539 --> 01:54:04,420
want out by two right and so we're going

2420
01:54:01,779 --> 01:54:09,239
to have our cross convolution take our

2421
01:54:04,420 --> 01:54:12,399
cross path and create number out / - and

2422
01:54:09,239 --> 01:54:14,979
then the upward path is going to be a

2423
01:54:12,399 --> 01:54:18,039
common transpose to D right because we

2424
01:54:14,979 --> 01:54:20,949
want to increase up sample and again

2425
01:54:18,039 --> 01:54:23,079
here we've got the number n divided by

2426
01:54:20,949 --> 01:54:27,010
two and then at the end I just

2427
01:54:23,079 --> 01:54:29,019
concatenate those together alright so

2428
01:54:27,010 --> 01:54:31,449
I've got an upward sample I've got a

2429
01:54:29,020 --> 01:54:34,000
cross convolution I can catenate the two

2430
01:54:31,449 --> 01:54:38,349
together yeah and so that's all a unit

2431
01:54:34,000 --> 01:54:41,710
block is and so that's actually a pretty

2432
01:54:38,350 --> 01:54:44,110
easy module to create and so then in my

2433
01:54:41,710 --> 01:54:46,600
forward path I need

2434
01:54:44,109 --> 01:54:49,658
to pass to the forward of the of the

2435
01:54:46,600 --> 01:54:52,719
unit block the upward path and the cross

2436
01:54:49,658 --> 01:54:55,448
plus so the upward path is just wherever

2437
01:54:52,719 --> 01:54:58,840
I'm up to so far right but then the

2438
01:54:55,448 --> 01:55:00,969
cross path is whatever the value is of

2439
01:54:58,840 --> 01:55:04,900
whatever the activations are that I

2440
01:55:00,969 --> 01:55:07,210
stored on the way down right so as I

2441
01:55:04,899 --> 01:55:09,488
come up it's the last set of saved

2442
01:55:07,210 --> 01:55:10,989
features that I need first and in as I

2443
01:55:09,488 --> 01:55:13,359
gradually keep going up further and

2444
01:55:10,988 --> 01:55:18,819
further and further eventually it's the

2445
01:55:13,359 --> 01:55:20,019
first set of features okay and so there

2446
01:55:18,819 --> 01:55:21,279
are some more tricks we can do to make

2447
01:55:20,020 --> 01:55:25,300
this a little bit better but this is

2448
01:55:21,279 --> 01:55:28,090
this is a good stuff right so if we try

2449
01:55:25,300 --> 01:55:30,699
this so the simple up sampling approach

2450
01:55:28,090 --> 01:55:34,869
looked horrible right and had a dice of

2451
01:55:30,698 --> 01:55:36,638
nine six eight now you net with

2452
01:55:34,868 --> 01:55:39,219
everything else identical except we've

2453
01:55:36,639 --> 01:55:44,650
been out got these unit blocks has a

2454
01:55:39,219 --> 01:55:48,460
dice of nine eight five right sir that's

2455
01:55:44,649 --> 01:55:50,079
like we've kind of halved the error with

2456
01:55:48,460 --> 01:55:52,270
with everything else exactly the same

2457
01:55:50,079 --> 01:55:54,158
and more the point you can look at it

2458
01:55:52,270 --> 01:55:57,400
this is actually looking somewhat

2459
01:55:54,158 --> 01:55:59,710
car-like compared to our non unit

2460
01:55:57,399 --> 01:56:02,679
equivalent which is just a block now

2461
01:55:59,710 --> 01:56:05,439
because you know try to do this through

2462
01:56:02,679 --> 01:56:08,289
down and up paths just it's just asking

2463
01:56:05,439 --> 01:56:11,229
too much you know where else when we

2464
01:56:08,289 --> 01:56:14,260
actually provide the downward path

2465
01:56:11,229 --> 01:56:18,339
pixels at every point it can actually

2466
01:56:14,260 --> 01:56:20,079
start to create something karush so at

2467
01:56:18,340 --> 01:56:24,639
the end of that we'll go dot close to

2468
01:56:20,079 --> 01:56:28,300
again remove those s FS features taking

2469
01:56:24,639 --> 01:56:31,270
up GPU memory go to a smaller batch size

2470
01:56:28,300 --> 01:56:32,949
a higher size and you can see the dice

2471
01:56:31,270 --> 01:56:34,900
coefficients really going up this is

2472
01:56:32,948 --> 01:56:40,238
just so notice here I'm learning I'm

2473
01:56:34,899 --> 01:56:42,670
loading in right the 128 by 128 version

2474
01:56:40,238 --> 01:56:44,799
of the network okay so we're doing this

2475
01:56:42,670 --> 01:56:48,460
progressive resizing trick again so that

2476
01:56:44,800 --> 01:56:52,989
gets us 99 3 and then unfreeze to get to

2477
01:56:48,460 --> 01:56:55,840
99 4 and you can see it's now looking

2478
01:56:52,988 --> 01:56:57,329
pretty good okay go down to a batch size

2479
01:56:55,840 --> 01:57:01,770
of 4 so

2480
01:56:57,329 --> 01:57:08,930
102 for load-in what we just did with

2481
01:57:01,770 --> 01:57:14,000
the 512 Texas 299 5 unfreeze takes us to

2482
01:57:08,930 --> 01:57:19,490
99 we'll call that 99 six five nine nine

2483
01:57:14,000 --> 01:57:23,399
and as you can see that actually looks

2484
01:57:19,489 --> 01:57:26,699
good right in accuracy terms ninety-nine

2485
01:57:23,399 --> 01:57:29,309
point eight two you know you can see

2486
01:57:26,699 --> 01:57:32,130
this is looking like something you could

2487
01:57:29,310 --> 01:57:34,650
just about used to cut out I think too

2488
01:57:32,130 --> 01:57:37,020
you know at this point there's a couple

2489
01:57:34,649 --> 01:57:39,869
of minor tweaks we can do to get up to

2490
01:57:37,020 --> 01:57:41,580
ninety-nine point seven but really the

2491
01:57:39,869 --> 01:57:44,369
key thing then I think is just maybe to

2492
01:57:41,579 --> 01:57:47,119
do a you know a few bit of smoothing

2493
01:57:44,369 --> 01:57:49,409
maybe or a little bit of post-processing

2494
01:57:47,119 --> 01:57:53,729
you can go and have a look at the

2495
01:57:49,409 --> 01:57:56,099
carvanha winners blogs and see some of

2496
01:57:53,729 --> 01:57:57,449
these tricks but as I say the difference

2497
01:57:56,100 --> 01:58:00,350
between where we are at ninety nine

2498
01:57:57,449 --> 01:58:06,059
point six and what the winners got of

2499
01:58:00,350 --> 01:58:09,090
99.7 you know is it's not heaps and so

2500
01:58:06,060 --> 01:58:12,300
really that just the you net on its own

2501
01:58:09,090 --> 01:58:17,850
pretty much pretty much solves our

2502
01:58:12,300 --> 01:58:20,100
problem okay so that's it so the last

2503
01:58:17,850 --> 01:58:22,500
thing I wanted to mention is now to come

2504
01:58:20,100 --> 01:58:25,289
all the way back to bounding boxes

2505
01:58:22,500 --> 01:58:28,890
because you might remember I said out

2506
01:58:25,289 --> 01:58:33,449
our bounding box model was still not

2507
01:58:28,890 --> 01:58:34,590
doing very well on small objects so

2508
01:58:33,449 --> 01:58:36,449
hopefully you might be able to guess

2509
01:58:34,590 --> 01:58:41,850
where I'm going to go with this which is

2510
01:58:36,449 --> 01:58:45,899
that for the bounding box model remember

2511
01:58:41,850 --> 01:58:51,690
how we we had at different grid cells we

2512
01:58:45,899 --> 01:58:54,029
spat out outputs of their model and it

2513
01:58:51,689 --> 01:58:57,239
was those earlier ones with the small

2514
01:58:54,029 --> 01:59:01,199
grits sizes that weren't very good for

2515
01:58:57,239 --> 01:59:04,050
how do we fix it you net it right let's

2516
01:59:01,199 --> 01:59:06,989
have an upward path with cross

2517
01:59:04,050 --> 01:59:10,199
connections right and so then we're just

2518
01:59:06,989 --> 01:59:11,038
going to do a unit and then spit them

2519
01:59:10,199 --> 01:59:16,198
out of that the

2520
01:59:11,038 --> 01:59:18,000
now does those finer grid cells have all

2521
01:59:16,198 --> 01:59:20,609
of the information of that path and that

2522
01:59:18,000 --> 01:59:24,510
path and that path and that path for

2523
01:59:20,609 --> 01:59:27,029
leverage now of course this is deep

2524
01:59:24,510 --> 01:59:30,030
learning so that means you can't write a

2525
01:59:27,029 --> 01:59:32,550
paper saying we just used you net for

2526
01:59:30,029 --> 01:59:36,059
bounding boxes you have to invent a new

2527
01:59:32,550 --> 01:59:41,070
word so this is called feature pyramid

2528
01:59:36,059 --> 01:59:42,538
networks or fbms okay and like that

2529
01:59:41,069 --> 01:59:45,439
literally the paper this is part of the

2530
01:59:42,538 --> 01:59:47,939
retina net paper which is actually a

2531
01:59:45,439 --> 01:59:49,979
it's used in the retina net paper it was

2532
01:59:47,939 --> 01:59:53,518
you it was created an earlier paper

2533
01:59:49,979 --> 01:59:55,018
specifically of Olympians and like if

2534
01:59:53,519 --> 01:59:57,929
memory serves correctly they did briefly

2535
01:59:55,019 --> 02:00:00,960
cite the unit paper but they kind of

2536
01:59:57,929 --> 02:00:04,109
made it sound like it was this vaguely

2537
02:00:00,960 --> 02:00:06,359
slightly connected thing that maybe some

2538
02:00:04,109 --> 02:00:11,219
people could consider slightly useful

2539
02:00:06,359 --> 02:00:13,889
but it really F P ends as units okay I

2540
02:00:11,219 --> 02:00:16,859
don't have an implementation of it to

2541
02:00:13,889 --> 02:00:18,719
show you but you know it'll be a fun

2542
02:00:16,859 --> 02:00:20,908
thing maybe for some of us to try and

2543
02:00:18,719 --> 02:00:22,260
some of us have already some I haven't

2544
02:00:20,908 --> 02:00:25,529
yet but I know some of the students have

2545
02:00:22,260 --> 02:00:29,550
been trying so to get it working well on

2546
02:00:25,529 --> 02:00:31,078
the forums so yeah interesting thing to

2547
02:00:29,550 --> 02:00:34,619
try so I think a couple of couple of

2548
02:00:31,078 --> 02:00:35,880
things to look at after this class as

2549
02:00:34,618 --> 02:00:39,238
well as the other things I mentioned

2550
02:00:35,880 --> 02:00:42,618
would be playing around with FP ends and

2551
02:00:39,238 --> 02:00:44,848
also maybe trying caroms dynamic unit

2552
02:00:42,618 --> 02:00:48,839
they would both be interesting things to

2553
02:00:44,849 --> 02:00:51,389
look at all right so so you guys have

2554
02:00:48,840 --> 02:00:52,529
all been through fourteen lessons of me

2555
02:00:51,389 --> 02:00:55,440
talking at you now

2556
02:00:52,529 --> 02:01:00,210
so I'm sorry about that thanks for

2557
02:00:55,439 --> 02:01:02,609
putting up with me you know I think it's

2558
02:01:00,210 --> 02:01:06,569
it it's you're gonna find it hard to

2559
02:01:02,609 --> 02:01:09,268
find people who actually as know them as

2560
02:01:06,569 --> 02:01:12,149
much about training neural networks and

2561
02:01:09,269 --> 02:01:17,250
practice as you do it'll be really easy

2562
02:01:12,149 --> 02:01:18,960
for you to overestimate how capable all

2563
02:01:17,250 --> 02:01:21,029
these other people are an underestimate

2564
02:01:18,960 --> 02:01:24,180
how poor you are and so like the main

2565
02:01:21,029 --> 02:01:28,380
thing I'd say is like please practice

2566
02:01:24,180 --> 02:01:30,300
please just because you don't have this

2567
02:01:28,380 --> 02:01:33,119
constant thing getting you to come back

2568
02:01:30,300 --> 02:01:36,930
here every Monday night now it's very

2569
02:01:33,119 --> 02:01:40,829
easy to kind of lose that momentum so

2570
02:01:36,930 --> 02:01:43,619
find ways to keep it you know you know

2571
02:01:40,829 --> 02:01:46,829
organize a study group you know or a

2572
02:01:43,619 --> 02:01:48,840
book a reading group or get together

2573
02:01:46,829 --> 02:01:52,409
some friends and work on a project or

2574
02:01:48,840 --> 02:01:54,869
you know do something more than just

2575
02:01:52,409 --> 02:01:57,300
deciding I want to keep working on X

2576
02:01:54,869 --> 02:01:58,380
like it's gonna need to involve problem

2577
02:01:57,300 --> 02:01:59,970
unless you're the kind of person who's

2578
02:01:58,380 --> 02:02:01,980
super motivated and you know that

2579
02:01:59,970 --> 02:02:05,550
whenever you decide to do something it

2580
02:02:01,979 --> 02:02:07,559
happens that's not me right it's like I

2581
02:02:05,550 --> 02:02:10,650
know something to happen I have to like

2582
02:02:07,560 --> 02:02:13,710
say yes David in October I will

2583
02:02:10,649 --> 02:02:16,259
absolutely teach that course and then

2584
02:02:13,710 --> 02:02:18,510
it's like okay if it actually writes a

2585
02:02:16,260 --> 02:02:20,760
material let's see only way I can get

2586
02:02:18,510 --> 02:02:22,500
stuff to happen so we've got a great

2587
02:02:20,760 --> 02:02:23,970
community there on the forums if people

2588
02:02:22,500 --> 02:02:26,909
have ideas for ways to make it better

2589
02:02:23,970 --> 02:02:29,130
please tell me you know if you think you

2590
02:02:26,909 --> 02:02:30,899
can help with you know if you want to

2591
02:02:29,130 --> 02:02:33,930
create some new forum or moderated in

2592
02:02:30,899 --> 02:02:37,019
some different way or whatever it is let

2593
02:02:33,930 --> 02:02:38,400
me know right you can always PM me and

2594
02:02:37,020 --> 02:02:39,750
there's a lot of projects going on

2595
02:02:38,399 --> 02:02:42,539
through github as well

2596
02:02:39,750 --> 02:02:44,069
lots of stuff so yeah I hope to see you

2597
02:02:42,539 --> 02:02:45,390
all back here at something else and

2598
02:02:44,069 --> 02:02:47,529
thanks so much for joining me on this

2599
02:02:45,390 --> 02:02:51,170
journey

2600
02:02:47,529 --> 02:02:51,170
[Applause]

