<p><strong>Lesson 12</strong></p>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=5s">00:00:05</a> K-means clustering in TensorFlow</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=6m">00:06:00</a> ‘find_initial_centroids’, a simple heuristic</p>
</li>
<li><a href="https://youtu.be/jy1w0mPCHb0?t=12m30s">00:12:30</a> A trick to make TensorFlow feel more like Pytorch<br>
&amp; other tips around Broacasting, GPU tensors and co.</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=24m30s">00:24:30</a> Student’s question about “figuring out the number of clusters”</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=26m">00:26:00</a> “Step 1 was to copy our initial_centroids and copy them into our GPU”,<br>
"Step 2 is to assign every point and assign them to a cluster "</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=29m30s">00:29:30</a> ‘Dynamic_partition’, one of the crazy GPU functions in TensorFlow</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=37m45s">00:37:45</a> Digress: “Jeremy, if you were to start a company today, what would it be ?”</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=40m">00:40:00</a> Intro to next step: NLP and translation deep-dive, with CMU pronouncing dictionary<br>
via spelling_bee_RNN.ipynb</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=55m15s">00:55:15</a> Create spelling_bee_RNN model with Keras</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h17m30s">01:17:30</a> Question: "Why not treat text problems the same way we do with images’ ? "</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h26m">01:26:00</a> Graph for Attentional Model on Neural Translation</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h32m">01:32:00</a> Attention Models (cont.)</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h37m20s">01:37:20</a> Neural Machine Translation (research paper)</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h44m">01:44:00</a> Grammar as a Foreign Language (research paper)</p>
</li>



