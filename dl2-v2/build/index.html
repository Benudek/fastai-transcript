<p><strong>Lesson 8</strong></p>
<ul>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=0">00:00:00</a> Intro and review of Part 1</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=8m">00:08:00</a> Moving to Python 3</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=10m30s">00:10:30</a> Moving to Tensorflow and TF Dev Summit videos</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=22m10s">00:22:15</a> Moving to PyTorch</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=27m30s">00:27:30</a> From Part 1 “best practices” to Part 2 “new directions”</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=31m40s">00:31:40</a> Time to build your own box</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=36m20s">00:36:20</a> Time to start reading papers</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=39m30s">00:39:30</a> Time to start writing about your work in this course</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=41m30s">00:41:30</a> What we’ll study in Part 2</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=40m40s">00:40:40</a> Artistic style (or neural style) transfer</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=52m10s">00:52:10</a> Neural style notebook</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=54m15s">00:54:15</a> Mendeley Desktop, an app to track research papers</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=56m15s">00:56:15</a> <a href="http://arxiv-sanity.com/">arXiv-Sanity.com</a></p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=59m">00:59:00</a> Jeremy on <a href="http://twitter.com/">twitter.com</a> and <a href="http://reddit.com/r/MachineLearning/">reddit.com/r/MachineLearning/</a></p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h1m15s">01:01:15</a>  Neural style notebook (continued)</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h4m5s">01:04:05</a> Broadcasting, APL as “A Programming Language”, and Jsoftware</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h7m15s">01:07:15</a> Broadcasting with Keras</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h12m">01:12:00</a> Recreate input with a VGG model</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h22m45s">01:22:45</a> Optimize the loss function with a deterministic approach</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h33m25s">01:33:25</a> Visualize the iterations through a short video</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1hm7m30s">01:37:30</a> Recreate a style</p>
</li>
<li>
<p><a href="https://youtu.be/cRjPVN3oo4s?t=1h44m5s">01:44:05</a> Transfer a style</p>
</li>

<p><strong>Lesson 9</strong></p>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=30s">00:00:30</a>  Contribute to, and use Lesson 8 Wiki</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=2m">00:02:00</a> Experiments on Image/Neural Style Transfer</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=5m45s">00:05:45</a> Advanced tips from Keras on Neural Style Transfer</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=10m15s">00:10:15</a> More tips to read research papers &amp;<br>
“A Neural Algorithm of Artistic Style, Sep-2015”</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=23m">00:23:00</a> From Style Transfer to Generative Models</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=32m50s">00:32:50</a> “Perpetual Losses for Real-Time Style Transfer<br>
&amp; Super-Resolution, Mar-2016”</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=39m30s">00:39:30</a> Implementation notebook w/ re-use of ‘bcolz’ arrays from Part 1.</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=43m">00:43:00</a> Digress: how “practical” are the tools learnt in Part 2, vs. Part 1 ?</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=52m10s">00:52:10</a> Two approaches to up-sampling: Deconvolution &amp; Resizing</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h9m30s">01:09:30</a> TQDM library: add a progress meter to your loops</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h17m30s">01:17:30</a> Fast Style Transfer w/ “Supplementary Material, Mar-2016”</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h27m45s">01:27:45</a> Ugly artifacts like “checkerboard”: cause and fixes; Keras UpSampling2D</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h31m20s">01:31:20</a> ImageNet Processing in parallel</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h33m15s">01:33:15</a> DeVISE research paper</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h38m">01:38:00</a> Digress: Tips on path setup for SSD vs. HD</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h42m">01:42:00</a> <code>words, vectors = zip(*w2v_list)</code></p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h49m30s">01:49:30</a> Resize images</p>
</li>
<li>
<p><a href="https://youtu.be/I-P363wSv0Q?t=1h52m15s">01:52:15</a> Three ways to make an algorithm faster:<br>
memory locality,<br>
simd/vectorization,<br>
parallel processing</p>
</li>

<p><strong>Lesson 10</strong></p>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=16s">00:00:10</a> Picking an optimizer for Style Transfer (student post on Medium)<br>
Plus other student posts and tips on class project.</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=7m30s">00:07:30</a> Use Excel to understand Deep Learning concepts</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=9m20s">00:09:20</a> ImageNet Processing (continued from Lesson 9)<br>
&amp; Tips to speed up your model (simd &amp; parallel processing)</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=26m45s">00:26:45</a> Adding Preprocessing to Keras ResNet50</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=28m30s">00:28:30</a> Transfer Learning with ResNet in Keras: difficulty #1</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=33m40s">00:33:40</a> Transfer Learning with ResNet in Keras: difficulty #2</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=38m">00:38:00</a> Use batches to overcome RAM “Out of Memory”</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=42m">00:42:00</a> Final layers to our ResNet model</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=47m">00:47:00</a> Nearest Neighbors to look at examples</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=55m">00:55:00</a> Fine-Tuning our models and more “Out of Memory” fixes</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h3m">01:03:00</a> Find images similar to a word or phrase &amp;<br>
Find images similar to an image !</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h8m15s">01:08:15</a> Homework discussion</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h16m45s">01:16:45</a> How to: multi-input models on large datasets</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h23m15s">01:23:15</a> Generative Adversarial Networks (GAN) in Keras</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h32m">01:32:00</a> Multi-Layer-Perceptron (MLP)</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h37m10s">01:37:10</a> Deep Convolutional GAN (DCGAN)</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h40m15s">01:40:15</a> Wasserstein GAN in Pytorch</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h46m30s">01:46:30</a> Introduction to Pytorch</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=1h55m20s">01:55:20</a> Wasserstein GAN in Pytorch (cont.)<br>
&amp; LSUN dataset</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=2h5m">02:05:00</a> Examples of generated images</p>
</li>
<li>
<p><a href="https://youtu.be/uv0gmrXSXVg?t=2h9m15s">02:09:15</a> Lesson 10 conclusion and assignments for Lesson 11</p>
</li>

<p><strong>Lesson 11</strong></p>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=30s">00:00:30</a> Tips on using notebooks and reading research papers</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=3m15s">00:03:15</a> Follow-up on lesson 10 and more word-to-image searches</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=7m30s">00:07:30</a> Linear algebra cheat sheet for deep learning (student’s post on Medium)<br>
&amp; Zero-Shot Learning by Convex Combination of Semantinc Embeddings (arXiv)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=10m">00:10:00</a> Systematic evaluation of CNN advances on ImageNet (arXiv)<br>
ELU better than RELU, learning rate annealing, different color transformations,<br>
Max pooling vs Average pooling, learning rate &amp; batch size, design patterns.</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=27m15s">00:27:15</a> Data Science Bowl 2017 (Cancer Diagnosis) on Kaggle</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=36m30s">00:36:30</a> DSB 2017: full preprocessing tutorial, + others.</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=48m30s">00:48:30</a> A non-deep-learning approach to find lung nodules (research)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=53m">00:53:00</a> Clustering (and why Jeremy wasn’t a fan before)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h8m">01:08:00</a> Using Pytorch with GPU for ‘meanshift’ (clustering cont.)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h22m15s">01:22:15</a> Candidate Generation and LUNA 16 (Kaggle)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h26m30s">01:26:30</a> Accelerating K-Means on GPU via CUDA (research)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h27m15s">01:27:15</a> ChatBots ! (long section)<br>
Staring with “memory networks” at Facebook (research)</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h57m30s">01:57:30</a> Recurrent Entity Networks: an exciting area of research in Memory Networks</p>
</li>
<li>
<p><a href="https://youtu.be/bZmJvmxfH6I?t=1h58m45s">01:58:45</a> Concept of “Attention” and “Attentional Models”</p>
</li>

<p><strong>Lesson 12</strong></p>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=5s">00:00:05</a> K-means clustering in TensorFlow</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=6m">00:06:00</a> ‘find_initial_centroids’, a simple heuristic</p>
</li>
<li><a href="https://youtu.be/jy1w0mPCHb0?t=12m30s">00:12:30</a> A trick to make TensorFlow feel more like Pytorch<br>
&amp; other tips around Broacasting, GPU tensors and co.</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=24m30s">00:24:30</a> Student’s question about “figuring out the number of clusters”</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=26m">00:26:00</a> “Step 1 was to copy our initial_centroids and copy them into our GPU”,<br>
"Step 2 is to assign every point and assign them to a cluster "</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=29m30s">00:29:30</a> ‘Dynamic_partition’, one of the crazy GPU functions in TensorFlow</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=37m45s">00:37:45</a> Digress: “Jeremy, if you were to start a company today, what would it be ?”</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=40m">00:40:00</a> Intro to next step: NLP and translation deep-dive, with CMU pronouncing dictionary<br>
via spelling_bee_RNN.ipynb</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=55m15s">00:55:15</a> Create spelling_bee_RNN model with Keras</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h17m30s">01:17:30</a> Question: "Why not treat text problems the same way we do with images’ ? "</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h26m">01:26:00</a> Graph for Attentional Model on Neural Translation</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h32m">01:32:00</a> Attention Models (cont.)</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h37m20s">01:37:20</a> Neural Machine Translation (research paper)</p>
</li>
<li>
<p><a href="https://youtu.be/jy1w0mPCHb0?t=1h44m">01:44:00</a> Grammar as a Foreign Language (research paper)</p>
</li>

<p><strong>Lesson 13</strong></p>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=9s">00:00:10</a> <a href="http://fast.ai/">Fast.ai</a> student accepted into Google Brain Residency program</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=6m30s">00:06:30</a> Cyclical Learning Rates for Training Neural Networks (another student’s paper)<br>
&amp; updates on Style Transfer, GAN, and Mean Shift Clustering research papers</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=13m45s">00:13:45</a> Tiramisu: combining Mean Shitft Clustering and Approximate Nearest Neighbors</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=22m15s">00:22:15</a> Facebook AI Similarity Search (FAISS)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=28m15s">00:28:15</a> The BiLSTM Hegemony</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=35m">00:35:00</a> Implementing the BiLSTM, and Grammar as a Foreign Language (research)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=45m30s">00:45:30</a> Reminder on how RNN’s work from Lesson #5 (Part 1)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=47m20s">00:47:20</a> Why Attentional Models use “such” a simple architecture<br>
&amp; “Tacotron: a Fully End-To-End Text-To-Speech Synthesis Model” (research)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=50m15s">00:50:15</a> Continuing on Spelling_bee_RNN notebook (Attention Model), from Lesson 12</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=58m40s">00:58:40</a> Building the Attention Layer and the ‘attention_wrapper.py’ walk-through</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h15m40s">01:15:40</a> Impressive student’s experiment with different mathematical technique on Style Transfer</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h18m">01:18:00</a> Translate English into French, with Pytorch</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h31m20s">01:31:20</a> Translate English into French: using Keras to prepare the data<br>
Note: Pytorch latest version now supports Broadcasting</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h38m50s">01:38:50</a> Writing and running the ‘Train &amp; Test’ code with Pytorch</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h44m">01:44:00</a> NLP Programming Tutorial, by Graham Neubig (NAIST)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h48m25s">01:48:25</a> Question: “Could we translate Chinese to English with that technique ?”<br>
&amp; new technique: Neural Machine Translation of Rare Words with Subword Units (Research)</p>
</li>
<li>
<p><a href="https://youtu.be/-lx2shfA-5s?t=1h54m45s">01:54:45</a> Leaving Translation aside and moving to Image Segmentation,<br>
with the “The 100 layers Tiramisu: Fully Convolutional DenseNets” (research)<br>
and “Densely Connected Convolutional Networks” (research)</p>
</li>

<p><strong>Lesson 14</strong></p>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1m25s">00:01:25</a> Time-Series and Structured Data<br>
&amp; “Patient Mortality Risk Predictions in Pediatric Intensive Care, using RNN’s” (research)</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=7m30s">00:07:30</a> Time-Series with Rossmann Store Sales (Kaggle)<br>
&amp; 3rd place solution with “a very uncool NN ;-)”.</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=18m">00:18:00</a> Implementing the Rossman solution with Keras + TensorFlow + Pandas + Sklearn<br>
Building Tables &amp; Exploratory Data Analysis (EDA)</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=27m15s">00:27:15</a> Digress: categorical variable encodings and “Vtreat for R”</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=30m15s">00:30:15</a> Back to Rossmann solution<br>
&amp; “Python for Data Analysis” (book)</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=36m30s">00:36:30</a> What Jeremy does everytime he sees a ‘date’ in a structured ML model<br>
&amp; other tips</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=43m">00:43:00</a> Dealing with duration of special events (holidays, promotions) in Time-Series</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=52m">00:52:00</a> Using ‘inplace=True’ in .drop(), &amp; a look at our final ‘feature engineering’ results</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=53m40s">00:53:40</a> Starting to feed our NN<br>
&amp; using ‘pickle.dump()’ for storage encodings</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h45s">01:00:45</a> “Their big mistake” and how they could have won #1</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h5m30s">01:05:30</a> Splitting into Training and Test, but not randomly</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h8m20s">01:08:20</a> Why they modified their Sales Target with ‘np.log()/max_log_y’</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h11m20s">01:11:20</a> A look at our basic model</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h14m45s">01:14:45</a> Training our model and questions</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h16m45s">01:16:45</a> Running the same model with XGBoost</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h20m10s">01:20:10</a> “The really, really, really weird things here !”<br>
&amp; end of the Rossmann competition;-)</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h26m30s">01:26:30</a> Taxi Trajectory Prediction (Kaggle) with “another uncool NN” winner</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h38m">01:38:00</a> “Start with a Conv layer and pass it to an RNN” question and research</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h42m40s">01:42:40</a> The 100-layers Tiramisu: Fully Convolutional Densenets, for Image Segmentation (Lesson 13 cont.)</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=1h58m">01:58:00</a> Building and training the Tiramisu model</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=2h2m50s">02:02:50</a> ENet and LINKNet models: better than the Tiramisu ?</p>
</li>
<li>
<p><a href="https://youtu.be/1-NYPQw5THU?t=2h4m">02:04:00</a> Part 2: conclusion and next steps</p>
</li>
</ul>
