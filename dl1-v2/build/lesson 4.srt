1
00:00:00,060 --> 00:00:09,929
okay hi everybody welcome back let's see

2
00:00:02,759 --> 00:00:14,189
you all here it's been another busy week

3
00:00:09,929 --> 00:00:16,769
of deep learning lots of cool things

4
00:00:14,189 --> 00:00:18,239
going on and like last week I would have

5
00:00:16,769 --> 00:00:20,368
to highlight a few really interesting

6
00:00:18,239 --> 00:00:23,329
articles that some of some of you folks

7
00:00:20,368 --> 00:00:23,329
have have written

8
00:00:24,480 --> 00:00:31,980
vitaliy wrote one of the best articles

9
00:00:29,609 --> 00:00:34,620
I've seen for a while I think actually

10
00:00:31,980 --> 00:00:35,910
talking about differential learning

11
00:00:34,619 --> 00:00:39,959
rates and stochastic gradient descent

12
00:00:35,909 --> 00:00:41,640
with restarts be sure to check it out if

13
00:00:39,960 --> 00:00:45,410
you can because what he's done I feel

14
00:00:41,640 --> 00:00:47,489
like he's done a great job of kind of

15
00:00:45,409 --> 00:00:49,619
positioning it a place that you can get

16
00:00:47,488 --> 00:00:51,750
a lot out of it you know regardless of

17
00:00:49,619 --> 00:00:53,308
your background but for those who want

18
00:00:51,750 --> 00:00:55,079
to go further he's also got links to

19
00:00:53,308 --> 00:00:58,108
like the academic papers it came from

20
00:00:55,079 --> 00:00:59,780
and kind of rests of showing examples of

21
00:00:58,109 --> 00:01:02,809
all of all the things he's talking about

22
00:00:59,780 --> 00:01:06,359
and I think it's a it's a particularly

23
00:01:02,808 --> 00:01:09,959
nicely done article so good kind of role

24
00:01:06,359 --> 00:01:11,250
model for technical communication one of

25
00:01:09,959 --> 00:01:14,129
the things I've liked about you know

26
00:01:11,250 --> 00:01:15,688
seeing people post these post these

27
00:01:14,129 --> 00:01:17,548
articles during the week is the

28
00:01:15,688 --> 00:01:19,199
discussion on the forums have also been

29
00:01:17,549 --> 00:01:22,460
like really great there's been a lot of

30
00:01:19,200 --> 00:01:24,960
a lot of people helping out like

31
00:01:22,459 --> 00:01:26,219
explaining things you know which you

32
00:01:24,959 --> 00:01:27,509
know maybe those parts of the post

33
00:01:26,219 --> 00:01:29,219
period where people have said actually

34
00:01:27,509 --> 00:01:31,259
that's not quite how it works and people

35
00:01:29,219 --> 00:01:32,938
have learnt new things that way people

36
00:01:31,259 --> 00:01:37,920
have come up with new ideas as a result

37
00:01:32,938 --> 00:01:39,359
as well these discussions of stochastic

38
00:01:37,920 --> 00:01:40,710
gradient descent with restarts and

39
00:01:39,359 --> 00:01:42,750
cyclic or learning rates just being a

40
00:01:40,709 --> 00:01:45,618
few of them actually Anand

41
00:01:42,750 --> 00:01:49,590
sahar has written another great post

42
00:01:45,618 --> 00:01:51,780
talking about a similar similar topic

43
00:01:49,590 --> 00:01:54,649
and why it works so well and again lots

44
00:01:51,780 --> 00:01:57,960
of great pictures and references to

45
00:01:54,649 --> 00:02:01,670
papers and most importantly perhaps code

46
00:01:57,959 --> 00:02:01,669
showing how it actually works

47
00:02:01,950 --> 00:02:07,600
mark Hoffman covered the same topic at

48
00:02:05,379 --> 00:02:09,579
kind of a nice introductory level I

49
00:02:07,599 --> 00:02:13,870
think really really kind of clear

50
00:02:09,580 --> 00:02:16,450
intuition many Cantor talk specifically

51
00:02:13,870 --> 00:02:19,390
about differential learning rates and

52
00:02:16,449 --> 00:02:20,919
why it's interesting and again providing

53
00:02:19,389 --> 00:02:22,568
some nice context to people not familiar

54
00:02:20,919 --> 00:02:23,889
with transfer learning you're not going

55
00:02:22,568 --> 00:02:25,719
right back to saying like or what is

56
00:02:23,889 --> 00:02:28,689
transfer learning why is that

57
00:02:25,719 --> 00:02:31,019
interesting and given that why good

58
00:02:28,689 --> 00:02:34,719
differential learning rates be helpful

59
00:02:31,019 --> 00:02:35,700
and then one thing I particularly liked

60
00:02:34,719 --> 00:02:38,169
about arjen's

61
00:02:35,699 --> 00:02:39,729
article was that he talked not just

62
00:02:38,169 --> 00:02:42,000
about the technology that we're looking

63
00:02:39,729 --> 00:02:44,318
at but also talked about some of the

64
00:02:42,000 --> 00:02:46,750
implications particularly from a

65
00:02:44,318 --> 00:02:48,699
commercial point of view so thinking

66
00:02:46,750 --> 00:02:50,379
about like based on some of the things

67
00:02:48,699 --> 00:02:52,419
we've learned about so far what are some

68
00:02:50,379 --> 00:02:54,848
of the implications that that has you

69
00:02:52,419 --> 00:02:58,539
know in real life and lots of background

70
00:02:54,848 --> 00:02:59,828
lots of pictures and then discussing

71
00:02:58,539 --> 00:03:02,348
some of the yeah some of the

72
00:02:59,829 --> 00:03:04,090
implications so there's been lots of

73
00:03:02,348 --> 00:03:06,039
great stuff online and thanks to

74
00:03:04,090 --> 00:03:09,819
everybody for all the great work that

75
00:03:06,039 --> 00:03:12,219
you've been doing as we talked about

76
00:03:09,818 --> 00:03:13,958
last week if you're kind of vaguely

77
00:03:12,219 --> 00:03:15,250
wondering about writing something but

78
00:03:13,959 --> 00:03:16,719
you're feeling a bit intimidated about

79
00:03:15,250 --> 00:03:19,120
it because you've never really written a

80
00:03:16,719 --> 00:03:22,318
technical post before just jump in you

81
00:03:19,120 --> 00:03:25,030
know it's it's it's it's a really

82
00:03:22,318 --> 00:03:28,349
welcoming and encouraging group I think

83
00:03:25,030 --> 00:03:28,349
to to work with

84
00:03:30,689 --> 00:03:34,740
so we're going to have a kind of an

85
00:03:32,009 --> 00:03:39,120
interesting lesson today which is we're

86
00:03:34,740 --> 00:03:41,219
going to cover a whole lot of different

87
00:03:39,120 --> 00:03:42,810
applications so we've we've spent quite

88
00:03:41,219 --> 00:03:45,539
a lot of time on computer vision and

89
00:03:42,810 --> 00:03:47,819
today we're going to try if we can to

90
00:03:45,539 --> 00:03:51,090
get through three totally different

91
00:03:47,819 --> 00:03:54,629
areas structured learning so looking at

92
00:03:51,090 --> 00:03:55,950
kind of how you look at so we're going

93
00:03:54,629 --> 00:03:58,740
to start out looking at structured

94
00:03:55,949 --> 00:04:02,369
learning or structured data learning by

95
00:03:58,740 --> 00:04:05,219
which I mean building models on top of

96
00:04:02,370 --> 00:04:07,469
things look more like database tables so

97
00:04:05,219 --> 00:04:09,180
kind of columns of different types of

98
00:04:07,469 --> 00:04:12,030
data there might be financial or

99
00:04:09,180 --> 00:04:14,909
geographical or whatever we're going to

100
00:04:12,030 --> 00:04:17,730
look at using deep learning for language

101
00:04:14,909 --> 00:04:19,529
natural language processing and we're

102
00:04:17,730 --> 00:04:21,810
going to look at using deep learning for

103
00:04:19,529 --> 00:04:24,479
recommendation systems and so we're

104
00:04:21,810 --> 00:04:28,379
going to cover these at a very high

105
00:04:24,480 --> 00:04:31,080
level and the focus will be on

106
00:04:28,379 --> 00:04:33,509
here's how to use the software to do it

107
00:04:31,079 --> 00:04:35,669
more then here is what's going on behind

108
00:04:33,509 --> 00:04:38,430
the scenes and then the next three

109
00:04:35,670 --> 00:04:39,870
lessons we'll be digging into the

110
00:04:38,430 --> 00:04:42,150
details of what's been going on behind

111
00:04:39,870 --> 00:04:44,069
the scenes and also coming back to

112
00:04:42,149 --> 00:04:46,199
looking at a lot of the details of

113
00:04:44,069 --> 00:04:49,379
computer vision that we've kind of

114
00:04:46,199 --> 00:04:52,800
skipped over so far so the focus today

115
00:04:49,379 --> 00:04:54,899
is really on like how do you actually do

116
00:04:52,800 --> 00:04:56,939
these applications and we'll kind of

117
00:04:54,899 --> 00:05:01,199
talk briefly about some of the concepts

118
00:04:56,939 --> 00:05:07,019
involved before we do I did want to talk

119
00:05:01,199 --> 00:05:09,839
about one key new concept which is

120
00:05:07,019 --> 00:05:11,490
dropout and you might have seen dropout

121
00:05:09,839 --> 00:05:12,750
mentioned a bunch of times already and

122
00:05:11,490 --> 00:05:14,810
got there got the impression that this

123
00:05:12,750 --> 00:05:17,310
is something important and indeed it is

124
00:05:14,810 --> 00:05:22,530
so look at dropout I'm going to look at

125
00:05:17,310 --> 00:05:25,079
the dog breeds current cable competition

126
00:05:22,529 --> 00:05:28,469
that's going on and what I've done is

127
00:05:25,079 --> 00:05:31,319
I've gone ahead and I've created a pre

128
00:05:28,470 --> 00:05:33,750
train network as per usual and I've

129
00:05:31,319 --> 00:05:36,870
passed in pre compute equals true and so

130
00:05:33,750 --> 00:05:38,939
that's going to pre compute the

131
00:05:36,870 --> 00:05:40,769
activations that come out of the last

132
00:05:38,939 --> 00:05:42,240
convolutional layer remember an

133
00:05:40,769 --> 00:05:45,299
activation is just a number

134
00:05:42,240 --> 00:05:48,720
it's a number just to remind you an

135
00:05:45,300 --> 00:05:51,000
activation like here is one activation

136
00:05:48,720 --> 00:05:53,720
it's a number and specifically the

137
00:05:51,000 --> 00:05:57,959
activations are calculated based on some

138
00:05:53,720 --> 00:06:00,990
weights also called parameters that make

139
00:05:57,959 --> 00:06:02,519
up kernels or filters and they get

140
00:06:00,990 --> 00:06:05,160
applied to the previous layers

141
00:06:02,519 --> 00:06:07,799
activations but it could well be the

142
00:06:05,160 --> 00:06:09,540
inputs or they could themselves be the

143
00:06:07,800 --> 00:06:11,220
results of other calculations okay so

144
00:06:09,540 --> 00:06:12,960
when we say activation keep remembering

145
00:06:11,220 --> 00:06:14,210
we're talking about a number that's

146
00:06:12,959 --> 00:06:17,549
being calculated

147
00:06:14,209 --> 00:06:20,430
so we've pre compute some activations

148
00:06:17,550 --> 00:06:23,370
and then what we do is we put on top of

149
00:06:20,430 --> 00:06:26,009
that a bunch of additional initially

150
00:06:23,370 --> 00:06:27,480
randomly generated fully connected

151
00:06:26,009 --> 00:06:29,370
layers so we're just going to do some

152
00:06:27,480 --> 00:06:32,640
matrix multiplications on top of these

153
00:06:29,370 --> 00:06:35,149
just like in our Excel worksheet at the

154
00:06:32,639 --> 00:06:35,149
very end

155
00:06:35,329 --> 00:06:43,008
we had this matrix that we just did a

156
00:06:38,449 --> 00:06:46,370
matrix multiplication but so what you

157
00:06:43,009 --> 00:06:48,110
can actually do is if you just type the

158
00:06:46,370 --> 00:06:50,569
name of your loner object you can

159
00:06:48,110 --> 00:06:52,340
actually see what's in it you can see

160
00:06:50,569 --> 00:06:54,319
the layers in it so when I was

161
00:06:52,339 --> 00:06:56,179
previously been skipping over a little

162
00:06:54,319 --> 00:06:58,870
bit about are we add a few layers to the

163
00:06:56,180 --> 00:07:01,459
end these are actually the layers of yet

164
00:06:58,870 --> 00:07:02,899
we're going to do batch norm in the last

165
00:07:01,459 --> 00:07:06,228
lesson so don't worry about that for now

166
00:07:02,899 --> 00:07:08,508
a linear layer simply means a matrix

167
00:07:06,228 --> 00:07:13,459
multiply okay so this is a matrix which

168
00:07:08,509 --> 00:07:14,680
has a 1024 rows and 512 columns and so

169
00:07:13,459 --> 00:07:18,859
in other words it's going to take in

170
00:07:14,680 --> 00:07:22,430
1024 activations and spit out 512

171
00:07:18,860 --> 00:07:23,810
activations then we have a rail unit

172
00:07:22,430 --> 00:07:26,750
which remember is just replace the

173
00:07:23,810 --> 00:07:29,060
negatives with 0 we'll skip over the

174
00:07:26,750 --> 00:07:30,560
batch norm we'll come back drop out then

175
00:07:29,060 --> 00:07:33,050
we have a second linear layer that takes

176
00:07:30,560 --> 00:07:35,060
those 512 activations from the previous

177
00:07:33,050 --> 00:07:39,259
linear layer and puts them through a new

178
00:07:35,060 --> 00:07:42,228
matrix multiply 5 12 by 120 it spits out

179
00:07:39,259 --> 00:07:45,110
a new 120 activations and then finally

180
00:07:42,228 --> 00:07:47,508
put that through soft mats and for those

181
00:07:45,110 --> 00:07:50,210
of you that don't remember softmax we

182
00:07:47,509 --> 00:07:53,090
looked at that last year last week it's

183
00:07:50,209 --> 00:07:57,019
this idea that we basically just take

184
00:07:53,089 --> 00:07:59,568
the the activation let's say the dog go

185
00:07:57,019 --> 00:08:02,180
e to the power of that and then divide

186
00:07:59,569 --> 00:08:03,770
that into the sum of e to the power of

187
00:08:02,180 --> 00:08:05,509
all the intermissions so that was the

188
00:08:03,769 --> 00:08:07,278
thing that adds up to one all of them

189
00:08:05,509 --> 00:08:12,439
add up to one and each one individually

190
00:08:07,278 --> 00:08:14,300
is between 0 and 1 ok so that's that's

191
00:08:12,439 --> 00:08:15,740
what we added on top and that's the

192
00:08:14,300 --> 00:08:17,658
thing when we have pre computed calls

193
00:08:15,740 --> 00:08:19,460
true that's the thing we trained so I

194
00:08:17,658 --> 00:08:21,620
wanted to talk about what this dropout

195
00:08:19,459 --> 00:08:24,138
is and what this key is because it's a

196
00:08:21,620 --> 00:08:27,288
really important thing that we get to

197
00:08:24,139 --> 00:08:30,408
choose so a dropout layer with P equals

198
00:08:27,288 --> 00:08:32,718
0.5 literally does this we go over to

199
00:08:30,408 --> 00:08:34,788
our spreadsheet and let's pick any layer

200
00:08:32,719 --> 00:08:37,459
with some activations and let's say ok

201
00:08:34,788 --> 00:08:41,360
I'm going to apply dropout with a P of

202
00:08:37,458 --> 00:08:46,069
0.5 to con true what that means is I go

203
00:08:41,360 --> 00:08:48,560
through and with a 50% chance I pick a

204
00:08:46,070 --> 00:08:48,860
cell right pick an activation so I kept

205
00:08:48,559 --> 00:08:53,229
like

206
00:08:48,860 --> 00:08:57,409
half of them randomly and I delete them

207
00:08:53,230 --> 00:09:01,129
okay that's that's what dropout is right

208
00:08:57,409 --> 00:09:03,969
so it's so the P equals 0.5 means what's

209
00:09:01,129 --> 00:09:08,350
the probability of deleting that cell

210
00:09:03,970 --> 00:09:11,209
all right so when I delete those cells

211
00:09:08,350 --> 00:09:13,370
if you have a log like look at the

212
00:09:11,208 --> 00:09:15,109
output it doesn't actually change by

213
00:09:13,370 --> 00:09:16,578
very much at all just a little bit

214
00:09:15,110 --> 00:09:17,810
particularly because remember it's

215
00:09:16,578 --> 00:09:19,338
getting through a Mac spalling layer

216
00:09:17,809 --> 00:09:22,009
right so it's only going to change it at

217
00:09:19,339 --> 00:09:25,100
all if it was actually the maximum in

218
00:09:22,009 --> 00:09:27,528
that group of four and furthermore it's

219
00:09:25,100 --> 00:09:29,450
just one piece of you know if it's going

220
00:09:27,528 --> 00:09:32,059
into a convolution rather than into a

221
00:09:29,450 --> 00:09:37,390
max Paul is just one piece of that that

222
00:09:32,059 --> 00:09:39,739
filter so interestingly the idea of like

223
00:09:37,389 --> 00:09:43,490
randomly throwing away half of the

224
00:09:39,740 --> 00:09:46,639
activations in a layer has a really

225
00:09:43,490 --> 00:09:49,909
interesting result and one important

226
00:09:46,639 --> 00:09:53,059
thing to mention is each mini batch we

227
00:09:49,909 --> 00:09:55,610
throw away a different random half of

228
00:09:53,059 --> 00:10:00,500
activations earlier and so what it means

229
00:09:55,610 --> 00:10:02,060
is it forces it to not over fit right in

230
00:10:00,500 --> 00:10:04,759
other words if there's some particular

231
00:10:02,059 --> 00:10:08,899
activation that's really learnt just

232
00:10:04,759 --> 00:10:11,899
that exact that exact dog or that exact

233
00:10:08,899 --> 00:10:14,570
cat right then when that gets dropped

234
00:10:11,899 --> 00:10:15,799
out the whole thing now isn't going to

235
00:10:14,570 --> 00:10:18,560
work as well it's not going to recognize

236
00:10:15,799 --> 00:10:21,109
that image right so it has to in order

237
00:10:18,559 --> 00:10:25,278
for this to work it has to try and find

238
00:10:21,110 --> 00:10:28,850
a representation that that actually

239
00:10:25,278 --> 00:10:31,189
continues to work even as random half of

240
00:10:28,850 --> 00:10:34,220
the activations get thrown away every

241
00:10:31,190 --> 00:10:36,769
time all right so it's a it's it's I

242
00:10:34,220 --> 00:10:41,720
guess about four years old now three or

243
00:10:36,769 --> 00:10:44,778
four years old and it's been absolutely

244
00:10:41,720 --> 00:10:47,750
critical in making modern deep learning

245
00:10:44,778 --> 00:10:50,870
work and the reason why is it really

246
00:10:47,750 --> 00:10:52,970
just about solve the problem of

247
00:10:50,870 --> 00:10:56,480
generalization for us before drop out

248
00:10:52,970 --> 00:10:59,569
came along if you try to train a model

249
00:10:56,480 --> 00:11:02,360
with lots of parameters and you were

250
00:10:59,568 --> 00:11:02,659
overfitting and you already tried all

251
00:11:02,360 --> 00:11:05,209
the

252
00:11:02,659 --> 00:11:08,149
imitation you could and you already had

253
00:11:05,208 --> 00:11:09,649
as much data as you could you there were

254
00:11:08,149 --> 00:11:12,078
some other things you could try but to a

255
00:11:09,649 --> 00:11:16,278
large degree you were kind of stuck okay

256
00:11:12,078 --> 00:11:17,870
and so then Geoffrey Hinton and his

257
00:11:16,278 --> 00:11:20,000
colleagues came up with this this

258
00:11:17,870 --> 00:11:23,810
dropout idea that was loosely inspired

259
00:11:20,000 --> 00:11:25,669
by the way the brain works and also

260
00:11:23,809 --> 00:11:27,409
loosely inspired by Geoffrey Hinton's

261
00:11:25,669 --> 00:11:31,549
experience in bank teller Hugh's

262
00:11:27,409 --> 00:11:32,990
apparently and yeah somehow they came up

263
00:11:31,549 --> 00:11:35,870
with this amazing idea of like hey let's

264
00:11:32,990 --> 00:11:40,669
let's try throwing things away at random

265
00:11:35,870 --> 00:11:43,578
and so as you could imagine if your P

266
00:11:40,669 --> 00:11:46,399
was like point O one then you're

267
00:11:43,578 --> 00:11:48,888
throwing away 1% of your activations for

268
00:11:46,399 --> 00:11:51,409
that layer at random it's not gonna

269
00:11:48,889 --> 00:11:54,318
randomly change things up very much at

270
00:11:51,409 --> 00:11:58,100
all so it's not really going to protect

271
00:11:54,318 --> 00:12:00,860
you from overfitting much at all on the

272
00:11:58,100 --> 00:12:02,810
other hand if your pain was 0.99 then

273
00:12:00,860 --> 00:12:04,759
that would be like going through the

274
00:12:02,809 --> 00:12:08,568
whole thing and throwing away nearly

275
00:12:04,759 --> 00:12:12,050
everything right and that would be very

276
00:12:08,568 --> 00:12:13,849
hard for it to overfit so that would be

277
00:12:12,049 --> 00:12:17,870
great for generalization but it's also

278
00:12:13,850 --> 00:12:21,860
going to kill your accuracy so this is

279
00:12:17,870 --> 00:12:24,289
kind of play off between high p-values

280
00:12:21,860 --> 00:12:27,169
generalized well but will decrease your

281
00:12:24,289 --> 00:12:29,269
training accuracy and low p-values will

282
00:12:27,169 --> 00:12:32,509
generalize less well that will give you

283
00:12:29,269 --> 00:12:33,799
a less good training accuracy so for

284
00:12:32,509 --> 00:12:36,139
those of you that have been wondering

285
00:12:33,799 --> 00:12:39,049
why is it that particularly early in

286
00:12:36,139 --> 00:12:41,750
training my validation losses better

287
00:12:39,049 --> 00:12:44,059
than my training losses but which seems

288
00:12:41,750 --> 00:12:45,528
otherwise really surprising hopefully

289
00:12:44,059 --> 00:12:48,979
some of you have been wondering why that

290
00:12:45,528 --> 00:12:50,929
is because on a data set that it never

291
00:12:48,980 --> 00:12:53,149
gets to see you wouldn't expect the

292
00:12:50,929 --> 00:12:55,578
losses to ever be that's better

293
00:12:53,149 --> 00:12:57,769
and the reason why is because when we

294
00:12:55,578 --> 00:12:59,870
look at the validation set we turn off

295
00:12:57,769 --> 00:13:01,068
dropout right so in other words when

296
00:12:59,870 --> 00:13:02,899
you're doing inference when you're

297
00:13:01,068 --> 00:13:05,179
trying to say is this or cat or is this

298
00:13:02,899 --> 00:13:07,879
a dog we certainly don't want to be

299
00:13:05,179 --> 00:13:10,419
including random drop out there right we

300
00:13:07,879 --> 00:13:13,278
want to be using the best model we can

301
00:13:10,419 --> 00:13:15,370
okay so that's why early in training in

302
00:13:13,278 --> 00:13:17,429
particular

303
00:13:15,370 --> 00:13:21,129
actually see that our validation

304
00:13:17,429 --> 00:13:26,519
accuracy and loss tends to be better if

305
00:13:21,129 --> 00:13:28,899
we're using dropout okay so yes you know

306
00:13:26,519 --> 00:13:30,460
you have to do anything to accommodate

307
00:13:28,899 --> 00:13:35,889
for the fact that you are throwing away

308
00:13:30,460 --> 00:13:38,860
some that's a great question so we don't

309
00:13:35,889 --> 00:13:41,110
that PI torch does so PI torch behind

310
00:13:38,860 --> 00:13:43,990
the scenes does two things if you say P

311
00:13:41,110 --> 00:13:49,600
equals point five it throws away half of

312
00:13:43,990 --> 00:13:51,310
the activations but it also doubles all

313
00:13:49,600 --> 00:13:53,649
the activations that are already there

314
00:13:51,309 --> 00:13:56,169
so when average the kind of the average

315
00:13:53,649 --> 00:14:00,220
activation doesn't change which is

316
00:13:56,169 --> 00:14:01,569
pretty pretty neat trick so yeah you

317
00:14:00,220 --> 00:14:06,519
don't have to worry about it basically

318
00:14:01,570 --> 00:14:09,910
it's it's done for you so if we say so

319
00:14:06,519 --> 00:14:12,730
you can pass in peas this is the this is

320
00:14:09,909 --> 00:14:16,689
the p value for all of the added layers

321
00:14:12,730 --> 00:14:18,370
to say with first AI what dropout do you

322
00:14:16,690 --> 00:14:20,890
want on each of the layers in these

323
00:14:18,370 --> 00:14:23,980
these added layers it won't change the

324
00:14:20,889 --> 00:14:25,500
dropout in the pre trained network like

325
00:14:23,980 --> 00:14:27,670
the hope is that that's already been

326
00:14:25,500 --> 00:14:29,740
pretty trained with some appropriate

327
00:14:27,669 --> 00:14:31,750
level of dropout we don't change it put

328
00:14:29,740 --> 00:14:33,220
on these layers that we add you can say

329
00:14:31,750 --> 00:14:36,909
how much and so you can see here as a

330
00:14:33,220 --> 00:14:40,839
T's equals 0.5 so my first dropout has

331
00:14:36,909 --> 00:14:44,439
0.5 my second dropout has 0.5 I remember

332
00:14:40,839 --> 00:14:46,390
coming to the input of this was the

333
00:14:44,440 --> 00:14:48,820
output of the last convolutional layer

334
00:14:46,389 --> 00:14:50,439
of pre-trained network and we go over it

335
00:14:48,820 --> 00:14:52,870
and we actually throw away half of that

336
00:14:50,440 --> 00:14:55,770
before you can start go through our

337
00:14:52,870 --> 00:14:58,839
linear layer throw away the negatives

338
00:14:55,769 --> 00:15:00,789
throw away half the result of that go

339
00:14:58,839 --> 00:15:05,230
through another linear layer and then

340
00:15:00,789 --> 00:15:08,169
pass it to our softness for minor

341
00:15:05,230 --> 00:15:09,550
numerical precision region reasons it

342
00:15:08,169 --> 00:15:12,519
turns out to be better to take the log

343
00:15:09,549 --> 00:15:14,319
of the softmax then softmax directly and

344
00:15:12,519 --> 00:15:16,240
that's why you'll have noticed that when

345
00:15:14,320 --> 00:15:19,480
you actually get predictions out of our

346
00:15:16,240 --> 00:15:22,480
models you always have to go npx both

347
00:15:19,480 --> 00:15:25,409
the predictions but again the details as

348
00:15:22,480 --> 00:15:28,639
to why aren't important so if we want to

349
00:15:25,409 --> 00:15:31,429
try removing dropout we could go peas

350
00:15:28,639 --> 00:15:32,929
equals zero all right and you'll see

351
00:15:31,429 --> 00:15:34,789
where else before we started with the

352
00:15:32,929 --> 00:15:36,379
point seven six accuracy in the first

353
00:15:34,789 --> 00:15:38,629
epoch now you could have point eight

354
00:15:36,379 --> 00:15:41,000
accuracy in the first debug alright so

355
00:15:38,629 --> 00:15:43,070
by not doing drop out our first teapot

356
00:15:41,000 --> 00:15:45,649
worked better not surprisingly because

357
00:15:43,070 --> 00:15:47,450
we're not throwing anything away but by

358
00:15:45,649 --> 00:15:50,179
the third epoch here we had eighty four

359
00:15:47,450 --> 00:15:52,160
point eight and here we have eighty four

360
00:15:50,179 --> 00:15:54,620
point one so it started out better and

361
00:15:52,159 --> 00:15:56,419
ended up worse so even after three

362
00:15:54,620 --> 00:15:58,339
epochs you can already see where master

363
00:15:56,419 --> 00:16:01,789
for overfitting right we've got point

364
00:15:58,339 --> 00:16:06,740
three loss on the train and point five

365
00:16:01,789 --> 00:16:09,259
loss on the validation yep and so if you

366
00:16:06,740 --> 00:16:12,139
look now you can see in the resulting

367
00:16:09,259 --> 00:16:14,509
model there's no drop out at all so if

368
00:16:12,139 --> 00:16:19,909
the P is zero we don't even add it to

369
00:16:14,509 --> 00:16:21,319
the model another thing to mention is

370
00:16:19,909 --> 00:16:23,708
you might have noticed that what we've

371
00:16:21,320 --> 00:16:27,680
been doing is we've been adding two

372
00:16:23,708 --> 00:16:29,449
linear layers right in our additional

373
00:16:27,679 --> 00:16:31,419
layers you don't have to do that by the

374
00:16:29,450 --> 00:16:34,910
way there's actually a parameter called

375
00:16:31,419 --> 00:16:38,149
extra fully connected layers that you

376
00:16:34,909 --> 00:16:40,039
can basically pass a list of how long do

377
00:16:38,149 --> 00:16:41,720
you want or how big do you want each of

378
00:16:40,039 --> 00:16:44,929
the additional fully connected layers to

379
00:16:41,720 --> 00:16:47,509
be and so by default well you need to

380
00:16:44,929 --> 00:16:49,159
have at least one right because you need

381
00:16:47,509 --> 00:16:51,169
something that takes the output of the

382
00:16:49,159 --> 00:16:52,939
convolutional layer which in this case

383
00:16:51,169 --> 00:16:56,659
is of size thousand twenty-four and

384
00:16:52,940 --> 00:16:59,570
turns it into the number of classes you

385
00:16:56,659 --> 00:17:02,719
have cats versus dogs would be two dog

386
00:16:59,570 --> 00:17:04,818
breeds would be 120 planet satellite

387
00:17:02,720 --> 00:17:07,429
seventeen whatever that's you always

388
00:17:04,818 --> 00:17:08,899
need one linear layer at least and you

389
00:17:07,429 --> 00:17:12,019
can't pick how big that is that's

390
00:17:08,900 --> 00:17:14,630
defined by your problem but you can

391
00:17:12,019 --> 00:17:16,970
choose what the other size is or if it

392
00:17:14,630 --> 00:17:19,699
happens at all so if we were to pass in

393
00:17:16,970 --> 00:17:21,529
an empty list and now we're saying don't

394
00:17:19,699 --> 00:17:24,169
add any additional mini layers just the

395
00:17:21,529 --> 00:17:25,879
one that we have to have right so here

396
00:17:24,169 --> 00:17:28,069
we've got P is equals zero

397
00:17:25,880 --> 00:17:32,780
extra fully connected layers is empty

398
00:17:28,068 --> 00:17:36,799
this is like the minimum possible kind

399
00:17:32,779 --> 00:17:39,819
of top model we can put on top and again

400
00:17:36,799 --> 00:17:39,819
like if we do that

401
00:17:40,849 --> 00:17:45,859
you can see above we actually end up

402
00:17:43,069 --> 00:17:47,839
with in this case a reasonably good

403
00:17:45,859 --> 00:17:49,308
result because we're not training it for

404
00:17:47,839 --> 00:17:51,379
very long and this particular

405
00:17:49,308 --> 00:17:53,058
pre-trained Network is really well

406
00:17:51,380 --> 00:17:57,830
suited to this particular problem

407
00:17:53,058 --> 00:18:01,639
yesterday so Jeremy what kind of piece

408
00:17:57,829 --> 00:18:05,359
should we were using by default so the

409
00:18:01,640 --> 00:18:09,500
one that's there by default for the

410
00:18:05,359 --> 00:18:13,129
first layer is 0.25 and for the second

411
00:18:09,500 --> 00:18:17,210
layer is 0.5 that seems to work pretty

412
00:18:13,130 --> 00:18:19,190
well for most things right so like it's

413
00:18:17,210 --> 00:18:20,710
it's it you don't necessarily need to

414
00:18:19,190 --> 00:18:22,960
change it at all

415
00:18:20,710 --> 00:18:26,179
basically if you find it's overfitting

416
00:18:22,960 --> 00:18:28,909
just start bumping it up so try first of

417
00:18:26,179 --> 00:18:31,250
all setting it to 0.5 that'll set them

418
00:18:28,909 --> 00:18:33,980
both to 0.5 if it still overfitting a

419
00:18:31,250 --> 00:18:38,079
lot try 0.7 like you can you can narrow

420
00:18:33,980 --> 00:18:41,529
down and like it's not that many numbers

421
00:18:38,079 --> 00:18:44,889
change right and if you're under fitting

422
00:18:41,529 --> 00:18:47,269
then you can try and making it lower

423
00:18:44,890 --> 00:18:49,850
it's unlikely you would need to make it

424
00:18:47,269 --> 00:18:54,048
much lower because like even in these

425
00:18:49,849 --> 00:18:55,339
dogs versus cats situations you know we

426
00:18:54,048 --> 00:18:57,048
don't see they have to make it lower so

427
00:18:55,339 --> 00:19:00,889
it's more likely to be increasing at

428
00:18:57,048 --> 00:19:03,619
about 0.6 0.7 but you can fiddle around

429
00:19:00,890 --> 00:19:05,509
I find these the ones that are there by

430
00:19:03,619 --> 00:19:08,658
defaults in work pretty well most of the

431
00:19:05,509 --> 00:19:12,230
time so one place I actually did

432
00:19:08,659 --> 00:19:15,289
increase this was in the dog breeds one

433
00:19:12,230 --> 00:19:19,548
I did set it them both to 0.5 when I

434
00:19:15,288 --> 00:19:22,158
used a bigger model so like ResNet 34

435
00:19:19,548 --> 00:19:23,929
has less parameters so it doesn't over

436
00:19:22,159 --> 00:19:25,970
fit as much but then when I started

437
00:19:23,929 --> 00:19:28,309
bumping pumping it up to like a resonate

438
00:19:25,970 --> 00:19:30,259
50 which has a lot more parameters and

439
00:19:28,308 --> 00:19:32,658
noticed it started overfitting so then I

440
00:19:30,259 --> 00:19:35,808
also increased my drop out so as you use

441
00:19:32,659 --> 00:19:38,570
like bigger models you'll often need to

442
00:19:35,808 --> 00:19:41,349
add more drama can you pass it over

443
00:19:38,569 --> 00:19:41,349
there please you know

444
00:19:42,000 --> 00:19:49,169
if we set B to 0.5 roughly what

445
00:19:46,058 --> 00:19:52,979
percentage is it 50%

446
00:19:49,169 --> 00:19:55,599
we say RP pasta

447
00:19:52,979 --> 00:19:57,940
is there a particular way in which you

448
00:19:55,598 --> 00:20:04,148
can determine if the data is being all

449
00:19:57,940 --> 00:20:06,308
fitted yeah you can see that the like

450
00:20:04,148 --> 00:20:08,978
here you can see that the training error

451
00:20:06,308 --> 00:20:11,888
is a loss is much lower than the

452
00:20:08,979 --> 00:20:16,298
validation list you can't tell if it's

453
00:20:11,888 --> 00:20:18,368
like to over fitted like zero

454
00:20:16,298 --> 00:20:19,898
overfitting is not generally optimal

455
00:20:18,368 --> 00:20:21,548
like the only way to find that out is

456
00:20:19,898 --> 00:20:23,228
remember the only thing you're trying to

457
00:20:21,548 --> 00:20:26,378
do is to get this number low right the

458
00:20:23,229 --> 00:20:28,058
validation loss number low so in the end

459
00:20:26,378 --> 00:20:29,678
you kind of have to play around with a

460
00:20:28,058 --> 00:20:32,108
few different things and see which thing

461
00:20:29,679 --> 00:20:35,200
ends up getting the validation loss low

462
00:20:32,108 --> 00:20:37,418
but you kind of get a feel overtime for

463
00:20:35,200 --> 00:20:38,919
your particular problem what does

464
00:20:37,419 --> 00:20:45,820
overfitting what does too much River

465
00:20:38,919 --> 00:20:47,619
fitting look like great so so that's

466
00:20:45,819 --> 00:20:49,658
dropout and we're going to be using that

467
00:20:47,618 --> 00:20:51,098
a lot and remember it's there by default

468
00:20:49,659 --> 00:20:56,830
service here another question

469
00:20:51,098 --> 00:21:01,388
oh so I have two questions so one is so

470
00:20:56,829 --> 00:21:04,298
when it says the dropout rate is 0.5 it

471
00:21:01,388 --> 00:21:07,808
does it like you know I delete each cell

472
00:21:04,298 --> 00:21:10,388
with a probability of 0.5 or does it

473
00:21:07,808 --> 00:21:12,638
just pick 50% randomly I mean I know

474
00:21:10,388 --> 00:21:16,148
both effectively is the 4-month yeah

475
00:21:12,638 --> 00:21:19,959
okay okay a second question is why does

476
00:21:16,148 --> 00:21:22,778
the average activation matter well it

477
00:21:19,960 --> 00:21:27,269
matters because the remember if you look

478
00:21:22,778 --> 00:21:36,368
the Excel spreadsheet that the result of

479
00:21:27,269 --> 00:21:40,138
this cell for example is equal to these

480
00:21:36,368 --> 00:21:42,999
nine multiplied by each of these nine

481
00:21:40,138 --> 00:21:45,998
right and add it up so if we deleted

482
00:21:42,999 --> 00:21:48,190
half of these then that would also cause

483
00:21:45,999 --> 00:21:50,319
this number to half which would cause

484
00:21:48,190 --> 00:21:53,409
like everything else after that to

485
00:21:50,319 --> 00:21:55,028
change and so if you change what it

486
00:21:53,409 --> 00:21:56,470
means you know like you then you're

487
00:21:55,028 --> 00:21:59,138
changing something that used to say like

488
00:21:56,470 --> 00:22:01,028
Oh fluffy ears are fluffy if this is

489
00:21:59,138 --> 00:22:02,469
greater than point six now it's only

490
00:22:01,028 --> 00:22:03,638
fluffy if it's greater than point three

491
00:22:02,470 --> 00:22:05,569
like we're changing the meaning of

492
00:22:03,638 --> 00:22:07,939
everything so you

493
00:22:05,569 --> 00:22:14,179
here is to delete things without

494
00:22:07,940 --> 00:22:16,789
changing where are you using a linear

495
00:22:14,180 --> 00:22:19,400
activation for one of the earlier

496
00:22:16,789 --> 00:22:21,470
activations why are we using when you

497
00:22:19,400 --> 00:22:23,720
yeah why that particular activation

498
00:22:21,470 --> 00:22:26,390
because that's what this set of layers

499
00:22:23,720 --> 00:22:28,789
is so we've with the the pre-trained

500
00:22:26,390 --> 00:22:31,100
network is or is the convolutional net

501
00:22:28,789 --> 00:22:35,000
work and that's pre computed so we don't

502
00:22:31,099 --> 00:22:37,429
see it so what that spits out is it's a

503
00:22:35,000 --> 00:22:42,259
vector so the only choice we have is to

504
00:22:37,430 --> 00:22:44,779
use linear layers at this point okay can

505
00:22:42,259 --> 00:22:47,690
we have different level of dropout by

506
00:22:44,779 --> 00:22:51,109
layer yes absolutely how to do that

507
00:22:47,690 --> 00:22:53,210
great so so you can absolutely have

508
00:22:51,109 --> 00:22:56,029
different dropout by layer and that's

509
00:22:53,210 --> 00:22:58,069
why this is actually called peas so you

510
00:22:56,029 --> 00:23:03,410
could pass in an array here so if I went

511
00:22:58,069 --> 00:23:05,200
0 comma 0.2 for example and then extra

512
00:23:03,410 --> 00:23:08,000
fully connecting it I might add 512

513
00:23:05,200 --> 00:23:10,759
right then that's going to be 0 drop out

514
00:23:08,000 --> 00:23:13,490
before the first of them and point to

515
00:23:10,759 --> 00:23:16,640
drop out before the second of them yes

516
00:23:13,490 --> 00:23:19,279
requests and I must admit I don't have a

517
00:23:16,640 --> 00:23:22,910
great intuition even after doing this

518
00:23:19,279 --> 00:23:25,849
for a few years for like when should

519
00:23:22,910 --> 00:23:28,100
earlier or later layers have different

520
00:23:25,849 --> 00:23:30,259
amounts of dropping out it's still

521
00:23:28,099 --> 00:23:32,719
something I kind of play with and I

522
00:23:30,259 --> 00:23:34,160
can't quite find rules of thumb so if

523
00:23:32,720 --> 00:23:36,650
some of you come up with some good rules

524
00:23:34,160 --> 00:23:40,580
of thumb I'd love to hear about them I

525
00:23:36,650 --> 00:23:42,490
think if in doubt you can use the same

526
00:23:40,579 --> 00:23:45,230
drop out and every fully connected layer

527
00:23:42,490 --> 00:23:47,000
the other thing you can try is often

528
00:23:45,230 --> 00:23:49,819
people only put drop out on the very

529
00:23:47,000 --> 00:23:52,450
last linear layer so there'd be the two

530
00:23:49,819 --> 00:23:52,450
things to try

531
00:23:53,670 --> 00:24:00,460
so Jeremy why do you monitor the log

532
00:23:57,190 --> 00:24:03,549
loss the loss instead of the accuracy

533
00:24:00,460 --> 00:24:08,769
going up well because the loss is the

534
00:24:03,549 --> 00:24:10,839
only thing that we can see for both the

535
00:24:08,769 --> 00:24:13,920
validation set in the training set so

536
00:24:10,839 --> 00:24:18,039
it's nice to be able to compare them

537
00:24:13,920 --> 00:24:21,779
also as we learn about later the loss is

538
00:24:18,039 --> 00:24:25,269
the thing that we're actually optimizing

539
00:24:21,779 --> 00:24:27,579
so it's it's kind of a little more it's

540
00:24:25,269 --> 00:24:29,639
a little easier to monitor that and

541
00:24:27,579 --> 00:24:35,139
understand what that means

542
00:24:29,640 --> 00:24:37,180
can you pass it over there so with the

543
00:24:35,140 --> 00:24:39,190
drop out we're kind of adding some

544
00:24:37,180 --> 00:24:42,430
random noise every iteration right you

545
00:24:39,190 --> 00:24:49,360
know so that means that we don't do as

546
00:24:42,430 --> 00:24:51,210
much learning yeah that's right so it

547
00:24:49,359 --> 00:24:54,609
doesn't seem to impact the learning rate

548
00:24:51,210 --> 00:24:56,319
enough thrive ever noticed it I I would

549
00:24:54,609 --> 00:24:58,629
say you're probably right in theory it

550
00:24:56,319 --> 00:25:06,609
might but not enough that it's ever

551
00:24:58,630 --> 00:25:10,450
affected me okay so let's talk about

552
00:25:06,609 --> 00:25:13,599
this structured data problem and so to

553
00:25:10,450 --> 00:25:17,009
remind you we were looking at kegels

554
00:25:13,599 --> 00:25:21,609
rossmann competition which is a German

555
00:25:17,009 --> 00:25:23,730
chain of supermarkets I believe and you

556
00:25:21,609 --> 00:25:30,609
can find this in lesson three Russman

557
00:25:23,730 --> 00:25:32,500
and the main data set is the one where

558
00:25:30,609 --> 00:25:36,879
we were looking to say at a particular

559
00:25:32,500 --> 00:25:38,619
store how much did they sell okay and

560
00:25:36,880 --> 00:25:40,260
there's a few big key piece of

561
00:25:38,619 --> 00:25:42,389
information one is what was the date

562
00:25:40,259 --> 00:25:46,180
another was were they open

563
00:25:42,390 --> 00:25:48,700
did they have a promotion on was it a

564
00:25:46,180 --> 00:25:50,950
holiday in that state and was it a

565
00:25:48,700 --> 00:25:53,890
holiday as for school a state holiday

566
00:25:50,950 --> 00:25:54,940
there wasn't a school holiday yeah and

567
00:25:53,890 --> 00:25:57,520
then we had some more information about

568
00:25:54,940 --> 00:25:59,289
stores like what for this store what

569
00:25:57,519 --> 00:26:01,480
kind of stuff did they tend to sell what

570
00:25:59,289 --> 00:26:04,750
kind of store are they how far away the

571
00:26:01,480 --> 00:26:05,110
competition and so forth so with the

572
00:26:04,750 --> 00:26:07,240
data

573
00:26:05,109 --> 00:26:09,279
set like this there's really two main

574
00:26:07,240 --> 00:26:11,589
kinds of column there's columns that we

575
00:26:09,279 --> 00:26:12,849
think of as categorical they have a

576
00:26:11,589 --> 00:26:16,240
number of levels

577
00:26:12,849 --> 00:26:20,669
so the assortment column is categorical

578
00:26:16,240 --> 00:26:23,289
and it has levels such as a B and C

579
00:26:20,670 --> 00:26:26,080
where else something like competition

580
00:26:23,289 --> 00:26:27,909
distance we will call continuous it has

581
00:26:26,079 --> 00:26:29,949
a number attached to it where

582
00:26:27,910 --> 00:26:32,380
differences or ratios even if that

583
00:26:29,950 --> 00:26:34,120
number have some kind of meaning and so

584
00:26:32,380 --> 00:26:37,720
we need to deal with these two things

585
00:26:34,119 --> 00:26:40,779
quite differently okay so anybody who's

586
00:26:37,720 --> 00:26:42,850
done any machine learning of any kind

587
00:26:40,779 --> 00:26:44,200
will be familiar with using continuous

588
00:26:42,849 --> 00:26:46,539
columns if you've done any linear

589
00:26:44,200 --> 00:26:49,230
regression for example you can just like

590
00:26:46,539 --> 00:26:51,190
modify them by parameters for instance

591
00:26:49,230 --> 00:26:54,849
categorical columns we're going to have

592
00:26:51,190 --> 00:26:55,990
to think about a little bit more we're

593
00:26:54,849 --> 00:26:57,279
not going to go through the data

594
00:26:55,990 --> 00:26:59,109
cleaning we're going to assume that

595
00:26:57,279 --> 00:27:03,190
that's a feature Engineering we're going

596
00:26:59,109 --> 00:27:06,039
to assume all that's been done and so

597
00:27:03,190 --> 00:27:10,798
basically at the end of that we have a

598
00:27:06,039 --> 00:27:14,289
list of columns and the in this case I

599
00:27:10,798 --> 00:27:16,690
didn't do any of the thinking around the

600
00:27:14,289 --> 00:27:18,548
feature engineering or dedicating myself

601
00:27:16,690 --> 00:27:21,600
this is all directly from the

602
00:27:18,548 --> 00:27:24,700
third-place winners of this competition

603
00:27:21,599 --> 00:27:28,168
and so they came up with all of these

604
00:27:24,700 --> 00:27:33,490
different columns that they found useful

605
00:27:28,169 --> 00:27:35,049
and so you'll notice the list here is a

606
00:27:33,490 --> 00:27:39,849
list of the things that we're going to

607
00:27:35,048 --> 00:27:44,859
treat as categorical variables numbers

608
00:27:39,849 --> 00:27:46,659
like year a month and day although we

609
00:27:44,859 --> 00:27:48,039
could treat them as continuous like they

610
00:27:46,660 --> 00:27:52,179
the different you know differences

611
00:27:48,039 --> 00:27:54,279
between 2000 and 2003 is meaningful we

612
00:27:52,179 --> 00:28:00,370
don't have to right and you'll see

613
00:27:54,279 --> 00:28:02,589
shortly how how categorical variables

614
00:28:00,369 --> 00:28:04,109
are treated but basically if we decide

615
00:28:02,589 --> 00:28:06,879
to make something a categorical variable

616
00:28:04,109 --> 00:28:08,979
what we're telling our neural net down

617
00:28:06,880 --> 00:28:12,250
the track is that for every different

618
00:28:08,980 --> 00:28:14,799
level of say year you know 2000 2001

619
00:28:12,250 --> 00:28:16,990
2002 you can treat it totally

620
00:28:14,799 --> 00:28:18,418
differently where else if we say it's

621
00:28:16,990 --> 00:28:20,069
continuous its

622
00:28:18,419 --> 00:28:22,220
have to come up with some kind of like

623
00:28:20,069 --> 00:28:26,249
function some kind of smooth ish

624
00:28:22,220 --> 00:28:28,470
function right and so often even for

625
00:28:26,249 --> 00:28:30,629
things like a year that actually are

626
00:28:28,470 --> 00:28:33,329
continuous but they don't actually have

627
00:28:30,628 --> 00:28:36,898
many distinct levels it often works

628
00:28:33,329 --> 00:28:39,599
better to treat it as categorical so

629
00:28:36,898 --> 00:28:42,918
another good example day of week right

630
00:28:39,599 --> 00:28:45,118
so like day of week between naught &amp; 6

631
00:28:42,919 --> 00:28:48,239
it's a number and it means something

632
00:28:45,118 --> 00:28:50,038
motifs between 3 &amp; 5 is two days and has

633
00:28:48,239 --> 00:28:54,119
meaning but if you think about like how

634
00:28:50,038 --> 00:28:56,608
word sales in a strawberry buy a day of

635
00:28:54,118 --> 00:28:58,499
week it could well be that like you know

636
00:28:56,608 --> 00:29:00,480
Saturdays and Sundays are over here and

637
00:28:58,499 --> 00:29:02,759
Fridays are over here and Wednesdays are

638
00:29:00,480 --> 00:29:05,700
over here like each day is going to

639
00:29:02,759 --> 00:29:07,470
behave kind of qualitatively differently

640
00:29:05,700 --> 00:29:10,288
right so by saying this is the

641
00:29:07,470 --> 00:29:13,048
categorical variable as you'll see we're

642
00:29:10,288 --> 00:29:15,628
going to let the neural-net do that

643
00:29:13,048 --> 00:29:18,089
right so this thing where we get where

644
00:29:15,628 --> 00:29:20,548
we say which are continuous in which a

645
00:29:18,089 --> 00:29:24,689
categorical to some extent this is the

646
00:29:20,548 --> 00:29:28,349
modeling decision you get to make now if

647
00:29:24,690 --> 00:29:31,679
something is coded in your data is like

648
00:29:28,349 --> 00:29:34,230
a B and C or you know Jeremy and you

649
00:29:31,679 --> 00:29:35,999
knit or whatever you actually you're

650
00:29:34,230 --> 00:29:37,618
going to have to call that categorical

651
00:29:35,999 --> 00:29:40,649
right there's no way to treat that

652
00:29:37,618 --> 00:29:42,569
directly as a continuous variable on the

653
00:29:40,648 --> 00:29:45,209
other hand if it starts out as a

654
00:29:42,569 --> 00:29:49,200
continuous variable like age or day of

655
00:29:45,210 --> 00:29:50,730
week you get to decide whether you want

656
00:29:49,200 --> 00:29:53,730
to treat it as continuous or categorical

657
00:29:50,730 --> 00:29:55,230
okay so summarize if it's categorical

658
00:29:53,730 --> 00:29:57,179
and data it's going to have to be

659
00:29:55,230 --> 00:29:59,608
categorical in the model if it's

660
00:29:57,179 --> 00:30:01,320
continuous in the data you get to pick

661
00:29:59,608 --> 00:30:05,428
whether to make it continuous or

662
00:30:01,319 --> 00:30:07,349
categorical in the model so in this case

663
00:30:05,429 --> 00:30:08,909
again what I just did whatever the

664
00:30:07,349 --> 00:30:11,158
third-place winners of this competition

665
00:30:08,909 --> 00:30:12,778
did these are the ones that they decided

666
00:30:11,159 --> 00:30:14,278
to use as categorical these were the

667
00:30:12,778 --> 00:30:18,509
ones they decided to use as continuous

668
00:30:14,278 --> 00:30:20,940
and you can see that basically the

669
00:30:18,509 --> 00:30:23,730
continuous ones are all of the ones

670
00:30:20,940 --> 00:30:26,009
which are actual floating-point numbers

671
00:30:23,730 --> 00:30:27,720
like competition distance actually has a

672
00:30:26,009 --> 00:30:29,759
decimal place to it right and

673
00:30:27,720 --> 00:30:31,470
temperature actually has a decimal place

674
00:30:29,759 --> 00:30:32,069
to it so these would be very hard to

675
00:30:31,470 --> 00:30:34,299
make

676
00:30:32,069 --> 00:30:37,869
categorical because they have many many

677
00:30:34,299 --> 00:30:39,579
levels right like if it's like five

678
00:30:37,869 --> 00:30:41,169
digits of floating-point then

679
00:30:39,579 --> 00:30:46,299
potentially there will be as many levels

680
00:30:41,170 --> 00:30:48,250
as there are as there are roads and by

681
00:30:46,299 --> 00:30:50,259
the way the word we use to say how many

682
00:30:48,250 --> 00:30:52,240
levels are in a category we use the word

683
00:30:50,259 --> 00:30:54,519
cardinality right so if you see me say

684
00:30:52,240 --> 00:30:57,160
cardinality example the cardinality of

685
00:30:54,519 --> 00:31:00,389
the day of week variable is 7 because

686
00:30:57,160 --> 00:31:00,390
there are 7 different days of the week

687
00:31:02,009 --> 00:31:06,099
do you have a heuristic for one to have

688
00:31:04,450 --> 00:31:07,929
been continuous variables or do you ever

689
00:31:06,099 --> 00:31:13,329
in variables I don't ever been

690
00:31:07,929 --> 00:31:14,950
continuous variables so yeah so one

691
00:31:13,329 --> 00:31:17,558
thing we could do with like max

692
00:31:14,950 --> 00:31:20,049
temperature is group it into nought to

693
00:31:17,558 --> 00:31:23,139
10 10 to 20 20 to 30 and then call that

694
00:31:20,049 --> 00:31:27,129
categorical interestingly a paper just

695
00:31:23,140 --> 00:31:29,620
came out last week in which a group of

696
00:31:27,130 --> 00:31:32,350
researchers found that sometimes bidding

697
00:31:29,619 --> 00:31:33,909
can be helpful but it literally came out

698
00:31:32,349 --> 00:31:35,199
in the last week and until that time I

699
00:31:33,910 --> 00:31:37,210
haven't seen anything in deep learning

700
00:31:35,200 --> 00:31:39,340
saying that so I haven't I haven't

701
00:31:37,210 --> 00:31:41,920
looked at it myself until this week I

702
00:31:39,339 --> 00:31:43,839
would have said it's a bad idea now I

703
00:31:41,920 --> 00:31:52,570
have to think differently I guess maybe

704
00:31:43,839 --> 00:31:55,509
it is sometimes so if you're using year

705
00:31:52,569 --> 00:31:57,250
as a category what happens when you run

706
00:31:55,509 --> 00:32:00,879
the model of a year it's never seen so

707
00:31:57,250 --> 00:32:03,250
your training will get there yeah the

708
00:32:00,880 --> 00:32:06,070
short answer is it will be treated as an

709
00:32:03,250 --> 00:32:09,039
unknown category and so pandas which is

710
00:32:06,069 --> 00:32:11,169
the underlying data frame thinking we're

711
00:32:09,039 --> 00:32:13,569
using with categories as a special

712
00:32:11,170 --> 00:32:15,730
category called unknown and if it stays

713
00:32:13,569 --> 00:32:20,049
a category it hasn't seen before it gets

714
00:32:15,730 --> 00:32:22,150
treated as unknown so for AB deep

715
00:32:20,049 --> 00:32:24,839
learning model unknown will just be

716
00:32:22,150 --> 00:32:24,840
another category

717
00:32:25,130 --> 00:32:32,940
if our data set training the data set

718
00:32:29,460 --> 00:32:36,240
doesn't have a category and test has

719
00:32:32,940 --> 00:32:39,120
unknown how will it did you know just

720
00:32:36,240 --> 00:32:41,490
paper this unknown category it's still

721
00:32:39,119 --> 00:32:44,219
predict it will predict something right

722
00:32:41,490 --> 00:32:46,679
like it will just have the value 0 barn

723
00:32:44,220 --> 00:32:48,990
scenes and if there's been any unknowns

724
00:32:46,679 --> 00:32:52,409
of any kind in the training set then it

725
00:32:48,990 --> 00:32:54,808
off learnt a way to predict unknown if

726
00:32:52,409 --> 00:32:58,019
it hasn't it's going to have some random

727
00:32:54,808 --> 00:33:00,240
vector and so that's a interesting

728
00:32:58,019 --> 00:33:01,500
detail around training that we probably

729
00:33:00,240 --> 00:33:02,669
want to talk about in this part of the

730
00:33:01,500 --> 00:33:05,528
course but we can certainly talk about

731
00:33:02,669 --> 00:33:08,809
on the forum

732
00:33:05,528 --> 00:33:11,808
okay so we've got our categorical and

733
00:33:08,808 --> 00:33:13,220
continuous variable lists defined in

734
00:33:11,808 --> 00:33:16,700
this case there was eight hundred

735
00:33:13,220 --> 00:33:21,919
thousand rows so eight hundred thousand

736
00:33:16,700 --> 00:33:26,929
dates basically by Storz and so you can

737
00:33:21,919 --> 00:33:29,720
now take all of these columns look

738
00:33:26,929 --> 00:33:31,820
through each one and replace it in the

739
00:33:29,720 --> 00:33:33,819
data frame where the version where you

740
00:33:31,819 --> 00:33:37,579
say take it and change its type to

741
00:33:33,819 --> 00:33:39,950
category okay and so that just that just

742
00:33:37,579 --> 00:33:40,668
a panda's things so I'm not going to

743
00:33:39,950 --> 00:33:42,558
teach you

744
00:33:40,669 --> 00:33:44,690
pandas there's plenty of books so

745
00:33:42,558 --> 00:33:48,378
particularly with McKinney's books book

746
00:33:44,690 --> 00:33:49,729
on python for data analysis is great but

747
00:33:48,378 --> 00:33:51,348
hopefully it's intuitive as to what's

748
00:33:49,729 --> 00:33:53,298
going on even if you haven't seen the

749
00:33:51,348 --> 00:33:55,878
specific syntax before so we're going to

750
00:33:53,298 --> 00:33:58,308
turn that column into a categorical

751
00:33:55,878 --> 00:34:00,908
column and then for the continuous

752
00:33:58,308 --> 00:34:03,829
variables we're going to make them all

753
00:34:00,909 --> 00:34:07,489
32-bit floating-point and for the reason

754
00:34:03,829 --> 00:34:09,710
for that is that pipe torch expects

755
00:34:07,489 --> 00:34:13,750
everything to be 32-bit floating-point

756
00:34:09,710 --> 00:34:19,639
okay so like some of these include like

757
00:34:13,750 --> 00:34:21,588
1 0 things like I can't see them

758
00:34:19,639 --> 00:34:23,720
straight away but anyway so much yeah

759
00:34:21,588 --> 00:34:25,788
like was there a promo was was a holiday

760
00:34:23,719 --> 00:34:33,709
and so that'll become the floating point

761
00:34:25,789 --> 00:34:35,480
values 1 and 0 for instance ok so I try

762
00:34:33,710 --> 00:34:39,349
to do as much of my work as possible

763
00:34:35,480 --> 00:34:40,730
on small data sets for when I'm working

764
00:34:39,349 --> 00:34:44,539
with images that generally means

765
00:34:40,730 --> 00:34:48,048
resizing the images to like 64 by 64 or

766
00:34:44,539 --> 00:34:49,849
128 by 128 we can't do that with

767
00:34:48,048 --> 00:34:52,460
structured data so instead I tend to

768
00:34:49,849 --> 00:34:55,159
take a sample so I randomly pick a few

769
00:34:52,460 --> 00:34:57,289
rows so I start running with a sample

770
00:34:55,159 --> 00:34:59,180
and I can use exactly the same thing

771
00:34:57,289 --> 00:35:01,400
that we've seen before for getting a

772
00:34:59,179 --> 00:35:04,608
validation set we can use the same way

773
00:35:01,400 --> 00:35:07,608
to get some random random row numbers to

774
00:35:04,608 --> 00:35:10,989
use in a random sample okay so this is

775
00:35:07,608 --> 00:35:10,989
just a bunch of random numbers

776
00:35:13,710 --> 00:35:21,300
and then okay so that's going to be a

777
00:35:15,210 --> 00:35:23,699
size 150,000 rather than 800 40,000 and

778
00:35:21,300 --> 00:35:25,650
so my data that before I go any further

779
00:35:23,699 --> 00:35:28,980
it basically looks like this you can see

780
00:35:25,650 --> 00:35:32,910
I've got some boolean x' here I've got

781
00:35:28,980 --> 00:35:37,019
some integers here of various different

782
00:35:32,909 --> 00:35:40,009
scales here's my year 2014 and I've got

783
00:35:37,019 --> 00:35:43,730
some letters here so even though I said

784
00:35:40,010 --> 00:35:45,839
please call that a pandas category

785
00:35:43,730 --> 00:35:49,769
pandas still displays that in the

786
00:35:45,838 --> 00:35:52,858
notebook as strings right it's just

787
00:35:49,769 --> 00:35:55,289
stored in internally differently so then

788
00:35:52,858 --> 00:35:56,940
the first day our library has a special

789
00:35:55,289 --> 00:35:59,579
little function called processed data

790
00:35:56,940 --> 00:36:02,338
frame and process data frame takes a

791
00:35:59,579 --> 00:36:05,069
data frame and you tell it what's my

792
00:36:02,338 --> 00:36:06,570
dependent variable right and it does a

793
00:36:05,070 --> 00:36:08,550
few different things the first thing is

794
00:36:06,570 --> 00:36:10,650
it's pulled out that dependent variable

795
00:36:08,550 --> 00:36:13,080
and puts it into a separate variable

796
00:36:10,650 --> 00:36:16,170
okay and deletes it from the original

797
00:36:13,079 --> 00:36:18,809
data frame so DF now does not have the

798
00:36:16,170 --> 00:36:22,588
sales column in where else Y just

799
00:36:18,809 --> 00:36:25,588
contains a sales column something else

800
00:36:22,588 --> 00:36:28,769
that it does is it does scaling so

801
00:36:25,588 --> 00:36:31,440
neural nets really like to have the

802
00:36:28,769 --> 00:36:33,929
input data to all be somewhere around

803
00:36:31,440 --> 00:36:35,940
zero with a standard deviation of

804
00:36:33,929 --> 00:36:39,899
somewhere around one all right so we can

805
00:36:35,940 --> 00:36:41,039
always take our data and subtract the

806
00:36:39,900 --> 00:36:43,650
mean and divide by the standard

807
00:36:41,039 --> 00:36:46,170
deviation to make that happen so that's

808
00:36:43,650 --> 00:36:48,358
what do see a littles true that's and it

809
00:36:46,170 --> 00:36:50,070
actually returns a special object which

810
00:36:48,358 --> 00:36:51,900
keeps track of what mean and standard

811
00:36:50,070 --> 00:36:53,970
deviation did it use for that

812
00:36:51,900 --> 00:36:57,780
normalizing so you can then do the same

813
00:36:53,969 --> 00:37:01,949
thing to the test set later it also

814
00:36:57,780 --> 00:37:04,589
handles missing values so missing values

815
00:37:01,949 --> 00:37:07,348
and categorical variables just become

816
00:37:04,588 --> 00:37:09,690
the ID 0 and then all the other

817
00:37:07,349 --> 00:37:12,930
categories become 1 2 3 4 5 4 that

818
00:37:09,690 --> 00:37:13,530
categorical variable for continuous

819
00:37:12,929 --> 00:37:17,579
variables

820
00:37:13,530 --> 00:37:21,150
it replaces the missing value with the

821
00:37:17,579 --> 00:37:23,098
median and creates a new column that's a

822
00:37:21,150 --> 00:37:24,660
boolean and just says is this missing or

823
00:37:23,099 --> 00:37:26,309
not and I'm gonna skip over this pretty

824
00:37:24,659 --> 00:37:27,239
quickly because we talked about this in

825
00:37:26,309 --> 00:37:29,369
detail

826
00:37:27,239 --> 00:37:31,129
the machine learning course okay so if

827
00:37:29,369 --> 00:37:34,140
you've got any questions about this part

828
00:37:31,130 --> 00:37:36,900
that would be a good place to go it's

829
00:37:34,139 --> 00:37:39,719
nothing deep learning specific there so

830
00:37:36,900 --> 00:37:42,329
you can see afterwards year 2014 for

831
00:37:39,719 --> 00:37:43,829
example has become year two okay because

832
00:37:42,329 --> 00:37:47,219
these categorical variables have all

833
00:37:43,829 --> 00:37:50,699
been replaced with with contiguous

834
00:37:47,219 --> 00:37:52,709
integers starting at zero and the reason

835
00:37:50,699 --> 00:37:55,019
for that is later on we're going to be

836
00:37:52,710 --> 00:37:57,059
putting them into a matrix right and so

837
00:37:55,019 --> 00:37:59,219
we wouldn't want the matrix to be 2014

838
00:37:57,059 --> 00:38:02,159
rows long when it could just be two rows

839
00:37:59,219 --> 00:38:06,599
one there so that's the basic idea there

840
00:38:02,159 --> 00:38:08,670
and you'll see that the AC for example

841
00:38:06,599 --> 00:38:13,739
has been replaced in the same way with

842
00:38:08,670 --> 00:38:15,329
one and three okay so we now have a data

843
00:38:13,739 --> 00:38:17,069
frame which does not contain the

844
00:38:15,329 --> 00:38:20,219
dependent variable and where everything

845
00:38:17,070 --> 00:38:21,869
is a number okay and so that's that

846
00:38:20,219 --> 00:38:23,909
that's where we need to get to to do

847
00:38:21,869 --> 00:38:26,039
deep learning and all of the stage about

848
00:38:23,909 --> 00:38:27,929
that as I said we talked about in detail

849
00:38:26,039 --> 00:38:29,880
in the machine learning course nothing

850
00:38:27,929 --> 00:38:32,009
deep learning specific about any of it

851
00:38:29,880 --> 00:38:36,900
this is exactly what we throw into our

852
00:38:32,010 --> 00:38:38,190
random forests as well so another thing

853
00:38:36,900 --> 00:38:39,809
we talk about a lot in the machine

854
00:38:38,190 --> 00:38:44,309
learning core of course is validation

855
00:38:39,809 --> 00:38:47,400
sets in this case we need to predict the

856
00:38:44,309 --> 00:38:50,099
next two weeks of sales right it's not

857
00:38:47,400 --> 00:38:52,230
like pick a random set of sales but we

858
00:38:50,099 --> 00:38:54,509
have to pick the next two weeks of sales

859
00:38:52,230 --> 00:38:57,090
that was what the cattle competition

860
00:38:54,510 --> 00:38:59,100
folks told us to do and therefore I'm

861
00:38:57,090 --> 00:39:03,510
going to create a validation set which

862
00:38:59,099 --> 00:39:05,460
is the last two weeks of my training set

863
00:39:03,510 --> 00:39:08,100
right to try and make it as similar to

864
00:39:05,460 --> 00:39:09,929
the test set as possible and we just

865
00:39:08,099 --> 00:39:13,469
posted actually Rachel wrote this thing

866
00:39:09,929 --> 00:39:15,868
last week about creating validation sets

867
00:39:13,469 --> 00:39:17,219
so if you go too fast at AI you can

868
00:39:15,869 --> 00:39:20,789
check it out we'll put that in the

869
00:39:17,219 --> 00:39:23,579
lesson wiki as well but it's basically a

870
00:39:20,789 --> 00:39:27,210
summary of a recent machine learning

871
00:39:23,579 --> 00:39:28,619
lesson that we did the videos are

872
00:39:27,210 --> 00:39:30,900
available for that as well and this is

873
00:39:28,619 --> 00:39:34,460
kind of a written a written summary of

874
00:39:30,900 --> 00:39:34,460
it okay

875
00:39:35,579 --> 00:39:40,420
so yeah so Rachel and I spend a lot of

876
00:39:38,199 --> 00:39:41,949
time thinking about kind of you know how

877
00:39:40,420 --> 00:39:43,930
do you need to think about validation

878
00:39:41,949 --> 00:39:46,689
sets and training sets and test sets and

879
00:39:43,929 --> 00:39:48,429
so forth and that's all there but again

880
00:39:46,690 --> 00:39:50,710
nothing deep learning specific so let's

881
00:39:48,429 --> 00:39:55,058
get straight to the deep learning action

882
00:39:50,710 --> 00:39:58,059
okay so in this particular competition

883
00:39:55,059 --> 00:40:01,660
as always with any competition or any

884
00:39:58,059 --> 00:40:02,980
kind of machine learning project you

885
00:40:01,659 --> 00:40:06,098
really need to make sure you have a

886
00:40:02,980 --> 00:40:08,079
strong understanding of your metric how

887
00:40:06,099 --> 00:40:09,460
are you going to be judged here and in

888
00:40:08,079 --> 00:40:10,720
this case you know Carol makes it easy

889
00:40:09,460 --> 00:40:12,400
they tell us how we're going to be

890
00:40:10,719 --> 00:40:14,949
judged and so we're going to be judged

891
00:40:12,400 --> 00:40:17,769
on the roots mean squared percentage

892
00:40:14,949 --> 00:40:21,039
error right so we're gonna say like oh

893
00:40:17,769 --> 00:40:24,130
you predicted three it was actually

894
00:40:21,039 --> 00:40:25,900
three point three so you were can sent

895
00:40:24,130 --> 00:40:28,890
out and then we're gonna average all

896
00:40:25,900 --> 00:40:33,818
those percents right and remember I

897
00:40:28,889 --> 00:40:35,679
warned you that you are gonna need to

898
00:40:33,818 --> 00:40:37,838
make sure you know logarithms really

899
00:40:35,679 --> 00:40:40,449
well right and so in this case from you

900
00:40:37,838 --> 00:40:43,358
know we're basically being saying your

901
00:40:40,449 --> 00:40:46,000
prediction divided by the actual the

902
00:40:43,358 --> 00:40:52,719
mean of that right is the thing that we

903
00:40:46,000 --> 00:40:54,460
care about and so we don't have a metric

904
00:40:52,719 --> 00:40:56,739
in play torch called root mean squared

905
00:40:54,460 --> 00:40:59,889
percent error we could actually easily

906
00:40:56,739 --> 00:41:01,929
create it by the way if you look at the

907
00:40:59,889 --> 00:41:03,789
source code you'll see like it's you

908
00:41:01,929 --> 00:41:08,139
know a line of code but easiest deal

909
00:41:03,789 --> 00:41:12,579
would be to realize that that if you

910
00:41:08,139 --> 00:41:16,750
have that right then you could replace a

911
00:41:12,579 --> 00:41:19,359
with like log of a dash and be with like

912
00:41:16,750 --> 00:41:22,380
log of B dash and then you can replace

913
00:41:19,358 --> 00:41:26,078
that whole thing with a subtraction

914
00:41:22,380 --> 00:41:28,930
that's just the rule of loaves right and

915
00:41:26,079 --> 00:41:30,400
so if you don't know that rule then

916
00:41:28,929 --> 00:41:32,108
don't make sure you go look it up

917
00:41:30,400 --> 00:41:35,430
because it's super helpful but it means

918
00:41:32,108 --> 00:41:39,880
in this case all we need to do is to

919
00:41:35,429 --> 00:41:42,068
take the log of our data which I

920
00:41:39,880 --> 00:41:44,200
actually did earlier in this notebook

921
00:41:42,068 --> 00:41:46,599
and when you take the log of the data

922
00:41:44,199 --> 00:41:47,980
getting the root mean squared error will

923
00:41:46,599 --> 00:41:50,740
actually get you there

924
00:41:47,980 --> 00:41:53,769
means great percent error for free okay

925
00:41:50,739 --> 00:41:56,679
but then when we want to like print out

926
00:41:53,769 --> 00:42:00,969
our it means percent error we actually

927
00:41:56,679 --> 00:42:02,949
have to go e ^ it again right and then

928
00:42:00,969 --> 00:42:04,509
we can actually return the percent

929
00:42:02,949 --> 00:42:06,039
difference so that's all that's going on

930
00:42:04,510 --> 00:42:11,020
here it's again not really deep learning

931
00:42:06,039 --> 00:42:14,529
specific at all so here we finally get

932
00:42:11,019 --> 00:42:16,119
to the deep learning alright so as per

933
00:42:14,530 --> 00:42:18,070
usual like you'll see everything we look

934
00:42:16,119 --> 00:42:20,019
at today looks exactly the same as

935
00:42:18,070 --> 00:42:22,740
everything we've looked at so far which

936
00:42:20,019 --> 00:42:25,650
is first we create a model data object

937
00:42:22,739 --> 00:42:28,149
something that has a validation set

938
00:42:25,650 --> 00:42:30,820
training set and optional test set built

939
00:42:28,150 --> 00:42:33,820
into it from that we will get a learner

940
00:42:30,820 --> 00:42:37,269
we will then optionally called learner

941
00:42:33,820 --> 00:42:39,160
dot LR find real then called learner dot

942
00:42:37,269 --> 00:42:41,110
fetch it'll be all the same parameters

943
00:42:39,159 --> 00:42:43,869
and everything that you've seen many

944
00:42:41,110 --> 00:42:45,370
times before okay so the difference

945
00:42:43,869 --> 00:42:50,079
though is obviously we're not going to

946
00:42:45,369 --> 00:42:52,269
go image classify a data dot from CSV or

947
00:42:50,079 --> 00:42:55,029
dot from paths we need to get some

948
00:42:52,269 --> 00:42:57,699
different kind of model data and so for

949
00:42:55,030 --> 00:43:00,880
stuff that is in rows and columns we use

950
00:42:57,699 --> 00:43:02,799
columnar model data but this will return

951
00:43:00,880 --> 00:43:05,500
an object with basically the same API

952
00:43:02,800 --> 00:43:09,160
that you're familiar with and rather

953
00:43:05,500 --> 00:43:12,130
than from paths or from CSV this is from

954
00:43:09,159 --> 00:43:15,940
data frame okay so this gets passed a

955
00:43:12,130 --> 00:43:17,670
few things the path here is just used

956
00:43:15,940 --> 00:43:20,740
for it to know where should it store

957
00:43:17,670 --> 00:43:22,210
like model files or stuff like that

958
00:43:20,739 --> 00:43:23,589
right this is just basically saying

959
00:43:22,210 --> 00:43:27,070
where do you want to store anything that

960
00:43:23,590 --> 00:43:29,050
you saved later this is the list of the

961
00:43:27,070 --> 00:43:31,180
indexes of the rows that we want to put

962
00:43:29,050 --> 00:43:39,820
in the validation set we created earlier

963
00:43:31,179 --> 00:43:41,469
here's our data frame okay and then look

964
00:43:39,820 --> 00:43:44,260
here's this is where we did the log

965
00:43:41,469 --> 00:43:46,089
right so I took the the Y that came out

966
00:43:44,260 --> 00:43:49,210
of property F our dependent variable I

967
00:43:46,090 --> 00:43:52,150
logged it and I call that yl all right

968
00:43:49,210 --> 00:43:53,470
so we tell it when we create our model

969
00:43:52,150 --> 00:43:56,139
data we need to tell it that's our

970
00:43:53,469 --> 00:43:57,819
dependent variable okay so so far we've

971
00:43:56,139 --> 00:43:59,769
got most of the stuff from the

972
00:43:57,820 --> 00:44:01,250
validation set which is what's our

973
00:43:59,769 --> 00:44:03,380
independent variables

974
00:44:01,250 --> 00:44:05,480
how dependent variables and then we have

975
00:44:03,380 --> 00:44:08,329
to tell it which things do we want

976
00:44:05,480 --> 00:44:13,280
traded as categorical right because

977
00:44:08,329 --> 00:44:15,298
remember by this time everything's a

978
00:44:13,280 --> 00:44:17,999
number

979
00:44:15,298 --> 00:44:19,768
right so it could do the whole things

980
00:44:17,998 --> 00:44:22,558
it's continuous it would just be totally

981
00:44:19,768 --> 00:44:24,238
meaningless right so we need to tell it

982
00:44:22,559 --> 00:44:26,729
which things do we want to treat as

983
00:44:24,239 --> 00:44:30,469
categories and so here we just pass in

984
00:44:26,728 --> 00:44:33,928
that list of names that we used before

985
00:44:30,469 --> 00:44:35,969
okay and then a bunch of the parameters

986
00:44:33,929 --> 00:44:37,849
are the same as the ones you're used to

987
00:44:35,969 --> 00:44:43,068
for example you can set the batch size

988
00:44:37,849 --> 00:44:46,769
yeah so after we do that we've got a

989
00:44:43,068 --> 00:44:49,978
little standard model data object but

990
00:44:46,768 --> 00:44:52,558
there's a trained DL attribute there's a

991
00:44:49,978 --> 00:44:55,259
Val DL attribute a trained es attribute

992
00:44:52,559 --> 00:44:57,809
of LDS attribute it's got a length it's

993
00:44:55,259 --> 00:45:04,349
got all the stuff exactly like it did in

994
00:44:57,809 --> 00:45:06,869
all of our image based data objects okay

995
00:45:04,349 --> 00:45:09,568
so now we need to create the the model

996
00:45:06,869 --> 00:45:12,838
or create the learner and so to skip

997
00:45:09,568 --> 00:45:14,849
ahead a little bit we're basically going

998
00:45:12,838 --> 00:45:16,679
to pass in something that looks pretty

999
00:45:14,849 --> 00:45:18,709
familiar we're going to be passing thing

1000
00:45:16,679 --> 00:45:21,769
from our model from our model data

1001
00:45:18,708 --> 00:45:24,868
create a learner that is suitable for it

1002
00:45:21,768 --> 00:45:26,638
and will basically be passing in a few

1003
00:45:24,869 --> 00:45:29,459
other bits of information which will

1004
00:45:26,639 --> 00:45:33,689
include how much dropout to use at the

1005
00:45:29,458 --> 00:45:34,798
very start how many how many activations

1006
00:45:33,688 --> 00:45:37,888
to have in each layer

1007
00:45:34,798 --> 00:45:40,528
how much dropout to use at the later

1008
00:45:37,889 --> 00:45:41,818
layers but then there's a couple of

1009
00:45:40,528 --> 00:45:44,688
extra things that we need to learn about

1010
00:45:41,818 --> 00:45:50,818
and specifically it's this thing called

1011
00:45:44,688 --> 00:45:53,518
embeddings so this is really the key new

1012
00:45:50,818 --> 00:45:58,679
concept we have to learn about all right

1013
00:45:53,518 --> 00:46:02,248
so all we're doing basically is we're

1014
00:45:58,679 --> 00:46:04,108
going to take our let's forget about

1015
00:46:02,248 --> 00:46:05,548
categorical variables for a moment and

1016
00:46:04,108 --> 00:46:08,699
just think about the continuous

1017
00:46:05,548 --> 00:46:11,759
variables for our continuous variables

1018
00:46:08,699 --> 00:46:14,298
all we're going to do is we're going to

1019
00:46:11,759 --> 00:46:14,298
grab them all

1020
00:46:16,440 --> 00:46:20,500
okay so for our continuous variables

1021
00:46:18,818 --> 00:46:23,798
we're basically going to say like okay

1022
00:46:20,500 --> 00:46:25,690
here's a big list of all of our

1023
00:46:23,798 --> 00:46:27,880
continuous variables like the minimum

1024
00:46:25,690 --> 00:46:29,740
temperature and the maximum temperature

1025
00:46:27,880 --> 00:46:32,588
and the distance to the nearest

1026
00:46:29,739 --> 00:46:34,389
competitor and so forth right and so

1027
00:46:32,588 --> 00:46:36,699
here's just a bunch of floating-point

1028
00:46:34,389 --> 00:46:38,469
numbers and so basically what the neuron

1029
00:46:36,699 --> 00:46:44,068
that's going to do is going to take that

1030
00:46:38,469 --> 00:46:49,058
that 1d array or or vector or to be very

1031
00:46:44,068 --> 00:46:49,659
DL like rank one tensor or means the

1032
00:46:49,059 --> 00:46:51,280
same thing

1033
00:46:49,659 --> 00:46:54,129
okay so we're going to take our egg one

1034
00:46:51,280 --> 00:46:56,710
tensor and let's put it through a matrix

1035
00:46:54,130 --> 00:46:59,380
multiplication so let's say this has got

1036
00:46:56,710 --> 00:47:01,568
like I don't know 20 continuous

1037
00:46:59,380 --> 00:47:05,470
variables and then we can put it through

1038
00:47:01,568 --> 00:47:07,960
a matrix which must have 20 rows that's

1039
00:47:05,469 --> 00:47:09,789
how matrix multiplication works and then

1040
00:47:07,960 --> 00:47:12,940
we can decide how many columns we want

1041
00:47:09,789 --> 00:47:14,829
right so maybe we decided 100 right and

1042
00:47:12,940 --> 00:47:20,338
so that matrix model captions going to

1043
00:47:14,829 --> 00:47:21,460
spit out a new length 100 rank 1 tensor

1044
00:47:20,338 --> 00:47:23,949
okay

1045
00:47:21,460 --> 00:47:26,108
that's that's what that's what a linear

1046
00:47:23,949 --> 00:47:28,409
that's what a matrix product does and

1047
00:47:26,108 --> 00:47:32,440
that's the definition of a linear layer

1048
00:47:28,409 --> 00:47:34,029
indeed what okay and so then the next

1049
00:47:32,440 --> 00:47:36,700
thing we do is we can put that through a

1050
00:47:34,030 --> 00:47:39,670
rail you right which means we throw away

1051
00:47:36,699 --> 00:47:42,250
the negatives okay and now we can put

1052
00:47:39,670 --> 00:47:43,240
that through another matrix product okay

1053
00:47:42,250 --> 00:47:47,079
so this is going to have to have a

1054
00:47:43,239 --> 00:47:49,088
hundred rows by definition and we can

1055
00:47:47,079 --> 00:47:51,910
have as many columns as we like and so

1056
00:47:49,088 --> 00:47:53,679
let's say maybe this was the last layer

1057
00:47:51,909 --> 00:47:57,210
so the next thing we're trying to do is

1058
00:47:53,679 --> 00:47:59,348
to predict sales so there's just one

1059
00:47:57,210 --> 00:48:01,480
value we're trying to predict for sales

1060
00:47:59,349 --> 00:48:02,980
so we could put it through a matrix

1061
00:48:01,480 --> 00:48:05,760
product that just had one column and

1062
00:48:02,980 --> 00:48:09,880
that's going to spit out a single number

1063
00:48:05,760 --> 00:48:14,829
all right so that's like that's kind of

1064
00:48:09,880 --> 00:48:17,108
like a one layer neural net if you like

1065
00:48:14,829 --> 00:48:19,750
now in practice you know we wouldn't

1066
00:48:17,108 --> 00:48:22,469
make it one layer so we would actually

1067
00:48:19,750 --> 00:48:22,469
have leg

1068
00:48:23,280 --> 00:48:30,740
you know maybe we'd have 50 here and so

1069
00:48:26,489 --> 00:48:34,469
then that gives us a 50 long vector and

1070
00:48:30,739 --> 00:48:40,379
then maybe we then put that into our

1071
00:48:34,469 --> 00:48:42,419
final 50 by one and that's if it's out a

1072
00:48:40,380 --> 00:48:43,530
single number and one reason I would

1073
00:48:42,420 --> 00:48:46,650
have to change that there was to point

1074
00:48:43,530 --> 00:48:48,510
out you know rally you would never put

1075
00:48:46,650 --> 00:48:49,769
rally you in the last layer

1076
00:48:48,510 --> 00:48:54,300
I could never want to throw away the

1077
00:48:49,769 --> 00:48:56,840
negatives because that the softmax let's

1078
00:48:54,300 --> 00:48:59,430
go back to the softness the soft max

1079
00:48:56,840 --> 00:49:00,599
needs negatives in it because it's the

1080
00:48:59,429 --> 00:49:04,379
negatives that are the things that allow

1081
00:49:00,599 --> 00:49:06,119
it to create low probabilities that's

1082
00:49:04,380 --> 00:49:09,800
minor detail but it's useful to remember

1083
00:49:06,119 --> 00:49:09,800
okay so basically

1084
00:49:13,389 --> 00:49:22,400
so basically a simple view of a fully

1085
00:49:19,940 --> 00:49:26,528
connected euro net is something that

1086
00:49:22,400 --> 00:49:31,119
takes in as an input a rank one tensor

1087
00:49:26,528 --> 00:49:36,190
it's bits it's through a linear layer an

1088
00:49:31,119 --> 00:49:43,579
activation layer another linear layer

1089
00:49:36,190 --> 00:49:46,970
softmax and that's the output okay and

1090
00:49:43,579 --> 00:49:50,390
so we could obviously decide to add more

1091
00:49:46,969 --> 00:49:53,509
linear layers we could decide maybe to

1092
00:49:50,389 --> 00:49:55,429
add dropout all right so these are some

1093
00:49:53,509 --> 00:49:58,278
of the decisions that we need we get to

1094
00:49:55,429 --> 00:49:59,989
make right but we there's not that much

1095
00:49:58,278 --> 00:50:02,838
we can do right there's not much really

1096
00:49:59,989 --> 00:50:06,229
crazy architecture stuff to do so when

1097
00:50:02,838 --> 00:50:07,278
we come back to image models later in

1098
00:50:06,230 --> 00:50:09,170
the course we're going to learn about

1099
00:50:07,278 --> 00:50:12,619
all the weird things that go on and like

1100
00:50:09,170 --> 00:50:14,059
resonates and inception networks and but

1101
00:50:12,619 --> 00:50:15,798
in these fully connected networks

1102
00:50:14,059 --> 00:50:17,000
they're really pretty simple they're

1103
00:50:15,798 --> 00:50:19,429
just in dispersed

1104
00:50:17,000 --> 00:50:23,088
linear layers that is matrix products

1105
00:50:19,429 --> 00:50:27,169
and activation functions like value and

1106
00:50:23,088 --> 00:50:29,210
a soft mix at the edge and if it's not

1107
00:50:27,170 --> 00:50:30,740
classification which actually ours is

1108
00:50:29,210 --> 00:50:33,259
not classification in this case we're

1109
00:50:30,739 --> 00:50:35,750
trying to predict sales there isn't even

1110
00:50:33,259 --> 00:50:39,349
a soft mix right we don't want it to be

1111
00:50:35,750 --> 00:50:43,579
between 0 and 1 ok so we can just throw

1112
00:50:39,349 --> 00:50:45,619
away the last activation altogether if

1113
00:50:43,579 --> 00:50:48,380
we have time we can talk about a slight

1114
00:50:45,619 --> 00:50:51,440
trick we can do there but for now we can

1115
00:50:48,380 --> 00:50:53,568
think of it that way so that was all

1116
00:50:51,440 --> 00:50:56,420
assuming that everything was continuous

1117
00:50:53,568 --> 00:51:04,000
right but what about categorical right

1118
00:50:56,420 --> 00:51:06,019
so we've got like day of week right and

1119
00:51:04,000 --> 00:51:11,259
we're going to treat it as categorical

1120
00:51:06,018 --> 00:51:15,259
practice like Saturday Sunday Monday

1121
00:51:11,259 --> 00:51:19,429
that should be 6

1122
00:51:15,260 --> 00:51:21,260
ready okay how do we feed that in

1123
00:51:19,429 --> 00:51:22,940
because I want to find a way of getting

1124
00:51:21,260 --> 00:51:26,000
that in so that we still end up with a

1125
00:51:22,940 --> 00:51:28,490
wreck one tends to refloat and so the

1126
00:51:26,000 --> 00:51:35,690
trick is this we create a new little

1127
00:51:28,489 --> 00:51:38,269
matrix of with seven rows and as many

1128
00:51:35,690 --> 00:51:43,130
columns as we choose right so let's pick

1129
00:51:38,269 --> 00:51:48,980
four all right so here's our seven rows

1130
00:51:43,130 --> 00:51:52,220
and four columns right and basically

1131
00:51:48,980 --> 00:51:53,690
what we do is let's add our categorical

1132
00:51:52,219 --> 00:51:57,949
variables to the end so let's say the

1133
00:51:53,690 --> 00:52:00,530
first row was Sunday right then what we

1134
00:51:57,949 --> 00:52:02,689
do is we do a lookup into this matrix we

1135
00:52:00,530 --> 00:52:06,680
say oh here's sunday we do and look up

1136
00:52:02,690 --> 00:52:08,869
into here and we grab this row and so

1137
00:52:06,679 --> 00:52:10,250
this matrix we basically fill with

1138
00:52:08,869 --> 00:52:15,710
floating-point numbers so we're going to

1139
00:52:10,250 --> 00:52:18,050
end up grabbing little subset of for

1140
00:52:15,710 --> 00:52:20,720
floating-point numbers at Sunday's

1141
00:52:18,050 --> 00:52:26,480
particular for floating-point numbers

1142
00:52:20,719 --> 00:52:29,269
and so that way we convert Sunday into a

1143
00:52:26,480 --> 00:52:31,730
rank 1 tensor of for floating-point

1144
00:52:29,269 --> 00:52:34,699
numbers and initially those four numbers

1145
00:52:31,730 --> 00:52:37,510
are random all right and in fact this

1146
00:52:34,699 --> 00:52:41,389
whole thing we initially start out

1147
00:52:37,510 --> 00:52:44,570
random okay but then we're going to put

1148
00:52:41,389 --> 00:52:46,279
that through our neural net right so we

1149
00:52:44,570 --> 00:52:50,150
basically then take those four numbers

1150
00:52:46,280 --> 00:52:52,160
and we remove sunday instead we add our

1151
00:52:50,150 --> 00:52:54,920
four numbers on here right so we've

1152
00:52:52,159 --> 00:52:58,549
turned our categorical thing into a

1153
00:52:54,920 --> 00:53:01,070
floating-point vector and so now we can

1154
00:52:58,550 --> 00:53:03,350
just put that throughout neural net just

1155
00:53:01,070 --> 00:53:05,960
like before and at the very end we found

1156
00:53:03,349 --> 00:53:09,618
out the loss and then we can figure out

1157
00:53:05,960 --> 00:53:11,840
which direction is down and do gradient

1158
00:53:09,619 --> 00:53:13,970
descent in that direction and eventually

1159
00:53:11,840 --> 00:53:16,010
that will find its way back to this

1160
00:53:13,969 --> 00:53:18,139
little list of four numbers and it'll

1161
00:53:16,010 --> 00:53:20,150
say okay those random numbers weren't

1162
00:53:18,139 --> 00:53:21,920
very good this one needs to go up a bit

1163
00:53:20,150 --> 00:53:23,510
that one is to go up a bit that one is

1164
00:53:21,920 --> 00:53:26,108
to go down a bit that one is to go up a

1165
00:53:23,510 --> 00:53:28,730
bit and so will actually update our

1166
00:53:26,108 --> 00:53:29,029
original those four numbers in that

1167
00:53:28,730 --> 00:53:31,519
match

1168
00:53:29,030 --> 00:53:34,610
and we'll do this again and again and

1169
00:53:31,519 --> 00:53:36,320
again and so this this matrix will stop

1170
00:53:34,610 --> 00:53:38,990
looking random and it will start looking

1171
00:53:36,320 --> 00:53:40,519
more and more like like the exact four

1172
00:53:38,989 --> 00:53:42,559
numbers that happen to work best for

1173
00:53:40,519 --> 00:53:44,869
Sunday the exact four numbers that

1174
00:53:42,559 --> 00:53:45,349
happen to work best for Friday and so

1175
00:53:44,869 --> 00:53:48,519
forth

1176
00:53:45,349 --> 00:53:52,639
and so in other words this matrix is

1177
00:53:48,519 --> 00:53:56,179
just another bunch of weights in our

1178
00:53:52,639 --> 00:54:01,480
neural net all right and so matrices of

1179
00:53:56,179 --> 00:54:01,480
this type are called embedding matrices

1180
00:54:03,639 --> 00:54:10,599
so an embedding matrix is something

1181
00:54:06,289 --> 00:54:13,849
where we start out with an integer

1182
00:54:10,599 --> 00:54:17,539
between zero and the maximum number of

1183
00:54:13,849 --> 00:54:20,239
levels of that category we literally

1184
00:54:17,539 --> 00:54:23,539
index into a matrix to find a particular

1185
00:54:20,239 --> 00:54:27,009
row so if it was the level was one we

1186
00:54:23,539 --> 00:54:30,409
take the first row we grab that road and

1187
00:54:27,010 --> 00:54:34,510
we append it to all of our continuous

1188
00:54:30,409 --> 00:54:37,069
variables and so we now have a new

1189
00:54:34,510 --> 00:54:39,080
vector of continuous variables and when

1190
00:54:37,070 --> 00:54:41,960
we can do the same thing so let's say

1191
00:54:39,079 --> 00:54:44,179
zip code right so we could like have an

1192
00:54:41,960 --> 00:54:46,909
embedding matrix let's say there are

1193
00:54:44,179 --> 00:54:49,969
5,000 zip codes it would be 5,000 rows

1194
00:54:46,909 --> 00:54:55,009
long as wide as we decide maybe it's 50

1195
00:54:49,969 --> 00:54:58,129
wide and so we'd say ok here's 9 4 0 0 3

1196
00:54:55,010 --> 00:54:59,660
that zip code is index number 4 you know

1197
00:54:58,130 --> 00:55:02,360
matrix ordered out and we'd find the

1198
00:54:59,659 --> 00:55:05,750
fourth row regret those 50 numbers and

1199
00:55:02,360 --> 00:55:07,550
append those on to our big vector and

1200
00:55:05,750 --> 00:55:08,690
then everything after that is just the

1201
00:55:07,550 --> 00:55:13,820
same we just put it through our linear

1202
00:55:08,690 --> 00:55:16,940
layer a linear layer whatever what are

1203
00:55:13,820 --> 00:55:19,160
those 4 numbers represent that's a great

1204
00:55:16,940 --> 00:55:20,679
question and we'll learn more about that

1205
00:55:19,159 --> 00:55:24,409
when we look at collaborative filtering

1206
00:55:20,679 --> 00:55:26,929
but now they represent no more or no

1207
00:55:24,409 --> 00:55:30,319
less than any other parameter in a

1208
00:55:26,929 --> 00:55:32,089
neural net you know they're just they're

1209
00:55:30,320 --> 00:55:35,260
just parameters that we're learning that

1210
00:55:32,090 --> 00:55:37,940
happen to end up giving us a good loss

1211
00:55:35,260 --> 00:55:39,800
we will discover later that these

1212
00:55:37,940 --> 00:55:41,659
particular parameters often however are

1213
00:55:39,800 --> 00:55:44,240
human interpretive all and quote can

1214
00:55:41,659 --> 00:55:47,269
quite interesting but that's a side

1215
00:55:44,239 --> 00:55:49,189
effect of them it's not fundamental

1216
00:55:47,269 --> 00:55:52,099
they're just for random numbers for now

1217
00:55:49,190 --> 00:55:57,650
that we're that we're learning or sets

1218
00:55:52,099 --> 00:55:59,359
of four random numbers to have a good

1219
00:55:57,650 --> 00:56:03,139
heuristic for at the dimensionality of

1220
00:55:59,358 --> 00:56:12,769
embedding matrix so why four here I sure

1221
00:56:03,139 --> 00:56:15,828
do so what I first of all did was I made

1222
00:56:12,769 --> 00:56:19,009
a little list of every categorical

1223
00:56:15,829 --> 00:56:20,599
variable and its cardinality okay so

1224
00:56:19,010 --> 00:56:22,970
they're they allow so there's a hundred

1225
00:56:20,599 --> 00:56:24,130
and there's a thousand plus different

1226
00:56:22,969 --> 00:56:27,288
stores

1227
00:56:24,130 --> 00:56:29,088
apparently in Rothman's Network

1228
00:56:27,289 --> 00:56:30,319
there are eight days of the week that's

1229
00:56:29,088 --> 00:56:33,619
because there are seven days of the week

1230
00:56:30,318 --> 00:56:35,480
plus one left over for unknown even if

1231
00:56:33,619 --> 00:56:37,490
there were no missing values in the

1232
00:56:35,480 --> 00:56:39,619
original data I always still set aside

1233
00:56:37,489 --> 00:56:41,479
one just in case there's a missing or an

1234
00:56:39,619 --> 00:56:44,630
unknown or something different in the

1235
00:56:41,480 --> 00:56:46,699
test set again for years but there's

1236
00:56:44,630 --> 00:56:51,140
actually three plus room for an unknown

1237
00:56:46,699 --> 00:56:55,489
and so forth right so what I do my rule

1238
00:56:51,139 --> 00:57:00,199
of thumb is this take the cardinality

1239
00:56:55,489 --> 00:57:04,179
with the variable divide it by two but

1240
00:57:00,199 --> 00:57:06,828
don't make it bigger than 50 okay so

1241
00:57:04,179 --> 00:57:10,210
these are my embedding matrices so my

1242
00:57:06,829 --> 00:57:12,650
store matrix so there has to have a

1243
00:57:10,210 --> 00:57:15,199
thousand one hundred and sixteen rows

1244
00:57:12,650 --> 00:57:17,389
cuz I need to look up right to find his

1245
00:57:15,199 --> 00:57:20,899
store number three and then it's been a

1246
00:57:17,389 --> 00:57:23,629
return back a rank one tensor of length

1247
00:57:20,900 --> 00:57:25,490
fifty day of week it's going to look up

1248
00:57:23,630 --> 00:57:31,220
into which one of the eight and

1249
00:57:25,489 --> 00:57:33,019
returning the thing of length four so

1250
00:57:31,219 --> 00:57:36,278
what you typically build on embedding

1251
00:57:33,019 --> 00:57:38,480
metrics for each categorical feature yes

1252
00:57:36,278 --> 00:57:43,699
yeah so that's what I've done here so

1253
00:57:38,480 --> 00:57:47,719
I've said for see in categorical

1254
00:57:43,699 --> 00:57:53,449
variables see how many categories there

1255
00:57:47,719 --> 00:57:56,299
are and then for each of those things

1256
00:57:53,449 --> 00:57:59,269
create one of these and then this is

1257
00:57:56,300 --> 00:58:01,130
called embedding sizes and then you may

1258
00:57:59,269 --> 00:58:03,320
have noticed that that's actually the

1259
00:58:01,130 --> 00:58:05,300
first thing that we pass to get learner

1260
00:58:03,320 --> 00:58:07,250
and so that tells it for every

1261
00:58:05,300 --> 00:58:08,990
categorical variable that's the

1262
00:58:07,250 --> 00:58:11,690
embedding matrix to use for that

1263
00:58:08,989 --> 00:58:16,569
variable that is behind you listen

1264
00:58:11,690 --> 00:58:19,190
yes traffic aggression so besides our

1265
00:58:16,570 --> 00:58:20,539
random initialization and there are

1266
00:58:19,190 --> 00:58:25,970
other ways to actually initialize

1267
00:58:20,539 --> 00:58:26,659
embedding yes or no there's two ways one

1268
00:58:25,969 --> 00:58:29,868
is random

1269
00:58:26,659 --> 00:58:31,279
the other is pre-trained and we'll

1270
00:58:29,869 --> 00:58:33,079
probably talk about pre-trained more

1271
00:58:31,280 --> 00:58:35,030
later in the course but the basic idea

1272
00:58:33,079 --> 00:58:37,700
though is if somebody else at Rossmann

1273
00:58:35,030 --> 00:58:39,589
had already trained a neural net just

1274
00:58:37,699 --> 00:58:41,509
like you you would use a pre trained net

1275
00:58:39,588 --> 00:58:43,578
from imagenet to look at pictures of

1276
00:58:41,510 --> 00:58:45,829
cats and dogs if somebody else is

1277
00:58:43,579 --> 00:58:48,589
pre-trained a network to predict cheese

1278
00:58:45,829 --> 00:58:50,390
sales in ruspin you may as well start

1279
00:58:48,588 --> 00:58:53,480
with their embedding matrix of stores to

1280
00:58:50,389 --> 00:58:56,230
predict liquor sales in Rossmann and

1281
00:58:53,480 --> 00:58:59,990
this is what happens for example at

1282
00:58:56,230 --> 00:59:02,000
Pinterest and Institute they both use

1283
00:58:59,989 --> 00:59:04,699
this technique instacart uses it for

1284
00:59:02,000 --> 00:59:06,920
routing their shoppers Pinterest uses it

1285
00:59:04,699 --> 00:59:09,068
for deciding what to display on a web

1286
00:59:06,920 --> 00:59:12,500
page when you go there and they have

1287
00:59:09,068 --> 00:59:15,920
embedding matrices of products in

1288
00:59:12,500 --> 00:59:18,230
instigates case of stores that get

1289
00:59:15,920 --> 00:59:21,818
shared in the organization so people

1290
00:59:18,230 --> 00:59:21,818
don't have to train you once

1291
00:59:23,260 --> 00:59:31,039
so for the embedding sighs why wouldn't

1292
00:59:28,338 --> 00:59:33,710
you just use like open hot scheme and

1293
00:59:31,039 --> 00:59:36,500
just well what is the advantage of doing

1294
00:59:33,710 --> 00:59:39,108
this they're supposed to just do it well

1295
00:59:36,500 --> 00:59:43,789
good question so so we could easily as

1296
00:59:39,108 --> 00:59:46,460
you point out have instead of passing in

1297
00:59:43,789 --> 00:59:50,359
these four numbers record instead of

1298
00:59:46,460 --> 00:59:52,309
passed in seven numbers all zeroes but

1299
00:59:50,358 --> 00:59:55,818
one of them is one and that also is a

1300
00:59:52,309 --> 01:00:00,619
list of floats and that would totally

1301
00:59:55,818 --> 01:00:03,400
work and that's how generally speaking

1302
01:00:00,619 --> 01:00:05,298
categorical variables have been used in

1303
01:00:03,400 --> 01:00:09,289
statistics for many years it's called

1304
01:00:05,298 --> 01:00:13,818
dummy variables the problem is that in

1305
01:00:09,289 --> 01:00:15,559
that case the concept of sundae could

1306
01:00:13,818 --> 01:00:19,548
only ever be associated with a single

1307
01:00:15,559 --> 01:00:21,470
floating-point number right and so it

1308
01:00:19,548 --> 01:00:24,139
basically gets this kind of linear

1309
01:00:21,469 --> 01:00:27,919
behavior it says like sunday is more or

1310
01:00:24,139 --> 01:00:29,598
less of a single thing yeah worth

1311
01:00:27,920 --> 01:00:31,970
noticing directions it's saying like now

1312
01:00:29,599 --> 01:00:34,760
sunday is a concept in four dimensional

1313
01:00:31,969 --> 01:00:38,929
space right and so what we tend to find

1314
01:00:34,760 --> 01:00:42,200
happen is that these embedding vectors

1315
01:00:38,929 --> 01:00:45,889
tend to get these kind of rich semantic

1316
01:00:42,199 --> 01:00:50,509
concepts so for example if it turns out

1317
01:00:45,889 --> 01:00:52,308
that weekends kind of have a different

1318
01:00:50,510 --> 01:00:54,680
behavior you'll tend to see that

1319
01:00:52,309 --> 01:00:57,349
Saturday and Sunday will have like some

1320
01:00:54,679 --> 01:00:59,868
particular number higher or more likely

1321
01:00:57,349 --> 01:01:05,230
it turns out that certain days of the

1322
01:00:59,869 --> 01:01:05,230
week are associated with higher sales of

1323
01:01:06,460 --> 01:01:11,028
certain kinds of goods that you kind of

1324
01:01:09,170 --> 01:01:14,269
can't go without I don't know like gas

1325
01:01:11,028 --> 01:01:18,798
or milk see where else there might be

1326
01:01:14,269 --> 01:01:23,778
other products like like wine for

1327
01:01:18,798 --> 01:01:26,028
example like wine that tend to be

1328
01:01:23,778 --> 01:01:28,250
associated with like the days before

1329
01:01:26,028 --> 01:01:31,239
weekends or holidays right so there

1330
01:01:28,250 --> 01:01:35,539
might be kind of a column which is like

1331
01:01:31,239 --> 01:01:37,959
to what extent is this day of the week

1332
01:01:35,539 --> 01:01:41,989
kind of associated with people going out

1333
01:01:37,960 --> 01:01:44,510
you know so basically yeah by by having

1334
01:01:41,989 --> 01:01:46,549
this higher dimensionality dektor rather

1335
01:01:44,510 --> 01:01:49,820
than just a single number it gives the

1336
01:01:46,550 --> 01:01:53,030
deep Learning Network a chance to learn

1337
01:01:49,820 --> 01:01:56,000
these rich representations and so this

1338
01:01:53,030 --> 01:01:58,790
idea of an embedding is actually what's

1339
01:01:56,000 --> 01:02:01,130
called a distributed representation it's

1340
01:01:58,789 --> 01:02:03,920
kind of the fun most fundamental concept

1341
01:02:01,130 --> 01:02:06,980
of neural networks this is the idea that

1342
01:02:03,920 --> 01:02:10,610
a concept in a neural network has a kind

1343
01:02:06,980 --> 01:02:12,980
of a a high dimensional representation

1344
01:02:10,610 --> 01:02:14,720
and often it can be hard to interpret

1345
01:02:12,980 --> 01:02:17,389
because the idea is like each of these

1346
01:02:14,719 --> 01:02:19,339
numbers in this vector doesn't even have

1347
01:02:17,389 --> 01:02:21,079
to have just one meaning you know it

1348
01:02:19,340 --> 01:02:22,579
could mean one thing if this is low and

1349
01:02:21,079 --> 01:02:23,630
that one's high and something else if

1350
01:02:22,579 --> 01:02:25,340
that one's high and that one's low

1351
01:02:23,630 --> 01:02:29,660
because it's going through this kind of

1352
01:02:25,340 --> 01:02:33,769
rich nonlinear function right and so

1353
01:02:29,659 --> 01:02:36,170
it's this it's this rich representation

1354
01:02:33,769 --> 01:02:41,539
that allows it to learn such such such

1355
01:02:36,170 --> 01:02:44,720
interesting relationships I'm kind of oh

1356
01:02:41,539 --> 01:02:50,300
another question sure I'll speak louder

1357
01:02:44,719 --> 01:02:52,309
so are there he's in a meeting so I get

1358
01:02:50,300 --> 01:02:55,310
the the fundamental of be like the word

1359
01:02:52,309 --> 01:02:57,469
vector were to Vic vector algebra even

1360
01:02:55,309 --> 01:03:00,049
run on this thing are the embedding

1361
01:02:57,469 --> 01:03:02,989
suited suitable for certain types of

1362
01:03:00,050 --> 01:03:05,600
variables like or are these only

1363
01:03:02,989 --> 01:03:07,279
suitable for there are different

1364
01:03:05,599 --> 01:03:09,769
categories that that the embeddings are

1365
01:03:07,280 --> 01:03:13,550
suitable for an embedding is suitable

1366
01:03:09,769 --> 01:03:16,130
for any categorical variable okay so so

1367
01:03:13,550 --> 01:03:18,440
the only thing it it can't really work

1368
01:03:16,130 --> 01:03:20,900
well at all four would be something that

1369
01:03:18,440 --> 01:03:22,429
is too high cardinality so I'm like in

1370
01:03:20,900 --> 01:03:24,740
other words we had like whatever it was

1371
01:03:22,429 --> 01:03:26,329
six hundred thousand rows if you had a

1372
01:03:24,739 --> 01:03:29,919
variable with six hundred thousand

1373
01:03:26,329 --> 01:03:33,139
levels that's just not a useful

1374
01:03:29,920 --> 01:03:36,470
categorical variable you could packetize

1375
01:03:33,139 --> 01:03:38,659
it I guess but yeah in general like you

1376
01:03:36,469 --> 01:03:41,599
can see here that the the third place

1377
01:03:38,659 --> 01:03:45,199
getters in this competition really

1378
01:03:41,599 --> 01:03:47,000
decided that everything that was not too

1379
01:03:45,199 --> 01:03:47,859
high cardinality they put them all as

1380
01:03:47,000 --> 01:03:49,150
categorical very

1381
01:03:47,860 --> 01:03:51,849
and I think that's a good rule of thumb

1382
01:03:49,150 --> 01:03:54,309
you know if you can make a categorical

1383
01:03:51,849 --> 01:03:56,170
variable you may as well because that

1384
01:03:54,309 --> 01:03:58,059
way it can learn this rich distributed

1385
01:03:56,170 --> 01:04:00,369
representation where else if you leave

1386
01:03:58,059 --> 01:04:03,639
it as continuous you know the most it

1387
01:04:00,369 --> 01:04:05,469
can do is to kind of try and find a know

1388
01:04:03,639 --> 01:04:10,119
a single functional form that fits it

1389
01:04:05,469 --> 01:04:12,399
well after question so you were saying

1390
01:04:10,119 --> 01:04:15,670
that you are kind of increasing the

1391
01:04:12,400 --> 01:04:18,610
dimension but actually in most cases we

1392
01:04:15,670 --> 01:04:22,180
will use a one holding column which has

1393
01:04:18,610 --> 01:04:24,340
even a bigger dimension that so in a way

1394
01:04:22,179 --> 01:04:27,669
you are also reducing but in the most

1395
01:04:24,340 --> 01:04:31,000
reach I think that's very good yeah it

1396
01:04:27,670 --> 01:04:33,700
like yes you know you can figure this

1397
01:04:31,000 --> 01:04:36,159
one hot encoding which actually is high

1398
01:04:33,699 --> 01:04:37,659
dimensional but it's not meaningfully

1399
01:04:36,159 --> 01:04:39,250
high dimensional because everything set

1400
01:04:37,659 --> 01:04:41,379
one is easy right I'm saying that also

1401
01:04:39,250 --> 01:04:43,119
because even this will reduce the amount

1402
01:04:41,380 --> 01:04:46,750
of memory and things like this that you

1403
01:04:43,119 --> 01:04:49,329
have to write you're absolutely right

1404
01:04:46,750 --> 01:04:51,219
and and so we may as well go ahead and

1405
01:04:49,329 --> 01:04:52,719
actually destroyed like what's going on

1406
01:04:51,219 --> 01:04:54,939
with the matrix algebra behind the

1407
01:04:52,719 --> 01:04:56,619
scenes see this if this doesn't quite

1408
01:04:54,940 --> 01:04:58,420
make sense you can kind of skip over it

1409
01:04:56,619 --> 01:05:01,239
but for some people I know this really

1410
01:04:58,420 --> 01:05:06,070
helps if we started out with something

1411
01:05:01,239 --> 01:05:08,259
saying this is Sunday right we could

1412
01:05:06,070 --> 01:05:12,250
represent this as a one hot encoded

1413
01:05:08,260 --> 01:05:15,160
vector right and so Sunday you know

1414
01:05:12,250 --> 01:05:19,239
maybe was position here so that would be

1415
01:05:15,159 --> 01:05:23,319
a 1 and then the rest of zeros okay and

1416
01:05:19,239 --> 01:05:27,669
then we've got our embedding matrix

1417
01:05:23,320 --> 01:05:30,539
right with eight rows and in this case

1418
01:05:27,670 --> 01:05:30,539
four columns

1419
01:05:32,440 --> 01:05:38,059
one way to think of this actually is a

1420
01:05:35,000 --> 01:05:40,699
matrix product right so I said you could

1421
01:05:38,059 --> 01:05:43,789
think of this as like looking up the

1422
01:05:40,699 --> 01:05:46,519
number one you know and finding like its

1423
01:05:43,789 --> 01:05:49,220
index in the array but if you think

1424
01:05:46,519 --> 01:05:51,980
about it that's actually identical to

1425
01:05:49,219 --> 01:05:54,949
doing a matrix product between a one-pot

1426
01:05:51,980 --> 01:05:58,460
encoded vector and the embedding matrix

1427
01:05:54,949 --> 01:06:01,788
like you're going to go zero times this

1428
01:05:58,460 --> 01:06:04,789
row one times this row zero times this

1429
01:06:01,789 --> 01:06:08,569
row and so it's like a one hot embedding

1430
01:06:04,789 --> 01:06:13,010
matrix product is identical to during

1431
01:06:08,568 --> 01:06:15,679
the lookup and so some people in the bad

1432
01:06:13,010 --> 01:06:18,710
old days actually implemented embedding

1433
01:06:15,679 --> 01:06:21,169
matrices by doing a one hot encoding and

1434
01:06:18,710 --> 01:06:23,449
then a matrix product and in fact a lot

1435
01:06:21,170 --> 01:06:27,230
of like machine learning methods still

1436
01:06:23,449 --> 01:06:29,480
kind of do that but as you know that was

1437
01:06:27,230 --> 01:06:31,659
kind of alluding to it's that's terribly

1438
01:06:29,480 --> 01:06:34,490
inefficient so all of the modern

1439
01:06:31,659 --> 01:06:37,068
libraries implement this as taking take

1440
01:06:34,489 --> 01:06:39,199
an integer and do a lookup into an array

1441
01:06:37,068 --> 01:06:40,400
but the nice thing about realizing that

1442
01:06:39,199 --> 01:06:42,500
is actually a matrix product

1443
01:06:40,400 --> 01:06:45,170
mathematically is it makes it more

1444
01:06:42,500 --> 01:06:46,760
obvious how the gradients are going to

1445
01:06:45,170 --> 01:06:49,700
flow so when we do stochastic gradient

1446
01:06:46,760 --> 01:06:52,819
descent it's we can think of it as just

1447
01:06:49,699 --> 01:06:55,368
another linear layer okay does it say

1448
01:06:52,818 --> 01:06:59,509
that's like somewhat minor detail but

1449
01:06:55,369 --> 01:07:02,059
hopefully for some of you it helps could

1450
01:06:59,510 --> 01:07:03,460
you touch on using dates and times this

1451
01:07:02,059 --> 01:07:06,048
category course and how that affects

1452
01:07:03,460 --> 01:07:09,108
seasonality yeah absolutely that's a

1453
01:07:06,048 --> 01:07:15,019
great question did I cover dates it all

1454
01:07:09,108 --> 01:07:16,219
remember no okay so I cover dates in a

1455
01:07:15,019 --> 01:07:18,710
lot of detail in the machine learning

1456
01:07:16,219 --> 01:07:26,209
course but it's worth briefly mentioning

1457
01:07:18,710 --> 01:07:29,778
here there's a fast AI function called

1458
01:07:26,210 --> 01:07:33,170
add date part which takes a data frame

1459
01:07:29,778 --> 01:07:36,829
and column in that column name needs to

1460
01:07:33,170 --> 01:07:39,079
be a date it removes unless you squat

1461
01:07:36,829 --> 01:07:41,240
drop equals false it optionally removes

1462
01:07:39,079 --> 01:07:43,610
the column from the data frame and

1463
01:07:41,239 --> 01:07:45,829
replaces it with lots of column

1464
01:07:43,610 --> 01:07:48,829
representing all of the useful

1465
01:07:45,829 --> 01:07:51,679
information about that date like day of

1466
01:07:48,829 --> 01:07:52,969
week day of month month of year year is

1467
01:07:51,679 --> 01:07:54,619
at the start of the quarter is at the

1468
01:07:52,969 --> 01:07:59,569
end of the quarter basically everything

1469
01:07:54,619 --> 01:08:03,230
that pandas gives us and so that way we

1470
01:07:59,570 --> 01:08:04,910
end up when we look at our list of

1471
01:08:03,230 --> 01:08:08,900
features where you can see them here

1472
01:08:04,909 --> 01:08:13,190
right yeah month week data etc so these

1473
01:08:08,900 --> 01:08:19,720
all get created for us by a date pad so

1474
01:08:13,190 --> 01:08:23,690
we end up with you know this eight long

1475
01:08:19,720 --> 01:08:26,180
embedding matrix so I guess eight rows

1476
01:08:23,689 --> 01:08:29,179
by four column embedding matrix for day

1477
01:08:26,180 --> 01:08:32,210
of week and conceptually that allows us

1478
01:08:29,180 --> 01:08:34,579
or allows our model to create some

1479
01:08:32,210 --> 01:08:36,890
pretty interesting time series models

1480
01:08:34,579 --> 01:08:40,039
all right like it can if there's

1481
01:08:36,890 --> 01:08:43,070
something that has a seven day period

1482
01:08:40,039 --> 01:08:45,500
cycle that kind of goes up on Mondays

1483
01:08:43,069 --> 01:08:48,859
and down on Wednesdays but only for

1484
01:08:45,500 --> 01:08:50,300
dairy and only in Berlin it can totally

1485
01:08:48,859 --> 01:08:54,859
do that but it has all the information

1486
01:08:50,300 --> 01:08:57,199
it needs to do that so this turns out to

1487
01:08:54,859 --> 01:08:59,179
be a really fantastic way to deal with

1488
01:08:57,199 --> 01:09:01,010
time series so I'm really glad you asked

1489
01:08:59,180 --> 01:09:05,240
the question you just need to make sure

1490
01:09:01,010 --> 01:09:08,300
that that the the cycle indicator in

1491
01:09:05,239 --> 01:09:10,159
your time series exists as a column so

1492
01:09:08,300 --> 01:09:12,829
if you didn't have a column there called

1493
01:09:10,159 --> 01:09:15,559
day of week it would be very very

1494
01:09:12,829 --> 01:09:18,380
difficult for the neural network to

1495
01:09:15,560 --> 01:09:20,180
somehow learn to do like a divide mod

1496
01:09:18,380 --> 01:09:22,220
seven and then somehow look that up in

1497
01:09:20,180 --> 01:09:25,039
an omitting matrix like it not

1498
01:09:22,220 --> 01:09:26,600
impossible but really hard it would use

1499
01:09:25,039 --> 01:09:27,100
lots of computation wouldn't do it very

1500
01:09:26,600 --> 01:09:29,539
well

1501
01:09:27,100 --> 01:09:32,890
so an example of the kind of thing that

1502
01:09:29,539 --> 01:09:32,890
you need to think about might be

1503
01:09:33,310 --> 01:09:39,590
holidays for example you know or if you

1504
01:09:36,890 --> 01:09:42,710
are doing something in you know sales of

1505
01:09:39,590 --> 01:09:44,720
beverages in San Francisco you probably

1506
01:09:42,710 --> 01:09:47,380
want a list of like when weather that

1507
01:09:44,720 --> 01:09:49,430
when is the ball game on at AT&amp;T Park

1508
01:09:47,380 --> 01:09:51,800
because that's going to impact how many

1509
01:09:49,430 --> 01:09:54,829
people that are drinking beer in Soma

1510
01:09:51,800 --> 01:09:57,320
right so you need to make sure that the

1511
01:09:54,829 --> 01:09:59,840
kind of the basic indicators or

1512
01:09:57,319 --> 01:10:01,639
or periodicity x' or whatever there and

1513
01:09:59,840 --> 01:10:03,819
your data and as long as they are the

1514
01:10:01,640 --> 01:10:06,860
neuron it's going to learn to use them

1515
01:10:03,819 --> 01:10:12,049
so I'm kind of trying to skip over some

1516
01:10:06,859 --> 01:10:15,319
of the non deep learning parts alright

1517
01:10:12,050 --> 01:10:17,270
so the key thing here is that we've got

1518
01:10:15,319 --> 01:10:19,909
our model data that came from the data

1519
01:10:17,270 --> 01:10:23,360
frame we tell it how big to make the

1520
01:10:19,909 --> 01:10:26,889
embedding matrices we also have to

1521
01:10:23,359 --> 01:10:30,979
tailor of the columns in that data frame

1522
01:10:26,890 --> 01:10:32,539
how many of those categorical variables

1523
01:10:30,979 --> 01:10:34,639
or how many of them are continuous

1524
01:10:32,539 --> 01:10:37,220
variables so the actual parameter is

1525
01:10:34,640 --> 01:10:39,320
number of continuous variables so you

1526
01:10:37,220 --> 01:10:41,600
can here you can see we just pass in how

1527
01:10:39,319 --> 01:10:43,880
many columns are there - how many

1528
01:10:41,600 --> 01:10:47,630
categorical variables are there so then

1529
01:10:43,880 --> 01:10:49,340
that way the the neural net knows how to

1530
01:10:47,630 --> 01:10:51,199
create something that puts the

1531
01:10:49,340 --> 01:10:55,010
continuous variables over here and the

1532
01:10:51,199 --> 01:10:57,920
categorical variables over there the

1533
01:10:55,010 --> 01:11:00,409
embedding matrix has its own drop out

1534
01:10:57,920 --> 01:11:02,840
alright so this is the dropout to apply

1535
01:11:00,409 --> 01:11:04,189
to the embedding matrix this is the

1536
01:11:02,840 --> 01:11:06,319
number of activations in the first

1537
01:11:04,189 --> 01:11:08,929
linear player the number of activations

1538
01:11:06,319 --> 01:11:10,819
in the second linear layer the dropout

1539
01:11:08,930 --> 01:11:12,980
in the first linear player the drop out

1540
01:11:10,819 --> 01:11:14,659
for the second linear layer this bit we

1541
01:11:12,979 --> 01:11:16,609
won't worry about for now and then

1542
01:11:14,659 --> 01:11:19,130
finally is how many outputs do we want

1543
01:11:16,609 --> 01:11:20,689
to create okay so this is the output of

1544
01:11:19,130 --> 01:11:22,909
the last mini layer and obviously it's

1545
01:11:20,689 --> 01:11:28,369
one because we want to predict a single

1546
01:11:22,909 --> 01:11:30,409
number which is sales okay so after that

1547
01:11:28,369 --> 01:11:32,539
we now have a learner where we can call

1548
01:11:30,409 --> 01:11:35,000
LR find and we get the standard looking

1549
01:11:32,539 --> 01:11:39,130
shape and we can say what amount do we

1550
01:11:35,000 --> 01:11:41,750
want to use and we can then go ahead and

1551
01:11:39,130 --> 01:11:45,770
start training using exactly the same

1552
01:11:41,750 --> 01:11:49,550
API we've seen before so this is all

1553
01:11:45,770 --> 01:11:51,530
identical you can pass in I'm not sure

1554
01:11:49,550 --> 01:11:54,020
if you've seen this before custom

1555
01:11:51,529 --> 01:11:56,149
metrics what this does is it just says

1556
01:11:54,020 --> 01:11:58,720
please print out a number at the end of

1557
01:11:56,149 --> 01:12:01,069
every epoch by calling this function

1558
01:11:58,720 --> 01:12:03,860
this is a function we defined a little

1559
01:12:01,069 --> 01:12:05,779
bit earlier which was the root means

1560
01:12:03,859 --> 01:12:08,420
bread percentage error first of all

1561
01:12:05,779 --> 01:12:10,859
going either the power of our sales

1562
01:12:08,420 --> 01:12:12,899
because our sales were

1563
01:12:10,859 --> 01:12:15,929
originally logged so this doesn't change

1564
01:12:12,899 --> 01:12:18,569
the training at all it just it's just

1565
01:12:15,929 --> 01:12:22,949
something to print out so we trained

1566
01:12:18,569 --> 01:12:25,500
that for a while and you know we've got

1567
01:12:22,948 --> 01:12:28,349
some benefits that the original people

1568
01:12:25,500 --> 01:12:31,800
that built this don't have specifically

1569
01:12:28,350 --> 01:12:33,150
we've got things like cyclic all muscle

1570
01:12:31,800 --> 01:12:35,489
learning rate stochastic gradient

1571
01:12:33,149 --> 01:12:37,019
descent with restarts and so it's

1572
01:12:35,488 --> 01:12:42,479
actually interesting to have a look and

1573
01:12:37,020 --> 01:12:45,060
compare although our validation set

1574
01:12:42,479 --> 01:12:47,399
isn't identical to the test set it's

1575
01:12:45,060 --> 01:12:49,619
very similar it's a two-week period that

1576
01:12:47,399 --> 01:12:52,529
is at the end of the training data and

1577
01:12:49,618 --> 01:12:54,839
so our numbers should be similar and if

1578
01:12:52,529 --> 01:12:58,759
we look at what we get point oh nine

1579
01:12:54,840 --> 01:13:06,210
seven and compare that to the

1580
01:12:58,760 --> 01:13:12,000
leaderboard public leaderboard you can

1581
01:13:06,210 --> 01:13:16,800
see we're kind of sort of look in the

1582
01:13:12,000 --> 01:13:18,179
top actually that's interesting there is

1583
01:13:16,800 --> 01:13:20,039
a big difference between the public and

1584
01:13:18,179 --> 01:13:21,480
private leaderboard it would have it

1585
01:13:20,039 --> 01:13:24,210
would have been right at the top of the

1586
01:13:21,479 --> 01:13:25,408
private leaderboard but only in the top

1587
01:13:24,210 --> 01:13:27,060
thirty or forty on the public

1588
01:13:25,408 --> 01:13:30,448
leaderboards so not quite sure but you

1589
01:13:27,060 --> 01:13:35,100
can see like we're certainly in the top

1590
01:13:30,448 --> 01:13:37,799
end of this competition I actually tried

1591
01:13:35,100 --> 01:13:41,070
running the third place to get his code

1592
01:13:37,800 --> 01:13:44,219
and their final result was over a point

1593
01:13:41,069 --> 01:13:46,259
one so I actually think that we're

1594
01:13:44,219 --> 01:13:50,279
trippy compared to private leaderboard

1595
01:13:46,260 --> 01:13:51,860
but I'm not sure so anyway so you can

1596
01:13:50,279 --> 01:13:55,229
see they're basically there's a

1597
01:13:51,859 --> 01:13:58,170
technique for dealing with time series

1598
01:13:55,229 --> 01:14:01,500
and structured data and you know

1599
01:13:58,170 --> 01:14:02,760
interestingly the group that that used

1600
01:14:01,500 --> 01:14:04,229
this technique they actually wrote a

1601
01:14:02,760 --> 01:14:08,369
paper about it that's linked in this

1602
01:14:04,229 --> 01:14:11,189
notebook when you compare it to the

1603
01:14:08,368 --> 01:14:13,948
folks that won this competition and came

1604
01:14:11,189 --> 01:14:16,229
second they did the other folks did way

1605
01:14:13,948 --> 01:14:18,059
more feature engineering like the

1606
01:14:16,229 --> 01:14:20,459
winners of this competition were

1607
01:14:18,060 --> 01:14:23,310
actually subject matter experts in

1608
01:14:20,460 --> 01:14:25,500
logistics sales forecasting and so they

1609
01:14:23,310 --> 01:14:28,710
had their own code to create lots and

1610
01:14:25,500 --> 01:14:31,198
lots of features and talking to the

1611
01:14:28,710 --> 01:14:33,029
folks at Pinterest who built their very

1612
01:14:31,198 --> 01:14:35,189
similar model for recommendations for

1613
01:14:33,029 --> 01:14:36,960
Pinterest they say the same thing which

1614
01:14:35,189 --> 01:14:39,509
is that when they switched from gradient

1615
01:14:36,960 --> 01:14:43,230
boosting machines to deep learning they

1616
01:14:39,510 --> 01:14:45,449
did like way way way less feature

1617
01:14:43,229 --> 01:14:47,928
engineering it was a much much simpler

1618
01:14:45,448 --> 01:14:50,219
model and requires much less maintenance

1619
01:14:47,929 --> 01:14:51,840
and so this is like one of the big

1620
01:14:50,219 --> 01:14:53,908
benefits of using this approach to deep

1621
01:14:51,840 --> 01:15:00,619
learning you can get state of the at

1622
01:14:53,908 --> 01:15:00,618
results but with a lot less work yes

1623
01:15:01,988 --> 01:15:11,139
are you using any time series in any of

1624
01:15:05,920 --> 01:15:13,779
these fits indirectly absolutely using

1625
01:15:11,140 --> 01:15:16,680
what we just saw we have a day of week

1626
01:15:13,779 --> 01:15:18,969
month of year all that stuff our columns

1627
01:15:16,680 --> 01:15:21,100
and most of them are being treated as

1628
01:15:18,969 --> 01:15:23,050
categories so we're building a

1629
01:15:21,100 --> 01:15:24,610
distributed representation of January

1630
01:15:23,050 --> 01:15:26,619
we're building a distributed

1631
01:15:24,609 --> 01:15:27,939
representation of Sunday we're building

1632
01:15:26,619 --> 01:15:28,719
a distributed representation of

1633
01:15:27,939 --> 01:15:33,250
Christmas

1634
01:15:28,719 --> 01:15:36,359
so we're not using any plastic time

1635
01:15:33,250 --> 01:15:39,039
series techniques all we're doing is

1636
01:15:36,359 --> 01:15:42,309
true fully connected layers in a neural

1637
01:15:39,039 --> 01:15:45,670
net better metrics

1638
01:15:42,310 --> 01:15:47,739
that's what exactly exactly yeah so the

1639
01:15:45,670 --> 01:15:50,380
embedding matrix is able to deal with

1640
01:15:47,738 --> 01:15:54,909
this stuff like day of week periodicity

1641
01:15:50,380 --> 01:15:58,000
and so forth in a way richer way than

1642
01:15:54,909 --> 01:15:58,829
any standard time series technique I've

1643
01:15:58,000 --> 01:16:03,100
ever come across

1644
01:15:58,829 --> 01:16:06,850
one last question the matrix in the

1645
01:16:03,100 --> 01:16:10,120
earlier models we did CNN did not pass

1646
01:16:06,850 --> 01:16:14,380
it during the fig we passed it when the

1647
01:16:10,119 --> 01:16:17,079
data was when we got the data so we're

1648
01:16:14,380 --> 01:16:18,989
not passing anything to fit just the

1649
01:16:17,079 --> 01:16:21,519
learning rate and the number of cycles

1650
01:16:18,988 --> 01:16:24,968
in this case we're passing in metrics is

1651
01:16:21,520 --> 01:16:27,430
not a printout some extra stuff there is

1652
01:16:24,969 --> 01:16:28,510
a difference in the we're calling data

1653
01:16:27,430 --> 01:16:35,619
get learner

1654
01:16:28,510 --> 01:16:38,969
so with the imaging approach we just go

1655
01:16:35,619 --> 01:16:43,840
learner dot trained and pass at the data

1656
01:16:38,969 --> 01:16:46,270
but in for these kinds of models in fact

1657
01:16:43,840 --> 01:16:49,239
for a lot of the models the model that

1658
01:16:46,270 --> 01:16:51,790
we build depends on the data in this

1659
01:16:49,238 --> 01:16:54,729
case we actually need to know like what

1660
01:16:51,789 --> 01:16:56,829
embedding matrices do we have and stuff

1661
01:16:54,729 --> 01:16:59,199
like that so in this case it's actually

1662
01:16:56,829 --> 01:17:01,930
the data object that creates the learner

1663
01:16:59,199 --> 01:17:04,469
so yeah it is it is a bit upside down to

1664
01:17:01,930 --> 01:17:04,469
what we've seen before

1665
01:17:04,639 --> 01:17:10,800
yeah so just to summarize or maybe I'm

1666
01:17:09,328 --> 01:17:14,399
confused

1667
01:17:10,800 --> 01:17:16,260
so in this case what we are doing is

1668
01:17:14,399 --> 01:17:20,399
that we have some kind of structured

1669
01:17:16,260 --> 01:17:25,159
data did feature engineering we got some

1670
01:17:20,399 --> 01:17:25,158
columnar database or something

1671
01:17:32,599 --> 01:17:38,099
embedding matrix for the categorical

1672
01:17:35,698 --> 01:17:46,589
variables so the continuous we just put

1673
01:17:38,099 --> 01:17:49,260
them straight feature engineering yeah

1674
01:17:46,590 --> 01:17:54,210
then to map it to deep learning I just

1675
01:17:49,260 --> 01:17:54,869
have to figure out which one I can great

1676
01:17:54,210 --> 01:17:57,779
question

1677
01:17:54,868 --> 01:18:01,768
so yes exactly if you want to use this

1678
01:17:57,779 --> 01:18:04,050
on your own data set step one is list

1679
01:18:01,769 --> 01:18:07,380
the categorical variable names list the

1680
01:18:04,050 --> 01:18:11,760
continuous variable names put it in a

1681
01:18:07,380 --> 01:18:17,609
data frame pandas dataframe step two is

1682
01:18:11,760 --> 01:18:20,489
to create a list of which row indexes do

1683
01:18:17,609 --> 01:18:25,859
you want in your validation set step

1684
01:18:20,488 --> 01:18:27,748
three is to call this line of code using

1685
01:18:25,859 --> 01:18:31,529
this except like these exact you can

1686
01:18:27,748 --> 01:18:33,779
just copy and paste it step four is to

1687
01:18:31,529 --> 01:18:37,259
create your list of how big you want

1688
01:18:33,779 --> 01:18:41,189
each embedding matrix to be and then

1689
01:18:37,260 --> 01:18:44,340
step 5 is to call get loner you can use

1690
01:18:41,189 --> 01:18:46,228
these exact parameters to start with and

1691
01:18:44,340 --> 01:18:48,239
if it over fits or under fits you can

1692
01:18:46,229 --> 01:18:53,099
fiddle with them and then the final step

1693
01:18:48,238 --> 01:18:56,268
is to call fit so yeah almost all of

1694
01:18:53,099 --> 01:18:56,269
this code will be nearly identical

1695
01:18:59,619 --> 01:19:07,399
have a couple of questions one is how is

1696
01:19:04,220 --> 01:19:12,409
data element ation can be used in this

1697
01:19:07,399 --> 01:19:14,000
case and the second one is why whatever

1698
01:19:12,409 --> 01:19:16,819
dropouts doing in here

1699
01:19:14,000 --> 01:19:17,630
okay so data augmentation I have no idea

1700
01:19:16,819 --> 01:19:20,079
I mean that's a really interesting

1701
01:19:17,630 --> 01:19:20,079
question

1702
01:19:21,199 --> 01:19:25,220
I think it's gotta be domain-specific

1703
01:19:22,609 --> 01:19:27,199
I've never seen any paper or anybody in

1704
01:19:25,220 --> 01:19:29,960
industry doing data augmentation with

1705
01:19:27,199 --> 01:19:31,579
structured data and deep blow so I don't

1706
01:19:29,960 --> 01:19:32,680
think it can be done I just haven't seen

1707
01:19:31,579 --> 01:19:36,769
it done

1708
01:19:32,680 --> 01:19:45,950
what is dropout doing exactly the same

1709
01:19:36,770 --> 01:19:48,020
as before so at each point we have the

1710
01:19:45,949 --> 01:19:52,460
output of each of these linear layers is

1711
01:19:48,020 --> 01:19:54,470
just a rank one tensor and so dropout is

1712
01:19:52,460 --> 01:19:58,250
going to go ahead and say let's throw

1713
01:19:54,470 --> 01:20:00,110
away half of the activations and the

1714
01:19:58,250 --> 01:20:01,819
very first dropout imbedding drop out

1715
01:20:00,109 --> 01:20:07,130
literally goes through the embedding

1716
01:20:01,819 --> 01:20:12,859
matrix and says let's throw away half

1717
01:20:07,130 --> 01:20:16,340
the activations that's it okay let's

1718
01:20:12,859 --> 01:20:30,219
take a break and let's come back at five

1719
01:20:16,340 --> 01:20:34,130
past eight okay thanks everybody so now

1720
01:20:30,220 --> 01:20:36,350
we're gonna move into something equally

1721
01:20:34,130 --> 01:20:38,000
exciting actually before I do I just

1722
01:20:36,350 --> 01:20:41,960
been sure that I had a good question

1723
01:20:38,000 --> 01:20:42,710
during the break which was what's the

1724
01:20:41,960 --> 01:20:49,369
downside

1725
01:20:42,710 --> 01:20:53,359
like like almost no one's using this why

1726
01:20:49,369 --> 01:20:55,909
not and and basically I think the answer

1727
01:20:53,359 --> 01:20:57,529
is like as we discussed before no one in

1728
01:20:55,909 --> 01:20:59,479
academia almost is working on this

1729
01:20:57,529 --> 01:21:04,579
because it's not something that people

1730
01:20:59,479 --> 01:21:06,500
really publish on and as a result there

1731
01:21:04,579 --> 01:21:07,939
haven't been really great examples where

1732
01:21:06,500 --> 01:21:10,100
people could look at and say oh here's a

1733
01:21:07,939 --> 01:21:12,769
technique that works well so let's have

1734
01:21:10,100 --> 01:21:16,220
our company implement it but perhaps

1735
01:21:12,770 --> 01:21:18,580
equally importantly until now with this

1736
01:21:16,220 --> 01:21:23,030
fast AI library there hasn't been any

1737
01:21:18,579 --> 01:21:25,550
way to do it conveniently if you wanted

1738
01:21:23,029 --> 01:21:28,340
to implement one of these models you had

1739
01:21:25,550 --> 01:21:30,860
to write all the custom code yourself

1740
01:21:28,340 --> 01:21:33,470
where else now as we discussed it's you

1741
01:21:30,859 --> 01:21:36,869
know sick

1742
01:21:33,470 --> 01:21:39,270
it's basically a six step process you

1743
01:21:36,869 --> 01:21:43,170
know involving about you know not much

1744
01:21:39,270 --> 01:21:44,880
more than six lines of code so the

1745
01:21:43,170 --> 01:21:47,340
reason I mentioned this is to say like I

1746
01:21:44,880 --> 01:21:51,569
think there are a lot of big commercial

1747
01:21:47,340 --> 01:21:53,550
and scientific opportunities to use this

1748
01:21:51,569 --> 01:21:57,809
to solve problems that previously

1749
01:21:53,550 --> 01:21:59,100
haven't been solved very well before so

1750
01:21:57,810 --> 01:22:02,730
like I'll be really interested to hear

1751
01:21:59,100 --> 01:22:06,210
if some of you try this out you know

1752
01:22:02,729 --> 01:22:08,009
maybe on like old cattle competitions

1753
01:22:06,210 --> 01:22:09,689
you might find like oh I would have won

1754
01:22:08,010 --> 01:22:11,190
this if I'd use this technique that

1755
01:22:09,689 --> 01:22:13,949
would be interesting or if you've got

1756
01:22:11,189 --> 01:22:15,750
some data set you work with at work

1757
01:22:13,949 --> 01:22:17,639
without some kind of model that you've

1758
01:22:15,750 --> 01:22:22,560
been doing to the GBM or a random forest

1759
01:22:17,640 --> 01:22:25,050
does this help you know the thing I I'm

1760
01:22:22,560 --> 01:22:28,230
still somewhat new to this I've been

1761
01:22:25,050 --> 01:22:29,640
doing this for basically since the start

1762
01:22:28,229 --> 01:22:31,889
of the year was when I started working

1763
01:22:29,640 --> 01:22:34,500
on these structured deep learning models

1764
01:22:31,890 --> 01:22:37,950
so I haven't had enough opportunity to

1765
01:22:34,500 --> 01:22:39,300
know where might it fail it's worked for

1766
01:22:37,949 --> 01:22:43,500
nearly everything I've tried it with so

1767
01:22:39,300 --> 01:22:46,590
far but yeah I think this class is the

1768
01:22:43,500 --> 01:22:48,689
first time that there's going to be like

1769
01:22:46,590 --> 01:22:50,670
more than half a dozen people fulfilled

1770
01:22:48,689 --> 01:22:51,960
who actually are working on this so I

1771
01:22:50,670 --> 01:22:54,539
think you know as a group we're gonna

1772
01:22:51,960 --> 01:22:55,710
hopefully learn a lot and build some

1773
01:22:54,539 --> 01:22:56,789
interesting things and this would be a

1774
01:22:55,710 --> 01:22:59,730
great thing if you're thinking of

1775
01:22:56,789 --> 01:23:02,729
writing a post about something or here's

1776
01:22:59,729 --> 01:23:04,889
an area that there's a couple of that

1777
01:23:02,729 --> 01:23:09,539
there's a poster in staccato about what

1778
01:23:04,890 --> 01:23:11,940
they did Pinterest has a an O'Reilly a a

1779
01:23:09,539 --> 01:23:15,060
video about what they did that's about

1780
01:23:11,939 --> 01:23:17,939
it and there's two academic papers both

1781
01:23:15,060 --> 01:23:21,539
about Carroll competition victories one

1782
01:23:17,939 --> 01:23:25,559
from Yoshi Joshua Ben geo and his group

1783
01:23:21,539 --> 01:23:28,640
they won a taxi destination forecasting

1784
01:23:25,560 --> 01:23:33,060
competition and then also the one linked

1785
01:23:28,640 --> 01:23:33,960
for this rossmann competition so yeah

1786
01:23:33,060 --> 01:23:38,670
there's some background on that

1787
01:23:33,960 --> 01:23:44,789
alright so language natural language

1788
01:23:38,670 --> 01:23:47,210
processing is the area which is kind of

1789
01:23:44,789 --> 01:23:48,829
like the most up-and-coming area

1790
01:23:47,210 --> 01:23:52,730
moaning it's kind of like two or three

1791
01:23:48,829 --> 01:23:54,529
years behind computer vision in deep

1792
01:23:52,729 --> 01:23:57,049
learning it was kind of like the the

1793
01:23:54,529 --> 01:23:59,960
second area that deep learning started

1794
01:23:57,050 --> 01:24:03,230
getting really popular in and you know

1795
01:23:59,960 --> 01:24:06,079
computer vision got to the point where

1796
01:24:03,229 --> 01:24:07,939
it was like clear state of the art for

1797
01:24:06,079 --> 01:24:10,819
most computer vision things maybe in

1798
01:24:07,939 --> 01:24:14,210
like 2014 you know and in some things in

1799
01:24:10,819 --> 01:24:17,179
like 2012 in NLP we're still at the

1800
01:24:14,210 --> 01:24:18,980
point where for a lot of things deep

1801
01:24:17,180 --> 01:24:21,310
learning is now the state of the art but

1802
01:24:18,979 --> 01:24:25,759
not quite everything but as you'll see

1803
01:24:21,310 --> 01:24:28,550
the state of kind of the software and

1804
01:24:25,760 --> 01:24:32,060
some of the concepts is much less mature

1805
01:24:28,550 --> 01:24:33,890
than it is for computer vision so in

1806
01:24:32,060 --> 01:24:34,280
general none of the stuff we talked

1807
01:24:33,890 --> 01:24:36,230
about

1808
01:24:34,279 --> 01:24:39,619
after computer vision is going to be as

1809
01:24:36,229 --> 01:24:42,469
like settled as the computer vision and

1810
01:24:39,619 --> 01:24:45,289
stuff was so NLP one of the interesting

1811
01:24:42,470 --> 01:24:47,360
things is in the last few months some of

1812
01:24:45,289 --> 01:24:49,760
the good ideas from computer vision have

1813
01:24:47,359 --> 01:24:51,199
started to spread into NLP for the first

1814
01:24:49,760 --> 01:24:52,730
time and we've seen some really big

1815
01:24:51,199 --> 01:24:57,859
advances so a lot of the stuff you'll

1816
01:24:52,729 --> 01:25:01,579
see in NLP is is pretty new so I'm going

1817
01:24:57,859 --> 01:25:03,380
to start with a particular kind of NLP

1818
01:25:01,579 --> 01:25:04,819
problem and one of the things refined in

1819
01:25:03,380 --> 01:25:06,770
NLP is like there are particular

1820
01:25:04,819 --> 01:25:08,960
problems you can solve and they have

1821
01:25:06,770 --> 01:25:10,850
particular names and so there's a

1822
01:25:08,960 --> 01:25:13,520
particular kind of problem in NLP called

1823
01:25:10,850 --> 01:25:15,650
language modeling and language modeling

1824
01:25:13,520 --> 01:25:19,280
has a very specific definition that

1825
01:25:15,649 --> 01:25:21,949
means build a model we're given a few

1826
01:25:19,279 --> 01:25:24,529
words of a sentence can you predict what

1827
01:25:21,949 --> 01:25:26,689
the next word is going to be so if

1828
01:25:24,529 --> 01:25:28,819
you're using your mobile phone and

1829
01:25:26,689 --> 01:25:30,529
you're typing away and you press space

1830
01:25:28,819 --> 01:25:33,079
and then it says like this is what the

1831
01:25:30,529 --> 01:25:35,239
next word might be like SwiftKey does

1832
01:25:33,079 --> 01:25:36,909
this like really well and SwiftKey

1833
01:25:35,239 --> 01:25:40,130
actually uses deep learning for this

1834
01:25:36,909 --> 01:25:41,809
that's that's a language model okay so

1835
01:25:40,130 --> 01:25:44,090
it has a very specific meaning when we

1836
01:25:41,810 --> 01:25:46,550
say language modeling we mean a model

1837
01:25:44,090 --> 01:25:48,150
that can predict the next word of a

1838
01:25:46,550 --> 01:25:49,940
sentence

1839
01:25:48,149 --> 01:25:54,619
so let me give you an example I

1840
01:25:49,939 --> 01:25:57,509
downloaded about 18 months worth of

1841
01:25:54,619 --> 01:26:01,050
papers from archive so for those of you

1842
01:25:57,510 --> 01:26:03,659
that don't know what archive is the most

1843
01:26:01,050 --> 01:26:07,140
popular preprint server in this

1844
01:26:03,659 --> 01:26:10,380
community and various others and has you

1845
01:26:07,140 --> 01:26:14,910
know lots of academic papers and so I

1846
01:26:10,380 --> 01:26:16,920
grabbed the abstracts and the topics for

1847
01:26:14,909 --> 01:26:18,960
each and so here's an example so the

1848
01:26:16,920 --> 01:26:21,480
category of this particular paper what

1849
01:26:18,960 --> 01:26:24,420
computer CSMA is computer science and

1850
01:26:21,479 --> 01:26:26,489
networking and then the summary let the

1851
01:26:24,420 --> 01:26:28,590
abstract of the paper they're seeing the

1852
01:26:26,489 --> 01:26:30,809
exploitation of mm-wave bands is one of

1853
01:26:28,590 --> 01:26:35,670
the key enabler for 5g mobile bla bla

1854
01:26:30,810 --> 01:26:39,990
bla okay so here's like an example piece

1855
01:26:35,670 --> 01:26:41,550
of text from my language model so I

1856
01:26:39,989 --> 01:26:44,010
trained a language model on this

1857
01:26:41,550 --> 01:26:46,739
archived data set that I downloaded and

1858
01:26:44,010 --> 01:26:50,970
then I built a simple little test which

1859
01:26:46,739 --> 01:26:53,039
basically you would pass it some like

1860
01:26:50,970 --> 01:26:54,449
priming text so you'd say like Oh

1861
01:26:53,039 --> 01:26:57,630
imagine you started reading a document

1862
01:26:54,449 --> 01:27:00,899
that said category is computer science

1863
01:26:57,630 --> 01:27:04,529
networking and the summary is algorithms

1864
01:27:00,899 --> 01:27:07,319
that and then I said please write an

1865
01:27:04,529 --> 01:27:08,449
archive abstract so it said that if it's

1866
01:27:07,319 --> 01:27:11,639
networking

1867
01:27:08,449 --> 01:27:13,229
algorithms that use the same network as

1868
01:27:11,640 --> 01:27:14,850
a single node I'm not able to achieve

1869
01:27:13,229 --> 01:27:16,889
the same performance as a traditional

1870
01:27:14,850 --> 01:27:18,750
network based routing algorithms in this

1871
01:27:16,890 --> 01:27:22,289
paper we propose a novel routing scheme

1872
01:27:18,750 --> 01:27:24,779
but okay so it it's learnt by reading

1873
01:27:22,289 --> 01:27:27,989
archive papers that somebody who is

1874
01:27:24,779 --> 01:27:31,439
playing algorithms that where the word

1875
01:27:27,989 --> 01:27:34,050
cat CSM ie came before it is going to

1876
01:27:31,439 --> 01:27:36,779
talk like this and remember it started

1877
01:27:34,050 --> 01:27:38,820
out not knowing English at all right it

1878
01:27:36,779 --> 01:27:41,699
actually started out with an embedding

1879
01:27:38,819 --> 01:27:44,789
matrix for every word in English that

1880
01:27:41,699 --> 01:27:46,949
was random okay and by reading lots of

1881
01:27:44,789 --> 01:27:48,420
archive papers it weren't what kind of

1882
01:27:46,949 --> 01:27:51,329
words followed others so then I tried

1883
01:27:48,420 --> 01:27:55,340
what if we said cat computer science

1884
01:27:51,329 --> 01:27:58,859
computer vision summary algorithms that

1885
01:27:55,340 --> 01:28:00,600
use the same data to perform image

1886
01:27:58,859 --> 01:28:01,289
specification are increasingly being

1887
01:28:00,600 --> 01:28:02,430
used to

1888
01:28:01,289 --> 01:28:04,619
proves the performance of image

1889
01:28:02,430 --> 01:28:06,270
classification algorithms and this paper

1890
01:28:04,619 --> 01:28:07,559
we propose a novel method for image

1891
01:28:06,270 --> 01:28:09,390
specification using a deeper

1892
01:28:07,560 --> 01:28:12,990
convolutional neural network parentheses

1893
01:28:09,390 --> 01:28:15,630
CNN so you can see like it's kind of

1894
01:28:12,989 --> 01:28:17,880
like almost the same sentence as back

1895
01:28:15,630 --> 01:28:20,190
here but things have just changed into

1896
01:28:17,880 --> 01:28:22,710
this world of computer vision rather

1897
01:28:20,189 --> 01:28:24,329
than networking so I tried something

1898
01:28:22,710 --> 01:28:26,939
else which is like okay category

1899
01:28:24,329 --> 01:28:28,859
computer vision and I created the

1900
01:28:26,939 --> 01:28:32,909
world's shortest ever abstract that

1901
01:28:28,859 --> 01:28:35,009
words and then I said title on and the

1902
01:28:32,909 --> 01:28:36,630
title of this is going to be on that

1903
01:28:35,010 --> 01:28:39,210
performance object learning for image

1904
01:28:36,630 --> 01:28:42,180
classification in OS is end of string so

1905
01:28:39,210 --> 01:28:44,640
that's like end of title what if it is

1906
01:28:42,180 --> 01:28:47,130
networking summary algorithms title on

1907
01:28:44,640 --> 01:28:50,490
the performance of wireless networks as

1908
01:28:47,130 --> 01:28:52,739
opposed to towards computer vision

1909
01:28:50,489 --> 01:28:55,590
towards a new approach to image

1910
01:28:52,739 --> 01:28:57,329
specification networking towards then

1911
01:28:55,590 --> 01:29:00,420
you approach to the analysis of wireless

1912
01:28:57,329 --> 01:29:02,939
networks so like I find this

1913
01:29:00,420 --> 01:29:06,060
mind-blowing right I started out with

1914
01:29:02,939 --> 01:29:09,960
some random matrices which had like

1915
01:29:06,060 --> 01:29:12,660
literally no no pre-trade anything

1916
01:29:09,960 --> 01:29:15,659
I fed at 18 months worth of archived

1917
01:29:12,659 --> 01:29:19,500
articles and it learnt not only how to

1918
01:29:15,659 --> 01:29:20,789
write English pretty well but also after

1919
01:29:19,500 --> 01:29:22,470
you say something's a convolutional

1920
01:29:20,789 --> 01:29:24,529
neural network you should then use

1921
01:29:22,470 --> 01:29:27,150
parentheses to say what it's called and

1922
01:29:24,529 --> 01:29:28,800
furthermore that the kinds of things

1923
01:29:27,149 --> 01:29:31,889
people talk could say create algorithms

1924
01:29:28,800 --> 01:29:33,779
for in computer vision are performing

1925
01:29:31,890 --> 01:29:37,740
image classification and in networking

1926
01:29:33,779 --> 01:29:38,849
are achieving the same performance as

1927
01:29:37,739 --> 01:29:42,649
traditional network based routing

1928
01:29:38,850 --> 01:29:47,360
algorithms so like a language model is

1929
01:29:42,649 --> 01:29:49,559
can be like incredibly deep and subtle

1930
01:29:47,359 --> 01:29:52,619
right and so we're going to try and

1931
01:29:49,560 --> 01:29:55,289
build that but actually not because we

1932
01:29:52,619 --> 01:29:56,880
care about this at all we're going to

1933
01:29:55,289 --> 01:29:58,739
build it because we're going to try and

1934
01:29:56,880 --> 01:30:00,829
create a pre-trained model what we're

1935
01:29:58,739 --> 01:30:04,139
actually going to try and do is take

1936
01:30:00,829 --> 01:30:07,350
IMDB movie reviews and figure out

1937
01:30:04,140 --> 01:30:08,820
whether they're positive or negative so

1938
01:30:07,350 --> 01:30:09,840
if you think about it this is a lot like

1939
01:30:08,819 --> 01:30:12,069
cats vs. dogs

1940
01:30:09,840 --> 01:30:14,380
that's a classification algorithm

1941
01:30:12,069 --> 01:30:18,279
but rather than an image we're going to

1942
01:30:14,380 --> 01:30:19,810
have the text of a review so I'd really

1943
01:30:18,279 --> 01:30:22,179
like to use a pre-trained Network

1944
01:30:19,810 --> 01:30:24,789
like I would at least my connect to

1945
01:30:22,179 --> 01:30:29,560
start with a network that knows how to

1946
01:30:24,789 --> 01:30:31,630
read English right and so my view was

1947
01:30:29,560 --> 01:30:33,610
like okay to know how to read English

1948
01:30:31,630 --> 01:30:36,190
means you should be able to like predict

1949
01:30:33,609 --> 01:30:39,789
the next word of a sentence so what if

1950
01:30:36,189 --> 01:30:42,009
we pre train a language model and then

1951
01:30:39,789 --> 01:30:44,408
use that pre-trained language model and

1952
01:30:42,010 --> 01:30:46,599
then just like in computer vision stick

1953
01:30:44,408 --> 01:30:48,848
some new layers on the end and ask it

1954
01:30:46,599 --> 01:30:51,489
instead of - predicting the next word in

1955
01:30:48,849 --> 01:30:54,130
the sentence instead predict whether

1956
01:30:51,488 --> 01:30:57,039
something is positive or negative so

1957
01:30:54,130 --> 01:30:59,828
when I started working on this this was

1958
01:30:57,039 --> 01:31:01,389
actually a new idea unfortunately in the

1959
01:30:59,828 --> 01:31:02,439
last couple of months I've been doing it

1960
01:31:01,389 --> 01:31:04,150
you know a few people have actually

1961
01:31:02,439 --> 01:31:06,250
couple people started publishing this

1962
01:31:04,149 --> 01:31:08,859
and so this has moved from being a

1963
01:31:06,250 --> 01:31:14,219
totally new idea to being a you know

1964
01:31:08,859 --> 01:31:17,529
somewhat new idea so so this idea of

1965
01:31:14,219 --> 01:31:18,939
creating a language model making that

1966
01:31:17,529 --> 01:31:21,009
the pre-trained model for a

1967
01:31:18,939 --> 01:31:23,979
classification model is what we're going

1968
01:31:21,010 --> 01:31:25,420
to learn to do now and so the idea is

1969
01:31:23,979 --> 01:31:28,000
we're really kind of trying to leverage

1970
01:31:25,420 --> 01:31:30,550
exactly what we learnt in our computer

1971
01:31:28,000 --> 01:31:32,710
vision work which is how do we do fine

1972
01:31:30,550 --> 01:31:36,789
tuning to create powerful classification

1973
01:31:32,710 --> 01:31:40,000
models yes you know so why don't you

1974
01:31:36,789 --> 01:31:44,219
think that doing just directly what you

1975
01:31:40,000 --> 01:31:47,109
want to do doesn't work better well

1976
01:31:44,219 --> 01:31:50,230
because it doesn't just turns out it

1977
01:31:47,109 --> 01:31:54,399
doesn't empirically and the reason it

1978
01:31:50,229 --> 01:31:58,388
doesn't is a number of things first of

1979
01:31:54,399 --> 01:32:01,359
all as we know fine-tuning a pre-trained

1980
01:31:58,389 --> 01:32:04,150
network is really powerful right so if

1981
01:32:01,359 --> 01:32:06,609
we can get it to learn some related

1982
01:32:04,149 --> 01:32:09,609
tasks first then we can use all that

1983
01:32:06,609 --> 01:32:15,880
information to try and help it on the

1984
01:32:09,609 --> 01:32:18,848
second task the other reason is IMDB

1985
01:32:15,880 --> 01:32:19,539
movie reviews you know up to a thousand

1986
01:32:18,849 --> 01:32:22,449
words long

1987
01:32:19,539 --> 01:32:24,920
they're pretty big and so after reading

1988
01:32:22,448 --> 01:32:27,199
a thousand words knowing nothing about

1989
01:32:24,920 --> 01:32:30,140
how English is structured or even what

1990
01:32:27,199 --> 01:32:33,250
the concept of a word is or punctuation

1991
01:32:30,140 --> 01:32:35,420
or whatever at the end of this thousand

1992
01:32:33,250 --> 01:32:37,810
integers you know they end up being

1993
01:32:35,420 --> 01:32:40,399
integers all you get is a 1 or a 0

1994
01:32:37,810 --> 01:32:42,200
positive or negative and so trying to

1995
01:32:40,399 --> 01:32:44,059
like learn the entire structure of

1996
01:32:42,199 --> 01:32:45,769
English and then how it expresses

1997
01:32:44,060 --> 01:32:48,500
positive and negative sentiments from a

1998
01:32:45,770 --> 01:32:51,950
single number is just too much to expect

1999
01:32:48,500 --> 01:32:53,539
so by building a language model first we

2000
01:32:51,949 --> 01:32:56,960
can try to build a neural network that

2001
01:32:53,539 --> 01:32:59,810
kind of understands the English of movie

2002
01:32:56,960 --> 01:33:02,329
reviews and then we hope that some of

2003
01:32:59,810 --> 01:33:03,860
the things that's learnt about are going

2004
01:33:02,329 --> 01:33:05,029
to be useful in deciding whether

2005
01:33:03,859 --> 01:33:07,130
something's a positive or a negative

2006
01:33:05,029 --> 01:33:12,739
nutrition that's a great question you

2007
01:33:07,130 --> 01:33:18,710
can pass that thanks is this similar to

2008
01:33:12,739 --> 01:33:21,199
the car RNN yeah this is somewhat

2009
01:33:18,710 --> 01:33:25,730
similar to our Olympic apathy so the

2010
01:33:21,199 --> 01:33:28,340
famous car as in CH AR AR and in try to

2011
01:33:25,729 --> 01:33:30,679
predict the next letter given a number

2012
01:33:28,340 --> 01:33:33,020
of previous letters language models

2013
01:33:30,680 --> 01:33:35,750
generally work at a word level they

2014
01:33:33,020 --> 01:33:38,810
don't have to and doing things that a

2015
01:33:35,750 --> 01:33:40,609
word level turns out to be can be quite

2016
01:33:38,810 --> 01:33:42,710
a bit more powerful and we're going to

2017
01:33:40,609 --> 01:33:46,429
focus on word level modeling in this

2018
01:33:42,710 --> 01:33:50,869
course to what extent are these

2019
01:33:46,430 --> 01:33:53,000
generated words actually copies of what

2020
01:33:50,869 --> 01:33:56,149
it found in the in the training data set

2021
01:33:53,000 --> 01:33:57,979
or are these completely random things

2022
01:33:56,149 --> 01:33:59,989
that it actually learned and how do we

2023
01:33:57,979 --> 01:34:01,879
know how to distinguish between those

2024
01:33:59,989 --> 01:34:04,130
two yeah I mean these are awkward

2025
01:34:01,880 --> 01:34:05,630
questions the the words are definitely

2026
01:34:04,130 --> 01:34:07,069
words we've seen before the work because

2027
01:34:05,630 --> 01:34:09,440
it's not at a character level so it can

2028
01:34:07,069 --> 01:34:13,309
only give us the word it seen before the

2029
01:34:09,439 --> 01:34:14,960
sentences there's a number of kind of

2030
01:34:13,310 --> 01:34:16,820
rigorous ways of doing it but I think

2031
01:34:14,960 --> 01:34:19,220
the easiest is to get a sense of like

2032
01:34:16,819 --> 01:34:21,859
well here are two like different

2033
01:34:19,220 --> 01:34:25,340
categories where it's kind of created

2034
01:34:21,859 --> 01:34:27,049
very similar concepts but mixing them up

2035
01:34:25,340 --> 01:34:30,440
in just the right way like it it would

2036
01:34:27,050 --> 01:34:33,020
be very hard to to do what we've seen

2037
01:34:30,439 --> 01:34:35,269
here just by like speeding back things

2038
01:34:33,020 --> 01:34:37,789
at scene before but you could of course

2039
01:34:35,270 --> 01:34:39,679
actually go back and check you know

2040
01:34:37,788 --> 01:34:41,328
have you seen that sentence before or

2041
01:34:39,679 --> 01:34:45,260
like a stream distance - have you seen a

2042
01:34:41,328 --> 01:34:47,359
similar sentence before in this case oh

2043
01:34:45,260 --> 01:34:49,130
and of course another way to do it is

2044
01:34:47,359 --> 01:34:51,078
the length most importantly when we

2045
01:34:49,130 --> 01:34:53,449
train the language model as we'll see

2046
01:34:51,078 --> 01:34:55,639
we'll have a validation set and so we're

2047
01:34:53,448 --> 01:34:57,439
trying to predict the next word of

2048
01:34:55,639 --> 01:34:59,659
something that's never seen before

2049
01:34:57,439 --> 01:35:01,848
and so if it's good at doing that it

2050
01:34:59,658 --> 01:35:04,549
should be good at generating text in

2051
01:35:01,849 --> 01:35:06,110
this case the purpose the purpose is not

2052
01:35:04,550 --> 01:35:08,059
to generate text that was just a fun

2053
01:35:06,109 --> 01:35:10,848
example and so I'm not really gonna

2054
01:35:08,059 --> 01:35:13,788
study that too much but you know you're

2055
01:35:10,849 --> 01:35:16,699
during the week turtley can like you can

2056
01:35:13,788 --> 01:35:19,268
totally build your you know Great

2057
01:35:16,698 --> 01:35:22,939
American Novel generator or whatever

2058
01:35:19,269 --> 01:35:24,909
there are actually some tricks to to

2059
01:35:22,939 --> 01:35:27,469
using language models to generate text

2060
01:35:24,908 --> 01:35:28,848
that I'm not using here they're pretty

2061
01:35:27,469 --> 01:35:31,819
simple we can talk about them on the

2062
01:35:28,849 --> 01:35:34,038
forum if you like but my focus is

2063
01:35:31,819 --> 01:35:37,880
actually on classification so I think

2064
01:35:34,038 --> 01:35:41,259
that's the thing which is incredibly

2065
01:35:37,880 --> 01:35:44,029
powerful like text classification I

2066
01:35:41,260 --> 01:35:46,760
don't know you're a hedge fund you want

2067
01:35:44,029 --> 01:35:49,099
to like read every article as soon as it

2068
01:35:46,760 --> 01:35:51,380
comes out through writers or Twitter or

2069
01:35:49,099 --> 01:35:54,500
whatever and immediately identify things

2070
01:35:51,380 --> 01:35:56,900
which in the past have caused you know

2071
01:35:54,500 --> 01:36:00,219
massive market drops that's a

2072
01:35:56,899 --> 01:36:03,158
classification model or you want to

2073
01:36:00,219 --> 01:36:06,109
recognize all of the customer service

2074
01:36:03,158 --> 01:36:09,920
queries which tend to be associated with

2075
01:36:06,109 --> 01:36:12,319
people who who leave your you know who

2076
01:36:09,920 --> 01:36:14,300
cancel their contracts in the next

2077
01:36:12,319 --> 01:36:16,488
month's that's a classification problem

2078
01:36:14,300 --> 01:36:21,050
so like it's a really powerful kind of

2079
01:36:16,488 --> 01:36:25,729
thing for data journalism Activision

2080
01:36:21,050 --> 01:36:29,449
that activism more promise so forth

2081
01:36:25,729 --> 01:36:30,979
right like I'm trying to class documents

2082
01:36:29,448 --> 01:36:33,578
into whether they're part of legal

2083
01:36:30,979 --> 01:36:39,198
discovery or not part of legal discovery

2084
01:36:33,578 --> 01:36:40,788
okay so you get the idea so in terms of

2085
01:36:39,198 --> 01:36:44,029
stuff we're importing we're importing a

2086
01:36:40,788 --> 01:36:47,599
few new things here one of the bunch of

2087
01:36:44,029 --> 01:36:51,229
things we're importing is torch text

2088
01:36:47,599 --> 01:36:55,220
torch text is PI torches like

2089
01:36:51,229 --> 01:36:57,109
LP library and so fast AI is designed to

2090
01:36:55,220 --> 01:37:01,100
work hand in hand with torch text as

2091
01:36:57,109 --> 01:37:03,738
you'll see and then there's a few text

2092
01:37:01,100 --> 01:37:06,680
specific sub bits of faster fast AI that

2093
01:37:03,738 --> 01:37:09,799
we'll be using so we're going to be

2094
01:37:06,680 --> 01:37:12,500
working with the IMDB large movie review

2095
01:37:09,800 --> 01:37:16,279
data set it's very very well studied in

2096
01:37:12,500 --> 01:37:19,430
academia you know lots and lots of

2097
01:37:16,279 --> 01:37:20,289
people over the years have studied this

2098
01:37:19,430 --> 01:37:23,210
data set

2099
01:37:20,289 --> 01:37:26,390
fifty thousand reviews highly polarized

2100
01:37:23,210 --> 01:37:29,569
reviews either positive or negative each

2101
01:37:26,390 --> 01:37:32,090
one has been classified by sentiment

2102
01:37:29,569 --> 01:37:33,559
okay so we're going to try our first of

2103
01:37:32,090 --> 01:37:35,090
all however to create a language model

2104
01:37:33,560 --> 01:37:37,250
so we're going to ignore the sentiment

2105
01:37:35,090 --> 01:37:39,199
entirely all right so just like the dogs

2106
01:37:37,250 --> 01:37:41,000
and cats Cree trainer model to do one

2107
01:37:39,199 --> 01:37:44,420
thing and then fine tune it to do

2108
01:37:41,000 --> 01:37:48,500
something else because this kind of idea

2109
01:37:44,420 --> 01:37:50,899
in NLP is is so so so new there's

2110
01:37:48,500 --> 01:37:52,310
basically no models you can download for

2111
01:37:50,899 --> 01:37:57,500
this so we're going to have to create

2112
01:37:52,310 --> 01:37:59,840
their own right so having downloaded the

2113
01:37:57,500 --> 01:38:01,699
data you can use the link here we do the

2114
01:37:59,840 --> 01:38:05,060
usual stuff of saying the path to

2115
01:38:01,699 --> 01:38:06,559
training and validation path and as you

2116
01:38:05,060 --> 01:38:08,960
can see it looks pretty pretty

2117
01:38:06,560 --> 01:38:10,880
traditional compared to a vision there's

2118
01:38:08,960 --> 01:38:12,859
a directory of training there's a

2119
01:38:10,880 --> 01:38:14,720
directory of tests we don't actually

2120
01:38:12,859 --> 01:38:19,399
have separate test and validation in

2121
01:38:14,720 --> 01:38:22,100
this case and just like in envision the

2122
01:38:19,399 --> 01:38:25,250
training directory has a bunch of files

2123
01:38:22,100 --> 01:38:28,970
in it in this case not representing

2124
01:38:25,250 --> 01:38:32,600
images but representing movie reviews so

2125
01:38:28,970 --> 01:38:36,140
we could cat one of those files and here

2126
01:38:32,600 --> 01:38:38,350
we learn about the classic zombie garand

2127
01:38:36,140 --> 01:38:41,660
movie I have to say with a name like

2128
01:38:38,350 --> 01:38:43,579
zombie gedan and an atom bomb on the

2129
01:38:41,659 --> 01:38:49,369
front cover I was expecting a flat-out

2130
01:38:43,579 --> 01:38:50,840
chop-socky fun coup rent it if you want

2131
01:38:49,369 --> 01:38:52,760
to get stoned on a Friday night and

2132
01:38:50,840 --> 01:38:54,289
laugh with your buddies don't rent it if

2133
01:38:52,760 --> 01:38:55,880
you're an uptight weenie or want a

2134
01:38:54,289 --> 01:38:58,010
zombie movie or lots of fresh eating I

2135
01:38:55,880 --> 01:39:00,170
think I'm going to enjoy zombie getting

2136
01:38:58,010 --> 01:39:02,409
so alright so we've learned something

2137
01:39:00,170 --> 01:39:02,409
today

2138
01:39:02,529 --> 01:39:06,880
all right so we can just use standard

2139
01:39:04,590 --> 01:39:08,890
UNIX stuff to see like how many words

2140
01:39:06,880 --> 01:39:12,010
are in the data set so the training set

2141
01:39:08,890 --> 01:39:15,970
we've got seventeen and a half million

2142
01:39:12,010 --> 01:39:24,100
words test set we've got 5.6 million

2143
01:39:15,970 --> 01:39:27,490
words so he is these are this is IMDB so

2144
01:39:24,100 --> 01:39:29,920
IMDB is random people this is not New

2145
01:39:27,489 --> 01:39:38,619
York Times listed review as far as I

2146
01:39:29,920 --> 01:39:40,869
know okay so before we can do anything

2147
01:39:38,619 --> 01:39:43,899
with text we have to turn it into a list

2148
01:39:40,869 --> 01:39:45,670
of tokens token is basically like a word

2149
01:39:43,899 --> 01:39:47,199
right so we're going to try and turn

2150
01:39:45,670 --> 01:39:49,060
this eventually into a list of numbers

2151
01:39:47,199 --> 01:39:49,920
so the first step is to turn it into a

2152
01:39:49,060 --> 01:39:52,870
list of words

2153
01:39:49,920 --> 01:39:55,600
that's called tokenization in NLP NLP

2154
01:39:52,869 --> 01:39:57,159
has a huge lot of jargon that will we'll

2155
01:39:55,600 --> 01:39:59,710
learn over time

2156
01:39:57,159 --> 01:40:02,739
one thing that's a bit tricky though

2157
01:39:59,710 --> 01:40:05,439
when we're doing tokenization is here

2158
01:40:02,739 --> 01:40:07,479
I've I've tokenized that review and then

2159
01:40:05,439 --> 01:40:10,629
joined it back up with spaces and you'll

2160
01:40:07,479 --> 01:40:12,879
see here that wasn't has become two

2161
01:40:10,630 --> 01:40:19,239
tokens which makes perfect sense right

2162
01:40:12,880 --> 01:40:22,600
was is two things right dot dot dot has

2163
01:40:19,239 --> 01:40:24,429
become one token right where else lots

2164
01:40:22,600 --> 01:40:27,280
of exclamation marks has become lots of

2165
01:40:24,430 --> 01:40:30,720
tokens so like a good tokenizer

2166
01:40:27,279 --> 01:40:33,639
will do a good job of recognizing like

2167
01:40:30,720 --> 01:40:35,409
pieces of it in your sentence each

2168
01:40:33,640 --> 01:40:39,789
separate piece of punctuation will be

2169
01:40:35,409 --> 01:40:43,380
separated and each part of a multi-part

2170
01:40:39,789 --> 01:40:45,880
word will be separated as appropriate so

2171
01:40:43,380 --> 01:40:47,590
Spacey is I think it's an Australian

2172
01:40:45,880 --> 01:40:50,050
develop piece of software actually that

2173
01:40:47,590 --> 01:40:53,470
does lots of you know P stuff it's got

2174
01:40:50,050 --> 01:40:55,810
the best tokenizer I know and so past AI

2175
01:40:53,470 --> 01:40:58,600
is designed to work well with the Spacey

2176
01:40:55,810 --> 01:41:02,590
tokenizer as is torch text so here's an

2177
01:40:58,600 --> 01:41:05,440
example of tokenization alright so what

2178
01:41:02,590 --> 01:41:07,210
we do with torch text is we basically

2179
01:41:05,439 --> 01:41:09,699
have to start out by creating something

2180
01:41:07,210 --> 01:41:12,250
called a field and a field is a

2181
01:41:09,699 --> 01:41:14,349
definition of how to pre-process some

2182
01:41:12,250 --> 01:41:15,609
text and so here's an example with the

2183
01:41:14,350 --> 01:41:19,660
definition of a field

2184
01:41:15,609 --> 01:41:21,489
it says I want to lowercase a text and I

2185
01:41:19,659 --> 01:41:24,970
want to tokenize it with the function

2186
01:41:21,489 --> 01:41:26,559
called Spacey tokenize okay so it hasn't

2187
01:41:24,970 --> 01:41:28,630
done anything yet we're just telling you

2188
01:41:26,560 --> 01:41:30,930
when we do do something this is what to

2189
01:41:28,630 --> 01:41:32,859
do and so that we're going to store that

2190
01:41:30,930 --> 01:41:37,300
description of what to do in a thing

2191
01:41:32,859 --> 01:41:39,130
called capital text and so this is this

2192
01:41:37,300 --> 01:41:40,750
is none of this but this is not fast AI

2193
01:41:39,130 --> 01:41:42,340
specific at all this is part of torch

2194
01:41:40,750 --> 01:41:44,680
text you can go to the torch text

2195
01:41:42,340 --> 01:41:46,720
website read the docs there's not lots

2196
01:41:44,680 --> 01:41:49,720
of Doc's yet this is all very very new

2197
01:41:46,720 --> 01:41:51,940
so probably the best information you'll

2198
01:41:49,720 --> 01:41:54,070
find about it is in this lesson but

2199
01:41:51,939 --> 01:41:57,849
there's some more information on this

2200
01:41:54,069 --> 01:42:01,090
site all right so what we can now do is

2201
01:41:57,850 --> 01:42:05,380
go ahead and create the usual fast AI

2202
01:42:01,090 --> 01:42:07,180
model data object okay and so to create

2203
01:42:05,380 --> 01:42:08,980
the model data object we have to provide

2204
01:42:07,180 --> 01:42:10,900
a few bits of information but you have

2205
01:42:08,979 --> 01:42:14,079
to say what's the training set so the

2206
01:42:10,899 --> 01:42:17,049
path to the text files the validation

2207
01:42:14,079 --> 01:42:18,309
set and the test set in this case just

2208
01:42:17,050 --> 01:42:20,770
to keep things simple I don't have a

2209
01:42:18,310 --> 01:42:22,450
separate validation and test set so I'm

2210
01:42:20,770 --> 01:42:24,820
going to pass in the validation set for

2211
01:42:22,449 --> 01:42:26,349
both of those two things right

2212
01:42:24,819 --> 01:42:29,049
so now we can create our model data

2213
01:42:26,350 --> 01:42:32,230
object as per usual the first thing you

2214
01:42:29,050 --> 01:42:34,539
give it as a path the second thing we

2215
01:42:32,229 --> 01:42:36,639
give it is the torch text field

2216
01:42:34,539 --> 01:42:39,909
definition of how to pre-process that

2217
01:42:36,640 --> 01:42:42,700
text the third thing we give it is the

2218
01:42:39,909 --> 01:42:45,119
dictionary or the list of all of the

2219
01:42:42,699 --> 01:42:47,979
files we have trained validation tests

2220
01:42:45,119 --> 01:42:50,590
as per usual we can pass in a batch size

2221
01:42:47,979 --> 01:42:54,789
and then we've got a special special

2222
01:42:50,590 --> 01:42:57,130
couple of extra things here one is very

2223
01:42:54,789 --> 01:43:01,630
commonly used in NLP minimum frequency

2224
01:42:57,130 --> 01:43:03,460
what this says is in a moment we're

2225
01:43:01,630 --> 01:43:05,890
going to be replacing every one of these

2226
01:43:03,460 --> 01:43:08,350
words with an integer which basically

2227
01:43:05,890 --> 01:43:10,840
will be a unique index for every word

2228
01:43:08,350 --> 01:43:14,190
and this basically says if there are any

2229
01:43:10,840 --> 01:43:17,680
words that occur less than 10 times just

2230
01:43:14,189 --> 01:43:19,989
call it unknown right don't think of it

2231
01:43:17,680 --> 01:43:21,929
as a word but we'll see that indeed more

2232
01:43:19,989 --> 01:43:23,158
detail in a moment

2233
01:43:21,929 --> 01:43:26,250
we're going to see this in more detail

2234
01:43:23,158 --> 01:43:28,859
as well be PTT stands for back prop

2235
01:43:26,250 --> 01:43:33,658
through time and this is where we define

2236
01:43:28,859 --> 01:43:35,880
how long a sentence will we stick on the

2237
01:43:33,658 --> 01:43:37,408
GPU at once so we're going to break them

2238
01:43:35,880 --> 01:43:41,730
up in this case we're going to break

2239
01:43:37,408 --> 01:43:44,189
them up into sentences of 70 tokens or

2240
01:43:41,729 --> 01:43:45,349
less on the whole so we're going to see

2241
01:43:44,189 --> 01:43:48,569
all this in a moment

2242
01:43:45,350 --> 01:43:51,690
okay so after building our model data

2243
01:43:48,569 --> 01:43:55,198
object right what it actually does is

2244
01:43:51,689 --> 01:43:58,198
it's going to fill this text field with

2245
01:43:55,198 --> 01:44:00,479
an additional attribute called vocab and

2246
01:43:58,198 --> 01:44:02,460
this is a really important and LP

2247
01:44:00,479 --> 01:44:03,839
concept I'm sorry there's so many NLP

2248
01:44:02,460 --> 01:44:05,730
concepts we just have to throw at you

2249
01:44:03,840 --> 01:44:09,539
kind of quickly but we'll see them a few

2250
01:44:05,729 --> 01:44:12,718
times right the vocab is the vocabulary

2251
01:44:09,539 --> 01:44:15,210
and the vocabulary in NLP has a very

2252
01:44:12,719 --> 01:44:17,539
specific meaning it is what is the list

2253
01:44:15,210 --> 01:44:19,710
of unique words that appear in this text

2254
01:44:17,539 --> 01:44:22,079
so every one of them is going to get a

2255
01:44:19,710 --> 01:44:26,939
unique in this so let's take a look

2256
01:44:22,079 --> 01:44:29,340
right here is text vocab dot I to s this

2257
01:44:26,939 --> 01:44:32,329
dancer this is all torch text not faster

2258
01:44:29,340 --> 01:44:37,230
hide text upper cap dot int 2 string

2259
01:44:32,329 --> 01:44:39,539
Maps the integer 0 to unknown the

2260
01:44:37,229 --> 01:44:43,529
integer 1 the padding unit 2 to desert

2261
01:44:39,539 --> 01:44:47,429
then in comma dot and of 2 and so forth

2262
01:44:43,529 --> 01:44:52,649
right so this is the first 12 elements

2263
01:44:47,429 --> 01:44:55,109
of the array of the vocab from the IMDB

2264
01:44:52,649 --> 01:44:57,929
movie review and it's been sorted by

2265
01:44:55,109 --> 01:45:00,149
frequency and except for the first two

2266
01:44:57,929 --> 01:45:00,899
special ones so for example we can then

2267
01:45:00,149 --> 01:45:05,279
go backwards

2268
01:45:00,899 --> 01:45:09,619
s2i string to int here is the it's in

2269
01:45:05,279 --> 01:45:14,099
position 0 1 2 so stream to end the is 2

2270
01:45:09,619 --> 01:45:17,039
so the vocab lets us take a word and map

2271
01:45:14,100 --> 01:45:20,789
it to an integer or take an integer and

2272
01:45:17,039 --> 01:45:24,600
that a tour word right and so that means

2273
01:45:20,789 --> 01:45:27,960
that we can then take the first 12

2274
01:45:24,600 --> 01:45:32,280
tokens for example of our text and turn

2275
01:45:27,960 --> 01:45:35,739
them into twelve inch so for example

2276
01:45:32,279 --> 01:45:40,779
here is of the agency 7 2

2277
01:45:35,739 --> 01:45:44,260
and here you can see 7/2 right so we're

2278
01:45:40,779 --> 01:45:45,819
going to be working in this form did you

2279
01:45:44,260 --> 01:45:49,750
have a question deputy plus that back

2280
01:45:45,819 --> 01:45:53,489
there you know is it a common tyranny

2281
01:45:49,750 --> 01:45:56,409
stemming or limit izing not really no

2282
01:45:53,489 --> 01:46:00,670
generally tokenization is is what we

2283
01:45:56,409 --> 01:46:01,630
want like with a language model we you

2284
01:46:00,670 --> 01:46:03,550
know to keep it as general as possible

2285
01:46:01,630 --> 01:46:06,609
we want to know what's coming next and

2286
01:46:03,550 --> 01:46:08,650
so like whether its future tense or past

2287
01:46:06,609 --> 01:46:10,329
tense or plural or seem to learn like we

2288
01:46:08,649 --> 01:46:15,969
don't really know which things are going

2289
01:46:10,329 --> 01:46:18,550
to be interesting in which ant so it

2290
01:46:15,970 --> 01:46:21,880
seems that it's generally best to kind

2291
01:46:18,550 --> 01:46:25,300
of leave it alone as much as possible be

2292
01:46:21,880 --> 01:46:27,310
the short answer you know having said

2293
01:46:25,300 --> 01:46:29,380
that as I say this is all pretty new so

2294
01:46:27,310 --> 01:46:30,880
if there are some particular areas that

2295
01:46:29,380 --> 01:46:32,470
some researcher maybe is already

2296
01:46:30,880 --> 01:46:35,470
discovered that some other kinds of

2297
01:46:32,470 --> 01:46:37,000
pre-processing you're helpful you know I

2298
01:46:35,470 --> 01:46:41,110
wouldn't be surprised not to know about

2299
01:46:37,000 --> 01:46:43,109
it so we Abdullah we know you don't

2300
01:46:41,109 --> 01:46:50,049
natural language is in context important

2301
01:46:43,109 --> 01:46:52,149
context is very important so individual

2302
01:46:50,050 --> 01:46:54,730
words no no we're not looking worth this

2303
01:46:52,149 --> 01:46:57,039
is this look this is I just don't get

2304
01:46:54,729 --> 01:46:59,949
some of the big premises of this like

2305
01:46:57,039 --> 01:47:02,739
they're there in order yeah so just

2306
01:46:59,949 --> 01:47:05,619
because we replaced I with the number 12

2307
01:47:02,739 --> 01:47:09,099
these are still in that order

2308
01:47:05,619 --> 01:47:11,050
yeah there is a different way of dealing

2309
01:47:09,100 --> 01:47:13,180
with natural language called a bag of

2310
01:47:11,050 --> 01:47:15,279
words and bag of words you through throw

2311
01:47:13,180 --> 01:47:16,570
away the order in the context and in the

2312
01:47:15,279 --> 01:47:18,189
machine learning course we'll be

2313
01:47:16,569 --> 01:47:21,039
learning about working with bag of words

2314
01:47:18,189 --> 01:47:24,789
representation z' but my belief is that

2315
01:47:21,039 --> 01:47:26,769
they are no longer useful or in the

2316
01:47:24,789 --> 01:47:28,779
verge of becoming no longer useful we're

2317
01:47:26,770 --> 01:47:33,160
starting to learn how to use deep

2318
01:47:28,779 --> 01:47:35,469
learning to use context properly now but

2319
01:47:33,159 --> 01:47:38,189
it's kind of for the first time it's

2320
01:47:35,470 --> 01:47:40,900
really like only in the last few months

2321
01:47:38,189 --> 01:47:44,829
right so I mentioned that we've got two

2322
01:47:40,899 --> 01:47:49,589
numbers batch size and B PTT back crop

2323
01:47:44,829 --> 01:47:49,590
through time so this is kind of subtle

2324
01:47:52,649 --> 01:48:00,609
so we've got some big long piece of text

2325
01:47:58,439 --> 01:48:02,409
okay so we've got some big long piece of

2326
01:48:00,609 --> 01:48:07,029
text you know here's our sentence it's a

2327
01:48:02,409 --> 01:48:09,010
bunch of words right and actually what

2328
01:48:07,029 --> 01:48:10,509
happens in a language model is even

2329
01:48:09,010 --> 01:48:13,239
though we have lots of movie reviews

2330
01:48:10,510 --> 01:48:15,489
they actually all get concatenated

2331
01:48:13,239 --> 01:48:18,279
together into one big block of text

2332
01:48:15,489 --> 01:48:21,760
right so it's basically predict the next

2333
01:48:18,279 --> 01:48:23,409
word in this huge long thing which is

2334
01:48:21,760 --> 01:48:25,329
all of the IMDB movie reviews

2335
01:48:23,409 --> 01:48:28,149
concatenated together so this thing is

2336
01:48:25,329 --> 01:48:31,750
you know what do we say it was like tens

2337
01:48:28,149 --> 01:48:37,658
of millions of words long and so what we

2338
01:48:31,750 --> 01:48:39,639
do is we split it up into batches first

2339
01:48:37,658 --> 01:48:43,779
right so these like aerial spits into

2340
01:48:39,639 --> 01:48:47,949
batches right and so if we said we want

2341
01:48:43,779 --> 01:48:50,738
a batch size of 64 we actually break the

2342
01:48:47,948 --> 01:48:56,649
whatever it was sixty million words into

2343
01:48:50,738 --> 01:49:03,569
64 sections right and then we take each

2344
01:48:56,649 --> 01:49:03,569
one of the 64 sections and we move it

2345
01:49:04,039 --> 01:49:10,960
like underneath the previous one I

2346
01:49:07,539 --> 01:49:16,789
didn't do a great job of that

2347
01:49:10,960 --> 01:49:22,960
all right move it underneath so we end

2348
01:49:16,789 --> 01:49:22,960
up with a matrix which is

2349
01:49:25,340 --> 01:49:27,400
you

2350
01:49:28,550 --> 01:49:34,409
sixty-four actually I think we've moved

2351
01:49:32,760 --> 01:49:36,000
them across twice so it's actually I

2352
01:49:34,408 --> 01:49:40,319
think just transpose it we end up with

2353
01:49:36,000 --> 01:49:44,460
the matrix it's like 64 columns wide and

2354
01:49:40,319 --> 01:49:48,029
the length let's say the original was 64

2355
01:49:44,460 --> 01:49:51,929
million right then the length is like 10

2356
01:49:48,029 --> 01:49:55,679
million long right so each of these

2357
01:49:51,929 --> 01:49:59,789
represents one sixty-fourth with our

2358
01:49:55,679 --> 01:50:02,550
entire IMDB refused it all right and so

2359
01:49:59,789 --> 01:50:06,810
that's our starting point so then what

2360
01:50:02,550 --> 01:50:09,630
we do is we then grab a little chunk of

2361
01:50:06,810 --> 01:50:14,039
this at a time and those chunk lengths

2362
01:50:09,630 --> 01:50:15,929
are approximately equal to be PTT which

2363
01:50:14,039 --> 01:50:20,010
I think we had equal to 70 so he

2364
01:50:15,929 --> 01:50:22,739
basically grab a little 70 long section

2365
01:50:20,010 --> 01:50:26,159
and that's the first thing we check into

2366
01:50:22,738 --> 01:50:29,908
our GPU that's a batch right so a batch

2367
01:50:26,158 --> 01:50:33,149
is always of length of width 64 or batch

2368
01:50:29,908 --> 01:50:37,618
size and each bit is a sequence of

2369
01:50:33,149 --> 01:50:41,789
length up to 70 so let me show you all

2370
01:50:37,618 --> 01:50:44,130
right so here if I go take my train data

2371
01:50:41,789 --> 01:50:45,630
loader I know if you folks have tried

2372
01:50:44,130 --> 01:50:48,300
playing with this yet but you can take

2373
01:50:45,630 --> 01:50:50,250
any data loader wrap it with inner -

2374
01:50:48,300 --> 01:50:54,150
turn it into an iterator and then call

2375
01:50:50,250 --> 01:50:55,710
next on it to grab a batch of data just

2376
01:50:54,149 --> 01:50:57,089
as if you were a neural net you get

2377
01:50:55,710 --> 01:51:03,560
exactly what the neuron that gets and

2378
01:50:57,090 --> 01:51:08,789
you can see here we get back a 75 by 64

2379
01:51:03,560 --> 01:51:13,830
sensor right so it's 64 wide right and I

2380
01:51:08,789 --> 01:51:16,380
said it's approximately 70 high and but

2381
01:51:13,829 --> 01:51:18,510
not exactly and that's actually kind of

2382
01:51:16,380 --> 01:51:22,190
interesting a really neat trick that

2383
01:51:18,510 --> 01:51:25,800
torch text does is they randomly change

2384
01:51:22,189 --> 01:51:28,710
the backprop through time number every

2385
01:51:25,800 --> 01:51:33,329
time so each epoch it's getting slightly

2386
01:51:28,710 --> 01:51:35,789
different bits of text this is kind of

2387
01:51:33,329 --> 01:51:38,519
like in computer vision we randomly

2388
01:51:35,789 --> 01:51:41,130
shuffle the images we can't randomly

2389
01:51:38,520 --> 01:51:42,270
shuffle the words right because we

2390
01:51:41,130 --> 01:51:44,039
needed to be in the right order so

2391
01:51:42,270 --> 01:51:46,680
instead we randomly move their

2392
01:51:44,039 --> 01:51:52,369
breakpoints a little bit okay so this is

2393
01:51:46,680 --> 01:51:52,369
the equivalent so in other words this

2394
01:51:54,510 --> 01:52:01,440
this here is of length 75 right there's

2395
01:51:59,130 --> 01:52:05,190
a there's an ellipsis in the middle and

2396
01:52:01,439 --> 01:52:07,679
that represents the first 75 words of

2397
01:52:05,189 --> 01:52:12,210
the first review right where else this

2398
01:52:07,680 --> 01:52:15,300
75 here represents the first 75 words of

2399
01:52:12,210 --> 01:52:17,670
this of the second of the 64 segments

2400
01:52:15,300 --> 01:52:20,159
let's it have to go in like 10 million

2401
01:52:17,670 --> 01:52:23,489
words to find that one right and so

2402
01:52:20,159 --> 01:52:27,449
here's the first 75 words of the last of

2403
01:52:23,488 --> 01:52:35,069
those 64 segments okay and so then what

2404
01:52:27,449 --> 01:52:41,399
we have down here is the next sequence

2405
01:52:35,069 --> 01:52:46,319
right so 51 there's 51 6 1 5 there's 6 1

2406
01:52:41,399 --> 01:52:48,359
5 25 is 25 right and in this case it

2407
01:52:46,319 --> 01:52:50,069
actually is of the same size it's also

2408
01:52:48,359 --> 01:52:52,380
75 plus 64

2409
01:52:50,069 --> 01:52:54,719
but for minor technical reasons it's

2410
01:52:52,380 --> 01:52:58,020
being flattened out into a single vector

2411
01:52:54,720 --> 01:53:01,940
but basically it's exactly the same at

2412
01:52:58,020 --> 01:53:05,250
this matrix but it's just moved down by

2413
01:53:01,939 --> 01:53:08,429
one because we're trying to predict the

2414
01:53:05,250 --> 01:53:11,579
next word right so that all happens for

2415
01:53:08,430 --> 01:53:13,770
us right if we ask for and this is the

2416
01:53:11,579 --> 01:53:17,100
first date I know if you ask for a

2417
01:53:13,770 --> 01:53:20,820
language model data object then it's

2418
01:53:17,100 --> 01:53:26,700
going to create these batches of batch

2419
01:53:20,819 --> 01:53:29,488
size width by B PTT height bits of our

2420
01:53:26,699 --> 01:53:32,729
language corpus along with the same

2421
01:53:29,488 --> 01:53:34,199
thing shuffled along by one word right

2422
01:53:32,729 --> 01:53:37,509
and so we're always going to try and

2423
01:53:34,199 --> 01:53:40,050
predict the next word

2424
01:53:37,510 --> 01:53:40,050
yes

2425
01:53:40,859 --> 01:53:49,750
so why don't you instead of just

2426
01:53:44,739 --> 01:53:52,689
arbitrarily choosing 64 why don't you

2427
01:53:49,750 --> 01:53:56,770
choose like like 64 is a large number

2428
01:53:52,689 --> 01:53:58,629
maybe like stood by sentences and make

2429
01:53:56,770 --> 01:54:03,100
it a large number and then padded with

2430
01:53:58,630 --> 01:54:04,480
zero or something if you you know so

2431
01:54:03,100 --> 01:54:07,180
that you actually have a one full

2432
01:54:04,479 --> 01:54:09,009
sentence per line basically wouldn't

2433
01:54:07,180 --> 01:54:10,869
that make more sense not really because

2434
01:54:09,010 --> 01:54:12,640
remember we're using columns right so

2435
01:54:10,869 --> 01:54:15,460
each of our columns is of length about

2436
01:54:12,640 --> 01:54:17,440
10 million right so although it's true

2437
01:54:15,460 --> 01:54:20,020
that those columns aren't always exactly

2438
01:54:17,439 --> 01:54:23,259
finishing on a full stop there's so damn

2439
01:54:20,020 --> 01:54:27,550
long we don't care because they're like

2440
01:54:23,260 --> 01:54:30,880
10 million won and we're trying to also

2441
01:54:27,550 --> 01:54:33,159
line contains multiple cents incentive

2442
01:54:30,880 --> 01:54:35,980
column contains more costumes and sorry

2443
01:54:33,159 --> 01:54:38,260
yeah it's of length about 10 million and

2444
01:54:35,979 --> 01:54:40,299
it contains many many many many many

2445
01:54:38,260 --> 01:54:42,159
sentences because remember the first

2446
01:54:40,300 --> 01:54:45,690
thing we did was take all thing and

2447
01:54:42,159 --> 01:54:45,689
split it into 64 groups

2448
01:54:47,158 --> 01:54:55,479
okay great so um I found this you know

2449
01:54:53,738 --> 01:54:58,809
pertaining to this question this thing

2450
01:54:55,479 --> 01:55:01,598
about like what's in this language model

2451
01:54:58,810 --> 01:55:04,060
matrix a little mind-bending for quite a

2452
01:55:01,599 --> 01:55:05,920
while so don't worry if it takes a while

2453
01:55:04,060 --> 01:55:10,090
and you have to ask a thousand questions

2454
01:55:05,920 --> 01:55:11,710
on the forum that's fine right but go

2455
01:55:10,090 --> 01:55:13,300
back and listen to what I just said in

2456
01:55:11,710 --> 01:55:14,948
this lecture again go back to that bit

2457
01:55:13,300 --> 01:55:16,779
where I showed you splitting it up to 64

2458
01:55:14,948 --> 01:55:18,759
and moving them around and try it with

2459
01:55:16,779 --> 01:55:21,399
some sentences in Excel or something and

2460
01:55:18,760 --> 01:55:23,380
see if you can do a better job of

2461
01:55:21,399 --> 01:55:27,519
explaining it than I did okay because

2462
01:55:23,380 --> 01:55:30,159
this is like how torch text works and

2463
01:55:27,520 --> 01:55:31,869
then what fast AI adds on is this idea

2464
01:55:30,158 --> 01:55:34,629
of like kind of how to build a a

2465
01:55:31,868 --> 01:55:35,948
language model out of it well they'll

2466
01:55:34,630 --> 01:55:37,539
actually a lot of that stolen from torch

2467
01:55:35,948 --> 01:55:39,669
text as well like there's some times

2468
01:55:37,539 --> 01:55:42,819
where torch text starts and fast AI ends

2469
01:55:39,670 --> 01:55:46,109
is or vice versa trees a little saddle

2470
01:55:42,819 --> 01:55:51,009
they really work closely together okay

2471
01:55:46,109 --> 01:55:55,750
so now that we have a model data object

2472
01:55:51,010 --> 01:55:58,960
that can feed us batches we can go ahead

2473
01:55:55,750 --> 01:56:01,630
and create a model right and so in this

2474
01:55:58,960 --> 01:56:05,980
case we're going to create an embedding

2475
01:56:01,630 --> 01:56:09,670
matrix and our vocab we can see how big

2476
01:56:05,979 --> 01:56:13,209
a vocab was let's have a look back here

2477
01:56:09,670 --> 01:56:15,819
so we can see here in the model data

2478
01:56:13,210 --> 01:56:19,569
object there are four thousand six

2479
01:56:15,819 --> 01:56:20,859
hundred and two kind of pieces that

2480
01:56:19,569 --> 01:56:24,670
we're going to go through that's

2481
01:56:20,859 --> 01:56:26,559
basically equal to the number of the

2482
01:56:24,670 --> 01:56:29,710
total length of everything divided by

2483
01:56:26,560 --> 01:56:32,110
batch size times B PTT and this one I

2484
01:56:29,710 --> 01:56:34,000
wanted to show you NT I've got the

2485
01:56:32,109 --> 01:56:36,759
definition up here number of unique

2486
01:56:34,000 --> 01:56:39,069
tokens NT is the number of tokens that's

2487
01:56:36,760 --> 01:56:40,840
the size of our vocab so we've got three

2488
01:56:39,069 --> 01:56:44,738
thirty four thousand nine hundred and

2489
01:56:40,840 --> 01:56:46,389
forty five unique words and notice the

2490
01:56:44,738 --> 01:56:49,598
unique words that had to appear at least

2491
01:56:46,389 --> 01:56:56,289
ten times okay because otherwise they've

2492
01:56:49,599 --> 01:56:58,389
been replaced with the length of the

2493
01:56:56,289 --> 01:56:59,859
data set is one

2494
01:56:58,389 --> 01:57:02,650
because as far as the language model is

2495
01:56:59,859 --> 01:57:05,170
concerned there's only one thing which

2496
01:57:02,649 --> 01:57:08,948
is the whole corpus all right and then

2497
01:57:05,170 --> 01:57:12,329
that thing has I hear it is twenty point

2498
01:57:08,948 --> 01:57:15,549
six million words you know right

2499
01:57:12,329 --> 01:57:17,800
so those thirty four thousand hundred

2500
01:57:15,550 --> 01:57:22,570
and forty five things are used to create

2501
01:57:17,800 --> 01:57:28,960
an embedding matrix of number of rows is

2502
01:57:22,569 --> 01:57:31,840
equal to thirty four nine four five

2503
01:57:28,960 --> 01:57:36,340
right and so the first one represents

2504
01:57:31,840 --> 01:57:38,500
UNK the second one represents pad the

2505
01:57:36,340 --> 01:57:41,199
third one was dot the fourth one was

2506
01:57:38,500 --> 01:57:44,439
comma with one under sketching was there

2507
01:57:41,198 --> 01:57:48,399
and so forth right and so each one of

2508
01:57:44,439 --> 01:57:50,469
these gets an embedding vector so this

2509
01:57:48,399 --> 01:57:53,738
is literally identical to what we did

2510
01:57:50,469 --> 01:57:56,198
before the brick right this is a

2511
01:57:53,738 --> 01:57:58,149
categorical variable it's just a very

2512
01:57:56,198 --> 01:58:00,849
high cardinality categorical variable

2513
01:57:58,149 --> 01:58:03,729
and furthermore it's the only variable

2514
01:58:00,850 --> 01:58:07,539
right this is pretty standard in NLP you

2515
01:58:03,729 --> 01:58:09,819
have a variable which is a word right

2516
01:58:07,539 --> 01:58:13,899
you have a single categorical variable

2517
01:58:09,819 --> 01:58:16,689
single column basically and it's it's of

2518
01:58:13,899 --> 01:58:19,089
thirty four thousand nine hundred forty

2519
01:58:16,689 --> 01:58:20,948
five cardinality categorical variable

2520
01:58:19,090 --> 01:58:25,360
and so we're going to create an

2521
01:58:20,948 --> 01:58:28,210
embedding matrix for it so M size is the

2522
01:58:25,359 --> 01:58:31,118
size of the omitting vector 200 okay

2523
01:58:28,210 --> 01:58:32,439
so that's going to be length 200 a lot

2524
01:58:31,118 --> 01:58:34,719
bigger than our previous embedding

2525
01:58:32,439 --> 01:58:37,960
vectors not surprising because a word

2526
01:58:34,719 --> 01:58:42,579
has a lot more nuance to it than the

2527
01:58:37,960 --> 01:58:45,399
concept of Sunday right or Russ means

2528
01:58:42,579 --> 01:58:47,649
Berlin's door or whatever right so it's

2529
01:58:45,399 --> 01:58:49,599
generally an embedding size for a word

2530
01:58:47,649 --> 01:58:52,359
will be somewhere between about 50 and

2531
01:58:49,600 --> 01:58:56,710
about 600 okay so I've kind of done some

2532
01:58:52,359 --> 01:58:58,658
in the middle we then have to say as per

2533
01:58:56,710 --> 01:59:01,029
usual how many activations do you want

2534
01:58:58,658 --> 01:59:02,769
in your layers so we're going to use 500

2535
01:59:01,029 --> 01:59:04,899
and then how many layers do you want in

2536
01:59:02,770 --> 01:59:10,510
your neural net we're going to use three

2537
01:59:04,899 --> 01:59:11,219
okay this is a minor technical detail it

2538
01:59:10,510 --> 01:59:13,530
turns out

2539
01:59:11,220 --> 01:59:16,170
that we're going to learn later about

2540
01:59:13,529 --> 01:59:17,699
the atom optimizer that basically the

2541
01:59:16,170 --> 01:59:19,470
defaults for it don't work very well

2542
01:59:17,699 --> 01:59:21,569
with these kinds of models so you just

2543
01:59:19,470 --> 01:59:24,240
have to change some of these you know

2544
01:59:21,569 --> 01:59:27,559
basically any time you're doing NLP you

2545
01:59:24,239 --> 01:59:31,800
should probably include this mine

2546
01:59:27,560 --> 01:59:34,020
because it works pretty well so having

2547
01:59:31,800 --> 01:59:36,000
done that we can now again take our

2548
01:59:34,020 --> 01:59:38,280
model data object and grab a model out

2549
01:59:36,000 --> 01:59:38,960
of it and we can pass in a few different

2550
01:59:38,279 --> 01:59:41,609
things

2551
01:59:38,960 --> 01:59:43,260
what optimization function do we want

2552
01:59:41,609 --> 01:59:45,239
how big an embedding do we want

2553
01:59:43,260 --> 01:59:47,640
how many hidden activate how many

2554
01:59:45,239 --> 01:59:51,809
activations number of Hitler how many

2555
01:59:47,640 --> 01:59:55,260
layers and how much drop out of many

2556
01:59:51,810 --> 01:59:56,610
different kinds so this language model

2557
01:59:55,260 --> 02:00:00,690
we're going to use is a very recent

2558
01:59:56,609 --> 02:00:03,689
development called AWD LS TM by Steven

2559
02:00:00,689 --> 02:00:05,849
marady who's a NLP research based in San

2560
02:00:03,689 --> 02:00:09,809
Francisco and his main contribution

2561
02:00:05,850 --> 02:00:13,050
really was to show like how to put drop

2562
02:00:09,810 --> 02:00:15,720
out all over the place in in these NLP

2563
02:00:13,050 --> 02:00:17,250
models so we're not going to worry now

2564
02:00:15,720 --> 02:00:18,780
we'll do this in the last lecture is

2565
02:00:17,250 --> 02:00:20,760
worrying about like what all that like

2566
02:00:18,779 --> 02:00:21,719
what is the architecture and what are

2567
02:00:20,760 --> 02:00:24,420
all these dropouts

2568
02:00:21,720 --> 02:00:26,789
for now just know is the same as per

2569
02:00:24,420 --> 02:00:28,350
usual if you try to build an NLP model

2570
02:00:26,789 --> 02:00:31,350
and draw underfitting

2571
02:00:28,350 --> 02:00:33,690
and decrease all of these dropouts if

2572
02:00:31,350 --> 02:00:36,110
you're overfitting then increase all of

2573
02:00:33,689 --> 02:00:39,829
these dropouts in roughly this ratio

2574
02:00:36,109 --> 02:00:44,189
okay that's that's my rule of thumb and

2575
02:00:39,829 --> 02:00:45,930
again this is such a recent paper nobody

2576
02:00:44,189 --> 02:00:47,399
else is working on this model anyway so

2577
02:00:45,930 --> 02:00:50,039
there's not a lot of guidance but I

2578
02:00:47,399 --> 02:00:53,819
found this these ratios worked well it's

2579
02:00:50,039 --> 02:00:55,949
what Stephens been using as well there's

2580
02:00:53,819 --> 02:00:57,779
another kind of way we can avoid

2581
02:00:55,949 --> 02:00:59,880
overfitting that we'll talk about in the

2582
02:00:57,779 --> 02:01:02,130
last class again for now this one

2583
02:00:59,880 --> 02:01:04,350
actually works totally reliably so all

2584
02:01:02,130 --> 02:01:09,000
of your NLP models probably want this

2585
02:01:04,350 --> 02:01:10,140
particular line of code and then this

2586
02:01:09,000 --> 02:01:12,869
point we're going to talk about at the

2587
02:01:10,140 --> 02:01:16,700
end last lecture as well you can always

2588
02:01:12,869 --> 02:01:16,699
improve this basically what it says is

2589
02:01:17,060 --> 02:01:21,690
when you do when you look at your

2590
02:01:20,189 --> 02:01:23,759
gradients and you multiply them by the

2591
02:01:21,689 --> 02:01:24,989
learning rate and you decide how much to

2592
02:01:23,760 --> 02:01:29,880
update you

2593
02:01:24,989 --> 02:01:32,429
or weights by this is clip them like

2594
02:01:29,880 --> 02:01:36,869
literally like sit like don't let them

2595
02:01:32,430 --> 02:01:41,520
be more than 0.3 and this is quite a

2596
02:01:36,869 --> 02:01:43,849
cool little trick right because like if

2597
02:01:41,520 --> 02:01:45,870
you're learning rates pretty high and

2598
02:01:43,850 --> 02:01:49,110
you kind of don't want to get in that

2599
02:01:45,869 --> 02:01:51,569
situation we talked about where you're

2600
02:01:49,109 --> 02:01:53,809
kind of got this kind of thing where you

2601
02:01:51,569 --> 02:01:53,809
go

2602
02:01:54,390 --> 02:01:57,690
you know rather than little snippets

2603
02:01:55,890 --> 02:02:01,320
that little step instead you go like Oh

2604
02:01:57,689 --> 02:02:03,750
too big Oh too big right with gradient

2605
02:02:01,319 --> 02:02:05,219
clipping it kind of goes this far and

2606
02:02:03,750 --> 02:02:07,979
it's like oh my goodness I'm going too

2607
02:02:05,220 --> 02:02:12,539
far I'll stop and that's basically what

2608
02:02:07,979 --> 02:02:14,039
gradient flipping does so anyway so

2609
02:02:12,539 --> 02:02:15,810
these are a bunch of parameters the

2610
02:02:14,039 --> 02:02:19,350
details don't matter too much right now

2611
02:02:15,810 --> 02:02:23,190
you can just deal these and then we can

2612
02:02:19,350 --> 02:02:30,960
go ahead and call fit with exactly the

2613
02:02:23,189 --> 02:02:35,519
same parameters as usual so Jeremy um

2614
02:02:30,960 --> 02:02:38,819
there are all this other work embedding

2615
02:02:35,520 --> 02:02:41,640
things like like worked vague and glow

2616
02:02:38,819 --> 02:02:44,729
so I have two questions about that one

2617
02:02:41,640 --> 02:02:47,340
is how are those different from these

2618
02:02:44,729 --> 02:02:50,309
and the second question why don't you

2619
02:02:47,340 --> 02:02:54,029
initialize them with one of those yeah

2620
02:02:50,310 --> 02:02:57,830
so so basically that's a great question

2621
02:02:54,029 --> 02:03:00,960
so basically people have pre trained

2622
02:02:57,829 --> 02:03:02,909
these embedding matrices before to do

2623
02:03:00,960 --> 02:03:04,829
various other tasks they're not called

2624
02:03:02,909 --> 02:03:06,510
pre-trained models they're just a pre

2625
02:03:04,829 --> 02:03:09,000
trained embedding matrix and you can

2626
02:03:06,510 --> 02:03:11,070
download them and as unit says they have

2627
02:03:09,000 --> 02:03:15,329
names like word to Veck and love and

2628
02:03:11,069 --> 02:03:17,599
they're literally just a matrix there's

2629
02:03:15,329 --> 02:03:24,479
no reason we couldn't download them

2630
02:03:17,600 --> 02:03:27,660
really it's just like kind of I found

2631
02:03:24,479 --> 02:03:30,149
that building a whole pre-trained model

2632
02:03:27,659 --> 02:03:32,279
in this way didn't seem to benefit much

2633
02:03:30,149 --> 02:03:33,719
if at all from using pre trained word

2634
02:03:32,279 --> 02:03:36,599
vectors where else using a whole

2635
02:03:33,720 --> 02:03:38,760
pre-trained language model made a much

2636
02:03:36,600 --> 02:03:40,890
bigger difference so I can remember what

2637
02:03:38,760 --> 02:03:43,350
a big those of you who saw word Tyvek it

2638
02:03:40,890 --> 02:03:46,280
made a big splash when it came out

2639
02:03:43,350 --> 02:03:48,990
I mean I'm finding this technique of

2640
02:03:46,279 --> 02:03:51,119
pre-trained language models seems much

2641
02:03:48,989 --> 02:03:52,739
more powerful basically but I think we

2642
02:03:51,119 --> 02:03:57,000
can combine both to make them a little

2643
02:03:52,739 --> 02:03:58,679
better still what what is the model that

2644
02:03:57,000 --> 02:04:01,010
you have used like how can I know that

2645
02:03:58,680 --> 02:04:03,270
architecture of the model

2646
02:04:01,010 --> 02:04:05,640
so we'll be learning about the model

2647
02:04:03,270 --> 02:04:08,090
architecture in the last lesson and for

2648
02:04:05,640 --> 02:04:10,800
now it's a recurrent neural network

2649
02:04:08,090 --> 02:04:18,569
using something called an LS TN long

2650
02:04:10,800 --> 02:04:20,130
short-term memory okay so so if they had

2651
02:04:18,569 --> 02:04:22,319
lots of details that we're skipping over

2652
02:04:20,130 --> 02:04:25,140
but you know you can do all this without

2653
02:04:22,319 --> 02:04:28,019
any of those details we go ahead and fit

2654
02:04:25,140 --> 02:04:29,820
the model I found that this language

2655
02:04:28,020 --> 02:04:31,710
model took quite a while to fit so I

2656
02:04:29,819 --> 02:04:34,259
kind of like ran it for a while

2657
02:04:31,710 --> 02:04:37,020
noticed it was still under fitting safer

2658
02:04:34,260 --> 02:04:40,710
it was up to ran it a bit more longer

2659
02:04:37,020 --> 02:04:43,230
cycle length saved it again it still was

2660
02:04:40,710 --> 02:04:45,539
kind of under fitting you know run it

2661
02:04:43,229 --> 02:04:47,309
again and kind of finally got to the

2662
02:04:45,539 --> 02:04:49,829
point where it's like kind of honestly I

2663
02:04:47,310 --> 02:04:54,360
kind of ran out of patience so I just

2664
02:04:49,829 --> 02:04:55,829
like saved it at that point and I did

2665
02:04:54,359 --> 02:04:58,049
the same kind of tests that we looked at

2666
02:04:55,829 --> 02:04:59,430
before so I was like oh it wasn't quite

2667
02:04:58,050 --> 02:05:01,440
expecting but I realized it anyway the

2668
02:04:59,430 --> 02:05:03,090
best and the most like okay let's see

2669
02:05:01,439 --> 02:05:05,460
how that goes the best performance with

2670
02:05:03,090 --> 02:05:07,610
one movie were I say okay it looks like

2671
02:05:05,460 --> 02:05:13,470
the language models working pretty well

2672
02:05:07,609 --> 02:05:16,589
so I've pre-trained a language model and

2673
02:05:13,470 --> 02:05:18,600
so now I want to use it fine tune it to

2674
02:05:16,590 --> 02:05:20,400
do classification sentiment

2675
02:05:18,600 --> 02:05:22,320
classification now obviously if I'm

2676
02:05:20,399 --> 02:05:25,049
gonna use a pre trained model I need to

2677
02:05:22,319 --> 02:05:27,599
use exactly the same vocab but the the

2678
02:05:25,050 --> 02:05:29,760
word the still needs to map for the

2679
02:05:27,600 --> 02:05:33,510
number two so that I can look up the

2680
02:05:29,760 --> 02:05:37,829
vector that right so that's why I first

2681
02:05:33,510 --> 02:05:40,409
of all load back up my my field object

2682
02:05:37,829 --> 02:05:42,300
the thing with the vocab in right now in

2683
02:05:40,409 --> 02:05:44,069
this case if I ran it straight

2684
02:05:42,300 --> 02:05:46,260
afterwards this is unnecessary it's

2685
02:05:44,069 --> 02:05:49,799
already in memory but this means I can

2686
02:05:46,260 --> 02:05:55,140
come back to this later right in a new

2687
02:05:49,800 --> 02:05:56,880
session basically I can then go ahead

2688
02:05:55,140 --> 02:05:59,789
and say okay I've never got one more

2689
02:05:56,880 --> 02:06:02,250
field right in addition to my field

2690
02:05:59,789 --> 02:06:04,010
which represents the reviews I've also

2691
02:06:02,250 --> 02:06:08,069
got a field which represents the label

2692
02:06:04,010 --> 02:06:12,239
okay and the details are too important

2693
02:06:08,069 --> 02:06:13,738
here now this time I need to not treat

2694
02:06:12,239 --> 02:06:16,829
the whole thing as one

2695
02:06:13,738 --> 02:06:18,599
big piece of text but every review is

2696
02:06:16,829 --> 02:06:20,909
separate because each one has a

2697
02:06:18,600 --> 02:06:22,680
different sentiment attached to it but

2698
02:06:20,909 --> 02:06:25,829
it so happens that torch text already

2699
02:06:22,680 --> 02:06:29,460
has a data set that does that for IMDB

2700
02:06:25,829 --> 02:06:32,460
so I just used IMDB built into torch

2701
02:06:29,460 --> 02:06:33,989
text so basically once we've done all

2702
02:06:32,460 --> 02:06:36,600
that we end up with something where we

2703
02:06:33,988 --> 02:06:39,559
can like grab for a particular example

2704
02:06:36,600 --> 02:06:41,760
or you can grab its label positive and

2705
02:06:39,560 --> 02:06:45,950
here's some of the text this is another

2706
02:06:41,760 --> 02:06:48,989
great Tom Berenger movie all right so

2707
02:06:45,949 --> 02:06:50,729
this is all not nothing faster I

2708
02:06:48,988 --> 02:06:53,429
specific here we'll come back to it in

2709
02:06:50,729 --> 02:06:55,829
the last lecture but torch text Docs can

2710
02:06:53,430 --> 02:06:57,900
help understand what's going on all you

2711
02:06:55,829 --> 02:07:00,390
need to know is that once you've used

2712
02:06:57,899 --> 02:07:03,569
this special tox torch text thing called

2713
02:07:00,390 --> 02:07:06,539
splits to grab a Spitz object you can

2714
02:07:03,569 --> 02:07:08,729
passed it straight into faster a text

2715
02:07:06,539 --> 02:07:12,269
data from splits and that basically

2716
02:07:08,729 --> 02:07:15,119
converts a torch text object into a fast

2717
02:07:12,270 --> 02:07:17,100
AI object we can train on so as soon as

2718
02:07:15,119 --> 02:07:20,309
you've done that you can just go ahead

2719
02:07:17,100 --> 02:07:23,850
and say get model right and that gets us

2720
02:07:20,310 --> 02:07:26,960
our learner and then we can load into it

2721
02:07:23,850 --> 02:07:29,430
the pre trained model the language model

2722
02:07:26,960 --> 02:07:32,579
right and so we can now take that

2723
02:07:29,430 --> 02:07:34,260
pre-trained language model and use the

2724
02:07:32,579 --> 02:07:37,350
stuff that we're kind of familiar with

2725
02:07:34,260 --> 02:07:39,119
right so we can make sure all that you

2726
02:07:37,350 --> 02:07:42,300
know all its at the last layers frozen

2727
02:07:39,119 --> 02:07:44,309
training a bit unfreeze it train it a

2728
02:07:42,300 --> 02:07:47,430
bit and the nice thing is once you've

2729
02:07:44,310 --> 02:07:49,020
got a pre trained language model it

2730
02:07:47,430 --> 02:07:51,360
actually trains super fast you can see

2731
02:07:49,020 --> 02:07:55,170
here it's like a couple of minutes for

2732
02:07:51,359 --> 02:07:57,210
epoch and it only took me to get my is

2733
02:07:55,170 --> 02:07:59,909
my best one here and he took me like 10

2734
02:07:57,210 --> 02:08:03,000
a box so it's like 20 minutes to train

2735
02:07:59,909 --> 02:08:10,590
this bit it's really fast and I ended up

2736
02:08:03,000 --> 02:08:14,189
with 94.5% so how gone is 94.5% well it

2737
02:08:10,590 --> 02:08:15,600
so happens that actually one of Steven

2738
02:08:14,189 --> 02:08:21,449
verities colleagues James Bradbury

2739
02:08:15,600 --> 02:08:22,810
recently created a paper looking at the

2740
02:08:21,449 --> 02:08:23,920
state at like

2741
02:08:22,810 --> 02:08:25,690
they tried to create a new state of the

2742
02:08:23,920 --> 02:08:28,720
art for a bunch of NLP things and one of

2743
02:08:25,689 --> 02:08:31,329
the things that looked at was IMDB and

2744
02:08:28,720 --> 02:08:36,310
they actually have here a list of the

2745
02:08:31,329 --> 02:08:38,439
current world's best for IMDB and even

2746
02:08:36,310 --> 02:08:40,750
with stuff that is highly specialized

2747
02:08:38,439 --> 02:08:44,500
for sentiment analysis the best anybody

2748
02:08:40,750 --> 02:08:47,979
had previously come up with 94.1 so in

2749
02:08:44,500 --> 02:08:51,850
other words this technique getting 94.5

2750
02:08:47,979 --> 02:08:55,119
it's literally better than anybody has

2751
02:08:51,850 --> 02:08:57,130
created in the world before as far as we

2752
02:08:55,119 --> 02:09:01,149
know or as far as James Bradbury knows

2753
02:08:57,130 --> 02:09:03,190
so so when I say like there are big

2754
02:09:01,149 --> 02:09:05,619
opportunities to use this I mean like

2755
02:09:03,189 --> 02:09:08,229
this is a technique that nobody else

2756
02:09:05,619 --> 02:09:12,069
currently has access to which you know

2757
02:09:08,229 --> 02:09:14,439
you could like you know whatever iBM has

2758
02:09:12,069 --> 02:09:17,369
in what CERN or whatever any big company

2759
02:09:14,439 --> 02:09:19,539
has you know that they're advertising

2760
02:09:17,369 --> 02:09:21,340
unless they have some secret sauce that

2761
02:09:19,539 --> 02:09:23,229
they're not publishing which they don't

2762
02:09:21,340 --> 02:09:24,900
right because people get you know if

2763
02:09:23,229 --> 02:09:27,369
they have a better thing they publish it

2764
02:09:24,899 --> 02:09:29,920
then you now have access to a better

2765
02:09:27,369 --> 02:09:32,199
text classification method then has ever

2766
02:09:29,920 --> 02:09:34,840
existed before so I really hope that you

2767
02:09:32,199 --> 02:09:39,399
know you can try this out and see how

2768
02:09:34,840 --> 02:09:40,630
you go there may be some things it works

2769
02:09:39,399 --> 02:09:42,789
really well on and others that it

2770
02:09:40,630 --> 02:09:46,180
doesn't work as well and I don't know I

2771
02:09:42,789 --> 02:09:50,319
think this kind of sweet spot here that

2772
02:09:46,180 --> 02:09:52,900
we had about 25,000 you know short to

2773
02:09:50,319 --> 02:09:55,029
medium size documents if you don't have

2774
02:09:52,899 --> 02:09:57,549
at least that much text it may be hard

2775
02:09:55,029 --> 02:09:59,529
to train a different language model but

2776
02:09:57,550 --> 02:10:01,659
having said that there's a lot more we

2777
02:09:59,529 --> 02:10:03,309
do here right and we won't be able to do

2778
02:10:01,659 --> 02:10:06,159
it in part 1 of this course but in part

2779
02:10:03,310 --> 02:10:08,680
2 that for example we could start like

2780
02:10:06,159 --> 02:10:11,229
training language models that look at

2781
02:10:08,680 --> 02:10:13,030
like you know lots and lots of medical

2782
02:10:11,229 --> 02:10:15,759
journals and then we could like make a

2783
02:10:13,029 --> 02:10:18,219
downloadable medical language model that

2784
02:10:15,760 --> 02:10:21,670
then anybody could use to like fine tune

2785
02:10:18,220 --> 02:10:23,970
on like a prostate cancer subset of

2786
02:10:21,670 --> 02:10:26,829
medical literature for instance like

2787
02:10:23,970 --> 02:10:28,810
there's so much we could do it's kind of

2788
02:10:26,829 --> 02:10:30,340
exciting and then you know to the next

2789
02:10:28,810 --> 02:10:32,890
point we could also combine this with

2790
02:10:30,340 --> 02:10:36,460
like pre-trained word vectors it's like

2791
02:10:32,890 --> 02:10:39,010
even without trying that hard like

2792
02:10:36,460 --> 02:10:41,500
you know we even without use like we

2793
02:10:39,010 --> 02:10:43,420
could have pre-trained a Wikipedia say

2794
02:10:41,500 --> 02:10:47,170
corpus language model and then

2795
02:10:43,420 --> 02:10:49,869
fine-tuned it into a IMDB language model

2796
02:10:47,170 --> 02:10:51,640
and then fine tune that into an IBM IMDB

2797
02:10:49,869 --> 02:10:54,488
sentiment analysis model and we would

2798
02:10:51,640 --> 02:10:56,560
have got something better than this so

2799
02:10:54,488 --> 02:11:00,669
like this I really think this is the tip

2800
02:10:56,560 --> 02:11:02,920
of the iceberg and I was talking there's

2801
02:11:00,670 --> 02:11:05,770
a really fantastic researcher called

2802
02:11:02,920 --> 02:11:07,989
Sebastian Reuter who is basically the

2803
02:11:05,770 --> 02:11:10,620
only NLP researcher I know who's been

2804
02:11:07,988 --> 02:11:13,179
really really writing a lot about

2805
02:11:10,619 --> 02:11:15,250
pre-training and fine tuning and

2806
02:11:13,180 --> 02:11:17,289
transfer learning and NLP and I was

2807
02:11:15,250 --> 02:11:20,529
asking him like why isn't this happening

2808
02:11:17,289 --> 02:11:23,380
more and his view was it's because there

2809
02:11:20,529 --> 02:11:25,569
isn't the software to make it easy you

2810
02:11:23,380 --> 02:11:29,800
know so I'm actually going to share this

2811
02:11:25,569 --> 02:11:32,559
lecture with with him tomorrow because

2812
02:11:29,800 --> 02:11:34,690
you know it feels like there's you know

2813
02:11:32,560 --> 02:11:36,730
hopefully gonna be a lot of stuff coming

2814
02:11:34,689 --> 02:11:43,029
out now that we're making it really easy

2815
02:11:36,729 --> 02:11:45,869
to do this ok we're kind of out of time

2816
02:11:43,029 --> 02:11:48,670
so what I'll do is I'll quickly look at

2817
02:11:45,869 --> 02:11:50,529
collaborative filtering introduction and

2818
02:11:48,670 --> 02:11:52,060
then we'll finish it next time but

2819
02:11:50,529 --> 02:11:53,649
collaborative filtering there's very

2820
02:11:52,060 --> 02:11:55,900
very little new to learn

2821
02:11:53,649 --> 02:11:59,500
we've basically learned everything we're

2822
02:11:55,899 --> 02:12:02,710
gonna need so collaborative filtering

2823
02:11:59,500 --> 02:12:04,029
will will cover this quite quickly next

2824
02:12:02,710 --> 02:12:06,279
week and then we're going to do a really

2825
02:12:04,029 --> 02:12:09,099
deep dive into collaborative filtering

2826
02:12:06,279 --> 02:12:10,929
next week where we're going to learn

2827
02:12:09,100 --> 02:12:13,150
about like we're actually going to from

2828
02:12:10,930 --> 02:12:15,969
scratch learn how to do mr. plastic

2829
02:12:13,149 --> 02:12:18,099
gradient descent how to create loss

2830
02:12:15,969 --> 02:12:19,689
functions how they work exactly

2831
02:12:18,100 --> 02:12:22,180
and then we'll grow from there and will

2832
02:12:19,689 --> 02:12:25,839
gradually build back up to really deeply

2833
02:12:22,180 --> 02:12:27,340
understand what's going on in the

2834
02:12:25,840 --> 02:12:28,930
structured models and then what's going

2835
02:12:27,340 --> 02:12:30,520
on in confidence and then finally what's

2836
02:12:28,930 --> 02:12:32,079
going on in recurrent neural networks

2837
02:12:30,520 --> 02:12:33,790
and hopefully we'll be able to build

2838
02:12:32,079 --> 02:12:36,399
them all from scratch

2839
02:12:33,789 --> 02:12:38,199
ok so this is kind of a gonna be really

2840
02:12:36,399 --> 02:12:39,729
important this movie lens data set

2841
02:12:38,199 --> 02:12:43,420
because we've got a user to learn a lot

2842
02:12:39,729 --> 02:12:46,779
of like really foundational theory and

2843
02:12:43,420 --> 02:12:49,869
kind of math behind it so the movie lens

2844
02:12:46,779 --> 02:12:50,259
data set this is basically what it looks

2845
02:12:49,869 --> 02:12:52,840
like

2846
02:12:50,260 --> 02:12:56,619
it contains a bunch of ratings it says

2847
02:12:52,840 --> 02:12:58,599
user number one watched movie number 31

2848
02:12:56,618 --> 02:13:02,558
and they gave it a rating of two and a

2849
02:12:58,599 --> 02:13:05,288
half at this particular time and then

2850
02:13:02,559 --> 02:13:06,460
they watched movie 102 nine and they

2851
02:13:05,288 --> 02:13:08,170
gave it a rating of three and they

2852
02:13:06,460 --> 02:13:09,099
watched reading one one's really one one

2853
02:13:08,170 --> 02:13:12,519
seven two and they gave it a rating

2854
02:13:09,099 --> 02:13:13,929
before okay and so forth okay so this is

2855
02:13:12,519 --> 02:13:17,559
the ratings table this is really the

2856
02:13:13,929 --> 02:13:19,480
only one that matters and our goal will

2857
02:13:17,559 --> 02:13:22,599
be for some use that we haven't seen

2858
02:13:19,479 --> 02:13:24,428
before so for some user movie

2859
02:13:22,599 --> 02:13:26,650
combination we haven't seen before we

2860
02:13:24,429 --> 02:13:28,449
have to predict if they'll like it right

2861
02:13:26,649 --> 02:13:30,038
and so this is how recommendation

2862
02:13:28,448 --> 02:13:31,808
systems are built this is how like

2863
02:13:30,038 --> 02:13:33,939
Amazon besides what books to recommend

2864
02:13:31,809 --> 02:13:36,480
how Netflix decides what movies to

2865
02:13:33,939 --> 02:13:39,009
recommend and so forth

2866
02:13:36,479 --> 02:13:41,169
to make it more interesting we'll also

2867
02:13:39,010 --> 02:13:42,760
actually download a list of movies so

2868
02:13:41,170 --> 02:13:44,710
each movie we're actually gonna have the

2869
02:13:42,760 --> 02:13:46,239
title and so for that question earlier

2870
02:13:44,710 --> 02:13:47,828
about like what's actually going to be

2871
02:13:46,238 --> 02:13:49,299
in these embedding matrices how do we

2872
02:13:47,828 --> 02:13:51,698
interpret them we're actually going to

2873
02:13:49,300 --> 02:13:54,880
be able to look and see how that's

2874
02:13:51,698 --> 02:13:57,669
working so basically this is kind of

2875
02:13:54,880 --> 02:14:02,078
like what we're creating this is kind of

2876
02:13:57,670 --> 02:14:03,940
crosstab of users by movies alright and

2877
02:14:02,078 --> 02:14:06,149
so feel free to look ahead during the

2878
02:14:03,939 --> 02:14:09,638
week you'll see basically as per usual

2879
02:14:06,149 --> 02:14:12,578
collaborative data set from CSP model

2880
02:14:09,639 --> 02:14:14,618
data docket learner learn it and we're

2881
02:14:12,578 --> 02:14:16,000
done and don't be surprised to hear when

2882
02:14:14,618 --> 02:14:17,618
we then take that and we can kick the

2883
02:14:16,000 --> 02:14:19,328
benchmarks it seems to be better than

2884
02:14:17,618 --> 02:14:21,788
the benchmarks where you look at so

2885
02:14:19,328 --> 02:14:23,198
that'll basically be it and then next

2886
02:14:21,788 --> 02:14:25,300
week we'll have a deep dive and we'll

2887
02:14:23,198 --> 02:14:27,819
see how to actually build this from

2888
02:14:25,300 --> 02:14:29,039
scratch alright see you next week

2889
02:14:27,819 --> 02:14:32,818
thank you

2890
02:14:29,039 --> 02:14:32,819
[Applause]

