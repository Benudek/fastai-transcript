<p><strong>Lesson 5</strong></p>
<ul>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1s">00:00:01</a> Review of students articles and works<br>
<a href="https://towardsdatascience.com/structured-deep-learning-b8ca4138b848">“Structured Deep Learning” for structured data using Entity Embeddings,</a><br>
<a href="https://towardsdatascience.com/fun-with-small-image-data-sets-part-2-54d683ca8c96">“Fun with small image data-sets (part 2)” with unfreezing layers and downloading images from Google,</a><br>
<a href="https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73">“How do we train neural networks” technical writing with detailed walk-through,</a><br>
“Plant Seedlings Kaggle competition”</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=7m45s">00:07:45</a> Starting the 2nd half of the course: what’s next ?<br>
MovieLens dataset: build an effective collaborative filtering model from scratch</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=12m45s">00:12:15</a> Why a matrix factorization and not a neural net ?<br>
Using Excel solver for Gradient Descent ‘GRG Nonlinear’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=23m15s">00:23:15</a> What are the negative values for ‘movieid’ &amp; ‘userid’, and more student questions</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=26m">00:26:00</a> Collaborative filtering notebook, ‘n_factors=’, ‘CollabFilterDataset.from_csv’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=34m5s">00:34:05</a> Dot Product example in PyTorch, module ‘DotProduct()’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=41m45s">00:41:45</a> Class ‘EmbeddingDot()’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=47m5s">00:47:05</a> Kaiming He Initialization (via DeepGrid),<br>
sticking an underscore ‘_’ in PyTorch, ‘ColumnarModelData.from_data_frame()’, ‘optim.SGD()’</p>
</li>
<li>
<p>Pause</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=58m30s">00:58:30</a> ‘fit()’ in ‘<a href="http://model.py/">model.py</a>’ walk-through</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h30s">01:00:30</a> Improving the MovieLens model in Excel again,<br>
adding a constant for movies and users called “a bias”</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h2m30s">01:02:30</a> Function ‘get_emb(ni, nf)’ and Class ‘EmbeddingDotBias(nn.Module)’, ‘.squeeze()’ for broadcasting in PyTorch</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h6m45s">01:06:45</a> Squeashing the ratings between 1 and 5, with Sigmoid function</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h12m30s">01:12:30</a> What happened in the Netflix prize, looking at ‘column_data.py’ module and ‘get_learner()’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h17m15s">01:17:15</a> Creating a Neural Net version “of all this”, using the ‘movielens_emb’ tab in our Excel file, the “Mini net” section in ‘lesson5-movielens.ipynb’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h33m15s">01:33:15</a> What is happening inside the “Training Loop”, what the optimizer ‘optim.SGD()’ and ‘momentum=’ do, spreadsheet ‘graddesc.xlsm’ basic tab</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h41m15s">01:41:15</a> “You don’t need to learn how to calculate derivates &amp; integrals, but you need to learn how to think about the spatially”, the ‘chain rule’, ‘jacobian’ &amp; ‘hessian’</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h53m45s">01:53:45</a> Spreadsheet ‘Momentum’ tab</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=1h59m5s">01:59:05</a> Spreasheet ‘Adam’ tab</p>
</li>
<li>
<p><a href="https://youtu.be/J99NV9Cr75I?t=2h12m1s">02:12:01</a> Beyond Dropout: ‘Weight-decay’ or L2 regularization<br>
</p>
</li>
</ul>


