<p><strong>Lesson 4</strong></p>
<ul>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=4s">00:00:04</a> More cool guides &amp; posts made by <a href="http://fast.ai/">Fast.ai</a> classmates<br>
"Improving the way we work with learning rate", “Cyclical Learning Rate technique”,<br>
“Exploring Stochastic Gradient Descent with Restarts (SGDR)”, “Transfer Learning using differential learning rates”, “Getting Computers to see better than Humans”</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=3m4s">00:03:04</a> Where we go from here: Lesson 3 -&gt; 4 -&gt; 5<br>
Structured Data Deep Learning, Natural Language Processing (NLP), Recommendation Systems</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=5m4s">00:05:04</a> Dropout discussion with “Dog_Breeds”,<br>
looking at a sequential model’s layers with ‘learn’, Linear activation, ReLu, LogSoftmax</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=18m4s">00:18:04</a> Question: “What kind of ‘p’ to use for Dropout as default”, overfitting, underfitting, ‘xtra_fc=’</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=23m45s">00:23:45</a> Question: “Why monitor the Loss / LogLoss vs Accuracy”</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=25m4s">00:25:04</a> Looking at Structured and Time Series data with Rossmann Kaggle competition, categorical &amp; continuous variables, ‘.astype(‘category’)’</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=35m50s">00:35:50</a> fastai library ‘proc_df()’, ‘yl = np.log(y)’, missing values, ‘train_ratio’, ‘val_idx’. “How (and why) to create a good validation set” post by Rachel</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=39m45s">00:39:45</a> RMSPE: Root Mean Square Percentage Error,<br>
create ModelData object, ‘md = ColumnarModelData.from_data_frame()’</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=45m30s">00:45:30</a> ‘md.get_learner(emb_szs,…)’, embeddings</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=50m40s">00:50:40</a> Dealing with categorical variables<br>
like ‘day-of-week’ (Rossmann cont.), embedding matrices, ‘cat_sz’, ‘emb_szs’, Pinterest, Instacart</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h7m10s">01:07:10</a> Improving Date fields with ‘add_datepart’, and final results &amp; questions on Rossmann, step-by-step summary of Jeremy’s approach</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h20m10s">01:20:10</a> More discussion on using <a href="http://fast.ai/">Fast.ai</a> library for Structured Data.</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h23m30s">01:23:30</a> Intro to Natural Language Processing (NLP)<br>
notebook ‘lang_model-arxiv.ipynb’</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h31m15s">01:31:15</a> Creating a Language Model with IMDB dataset<br>
notebook ‘lesson4-imdb.ipynb’</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h31m34s">01:31:34</a> Question: “So why don’t you think that doing just directly what you want to do doesn’t work better?” (referring to the pre-training of a language model before predicting whether a review is positive or negative)</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h33m09s">01:33:09</a> Question: “Is this similar to the <a href="https://github.com/karpathy/char-rnn">char-rnn</a> by karpathy?”</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h39m30s">01:39:30</a> Tokenize: splitting a sentence into an array of tokens</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=1h43m45s">01:43:45</a> Build a vocabulary ‘TEXT.vocab’ with ‘dill/pickle’; ‘next(iter(md.trn_dl))’</p>
</li>
<li>
<p>The rest of the video covers the ins and outs of the notebook ‘lesson4-imdb’, don’t forget to use ‘J’ and ‘L’ for 10 sec backward/forward on YouTube videos.</p>
</li>
<li>
<p><a href="https://youtu.be/gbceqO8PpBg?t=2h11m30s">02:11:30</a> Intro to Lesson 5: Collaborative Filtering with Movielens<br>
</p>
</li>
</ul>


